{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from dataset import *\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-3\n",
    "batch_size=128\n",
    "num_epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([ToTensor()])\n",
    "train_dataset=ImageDataset(path=\"./fer2013_features/Training\",transform=composed)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "validate_dataset=ImageDataset(path=\"./fer2013_features/PublicTest\",transform=composed)\n",
    "validate_loader=DataLoader(validate_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_dataset=ImageDataset(path=\"./fer2013_features/PrivateTest\",transform=composed)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,drop_rate=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.image_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2))\n",
    "        self.image_fc = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(5*5*256, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.landmark_fc = nn.Sequential(\n",
    "            nn.Linear(2592, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128))\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(256,7))\n",
    "#             nn.Softmax())\n",
    "    def forward(self, image,hog_feature,batch_size):\n",
    "        #image\n",
    "        image_out = self.image_conv(image)\n",
    "#         print(\"after iamge conv : \",image_out.shape)\n",
    "        image_out=image_out.view(batch_size,-1)\n",
    "#         print(\"before image fc : \",image_out.shape)\n",
    "        image_out=self.image_fc(image_out)\n",
    "#         print(\"after image fc : \", image_out.shape)\n",
    "        #hog_feature\n",
    "        hog_out = self.landmark_fc(hog_feature)\n",
    "#         print(\"after hog_fc : \",hog_out.shape)\n",
    "        out = torch.cat((image_out,hog_out),1)\n",
    "#         print(\"total shape : \",out.shape)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(drop_rate=0.5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [100/225], Loss: 1.4938\n",
      "Epoch [1/300], Step [200/225], Loss: 1.1911\n",
      "Epoch [2/300], Step [100/225], Loss: 1.2515\n",
      "Epoch [2/300], Step [200/225], Loss: 1.2251\n",
      "Epoch [3/300], Step [100/225], Loss: 1.0565\n",
      "Epoch [3/300], Step [200/225], Loss: 1.1073\n",
      "Epoch [4/300], Step [100/225], Loss: 0.9575\n",
      "Epoch [4/300], Step [200/225], Loss: 1.0961\n",
      "Epoch [5/300], Step [100/225], Loss: 0.8727\n",
      "Epoch [5/300], Step [200/225], Loss: 0.9639\n",
      "Epoch [6/300], Step [100/225], Loss: 0.7368\n",
      "Epoch [6/300], Step [200/225], Loss: 0.9729\n",
      "Epoch [7/300], Step [100/225], Loss: 0.8446\n",
      "Epoch [7/300], Step [200/225], Loss: 0.8174\n",
      "Epoch [8/300], Step [100/225], Loss: 0.7001\n",
      "Epoch [8/300], Step [200/225], Loss: 0.7862\n",
      "Epoch [9/300], Step [100/225], Loss: 0.7201\n",
      "Epoch [9/300], Step [200/225], Loss: 0.6218\n",
      "Epoch [10/300], Step [100/225], Loss: 0.4454\n",
      "Epoch [10/300], Step [200/225], Loss: 0.4000\n",
      "Epoch [11/300], Step [100/225], Loss: 0.4054\n",
      "Epoch [11/300], Step [200/225], Loss: 0.4094\n",
      "Epoch [12/300], Step [100/225], Loss: 0.5303\n",
      "Epoch [12/300], Step [200/225], Loss: 0.4117\n",
      "Epoch [13/300], Step [100/225], Loss: 0.4856\n",
      "Epoch [13/300], Step [200/225], Loss: 0.4375\n",
      "Epoch [14/300], Step [100/225], Loss: 0.5933\n",
      "Epoch [14/300], Step [200/225], Loss: 0.4031\n",
      "Epoch [15/300], Step [100/225], Loss: 0.4087\n",
      "Epoch [15/300], Step [200/225], Loss: 0.4691\n",
      "Epoch [16/300], Step [100/225], Loss: 0.5544\n",
      "Epoch [16/300], Step [200/225], Loss: 0.4679\n",
      "Epoch [17/300], Step [100/225], Loss: 0.4327\n",
      "Epoch [17/300], Step [200/225], Loss: 0.4123\n",
      "Epoch [18/300], Step [100/225], Loss: 0.5691\n",
      "Epoch [18/300], Step [200/225], Loss: 0.4793\n",
      "Epoch [19/300], Step [100/225], Loss: 0.4812\n",
      "Epoch [19/300], Step [200/225], Loss: 0.3954\n",
      "Epoch [20/300], Step [100/225], Loss: 0.4970\n",
      "Epoch [20/300], Step [200/225], Loss: 0.4963\n",
      "Epoch [21/300], Step [100/225], Loss: 0.4783\n",
      "Epoch [21/300], Step [200/225], Loss: 0.4692\n",
      "Epoch [22/300], Step [100/225], Loss: 0.4849\n",
      "Epoch [22/300], Step [200/225], Loss: 0.5099\n",
      "Epoch [23/300], Step [100/225], Loss: 0.4549\n",
      "Epoch [23/300], Step [200/225], Loss: 0.4978\n",
      "Epoch [24/300], Step [100/225], Loss: 0.4194\n",
      "Epoch [24/300], Step [200/225], Loss: 0.5405\n",
      "Epoch [25/300], Step [100/225], Loss: 0.3695\n",
      "Epoch [25/300], Step [200/225], Loss: 0.5173\n",
      "Epoch [26/300], Step [100/225], Loss: 0.4769\n",
      "Epoch [26/300], Step [200/225], Loss: 0.4959\n",
      "Epoch [27/300], Step [100/225], Loss: 0.5347\n",
      "Epoch [27/300], Step [200/225], Loss: 0.4665\n",
      "Epoch [28/300], Step [100/225], Loss: 0.4409\n",
      "Epoch [28/300], Step [200/225], Loss: 0.4294\n",
      "Epoch [29/300], Step [100/225], Loss: 0.5241\n",
      "Epoch [29/300], Step [200/225], Loss: 0.3977\n",
      "Epoch [30/300], Step [100/225], Loss: 0.5398\n",
      "Epoch [30/300], Step [200/225], Loss: 0.5484\n",
      "Epoch [31/300], Step [100/225], Loss: 0.4892\n",
      "Epoch [31/300], Step [200/225], Loss: 0.5514\n",
      "Epoch [32/300], Step [100/225], Loss: 0.4555\n",
      "Epoch [32/300], Step [200/225], Loss: 0.4221\n",
      "Epoch [33/300], Step [100/225], Loss: 0.4663\n",
      "Epoch [33/300], Step [200/225], Loss: 0.6109\n",
      "Epoch [34/300], Step [100/225], Loss: 0.4236\n",
      "Epoch [34/300], Step [200/225], Loss: 0.4203\n",
      "Epoch [35/300], Step [100/225], Loss: 0.4338\n",
      "Epoch [35/300], Step [200/225], Loss: 0.4847\n",
      "Epoch [36/300], Step [100/225], Loss: 0.5138\n",
      "Epoch [36/300], Step [200/225], Loss: 0.4619\n",
      "Epoch [37/300], Step [100/225], Loss: 0.5962\n",
      "Epoch [37/300], Step [200/225], Loss: 0.5409\n",
      "Epoch [38/300], Step [100/225], Loss: 0.5570\n",
      "Epoch [38/300], Step [200/225], Loss: 0.4229\n",
      "Epoch [39/300], Step [100/225], Loss: 0.4902\n",
      "Epoch [39/300], Step [200/225], Loss: 0.5813\n",
      "Epoch [40/300], Step [100/225], Loss: 0.4658\n",
      "Epoch [40/300], Step [200/225], Loss: 0.5409\n",
      "Epoch [41/300], Step [100/225], Loss: 0.5473\n",
      "Epoch [41/300], Step [200/225], Loss: 0.4529\n",
      "Epoch [42/300], Step [100/225], Loss: 0.5228\n",
      "Epoch [42/300], Step [200/225], Loss: 0.3585\n",
      "Epoch [43/300], Step [100/225], Loss: 0.3899\n",
      "Epoch [43/300], Step [200/225], Loss: 0.5273\n",
      "Epoch [44/300], Step [100/225], Loss: 0.5115\n",
      "Epoch [44/300], Step [200/225], Loss: 0.3899\n",
      "Epoch [45/300], Step [100/225], Loss: 0.4775\n",
      "Epoch [45/300], Step [200/225], Loss: 0.4344\n",
      "Epoch [46/300], Step [100/225], Loss: 0.5548\n",
      "Epoch [46/300], Step [200/225], Loss: 0.5214\n",
      "Epoch [47/300], Step [100/225], Loss: 0.5135\n",
      "Epoch [47/300], Step [200/225], Loss: 0.3589\n",
      "Epoch [48/300], Step [100/225], Loss: 0.3684\n",
      "Epoch [48/300], Step [200/225], Loss: 0.4073\n",
      "Epoch [49/300], Step [100/225], Loss: 0.4331\n",
      "Epoch [49/300], Step [200/225], Loss: 0.5021\n",
      "Epoch [50/300], Step [100/225], Loss: 0.4819\n",
      "Epoch [50/300], Step [200/225], Loss: 0.3834\n",
      "Epoch [51/300], Step [100/225], Loss: 0.5121\n",
      "Epoch [51/300], Step [200/225], Loss: 0.4974\n",
      "Epoch [52/300], Step [100/225], Loss: 0.6198\n",
      "Epoch [52/300], Step [200/225], Loss: 0.4255\n",
      "Epoch [53/300], Step [100/225], Loss: 0.4125\n",
      "Epoch [53/300], Step [200/225], Loss: 0.5341\n",
      "Epoch [54/300], Step [100/225], Loss: 0.4712\n",
      "Epoch [54/300], Step [200/225], Loss: 0.5453\n",
      "Epoch [55/300], Step [100/225], Loss: 0.5506\n",
      "Epoch [55/300], Step [200/225], Loss: 0.4744\n",
      "Epoch [56/300], Step [100/225], Loss: 0.5398\n",
      "Epoch [56/300], Step [200/225], Loss: 0.4836\n",
      "Epoch [57/300], Step [100/225], Loss: 0.4741\n",
      "Epoch [57/300], Step [200/225], Loss: 0.4729\n",
      "Epoch [58/300], Step [100/225], Loss: 0.4406\n",
      "Epoch [58/300], Step [200/225], Loss: 0.5042\n",
      "Epoch [59/300], Step [100/225], Loss: 0.5249\n",
      "Epoch [59/300], Step [200/225], Loss: 0.5141\n",
      "Epoch [60/300], Step [100/225], Loss: 0.4828\n",
      "Epoch [60/300], Step [200/225], Loss: 0.4512\n",
      "Epoch [61/300], Step [100/225], Loss: 0.4172\n",
      "Epoch [61/300], Step [200/225], Loss: 0.4113\n",
      "Epoch [62/300], Step [100/225], Loss: 0.5612\n",
      "Epoch [62/300], Step [200/225], Loss: 0.4890\n",
      "Epoch [63/300], Step [100/225], Loss: 0.4961\n",
      "Epoch [63/300], Step [200/225], Loss: 0.4089\n",
      "Epoch [64/300], Step [100/225], Loss: 0.4486\n",
      "Epoch [64/300], Step [200/225], Loss: 0.4293\n",
      "Epoch [65/300], Step [100/225], Loss: 0.5450\n",
      "Epoch [65/300], Step [200/225], Loss: 0.4816\n",
      "Epoch [66/300], Step [100/225], Loss: 0.4425\n",
      "Epoch [66/300], Step [200/225], Loss: 0.3606\n",
      "Epoch [67/300], Step [100/225], Loss: 0.4581\n",
      "Epoch [67/300], Step [200/225], Loss: 0.3161\n",
      "Epoch [68/300], Step [100/225], Loss: 0.4996\n",
      "Epoch [68/300], Step [200/225], Loss: 0.4067\n",
      "Epoch [69/300], Step [100/225], Loss: 0.5459\n",
      "Epoch [69/300], Step [200/225], Loss: 0.5327\n",
      "Epoch [70/300], Step [100/225], Loss: 0.4640\n",
      "Epoch [70/300], Step [200/225], Loss: 0.4729\n",
      "Epoch [71/300], Step [100/225], Loss: 0.4942\n",
      "Epoch [71/300], Step [200/225], Loss: 0.4811\n",
      "Epoch [72/300], Step [100/225], Loss: 0.4844\n",
      "Epoch [72/300], Step [200/225], Loss: 0.4743\n",
      "Epoch [73/300], Step [100/225], Loss: 0.4836\n",
      "Epoch [73/300], Step [200/225], Loss: 0.4342\n",
      "Epoch [74/300], Step [100/225], Loss: 0.4565\n",
      "Epoch [74/300], Step [200/225], Loss: 0.4750\n",
      "Epoch [75/300], Step [100/225], Loss: 0.4516\n",
      "Epoch [75/300], Step [200/225], Loss: 0.4619\n",
      "Epoch [76/300], Step [100/225], Loss: 0.4347\n",
      "Epoch [76/300], Step [200/225], Loss: 0.3930\n",
      "Epoch [77/300], Step [100/225], Loss: 0.5428\n",
      "Epoch [77/300], Step [200/225], Loss: 0.5075\n",
      "Epoch [78/300], Step [100/225], Loss: 0.4223\n",
      "Epoch [78/300], Step [200/225], Loss: 0.4896\n",
      "Epoch [79/300], Step [100/225], Loss: 0.4044\n",
      "Epoch [79/300], Step [200/225], Loss: 0.5621\n",
      "Epoch [80/300], Step [100/225], Loss: 0.3902\n",
      "Epoch [80/300], Step [200/225], Loss: 0.5132\n",
      "Epoch [81/300], Step [100/225], Loss: 0.3976\n",
      "Epoch [81/300], Step [200/225], Loss: 0.5762\n",
      "Epoch [82/300], Step [100/225], Loss: 0.4505\n",
      "Epoch [82/300], Step [200/225], Loss: 0.5655\n",
      "Epoch [83/300], Step [100/225], Loss: 0.3954\n",
      "Epoch [83/300], Step [200/225], Loss: 0.5313\n",
      "Epoch [84/300], Step [100/225], Loss: 0.3932\n",
      "Epoch [84/300], Step [200/225], Loss: 0.4049\n",
      "Epoch [85/300], Step [100/225], Loss: 0.4736\n",
      "Epoch [85/300], Step [200/225], Loss: 0.3691\n",
      "Epoch [86/300], Step [100/225], Loss: 0.5323\n",
      "Epoch [86/300], Step [200/225], Loss: 0.4878\n",
      "Epoch [87/300], Step [100/225], Loss: 0.4826\n",
      "Epoch [87/300], Step [200/225], Loss: 0.4045\n",
      "Epoch [88/300], Step [100/225], Loss: 0.4878\n",
      "Epoch [88/300], Step [200/225], Loss: 0.4332\n",
      "Epoch [89/300], Step [100/225], Loss: 0.3868\n",
      "Epoch [89/300], Step [200/225], Loss: 0.5111\n",
      "Epoch [90/300], Step [100/225], Loss: 0.4707\n",
      "Epoch [90/300], Step [200/225], Loss: 0.5170\n",
      "Epoch [91/300], Step [100/225], Loss: 0.5060\n",
      "Epoch [91/300], Step [200/225], Loss: 0.4199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/300], Step [100/225], Loss: 0.5246\n",
      "Epoch [92/300], Step [200/225], Loss: 0.4602\n",
      "Epoch [93/300], Step [100/225], Loss: 0.5172\n",
      "Epoch [93/300], Step [200/225], Loss: 0.4343\n",
      "Epoch [94/300], Step [100/225], Loss: 0.5114\n",
      "Epoch [94/300], Step [200/225], Loss: 0.4495\n",
      "Epoch [95/300], Step [100/225], Loss: 0.4204\n",
      "Epoch [95/300], Step [200/225], Loss: 0.5211\n",
      "Epoch [96/300], Step [100/225], Loss: 0.3849\n",
      "Epoch [96/300], Step [200/225], Loss: 0.5491\n",
      "Epoch [97/300], Step [100/225], Loss: 0.4356\n",
      "Epoch [97/300], Step [200/225], Loss: 0.4544\n",
      "Epoch [98/300], Step [100/225], Loss: 0.3631\n",
      "Epoch [98/300], Step [200/225], Loss: 0.5739\n",
      "Epoch [99/300], Step [100/225], Loss: 0.4311\n",
      "Epoch [99/300], Step [200/225], Loss: 0.4177\n",
      "Epoch [100/300], Step [100/225], Loss: 0.4306\n",
      "Epoch [100/300], Step [200/225], Loss: 0.6161\n",
      "Epoch [101/300], Step [100/225], Loss: 0.4586\n",
      "Epoch [101/300], Step [200/225], Loss: 0.4536\n",
      "Epoch [102/300], Step [100/225], Loss: 0.4456\n",
      "Epoch [102/300], Step [200/225], Loss: 0.4626\n",
      "Epoch [103/300], Step [100/225], Loss: 0.5211\n",
      "Epoch [103/300], Step [200/225], Loss: 0.4372\n",
      "Epoch [104/300], Step [100/225], Loss: 0.4631\n",
      "Epoch [104/300], Step [200/225], Loss: 0.4146\n",
      "Epoch [105/300], Step [100/225], Loss: 0.4599\n",
      "Epoch [105/300], Step [200/225], Loss: 0.5858\n",
      "Epoch [106/300], Step [100/225], Loss: 0.5370\n",
      "Epoch [106/300], Step [200/225], Loss: 0.5664\n",
      "Epoch [107/300], Step [100/225], Loss: 0.4750\n",
      "Epoch [107/300], Step [200/225], Loss: 0.3517\n",
      "Epoch [108/300], Step [100/225], Loss: 0.5379\n",
      "Epoch [108/300], Step [200/225], Loss: 0.4907\n",
      "Epoch [109/300], Step [100/225], Loss: 0.4970\n",
      "Epoch [109/300], Step [200/225], Loss: 0.3981\n",
      "Epoch [110/300], Step [100/225], Loss: 0.5161\n",
      "Epoch [110/300], Step [200/225], Loss: 0.4929\n",
      "Epoch [111/300], Step [100/225], Loss: 0.4271\n",
      "Epoch [111/300], Step [200/225], Loss: 0.4846\n",
      "Epoch [112/300], Step [100/225], Loss: 0.4847\n",
      "Epoch [112/300], Step [200/225], Loss: 0.4628\n",
      "Epoch [113/300], Step [100/225], Loss: 0.3747\n",
      "Epoch [113/300], Step [200/225], Loss: 0.4766\n",
      "Epoch [114/300], Step [100/225], Loss: 0.4922\n",
      "Epoch [114/300], Step [200/225], Loss: 0.4888\n",
      "Epoch [115/300], Step [100/225], Loss: 0.4856\n",
      "Epoch [115/300], Step [200/225], Loss: 0.4916\n",
      "Epoch [116/300], Step [100/225], Loss: 0.4888\n",
      "Epoch [116/300], Step [200/225], Loss: 0.4310\n",
      "Epoch [117/300], Step [100/225], Loss: 0.4163\n",
      "Epoch [117/300], Step [200/225], Loss: 0.4728\n",
      "Epoch [118/300], Step [100/225], Loss: 0.5056\n",
      "Epoch [118/300], Step [200/225], Loss: 0.4023\n",
      "Epoch [119/300], Step [100/225], Loss: 0.5206\n",
      "Epoch [119/300], Step [200/225], Loss: 0.4375\n",
      "Epoch [120/300], Step [100/225], Loss: 0.4429\n",
      "Epoch [120/300], Step [200/225], Loss: 0.5401\n",
      "Epoch [121/300], Step [100/225], Loss: 0.4910\n",
      "Epoch [121/300], Step [200/225], Loss: 0.3960\n",
      "Epoch [122/300], Step [100/225], Loss: 0.4700\n",
      "Epoch [122/300], Step [200/225], Loss: 0.5192\n",
      "Epoch [123/300], Step [100/225], Loss: 0.5008\n",
      "Epoch [123/300], Step [200/225], Loss: 0.4927\n",
      "Epoch [124/300], Step [100/225], Loss: 0.4800\n",
      "Epoch [124/300], Step [200/225], Loss: 0.5277\n",
      "Epoch [125/300], Step [100/225], Loss: 0.5023\n",
      "Epoch [125/300], Step [200/225], Loss: 0.4867\n",
      "Epoch [126/300], Step [100/225], Loss: 0.5427\n",
      "Epoch [126/300], Step [200/225], Loss: 0.4596\n",
      "Epoch [127/300], Step [100/225], Loss: 0.4892\n",
      "Epoch [127/300], Step [200/225], Loss: 0.4114\n",
      "Epoch [128/300], Step [100/225], Loss: 0.4662\n",
      "Epoch [128/300], Step [200/225], Loss: 0.4649\n",
      "Epoch [129/300], Step [100/225], Loss: 0.3713\n",
      "Epoch [129/300], Step [200/225], Loss: 0.3953\n",
      "Epoch [130/300], Step [100/225], Loss: 0.3818\n",
      "Epoch [130/300], Step [200/225], Loss: 0.4364\n",
      "Epoch [131/300], Step [100/225], Loss: 0.4683\n",
      "Epoch [131/300], Step [200/225], Loss: 0.4946\n",
      "Epoch [132/300], Step [100/225], Loss: 0.4963\n",
      "Epoch [132/300], Step [200/225], Loss: 0.3950\n",
      "Epoch [133/300], Step [100/225], Loss: 0.4913\n",
      "Epoch [133/300], Step [200/225], Loss: 0.4933\n",
      "Epoch [134/300], Step [100/225], Loss: 0.6067\n",
      "Epoch [134/300], Step [200/225], Loss: 0.3872\n",
      "Epoch [135/300], Step [100/225], Loss: 0.4945\n",
      "Epoch [135/300], Step [200/225], Loss: 0.4651\n",
      "Epoch [136/300], Step [100/225], Loss: 0.4637\n",
      "Epoch [136/300], Step [200/225], Loss: 0.4718\n",
      "Epoch [137/300], Step [100/225], Loss: 0.3890\n",
      "Epoch [137/300], Step [200/225], Loss: 0.4410\n",
      "Epoch [138/300], Step [100/225], Loss: 0.4033\n",
      "Epoch [138/300], Step [200/225], Loss: 0.5855\n",
      "Epoch [139/300], Step [100/225], Loss: 0.4903\n",
      "Epoch [139/300], Step [200/225], Loss: 0.5255\n",
      "Epoch [140/300], Step [100/225], Loss: 0.3894\n",
      "Epoch [140/300], Step [200/225], Loss: 0.4069\n",
      "Epoch [141/300], Step [100/225], Loss: 0.3943\n",
      "Epoch [141/300], Step [200/225], Loss: 0.4810\n",
      "Epoch [142/300], Step [100/225], Loss: 0.4888\n",
      "Epoch [142/300], Step [200/225], Loss: 0.4611\n",
      "Epoch [143/300], Step [100/225], Loss: 0.4564\n",
      "Epoch [143/300], Step [200/225], Loss: 0.5831\n",
      "Epoch [144/300], Step [100/225], Loss: 0.4372\n",
      "Epoch [144/300], Step [200/225], Loss: 0.4797\n",
      "Epoch [145/300], Step [100/225], Loss: 0.4301\n",
      "Epoch [145/300], Step [200/225], Loss: 0.4833\n",
      "Epoch [146/300], Step [100/225], Loss: 0.5186\n",
      "Epoch [146/300], Step [200/225], Loss: 0.4238\n",
      "Epoch [147/300], Step [100/225], Loss: 0.3296\n",
      "Epoch [147/300], Step [200/225], Loss: 0.5413\n",
      "Epoch [148/300], Step [100/225], Loss: 0.4316\n",
      "Epoch [148/300], Step [200/225], Loss: 0.4780\n",
      "Epoch [149/300], Step [100/225], Loss: 0.5364\n",
      "Epoch [149/300], Step [200/225], Loss: 0.4968\n",
      "Epoch [150/300], Step [100/225], Loss: 0.4666\n",
      "Epoch [150/300], Step [200/225], Loss: 0.5124\n",
      "Epoch [151/300], Step [100/225], Loss: 0.6156\n",
      "Epoch [151/300], Step [200/225], Loss: 0.3929\n",
      "Epoch [152/300], Step [100/225], Loss: 0.5524\n",
      "Epoch [152/300], Step [200/225], Loss: 0.5578\n",
      "Epoch [153/300], Step [100/225], Loss: 0.5051\n",
      "Epoch [153/300], Step [200/225], Loss: 0.4611\n",
      "Epoch [154/300], Step [100/225], Loss: 0.5721\n",
      "Epoch [154/300], Step [200/225], Loss: 0.4540\n",
      "Epoch [155/300], Step [100/225], Loss: 0.4463\n",
      "Epoch [155/300], Step [200/225], Loss: 0.5493\n",
      "Epoch [156/300], Step [100/225], Loss: 0.4476\n",
      "Epoch [156/300], Step [200/225], Loss: 0.5253\n",
      "Epoch [157/300], Step [100/225], Loss: 0.6053\n",
      "Epoch [157/300], Step [200/225], Loss: 0.4378\n",
      "Epoch [158/300], Step [100/225], Loss: 0.4093\n",
      "Epoch [158/300], Step [200/225], Loss: 0.4222\n",
      "Epoch [159/300], Step [100/225], Loss: 0.4727\n",
      "Epoch [159/300], Step [200/225], Loss: 0.4864\n",
      "Epoch [160/300], Step [100/225], Loss: 0.4923\n",
      "Epoch [160/300], Step [200/225], Loss: 0.4663\n",
      "Epoch [161/300], Step [100/225], Loss: 0.5217\n",
      "Epoch [161/300], Step [200/225], Loss: 0.4050\n",
      "Epoch [162/300], Step [100/225], Loss: 0.4922\n",
      "Epoch [162/300], Step [200/225], Loss: 0.4150\n",
      "Epoch [163/300], Step [100/225], Loss: 0.4961\n",
      "Epoch [163/300], Step [200/225], Loss: 0.3870\n",
      "Epoch [164/300], Step [100/225], Loss: 0.4255\n",
      "Epoch [164/300], Step [200/225], Loss: 0.4484\n",
      "Epoch [165/300], Step [100/225], Loss: 0.4414\n",
      "Epoch [165/300], Step [200/225], Loss: 0.4917\n",
      "Epoch [166/300], Step [100/225], Loss: 0.4895\n",
      "Epoch [166/300], Step [200/225], Loss: 0.4753\n",
      "Epoch [167/300], Step [100/225], Loss: 0.4542\n",
      "Epoch [167/300], Step [200/225], Loss: 0.4423\n",
      "Epoch [168/300], Step [100/225], Loss: 0.3830\n",
      "Epoch [168/300], Step [200/225], Loss: 0.4870\n",
      "Epoch [169/300], Step [100/225], Loss: 0.4071\n",
      "Epoch [169/300], Step [200/225], Loss: 0.4770\n",
      "Epoch [170/300], Step [100/225], Loss: 0.4716\n",
      "Epoch [170/300], Step [200/225], Loss: 0.5052\n",
      "Epoch [171/300], Step [100/225], Loss: 0.5429\n",
      "Epoch [171/300], Step [200/225], Loss: 0.4673\n",
      "Epoch [172/300], Step [100/225], Loss: 0.4241\n",
      "Epoch [172/300], Step [200/225], Loss: 0.4111\n",
      "Epoch [173/300], Step [100/225], Loss: 0.4024\n",
      "Epoch [173/300], Step [200/225], Loss: 0.5560\n",
      "Epoch [174/300], Step [100/225], Loss: 0.5450\n",
      "Epoch [174/300], Step [200/225], Loss: 0.5372\n",
      "Epoch [175/300], Step [100/225], Loss: 0.4628\n",
      "Epoch [175/300], Step [200/225], Loss: 0.4729\n",
      "Epoch [176/300], Step [100/225], Loss: 0.4750\n",
      "Epoch [176/300], Step [200/225], Loss: 0.4622\n",
      "Epoch [177/300], Step [100/225], Loss: 0.4374\n",
      "Epoch [177/300], Step [200/225], Loss: 0.5497\n",
      "Epoch [178/300], Step [100/225], Loss: 0.5670\n",
      "Epoch [178/300], Step [200/225], Loss: 0.5148\n",
      "Epoch [179/300], Step [100/225], Loss: 0.4767\n",
      "Epoch [179/300], Step [200/225], Loss: 0.4736\n",
      "Epoch [180/300], Step [100/225], Loss: 0.4834\n",
      "Epoch [180/300], Step [200/225], Loss: 0.5489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/300], Step [100/225], Loss: 0.4256\n",
      "Epoch [181/300], Step [200/225], Loss: 0.5204\n",
      "Epoch [182/300], Step [100/225], Loss: 0.3624\n",
      "Epoch [182/300], Step [200/225], Loss: 0.4413\n",
      "Epoch [183/300], Step [100/225], Loss: 0.4616\n",
      "Epoch [183/300], Step [200/225], Loss: 0.3144\n",
      "Epoch [184/300], Step [100/225], Loss: 0.3742\n",
      "Epoch [184/300], Step [200/225], Loss: 0.5571\n",
      "Epoch [185/300], Step [100/225], Loss: 0.4525\n",
      "Epoch [185/300], Step [200/225], Loss: 0.4082\n",
      "Epoch [186/300], Step [100/225], Loss: 0.5049\n",
      "Epoch [186/300], Step [200/225], Loss: 0.4100\n",
      "Epoch [187/300], Step [100/225], Loss: 0.4756\n",
      "Epoch [187/300], Step [200/225], Loss: 0.5198\n",
      "Epoch [188/300], Step [100/225], Loss: 0.5249\n",
      "Epoch [188/300], Step [200/225], Loss: 0.5014\n",
      "Epoch [189/300], Step [100/225], Loss: 0.3749\n",
      "Epoch [189/300], Step [200/225], Loss: 0.5444\n",
      "Epoch [190/300], Step [100/225], Loss: 0.4626\n",
      "Epoch [190/300], Step [200/225], Loss: 0.5231\n",
      "Epoch [191/300], Step [100/225], Loss: 0.4098\n",
      "Epoch [191/300], Step [200/225], Loss: 0.4193\n",
      "Epoch [192/300], Step [100/225], Loss: 0.4268\n",
      "Epoch [192/300], Step [200/225], Loss: 0.4494\n",
      "Epoch [193/300], Step [100/225], Loss: 0.5539\n",
      "Epoch [193/300], Step [200/225], Loss: 0.5675\n",
      "Epoch [194/300], Step [100/225], Loss: 0.4449\n",
      "Epoch [194/300], Step [200/225], Loss: 0.4437\n",
      "Epoch [195/300], Step [100/225], Loss: 0.5417\n",
      "Epoch [195/300], Step [200/225], Loss: 0.5936\n",
      "Epoch [196/300], Step [100/225], Loss: 0.5028\n",
      "Epoch [196/300], Step [200/225], Loss: 0.5863\n",
      "Epoch [197/300], Step [100/225], Loss: 0.4870\n",
      "Epoch [197/300], Step [200/225], Loss: 0.4220\n",
      "Epoch [198/300], Step [100/225], Loss: 0.3876\n",
      "Epoch [198/300], Step [200/225], Loss: 0.5202\n",
      "Epoch [199/300], Step [100/225], Loss: 0.4218\n",
      "Epoch [199/300], Step [200/225], Loss: 0.4349\n",
      "Epoch [200/300], Step [100/225], Loss: 0.4740\n",
      "Epoch [200/300], Step [200/225], Loss: 0.4361\n",
      "Epoch [201/300], Step [100/225], Loss: 0.4507\n",
      "Epoch [201/300], Step [200/225], Loss: 0.5376\n",
      "Epoch [202/300], Step [100/225], Loss: 0.4756\n",
      "Epoch [202/300], Step [200/225], Loss: 0.5167\n",
      "Epoch [203/300], Step [100/225], Loss: 0.4818\n",
      "Epoch [203/300], Step [200/225], Loss: 0.5228\n",
      "Epoch [204/300], Step [100/225], Loss: 0.4689\n",
      "Epoch [204/300], Step [200/225], Loss: 0.5387\n",
      "Epoch [205/300], Step [100/225], Loss: 0.4850\n",
      "Epoch [205/300], Step [200/225], Loss: 0.4581\n",
      "Epoch [206/300], Step [100/225], Loss: 0.4830\n",
      "Epoch [206/300], Step [200/225], Loss: 0.5368\n",
      "Epoch [207/300], Step [100/225], Loss: 0.4005\n",
      "Epoch [207/300], Step [200/225], Loss: 0.4137\n",
      "Epoch [208/300], Step [100/225], Loss: 0.4795\n",
      "Epoch [208/300], Step [200/225], Loss: 0.5974\n",
      "Epoch [209/300], Step [100/225], Loss: 0.5130\n",
      "Epoch [209/300], Step [200/225], Loss: 0.4191\n",
      "Epoch [210/300], Step [100/225], Loss: 0.4547\n",
      "Epoch [210/300], Step [200/225], Loss: 0.4028\n",
      "Epoch [211/300], Step [100/225], Loss: 0.4510\n",
      "Epoch [211/300], Step [200/225], Loss: 0.4065\n",
      "Epoch [212/300], Step [100/225], Loss: 0.3583\n",
      "Epoch [212/300], Step [200/225], Loss: 0.5721\n",
      "Epoch [213/300], Step [100/225], Loss: 0.3724\n",
      "Epoch [213/300], Step [200/225], Loss: 0.4358\n",
      "Epoch [214/300], Step [100/225], Loss: 0.5683\n",
      "Epoch [214/300], Step [200/225], Loss: 0.5611\n",
      "Epoch [215/300], Step [100/225], Loss: 0.4514\n",
      "Epoch [215/300], Step [200/225], Loss: 0.4328\n",
      "Epoch [216/300], Step [100/225], Loss: 0.4699\n",
      "Epoch [216/300], Step [200/225], Loss: 0.4725\n",
      "Epoch [217/300], Step [100/225], Loss: 0.4115\n",
      "Epoch [217/300], Step [200/225], Loss: 0.3787\n",
      "Epoch [218/300], Step [100/225], Loss: 0.4527\n",
      "Epoch [218/300], Step [200/225], Loss: 0.3894\n",
      "Epoch [219/300], Step [100/225], Loss: 0.4830\n",
      "Epoch [219/300], Step [200/225], Loss: 0.4276\n",
      "Epoch [220/300], Step [100/225], Loss: 0.4142\n",
      "Epoch [220/300], Step [200/225], Loss: 0.4786\n",
      "Epoch [221/300], Step [100/225], Loss: 0.4557\n",
      "Epoch [221/300], Step [200/225], Loss: 0.4841\n",
      "Epoch [222/300], Step [100/225], Loss: 0.4925\n",
      "Epoch [222/300], Step [200/225], Loss: 0.4854\n",
      "Epoch [223/300], Step [100/225], Loss: 0.5213\n",
      "Epoch [223/300], Step [200/225], Loss: 0.4377\n",
      "Epoch [224/300], Step [100/225], Loss: 0.3868\n",
      "Epoch [224/300], Step [200/225], Loss: 0.3484\n",
      "Epoch [225/300], Step [100/225], Loss: 0.4181\n",
      "Epoch [225/300], Step [200/225], Loss: 0.4571\n",
      "Epoch [226/300], Step [100/225], Loss: 0.4946\n",
      "Epoch [226/300], Step [200/225], Loss: 0.4552\n",
      "Epoch [227/300], Step [100/225], Loss: 0.4990\n",
      "Epoch [227/300], Step [200/225], Loss: 0.4708\n",
      "Epoch [228/300], Step [100/225], Loss: 0.3988\n",
      "Epoch [228/300], Step [200/225], Loss: 0.4820\n",
      "Epoch [229/300], Step [100/225], Loss: 0.5022\n",
      "Epoch [229/300], Step [200/225], Loss: 0.3614\n",
      "Epoch [230/300], Step [100/225], Loss: 0.3572\n",
      "Epoch [230/300], Step [200/225], Loss: 0.5172\n",
      "Epoch [231/300], Step [100/225], Loss: 0.4702\n",
      "Epoch [231/300], Step [200/225], Loss: 0.5259\n",
      "Epoch [232/300], Step [100/225], Loss: 0.4398\n",
      "Epoch [232/300], Step [200/225], Loss: 0.4286\n",
      "Epoch [233/300], Step [100/225], Loss: 0.4426\n",
      "Epoch [233/300], Step [200/225], Loss: 0.4613\n",
      "Epoch [234/300], Step [100/225], Loss: 0.4915\n",
      "Epoch [234/300], Step [200/225], Loss: 0.5046\n",
      "Epoch [235/300], Step [100/225], Loss: 0.5166\n",
      "Epoch [235/300], Step [200/225], Loss: 0.5253\n",
      "Epoch [236/300], Step [100/225], Loss: 0.4191\n",
      "Epoch [236/300], Step [200/225], Loss: 0.5223\n",
      "Epoch [237/300], Step [100/225], Loss: 0.5290\n",
      "Epoch [237/300], Step [200/225], Loss: 0.4748\n",
      "Epoch [238/300], Step [100/225], Loss: 0.4322\n",
      "Epoch [238/300], Step [200/225], Loss: 0.5073\n",
      "Epoch [239/300], Step [100/225], Loss: 0.4589\n",
      "Epoch [239/300], Step [200/225], Loss: 0.5594\n",
      "Epoch [240/300], Step [100/225], Loss: 0.4985\n",
      "Epoch [240/300], Step [200/225], Loss: 0.4521\n",
      "Epoch [241/300], Step [100/225], Loss: 0.5304\n",
      "Epoch [241/300], Step [200/225], Loss: 0.3467\n",
      "Epoch [242/300], Step [100/225], Loss: 0.4522\n",
      "Epoch [242/300], Step [200/225], Loss: 0.4842\n",
      "Epoch [243/300], Step [100/225], Loss: 0.5905\n",
      "Epoch [243/300], Step [200/225], Loss: 0.4652\n",
      "Epoch [244/300], Step [100/225], Loss: 0.5257\n",
      "Epoch [244/300], Step [200/225], Loss: 0.3998\n",
      "Epoch [245/300], Step [100/225], Loss: 0.3707\n",
      "Epoch [245/300], Step [200/225], Loss: 0.4688\n",
      "Epoch [246/300], Step [100/225], Loss: 0.5221\n",
      "Epoch [246/300], Step [200/225], Loss: 0.4170\n",
      "Epoch [247/300], Step [100/225], Loss: 0.4238\n",
      "Epoch [247/300], Step [200/225], Loss: 0.5530\n",
      "Epoch [248/300], Step [100/225], Loss: 0.5396\n",
      "Epoch [248/300], Step [200/225], Loss: 0.5488\n",
      "Epoch [249/300], Step [100/225], Loss: 0.5837\n",
      "Epoch [249/300], Step [200/225], Loss: 0.4362\n",
      "Epoch [250/300], Step [100/225], Loss: 0.3600\n",
      "Epoch [250/300], Step [200/225], Loss: 0.4024\n",
      "Epoch [251/300], Step [100/225], Loss: 0.4593\n",
      "Epoch [251/300], Step [200/225], Loss: 0.4029\n",
      "Epoch [252/300], Step [100/225], Loss: 0.4300\n",
      "Epoch [252/300], Step [200/225], Loss: 0.3718\n",
      "Epoch [253/300], Step [100/225], Loss: 0.4194\n",
      "Epoch [253/300], Step [200/225], Loss: 0.6371\n",
      "Epoch [254/300], Step [100/225], Loss: 0.4510\n",
      "Epoch [254/300], Step [200/225], Loss: 0.5093\n",
      "Epoch [255/300], Step [100/225], Loss: 0.4786\n",
      "Epoch [255/300], Step [200/225], Loss: 0.3578\n",
      "Epoch [256/300], Step [100/225], Loss: 0.4225\n",
      "Epoch [256/300], Step [200/225], Loss: 0.4428\n",
      "Epoch [257/300], Step [100/225], Loss: 0.4471\n",
      "Epoch [257/300], Step [200/225], Loss: 0.5007\n",
      "Epoch [258/300], Step [100/225], Loss: 0.4589\n",
      "Epoch [258/300], Step [200/225], Loss: 0.5416\n",
      "Epoch [259/300], Step [100/225], Loss: 0.4920\n",
      "Epoch [259/300], Step [200/225], Loss: 0.5776\n",
      "Epoch [260/300], Step [100/225], Loss: 0.4109\n",
      "Epoch [260/300], Step [200/225], Loss: 0.4480\n",
      "Epoch [261/300], Step [100/225], Loss: 0.5002\n",
      "Epoch [261/300], Step [200/225], Loss: 0.4915\n",
      "Epoch [262/300], Step [100/225], Loss: 0.5341\n",
      "Epoch [262/300], Step [200/225], Loss: 0.4883\n",
      "Epoch [263/300], Step [100/225], Loss: 0.5095\n",
      "Epoch [263/300], Step [200/225], Loss: 0.5481\n",
      "Epoch [264/300], Step [100/225], Loss: 0.5093\n",
      "Epoch [264/300], Step [200/225], Loss: 0.3884\n",
      "Epoch [265/300], Step [100/225], Loss: 0.6109\n",
      "Epoch [265/300], Step [200/225], Loss: 0.5276\n",
      "Epoch [266/300], Step [100/225], Loss: 0.4947\n",
      "Epoch [266/300], Step [200/225], Loss: 0.5124\n",
      "Epoch [267/300], Step [100/225], Loss: 0.5707\n",
      "Epoch [267/300], Step [200/225], Loss: 0.3960\n",
      "Epoch [268/300], Step [100/225], Loss: 0.4759\n",
      "Epoch [268/300], Step [200/225], Loss: 0.4267\n",
      "Epoch [269/300], Step [100/225], Loss: 0.4819\n",
      "Epoch [269/300], Step [200/225], Loss: 0.4338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [270/300], Step [100/225], Loss: 0.4783\n",
      "Epoch [270/300], Step [200/225], Loss: 0.5066\n",
      "Epoch [271/300], Step [100/225], Loss: 0.4524\n",
      "Epoch [271/300], Step [200/225], Loss: 0.5323\n",
      "Epoch [272/300], Step [100/225], Loss: 0.4373\n",
      "Epoch [272/300], Step [200/225], Loss: 0.4034\n",
      "Epoch [273/300], Step [100/225], Loss: 0.3608\n",
      "Epoch [273/300], Step [200/225], Loss: 0.4784\n",
      "Epoch [274/300], Step [100/225], Loss: 0.3901\n",
      "Epoch [274/300], Step [200/225], Loss: 0.5306\n",
      "Epoch [275/300], Step [100/225], Loss: 0.4601\n",
      "Epoch [275/300], Step [200/225], Loss: 0.4704\n",
      "Epoch [276/300], Step [100/225], Loss: 0.5104\n",
      "Epoch [276/300], Step [200/225], Loss: 0.5022\n",
      "Epoch [277/300], Step [100/225], Loss: 0.4699\n",
      "Epoch [277/300], Step [200/225], Loss: 0.4836\n",
      "Epoch [278/300], Step [100/225], Loss: 0.4046\n",
      "Epoch [278/300], Step [200/225], Loss: 0.4267\n",
      "Epoch [279/300], Step [100/225], Loss: 0.5263\n",
      "Epoch [279/300], Step [200/225], Loss: 0.3974\n",
      "Epoch [280/300], Step [100/225], Loss: 0.4597\n",
      "Epoch [280/300], Step [200/225], Loss: 0.4908\n",
      "Epoch [281/300], Step [100/225], Loss: 0.4111\n",
      "Epoch [281/300], Step [200/225], Loss: 0.5089\n",
      "Epoch [282/300], Step [100/225], Loss: 0.5029\n",
      "Epoch [282/300], Step [200/225], Loss: 0.5205\n",
      "Epoch [283/300], Step [100/225], Loss: 0.4566\n",
      "Epoch [283/300], Step [200/225], Loss: 0.5012\n",
      "Epoch [284/300], Step [100/225], Loss: 0.3562\n",
      "Epoch [284/300], Step [200/225], Loss: 0.5133\n",
      "Epoch [285/300], Step [100/225], Loss: 0.4575\n",
      "Epoch [285/300], Step [200/225], Loss: 0.5497\n",
      "Epoch [286/300], Step [100/225], Loss: 0.5275\n",
      "Epoch [286/300], Step [200/225], Loss: 0.4023\n",
      "Epoch [287/300], Step [100/225], Loss: 0.4078\n",
      "Epoch [287/300], Step [200/225], Loss: 0.4730\n",
      "Epoch [288/300], Step [100/225], Loss: 0.4044\n",
      "Epoch [288/300], Step [200/225], Loss: 0.4811\n",
      "Epoch [289/300], Step [100/225], Loss: 0.6091\n",
      "Epoch [289/300], Step [200/225], Loss: 0.4725\n",
      "Epoch [290/300], Step [100/225], Loss: 0.5007\n",
      "Epoch [290/300], Step [200/225], Loss: 0.3898\n",
      "Epoch [291/300], Step [100/225], Loss: 0.5122\n",
      "Epoch [291/300], Step [200/225], Loss: 0.4905\n",
      "Epoch [292/300], Step [100/225], Loss: 0.4829\n",
      "Epoch [292/300], Step [200/225], Loss: 0.5162\n",
      "Epoch [293/300], Step [100/225], Loss: 0.4918\n",
      "Epoch [293/300], Step [200/225], Loss: 0.5402\n",
      "Epoch [294/300], Step [100/225], Loss: 0.5282\n",
      "Epoch [294/300], Step [200/225], Loss: 0.4116\n",
      "Epoch [295/300], Step [100/225], Loss: 0.5153\n",
      "Epoch [295/300], Step [200/225], Loss: 0.4013\n",
      "Epoch [296/300], Step [100/225], Loss: 0.5254\n",
      "Epoch [296/300], Step [200/225], Loss: 0.4615\n",
      "Epoch [297/300], Step [100/225], Loss: 0.4046\n",
      "Epoch [297/300], Step [200/225], Loss: 0.4604\n",
      "Epoch [298/300], Step [100/225], Loss: 0.4251\n",
      "Epoch [298/300], Step [200/225], Loss: 0.4979\n",
      "Epoch [299/300], Step [100/225], Loss: 0.4176\n",
      "Epoch [299/300], Step [200/225], Loss: 0.3943\n",
      "Epoch [300/300], Step [100/225], Loss: 0.4921\n",
      "Epoch [300/300], Step [200/225], Loss: 0.5467\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsvXmYJEd1LX4iM2vpvWfp2Wc0WkbLaEWMFlYjVkkG9DM2IIENj4eRzTOGn3k8nrB5QsYGYzDY8AwGgQGDDUICbAQSCMSiBSHBCNAykkYazWhmevat19pyifdH5o2MyKUqq7uqu7o6zvfp03R1dlZkZuSJE+feuME459DQ0NDQ6C4Y890ADQ0NDY3WQ5O7hoaGRhdCk7uGhoZGF0KTu4aGhkYXQpO7hoaGRhdCk7uGhoZGF0KTu4aGhkYXQpO7hoaGRhdCk7uGhoZGF8Kary9evnw537hx43x9vYaGhsaCxIMPPniUcz7S6Lh5I/eNGzdi69at8/X1GhoaGgsSjLHdWY7TtoyGhoZGF0KTu4aGhkYXQpO7hoaGRhdCk7uGhoZGF0KTu4aGhkYXQpO7hoaGRhdCk7uGhoZGF2LBkfv2g5P4+A+349hUdb6boqGhodGxWHDkvuPwFP7vT3bg6FRtvpuioaGh0bFYcORumQwAYLvePLdEQ0NDo3Ox4Mg9F5C74/F5bomGhoZG52LBkbtp+E12Pa3cNTQ0NNKw4Mg9Z5Ato5W7hoaGRhoWHLlbpt9kR5O7hoaGRioWILkHyl3bMhoaGhqpWHDknjO0ctfQ0NBohAVH7qTcHZ0KqaGhoZGKhUfuhk6F1NDQ0GiEhUfuFFDVnruGhoZGKhYeuetUSA0NDY2GWHDkntOpkBoaGhoNseDIXQRUtS2joaGhkYoFR+6UCqltGQ0NDY10LDhyNwPlrmvLaGhoaKRjwZG7DqhqaGhoNEZDcmeMfZExdpgx9mjK79/IGHs4+O8+xtj5rW9mCB1Q1dDQ0GiMLMr9ywAur/P7XQB+h3N+HoC/AXBjC9qVCtNgYEwHVDU0NDTqwWp0AOf8bsbYxjq/v0/68X4A62bfrPrIGYa2ZTQ0NDTqoNWe+1sBfL/F54zBMpmuLaOhoaFRBw2Ve1Ywxi6DT+7Pr3PMtQCuBYANGzbM+Lssg+naMhoaGhp10BLlzhg7D8AXAFzFOT+Wdhzn/EbO+RbO+ZaRkZEZf59lGtpz19DQ0KiDWZM7Y2wDgG8D+CPO+ZOzb1JjWAbT2TIaGhoaddDQlmGMfR3AiwAsZ4yNAvgAgBwAcM4/C+B6AMsAfIYxBgAO53xLuxoM+OmQOqCqoaGhkY4s2TLXNPj9HwP445a1KAMsk2lbRkNDQ6MOFtwKVUDbMhoaGhqNsCDJ3bdltHLX0NDQSMOCJHfTYHB1KqSGhoZGKhYkuVumAVuTu4aGhkYqFiS55wy9QlVDQ0OjHhYkufvlB7Ry19DQ0EjDgiT3nGnA1qmQGhoaGqlYkOSuUyE1NDQ06mNBkrtpGLpwmIaGhkYdLEhyz+mSvxoaGhp1sSDJ3a8KqZW7hoaGRhoWJLnnDIapqoN/vXeXXsykoaGhkYAFSe6WyXBksoq/+d5jeHh0bL6bo6GhodFxWKDkHjZ7suLMY0s0NDQ0OhMLk9wNJv49VdXkrqGhoRHFAiX3sNma3DU0NDTiWJDknjMl5a5tGQ0NDY0YFiS5W6a2ZTQ0NDTqYWGSu7ZlNDQ0NOpiQZJ7Tit3DQ0NjbpYkORuyspde+4aGhoaMSxIctfKXUNDQ6M+FiS56zx3DQ0NjfpYkOTOmE6F1NDQ0KiHBUnupZor/q2Vu4aGhkYcC5Lcy7WQ0Kc1uWtoaGjEsCDJfTpQ7gYDJjW5a2hoaMTQkNwZY19kjB1mjD2a8nvGGPsUY2wHY+xhxtiFrW+milKg3FcOFlFzPNQcvSuThoaGhowsyv3LAC6v8/srAGwK/rsWwL/Mvln18ZoL1wEArjx3NQDggV3HwLnetENDQ0OD0JDcOed3Azhe55CrAHyF+7gfwDBjbHWrGpiEizYuxTMf+V2cuWoAAPBH//pL/Gav3rRDQ0NDg9AKz30tgL3Sz6PBZ22HXECsVHXrHKmhoaGxuNAKcmcJnyV6JIyxaxljWxljW48cOTLrLz537ZD4t+1p311DQ0OD0ApyHwWwXvp5HYD9SQdyzm/knG/hnG8ZGRmZ9ReftmIA3/vz5wMAbB1U1dDQ0BBoBbnfCuBNQdbMpQDGOecHWnDeTMhb/iXYrg6oamhoaBCsRgcwxr4O4EUAljPGRgF8AEAOADjnnwVwO4ArAewAUALwlnY1Ngk5k8hdK3cNDQ0NQkNy55xf0+D3HMCftaxFTYIqRNY0uWtoaGgILMgVqjLyWrlraGhoxLDgyV3YMjqgqjED7B8rY+/x0nw3Q0Oj5Vjw5E657jqgqjETXP+dbXjftx+Z72ZoaLQcDT33Tgcpd+25a8wE01UHJVsvgNPoPix45a6zZTRmA5dzOLrvaHQhFjy5mwaDaTBN7hozAuccrqctvUbYdXQaH7rtMXj6Xi0YLHhyB/x0SO25a8wEHgccTVgN8dMnDuPz9+zCsenafDdFIyO6hNwNXdNdY0bwMir3R/eN4yu/eKbt7elUOEHtJj1DXjjoCnLPm4budBozgufxTH3nP3+zD393+xNz0KLOBM1u9Hu2cNAV5J7T5K4xQ3gcmZS76y1ub95xNbkvNHQHuVvac9eYGTzOM3nu/nGLl9goo6jm6PcsCzjn+PRPd2D/WHne2tAd5G4aOs9dY0bIqshdj8PjWLTZIjQA6vcsG06UbHzsju24Y9vBeWtDV5B73jR0+QGNGYHzbFaDF+zRu1gza7Tn3hxoljefVl5XkHvONBbtS6cxO2TNliFHZrH67kTqWkRlQyf0ly4hd72ISWNmyOq5u4Fyn8vtHDnn+PDtj+Ox/RNz9p1pcLUt0xTcDpjpLfjaMoDOc9eYObJmy5DX7s5h4L5su7jx7p0Y6slh85rBOfveJNgiW2ZxzlyahegvWrnPDnmr81Ih/+OB3XjH137dsvNNVx385X8+gsmK3bJzaoS2DOf1X0JvHpQ7qT6nAwiVsmU67T3rVLia3FsDP899/l8AGX/1n4/iew+3bivZR/aN42sP7MFv94617Jwa2QOl1L3m8mWlWYLbASmYwpbRM+RMIFtGk/sssRg8905QAt2IrIEvbx5UtMhQ6YBnbmvPvSmI/qLJfXZYDHnujib3tiCrcp+PVMhOGtC1LdMcSLl7Dey+dqIryF2uLcM5x7d/PYqq010bMLgdkDfbjRCk3YC0QqKdS8/d/66O8NxpFqFtmUxwOyBe0hXknjMN2MGy6CcOTuLdNz+Eu588Os+tai3cDsib7UbQfe1s5T7/hBoqd93/siC0++bv2XUHuVuh514NlEW5y7ZOo06iF2u1Fjxj4It+vVg9d11+oDmIgKq2ZWYH2XMnEuy26SO9XPPp4XUjMmfLzEOATCj3DlDLNKjpbJls6IR4SVeQu+y5i07YZQqjEzy8bkSoyOv3l6zefCtBz7oTZmut3qxjsmJ3XBG20RMl/NOdTzZc85AFWWeE7URXkLuc5043s1Oi+q3oKICkBLRynxV2HJ7C6ImS+Dlrytp8eu6dUGrYbmE991LNwaUf/jF+MI8VE5Nw52OH8E93PtWSrQTnY6YXRdeQO5VuFd5gh0wfW8XFOhWyNXjvNx/Ch29/XPzsZVRY8zHNtjsozhIq99m3ZariYLrm4sB4ZdbnaiWE9dmC+71gFjExxi5njG1njO1gjF2X8PsNjLGfMsZ+wxh7mDF2Zeubmo6cxQAAp/7l7Xh41F/BOZ+2jKzWW6W0O2FRRDegVHMxXQ2D7VkDpSSe53JG2JGeewuuXxRh65DZNcFrYRB0QVSFZIyZAD4N4AoAmwFcwxjbHDns/QBu5pw/C8DVAD7T6obWQ94ML+NHjx0CML/KXVY3rXq4rVQVixnRzTnC6n3ZPPe5fFk7y3NPnxFzzvFQE2UxxJZ9HTK7JrQy3XihKPeLAezgnO/knNcA3ATgqsgxHACVrRsCsL91TWyMnETuS/ryAEJVUHM8/OlXH8SOw5Nz1h45DbNV2S2d4OF1A9xI/XaeNVtmkXvu9VaofuNXe3HVp3+OnzxxKNO5wiJsndWXKdOuFbe7E2baWch9LYC90s+jwWcybgDwh4yxUQC3A/jzlrQuI2Ry78v7VYxJPR8cr+AH2w5i6zMn5qw9VYncWzVyu1q5twRR5U7/7MzaMp2zKrneTkz7gn1CHx4dn/W55hPUnFYIsk54X7OQO0v4LNriawB8mXO+DsCVAL7KGIudmzF2LWNsK2Ns65EjR5pvbQpyZthEWsRE08f5CEpV7LDTtkp0aeXeGvhBd0/5GcjguZM3P4cqupPSX8M893hblgaz5eMZs0yI8DrOlmmh594Jm3VkIfdRAOuln9chbru8FcDNAMA5/wWAIoDl0RNxzm/knG/hnG8ZGRmZWYsTkLfCy6CaMrVI3ns71c/+sTKePjIlfpZtmVYFVMNsmc56IRYaPI+L8r1y4LsRac8H0XZShlS9PPehnhwA4NhUNnLvVOXutVBtL5TNOn4FYBNj7GTGWB5+wPTWyDF7ALwEABhjZ8En99ZJ8waQbZmqHVHubvuV+3M/8hO85ON3iZ8rbfHcaYrektMtWjgeD71Vrn5eD/MRUBVrNjpgQK9HyHRLjk1XM50r3LJv/gctGWIwbaFy72hy55w7AN4B4A4Aj8PPitnGGPsgY+zVwWH/E8DbGGMPAfg6gP/GW7V6JwMsQ7ZlfGKNkvpcel8KubfMc6f/z/+LvpDhcS7UtzzwNko3nI9FTB2l3OuUH6Bga1blHs6COqsvt3IA74TyA5n2UOWc3w4/UCp/dr3078cAPK+1TcuOUi0k00pEuTtzoNyjaIctowuHtQaOFFCVX7zstWXm0nPvnJK/dp1sGbp3WT33meS5n5iuoZAz0Jtv37bPYRB09udKy5l/zWd+jjc/dyOuuiCak9J6dMUK1aNT4XQwqtzDsgRz91LKAdVW57l3Y/mBg+MV/P6/3IdjU9mm9bOB63FxD+Vb2TjPPThuLj13d+4HlDTUs1KEcm82oNrEvXzzl36Jj92xPfPxM0ErS3wklZLmnOPXe8bw+IG5ScvuCnJ/9QVrcNKyXgAhsVLWjNNmxZvkPskbhbQsW4aUQAeouFbjiYMTeHD3Cew4PNX44FnCk5S7Yst0oOcuNsie59ka57yu5y63L8smOTMpH3xksoqjGW2fmaKVVkoYUJUy54RAmJvBuivIfcVAET941wsBJHjubc6WkVU6oVxrgy3jtk5VdBrmciWm44Weu3wvGyny+QhudornLj+XRuR+ZLLx7CtcM5D9XtoubzsphjO6VgZUpc/meLDuCnIHADMIqlYd1Y5pd7bMWDmuJtqRLdMpL3orsfvYNH7/X+7D8ZJ/D+eiHpDHuXgmPOHFS/27eajz4rqd4bnL96ZeQBUADmcg93AWkP26XM9r+y5QbkQIPnFwAlf9872YqjrNnytRuc9tCmjXkDtlzBCxioBqm0lxvGzHPqtIL0CrsmXmI1uj3fj4D5/Eg7tP4Ifb/GXrc0FicuVQeeBtpMjpts/lkvnQlplfz10mo0bKfbLSmAhJ1TYzmDsub/t9iC5i+tBtj+Oh0XH86pnjqX9zeDK5smXS+yqe5xwN1l1D7obBYDDpJYxE99t1Q8dKcXJvhy3TjYXDSBEVc343bPe0m3MOjycHzhqW/OVxJdZudEI6HaC+O8nKXSb3+PsQhRuZVWeB7XltJ8VwEZP/MwnFnpyZePzuY9O45MM/xq/3xEubJJUfmGtrr2vIHQAsaTFTmArZ3pcyWbm3obZMB1UIbBWI3AuW//K0WxVH86u9Jjz3+SgE1SkBVfr+npyZaI3MVLk3Q+6Oy9tuZ0Qz0iieZhpJFViAo1M1cJ4cZwjLVcTJXSv3GUBezCTKD7Q5W2Y8QblX21BbphuV+3RA7mE+99xMu+kWypOqrNkyc+l/d0ptGXqHevOmQrDlmouvPbBHeW5TWci9yeuibJ12k7voH0H7yhGLN3Z8nZlVUvmBuV4r0VXkLo+wtUhgtV0bSycq9zYsYupGz53Iveq01zojRF+uZjz3+bBIOsVzp+fSkzfheFwQ10+eOIy//M9H8MTBSQwULDCW0ZZpMhVyrmYwUUImezWN3OvV20kqPxAGVLVybxpyjRm64e1WP5QtI1emlAk/Kxk8c3Qa77nloVR10o3ZMmTLiCB4u5VZ5B4qqqojq0J2Rslf6nu9ed8+o+dEz22q6iBnGegvWJjIoNybzRoRm3u0mRSjgXZS7tU0cq+TZl1vFbTOc58BkpV7e18QInL5/CdKYXpk1pzZ+54+hm8+OIoDY8nR90550VuJqZhyb1+n/82ecJEU3UN1hWrn2TId47kHz6VH7JUQlPgI/l+qObAMhoGCFUsbfOLgROwdCHdiynZdzhzZdl6U3GtE7skLs+oJRzELkK59ruM2XUXuOYnc7UgAsm157oHn7vGQyMdKNvoL/ouQlYxrolRxg47UReROAStSgO28tvd+82F84kdPAvCflefxplaozsf9p9kE5/M7qNO71BtkjUTXkJRt1yf3Yk6xZXYdncbl/3QP7nv6mHK+rFsbEuZqkVt04RElRqTbMuntSlpRLrJltHJvHqapBlQ5D1e1tevlkJUKfcWJUg3L+v0NDLJ67qRek1a8AsmLIroFdM3tnHZPVR3h8QOIbbfXOM+9/pR67/ESPvL9J1oa8FZzpOfvudN96iFbJrIhTrnmwjINDBQtJVtmLJjByjNZ+XxZ9zm263jbrUQ0RZZe3TS70IkkbchIUuk6z30WyBnq5dgulxR8ezqGm/ACjpVsLAt2p8n6tWIHqUaee5cId3mqTgqpndPuiu0q3qnrcaWee3bPPfm4nzxxGJ+96+lMKzSj2HF4MtG+S9oxaj5A5NojlLvaV8s1X7n3F1VbRrZGD45XsPG623D7IwckBZvRlnHnhhTl3HT5fldTBFc9sk7a1Wmu947tKnKP5qPartf2fSjlB+t5fkevOh6W9Rf8782o3KNqKIpuU+5ymWZ6edrZ6Su2FyN3dSembLZMWj8iXzZL4SwZTxycwEs/cTc+87OnU78zS/vaCerjxYDcRfmAwDMv2S4sk2yZkNxtyVt/eHQMAPDtX482bU/MVXVM+RnL9lKa4KqX2hjuvxC3ZebqHe5qcq85Xtv9uqhypyloqNyz2jL1I/OdsFrxC/fsxF/95yMtOdeYlFEULfbWanDOUXVchXidqHKvc1/lZ5imNmsNbLU0HA8qHd7zVHzjMlk4zGeuO5FXT15dSUzxIc4ByyBbJnyu9DyrricyT3rylhK/kAfYG27dlrjUP7Rl2nsP5Brs8srzNMFVr26VXEWUc/Xdnatn2b7K9/MAORUS8G++XSddqRWQR23PC/1F4blnDqjWV+6dkAp5746jyl6xs8GY5MMSIbbLlrFdn8irkTr7SZZaEtTAa/Jx9NyaVe7kYyet7MzavnZD5Lnn1FRImWx95a567uI4x8N01b8vfXlTjXW4HHmLwfM4vnzfM+grmLho49LE7293toy8UHA8QXxEIQRXki2j5LcDJtMB1VkhqtyrTvttmegLSCP+0j7flsm6eKqa0ZaZz+n5ZMVBudaajim/PJQt0y5lVkmYFbmRbJl6asrNYN80Coinnjs430TC4p+kpevzASfiuSdtuUepkFXHi6Uh266HUs0n/Z68qdxPkarM4+eMfn+7veowFVLtn40EV9l2ccOt25RNg5IG5jBLSHvuTUNeSASoyr1dN1R5ATkXyn15oNyzknsj5ZdUiKgZfOyOJ7C1TnW7LJgo2yjXmi9/moQT0+HL0+6VmBU77of702UoP6dBblbaIFCdoXInddtQuc+nLUOee54893jw37dlcgDCVaoyyVPOeG9MuaviK7F2zQwKjc0EchB0LAO5U5ufPDSJL9/3DH6+46j4XVKara4tMwvEPHfXa3sqpDL98sK892WBcs/aH9OU+84jU/jdT90jihPNdJD6l589je8/enBGf0uYrDgo2W7mhVl3PXkEr/7nexOn0/vHyrHP2tXpq5HduQCfoLIociDbjk3hqs3mCIjILInc5cFuXgOqwXdTnnvNSVDugS0DhOnBYVYNRykYYIuWSu61yPuZFLyk+9DufH+xcbrHFRGTFgej66PkALn/yu383996BI+MjmtbZjaIee4OR72FBq2A/KB8W8ZX7kv7ms1zTw6o/sMPt2Pb/gnsC8hwJp3bcT14XM1QIZyYrokpcyNMVmxwnt7Zo3hkdAwPj44nbnawb6yMghVPXW0HSLlHlbpiy9SZNSg2Qos9d9tJFx9qpsX8ee7Ux8NsmXjeuWkwsXCPBqqapLhLQR/wIgQdnVknqWS5X9B3jpVqmerYNAM5CErt6MmZqDkedh6Zwov/4WeJ1ktZLMLzYucCgO8+tB93P3Vkzq3VriL3uHJ3pWlf+/Pc/YCqjb68KWqUZ8+WSVbuTx+eTv2+rIjWApHxpi/+Eh/9QeONhx3Xw3QwOCQNEkkoS7VHovuj7hsri31vCe1SNEmDUSwVss7AklSTO+07mlfu6ccnLYCZD0QXMQlFLt3XnGkIcqfFYjRw2Y6HyeAzx/MidlPUlklQ7m78PlzwwR/hkg//eLaXpkBYn5yL5zlQtFB1PXzurp3YeXQadz52KDaLFgXGUpQ7AFRtVyv32cAKFjGR915zeNsXQDgeB40pFFAd7s2LgSYrGactYtoRyU6ZEbk7NH2MK+gD42UcHE+uZyNDVt/lhEEiCRR8/eaDo7jik3crQap9J8pYO9yjlGlut+cuw8+WUX9Ownd+uw/v/ebD4ue0flSbYZ67/Lyj9lWnee49KeUHAF9Y0X4K0Q2wa66HibIj/jYpoFqvwqI8W5LvUVaRkRWyN66Qux2mcu46No2LPnQnth+cFPdFlM+Q2ha9jIoT2oDac58BiCiK0kq62WbL/McDu/Gz7YdTf+96XGw24XGOiYqNgaIFgwXk3mxAVSIi2/Vi7Z5JCeGQ3OMvw3TVVTYXSQO9nAAyB1Xphdg/VobtckxVHRwYL+NvvvcYdh2dxtolPcpsq322TJKPG7Vlkr/75zuO4oePHZKOq2/LzNRzB/xZn9LGBMU6HyByLUayZaqKcmehqJJSIAG/H1M2kBPp0+Tf1ytJ4Ci2TPvugxxQpWvrL1iouZ4gcHoPDk1UhBsgbBl5QWPkPa3arrThjlbuTYNqy4h8XGf2ee6fu2snbt66N/X3jsdRCCwY1/M3KxgoWoK0sgYfRbaFNOQn5ZTPZNSnc5cj5O56HGXbjX2eBDlVL6tiqkZeiKrt4t/v341/vXcXyraLtcO9SpykXXnMaco9i+dejpB1o1TIZpT7RMVWlOrxabUGi1p+YP489zRbRlXuhniW0eyWmsMxEczanMj6gug2mLWE/u0qgWWvbRvW0Nf4cSUXectAIWeiarvSbDUchOK2jJpqK6MqKXfb5Zl5YTboKnKnqpBy3enZ7sRUk/J2k+B6HHkxHfUwWbUxUMyFyj3jOymm9RKZ7D0ezyiZyaYjYWlWlXiowyaRH+HJQ5N4dN+4ks3RrOdOA0PN9bBqsCh+v2a4qCj3dqnTpJnJ8emaIBzTYKmDZnTgS7dlmlPuv9x1HOfd8EP8SJoVHJtW69I4Hhez0UaD+t/d/nhdETIb2DFbxlM+B/x3zzKprWGWDB1P/SfmuXsefvTYIVGTp5bwrOTvcVyOqRal40Yhz/JrjoeCZaBgGai5nngvSxKRU38NF+HVUe6Olyl200p0FbmbgefeH6RklWvurJV7zfXqZoc4rieUu+f5mQIDRQtUw6zZqpA1xVNMSo+buS0T9cpLYrOM9Ot7+T/ejVf+33sV5Z6k9HcdncZ3frtP+SxK7lXbU17UlYNFZW1C2wKqCdf3rpt+g/8VeOk5k6X2j+jA1ygVMqty/8avfCLefnBSfBZV7r7lp/rYabj90QO4+8l4CYNWgMi6N6/WlommQlLMqxZR9rbrhcrdVZX7RMXBtV/dim/8ak9wbPw65RmM7XqJW1u2AnI9mGpA7nnTQM3xhECgYLFc2iR6vUCc3Cu2O+cB8kzkzhi7nDG2nTG2gzF2Xcoxr2OMPcYY28YY+1prm5kNRBQDBX8xRanmzDrPveZ4qVXh6Lyycp+qOOgvWDAD5V5vCnn3k0dw+T/d7X9HQrZMkkKeTUA1SsqU/ZIlQCor96Tj/+2+Z/Dumx9S2kffR4HUquOJF+ElZ67A+euG58ZzTyDcEyVbXFPONFJXP8rknjeNVPtG5NJnVO4P7vYXlBFhAvHn7bgchUAt7zo6XXeGFSXNZjFddbAzpbSELchd3awjasvkI7ZMOJtxRbaM7XKF2CYrDjiHKE+QGFCNxB6StrZsBYiQPc5RtT0ULBOFnIGqEy7ConZWHTdmldmKjZag3BMCye1EQ3JnjJkAPg3gCgCbAVzDGNscOWYTgPcBeB7n/GwA/38b2toQRBS0mKJUC0fLGdsyrldXjTkeR14KqPrKPZcpW2bb/gk8cXAS42VbypNuA7lLO+bIIBWSjdzre+6HJytwPa6oz2gQquq44jo/90fPRk/eFGoPaKfnXv+8BctM/W753uQtQ5l6H56s4NaH9gNoTrlXHRfPHCsBgFJjPmr/uR5HMVDu7/+vR/Gum36Tek5bIvdbtu7FD5pcsPbZu57Giz9+F/70qw8mnhuASO+13bhyz5mSLRPJfDleklcjq/YEbahdrbMxhhpQDWcBrYYsBGtusnKnd0j23EXbpJ2lot3JHwzmNvspi3K/GMAOzvlOznkNwE0Arooc8zYAn+acnwAAznl6ekkbQQGdfoncQ1umeeLgnCuqOgny1LlUc1FzvcCWCZR7HVsm3KPRlTp3SA6UlcKk9P1ZKfeoLROQdCXFQ5eDPo2yZSj39/BkmFZJ3ycvR686rpI2Z5kzV+6ex/HGL9yPnz5Rv7vVU7yAT1ppSkq+ZwXLUF7oW7aO4p1f/w1KNacpz/2x/RPi33KKabSfOZ6Y43O3AAAgAElEQVQnlDsA3PvUUaRB9rL/9d5d+I8Hdjdshwx6fj96/FAs2Ge7HiyDIR/086rjYtfRacVCNCXP3Y7YFUelGveOp6ZCTlX9vkH3rd4KVTp3Uh2eVoAercs5qrYfUM1bPrlTWq+8NWSUoNMWMQH+jE7uO402h2kFspD7WgBypGY0+EzG6QBOZ4z9nDF2P2Ps8lY1sBmQWqZASNl2pd1SmidF6qRp5M45D5S7fxup9MBAMbRl6pFxRQQ0w6Bt1JYxg4JMhJmkUYU1PrhCYtMBSaelQk5KxDNZsUU+f5JyD8k9fJHphaVbQEWl8lKGjDmLPPeJio2f7ziGB3efqHtctQG5FywjdWCRB768ZUT8Yv95+zX8s+e57zleEv9O2tyCIAsHABjsyaWe05HsjkZWYhLk2FR0gLJdDznTELOsHzx6EC/9xF0YPREG/HOmITbLiQZc5Qqg0VTIqHKX++d133oY331ofySg6rXNlpHrN5HnXrBMX3zZ6gI+OaBKkNuZaMt0oHJnCZ9FW2YB2ATgRQCuAfAFxthw7ESMXcsY28oY23rkSOuDP5RZYBoMvXnT99ylhQnNQky1U8iBzkkvIBUbklMh630t+XilmqMQIKFUc9GbM0V+MZB9ZycZaVZPSficPFG5npAslsmKIzYgqUfuRyZCco/OFMiWyUuElVNsmeaeEb3kSeUNZFQalEsoWGZqRpT8t5Q5QQiJKZzdZVHuMil6XMruiil3rjx7shuTYLuhp1t1vMwLzQjyoDRZVcnTdrmSx75/rBJ7n0yDIWdFPffAp5b6C8UGaDY6GdkkXb4H33v4AH6+46gy67bd9nnu8h6qfraMGSp3Ox5QjXnuDQKqSi2jDiH3UQDrpZ/XAdifcMx3OOc253wXgO3wyV4B5/xGzvkWzvmWkZGRmbY5FTQttAwDvXkrsGVmrtyTfPD9Y2Ucmqgo56RFTOOBQhko5ETnzWLLKDWwpe8q11z05E2RjeN/5wyUu6uekyB78EnWheyfT1ZtDPXkULCM2LHTVUe8wLItE7V7qrYfUJXJXQmoSteWRQHTTKkRuTdS7km2zOGJCrYfnFTuV1/BCl5q/5lOi2wjV+orjdu993gJy/vzQowULAOWwWJ/G1XuVHUxCbYb2gRVx50BuccHLfncOdMAYwyWwYSVIiNnMHE99TbXsIM8d0qrpO9KKvtMWyOqAVVVubcy510tPxDaMhXJX6d+XnO8WBBeXaGakOfegbbMrwBsYoydzBjLA7gawK2RY/4LwGUAwBhbDt+m2dnKhmYBpUKSci/XXNHhZ+NVyx3/Pbc8hP/zX48q5yTybdaWEamCysYAHg5NVPC/bnkIJ0o19OZNxcbwePaFUdHrAFRClxV4EhnIGxtXbQ/FnBHMiNRjj0hWjGzLRM9J+cIyYSmpkEFAat9YGed84A6xNVsaaKY03Ui5ZwioRsn9Y3dsx9u+slW5hjBQ73/flJRK2oxy33uihHVLesV9yJmhtyvDXyDXWLl7nr8ZCSnDqu1lWpgmQ/7u6GDpuFzEsyyTJV5jvUVMhGLOgBvEBmhGMhVR7vKqVsfjfgphJM9djv+kbYE3E0Rry5C9m7RVXs3xYpt01LdlOjCgyjl3ALwDwB0AHgdwM+d8G2Psg4yxVweH3QHgGGPsMQA/BfC/OOfH2tXoNNAiJkvYMq6yMKFZUhTbhEmK6vh0LVxKTeRuqrZMv2TL1PXca2oeOOB3mru2H8EtD47it3vH0JO3xEtDJN/sQKXMBiSympbLmia8sMemQnK3PQ7LMNCTSyB3qVLe4cCWsRM8yartoVpHudOzOhCUK9h9rIR6IC+3sS3TwHPPxT33gxOVWFnifpFiq864lPuYQbmPnihj/dJeQdw50yeR8bKNl33iLvxyl58mGVXueTP5dbWlPu63wWsYRI5CbneScqdZcbTyKsEyGUyDgbHkwmIAMFjMiVRIygKaqqrKnVZoh/EoF7E894gYSkO55irWYj1EFxjVHH/9itxXZVSTsmUitoz8vGLKvRNSIQGAc3475/x0zvmpnPMPBZ9dzzm/Nfg355y/m3O+mXN+Luf8pnY2Og1UfsA0GHoC5V5vNG0EoSakNLOKHV8YFQ2oDhZzYMzv6GTLfPeh/fjDLzygnD/RlnE9YfscmaqiN2+G5J5xQUsUagZO3HOX2yJDVu624yFnBvfVVl9+Uu5L+/LClkk6n/DcpU5vSf+m+0rKsJH6HM+s3BvYMpYZU4DHpmqx+0zKmb6PiGlC2VWq/kvrehz7x8pYv6RHEDdN//eNlfHU4Sk8um8cgE8AsueeRgjyPsFekMbXPLl7Yt/fycj9tKW1HKnkboTkn1RYDPDvnxPEBvqCJAF6Z6qSYuecS6uno7YMz7RLEgD8/Q+ewOtv/EW9y1bOSyDlnjcNYblG4adCpnvurseVWWnFjij3TlnEtFBAwTlfuVuYlhYxATMhRS/277It+/j+/+klHS8HnntAAiYLVz4+sOsY7t1xVF3pGbFlevN+HYtDAUHyINhG6pbIvdkSBOqq12TlnkSkx4PdkvKWv3gnZ4axDBlE7mevGRS2TBK5UOBRthqUqpAR1TbdYJk5rVScrtYnsoa2TOC5yzO7aCkAQF0/AUjkXpGVZP22HJyowHZ5xJbx0wyjg1VUuadZEPImE1WpnzYzU605ntiDIKbcHU+KZyXlV4SDdM5gUvmBiHLvycHxfOXemzdhsFBAyDX3/+GH28WuRlXHVd7hqHKvZ8scHK/gyUNTdQf/g+MVfPvXo7ENWeSAahJqCUX91F3ZoPxtVOm3ez9YoMvI3RTZMkao3KXI/GxIkV5aOW0xTbmTKjEMJnxQqvgnl9ctC1vG73xUge6QlHHSkzOFAsi6FD12HQ2yZYBkpX08IDjX47BdDssM76uMw5MVmAbDmasGcHiiiortopKw16pfp8cVNhYQUe40OxILRuoT5VjWbJkMqZDyLj+cc8WSIkSV+7RQ7v7/DZY8kHDO8cjoOBzXwwe/uw0AcMaqAaEKc4FCpEGCrseJkHtaeiPZMo7HRT/1eHN+dNXxxKbu0ftJAVVqaxKoj1pmGJyWF/UAfkDYcf3ZhRkIMLJNZHvl0z99Gt960C9lUbGjpMiVuFE95U59ut6m7m/58q/w7psfUmaprue/74WcofRVGXL5AYJiy0gp0kBQjEyp+KqVe1MQ6sJk6A28Ycf1WkKK1STl7qrZMidKdkDG/vcZLNz9hzrxAYncxQrOShiIrToeDk+Ex/RKqziFcm/iOh7cfVwJeMqWynTDbBm/XT65e8hRoDpy7M4j01i3pAcv2DSCmuvhp08cTrFlvFgqZLJyz2bLZM6WaZAKWYzUKZ8oO4l9Jc1zp5lXf8GKZeY4rodbto7iVf98L/7+B0/gjm2H8O6XnY4LNwyLQHzO9FdCjkeuRw48Ao2Vu+upC+6SBtg0VB1XpLrGyN3jErknK3dTtmW8uC1jGv47SYutyDql7JOo7qIdjyqO6rk7nt+Hwj0bGpP7U4fSyZ2+R7ZGZVuGB1nfOZNhZKAgjol66P71quo/OhDKYmUuyv52F7lHsmWmq37+OL0grusrm43X3YYv3FM/mceTVBDgqyaarkW3BstLtoyc0SDbMpRWeHA8DNJFPfeBYi7IlpGUe94Sg1ZYwyYbudccD1ffeD/+7RfhakVFuddc8ZIkkTvZTNRWy2SJAdVH94/jnLVDeN5py7FioIBv/XpfuufuppO7x2kRTTblTu2brjp1LYgsyh0IieJogiUDqCuf5ZXL4eCcU/Lif7PnBDZffwfu3+nnFjwQBEpfetZKMMZCzz3IlpmUZgSc87gtk0Jk8ibTsrpvJh2yansYKFjIm0ac3CUytSKERSmNOWmjnCRbpjdnwjKZyHOndzQN9L5UbV8hUzexXf8dpF2f6pE7PfenDqeTO5VUkK0eOaC6efUQlvTm8I0/eY74Trq2aDqjbLV4nMcsnZL0PDoiW2YhwZKyZXrylnhZilZYzY7UzMfuqL+13B989j7lGLlEQHTrPnqItsuVDmAYIbnTtG//WAWlmoNH942Htoy0+KnmeEqueJLnnjUwPFaqiYGIrClZDU9XHbGRdxIRyGqmUnORS7Blxks29h4v45w1QzANhivPXY27njycWNGy6sRTIa2IErSlKpzRwG38+sKspXrqvGK7qZkmQDjzIjKKVmckDJItU3MUH5dsmcGeHGpO6N3TEn0iDlqGTwKAvtcKPHcan6aqYfCtJ2fiDZdswKrBYuo1ygv1ZEHSDLlTLZX+ohXz3CneAsRtmb6Cfw3UR4nAAZV4e4LEADvYmNw0mBgYkiDI3fETGORyw1XHEwNtzU2/RuqnOw5Pph4jZt3SM6dMr4Jl4tx1Q/jN9S/HhRuWKLOWaiRA6rdFVe7RPleS+kzHZMssFFhStkyfpAqKuZAUaTrUaKq+53gZTxwIO4VcGS66MEomKzlYaBoMHvdTME9Mh577V3+xG6/5zH1SQC4gh2CRitxnenKhLVNoktzlnX2ohEE5otwpiFZOmMJHt9bzA6qqLbNtv5/Zcc7aQQDA8v48bJcrAwOBqkKqyl3tgo6k3BsFSscktZUWNLNdL3G/VhkFMTj79+DYVIpyD+5hqeoo94ZWdBL5U98iy4HqDFHKaEjuIWHKfWi6GtpClmngw793Lp6/aXmqShUFr7g6yDWTMVO1/UB3f8GKKfdaEG/x26oOxhRfEqmSRriKVyYw315kokyCaRjibxOvSWSn+VkptFGII5S7/67UTYXMoNyjq8v973SV3xHkga3mJtSWkbNlEpS7slJXZ8s0B1NR7jK5h7u2Z72pjufFAqphoa9kz93/t5TDHdgy00FBMQA4MFHBnuMl1FxPkPik5LlH4SseCqj63/PX392m7MIOJOfxy0GivoKFnMmUqeF0zRFBNJkIbnv4AH647WCM3CkLSVbljwbkfvaaIQDh7ELMRqQXuGrHa8vQbCssF+vF6nikYbxsi++brroYL9kxRbT72DRsl+Os1YOp5ylGNqE4mhBMBcIVotM1V7k3snKn6/Tb5H9OC9poFkWDhOy5K+Rec0RbLGnWlpaJI1Jz3Zkr96rjz276C1ZsYLYdD/mUPHcqAxzuXxxWzpQ9aLIXKV3TZKhryxBoEZN4Rp6/VoLelSy2zJ7jpdSBjs4r14infhclZ4XcE1IhlXTKBOUuCyut3JsE3XwzKD9AIDVNgcF6ODBexlTVESvlCFXbE4E+2eMEVEKXO4QRKHd5yndwvKys4gTUgBxheRDckm0Zqt1xx7ZD+Itv/Db8+4qN8//6h7g7UjVQLtiUt/wFSGURwPIzQmhnJJkIbrz7aXz+np2YqjgYCgirYnt+tkzORMUOiyDtOlrCsr68mAHQM6DZyFBvuGTet7Y8pZwCKT65nGwlgy3DOcd4ycba4R4APtGf/8Ef4rpvPaIc92QQTNu8Jp3cC7mocvfvWzTrr5gzYBoMpZqq3Mlzp5mXyPYJjpGztHrzplDBNFjnLab0m6mKIyyn4eD+5U2jji0jZctInnul5mKiYjesxeIEQoNsmTsfP4SXfuIuMTjJtkw0FbK/EFpL9H9qT831xAyaEgOcwPIwgwVxjUAzOTqWlPtABs+9VHOxeqgIztMzZqjfjUXiS4Aq2gB1EVlSyV+5LR6PD4RyAoP23JuErNxlVUCr4RyPN7ypr/3sL/Dpn+6IpSpVpYUhaQFVIFm5k4Jet6QHB8YqMXKn2IBMeltOWgIAyiImeUZ8z1NHBRkdnqhgKmGzBdmWyYscdf+7jk7VMF62cdbqQTAWLrKgXOlDE1U4HscSiZzzZjgjkndZGpKqFUaV+7D097RlYd6UrSv/eHl2FQ2oOq6HG27dhn3SitFKUKdm9ZA/OD28zy9V8L2H1bJH2w9OgjHgjJUDSEMYUOX4/N078Y93PgkgXoXRYBSodxVfOnqtYmOHhM1Q5NmZUn5AIoKpqiMsnOVBhkYhFy9PQKD+6HGurMbdeXQa593wQ/zJV7emXjsQzkQLOUOQ5o7DU/jyfc+I81upnjsp9zDgWgv2CLVdD73B7/1BjUmpkNmUO+DfD+pXdC9Dzz35ntBCqHPXDonrSQIR+Jj0rtDzi9kyVvgCJue5q4uYosq/rLNlZg65KmSSLSN77kByjZZDExUcn6rFOs3uo9OCXFyPi/+AiOcujfYG80dwCg6dt24Ik1UHOw6pAR5qxrPW+4T+pbdchHVLfEXak7fEdUVb++WfPwMg9KajvvOJqHKX6sKQkjltRb9Q9Nd+ZSs+cOs2VGxXLL0f7s2Lc1iB5w6o6YADEgnSy09qUSb+pFRIspzE5stO6LmXRVun8eX7nsFd28NKouRzrwrI/f6dfiYK3TfCU4cnsWFpryADMyrHodoydwVb1b1g03KhxAl+LMdCueYqqzhpljLcQ7aNmgcvq3y5+JfquYf9ZrrqiODr8iDgXQiUe1Kflctay8r9/UENJLo3Udy/8xi+9sAeQe550xD3x2DAjXfvhON6QZ472TIRz51smcgiJsfj4BxCuVOKsO35doZlGOjJp3vuMqZrDizTQM5k4p42ypbx75U/YzMNlpoOSdcje+6ZbZk6tWU8zpV9GOg6ko5tF7qL3KXiRrIqIMuAFuMQJsp+ytk1N96P7/x2n4jMJ9UiueG7j+G6bz0sfvYj6mq2DKCqb8Ng8CTlvuWkpQDUwAohbxl46eaVePJvr8BlZ6wQpEgpZICaC/yKs1fi777/OB4ZHQ8X1UTOK6uRQsSWISVD5F4JNmB45ti0sppOVt6UCgnIuyzZIpBI3wOEmTZEkKbB/OqJKbVlKKPJ9kL7i14yii/IXj8NaCsDW+mBIN2QcrUJTx6awqYVA0omVZTf5YCq7Xq4+OSl+OpbL8Fgj0o+psHQWzAxXXOEcjdYY+UuLxZTlLtUWyaveO6upNzzyrHJe4zKnnuc7PpTApdfe2AP/unOJwVBFnImtgfC49Xnr8F42cbOo9PBGgd6t1TKkGfLdC2OVEKa7FGyF13PL3JmNEiFlDFddYOqk4Z47jRIppZqDvrnUE8OG5f14qmUjBkiaNnCzBRQzVB+gPo0BfNLVVfa8Fwr96YQredOeNEZfnlhN2LLHJmq4tBEFb/YeQz3PHU0VQETZJvDlqZlCrlHNqJwOReLgbZsXJLadiJBOhd51fIiJvm1/shrzoPHgXt2HBHKkPKjP/OzHdh7vKR4/dFMlx2Hp9CbN7F6qIhizkS55mGq6virSyUbYYmk3HNSLCNU7raicOkFoLKwRCyDxTALQ60KSbYMBVTlPHf/eFqEFU3jBCBiBmR1ycFA2hf07DWDyhqIaIaOnAo5XXOkNkdtGYiCdPT9S/vyglyHgntF9yYcdOsr97zJYipx7/GyOL9/jP/7pKCqiAFxnvj7qaqTmJo6VXWUbSQLloHTA/vqzc/dCMDfNcpxubAkosqd4gmhLcNge55YnUr3sidvIWewoHCYB5NByWirh8mK42/AbTJxHQMNbBnq5z05E5tWDKRmzNDfK7YMkXsu3XNPXsSk5rkv7c/ju+94Pj79hgsB+P1ipgsqZ4KuJHfLYMLXHSxa4iV1PK4sPDg6VRUj+uiJkrSsvHGWgbzRr5ItIyl34blP12Aw4KzVg6n51kMRlUjKvScvK/dwMFnSl8e6JT14bP+EII+pqoMTJRsf/cF2vOqf71WmmrbrxWyZU0f6wVhYDKxUc5XytYCq3HOKLROmccpqNC/I3UHBMoTlMdiTE8RbSFLukjVCAdWocpdnJnQuUu4EuYjXtv0T8Lhvh8lpshFulwKqHNNVV/jIg8WcGHQA8tytoH69//3y4EfxiSi5y1k/aZ57VCU+c3Qag0VLCrqqC61kyDGgqHI/c5VP1kcm4+mdkxXbr9TphDPQT7zufNz57hfinLVDyFsGHjswgZrrKdkw/v/9+7l+qa9K5aqRthtmmlEevBxItp0goJrRlpmq2v5OT6Yh+kAjW4aEQE/exJrhHlGtNAr6+7GkbBkzqtyZ8ndRgpaFo+txmIzh3HVD4l0u225sNXQ70V3kLl5gA6et6MdlZ4zg5j99jlR+V/XJjk5VhRc3eqIslGUpQwqZvDmC3AkUzz3Ilpmo2BjsySFnGjh5eZ9yHvrboUjw7jmnLMNVF6zBGasGYhkKywM1d/aaQTy2fwJT1XD6T6pjrGQrU82q44ka94Cv3E9b0Q/AD4pNVnzCKtdR7pbJROcsy8pd9twlWyZvhaQ1WMyJlE91JybVc5fz3Kn4FVkU5ZqqygFgxWBow7zi7JXKNVM9+HPXDYkXs55ytx1/9kIZIKuGimJmQH/bFwyQNcdTAveMQQR3KcsnSvL+fZDJ3RT3LKrcnzk2LYKp/rEBuScoVXlj52j9GQooJpO7E2wh54n2DBRzOG3FAHKmgTNXDWDb/nHYkpVG9+4dl23CPe+9TKSYWlLRPsflop3RgCrgZxM1E1Ct2P69tgwmMpCI3NMyiOg9KOZMDPfm/Ay4hHtHnyVlFMlCDYjnuUcz6hwpHZlW4UbPI5S7tmWaw4qBIkyDYdVgET15E196y8U4c9Wg5HNx5aYem6oJ5X5gvCIesLySLK2WhrzNlintQpOULTNVCaf6p4z45E4+HCnjaGbGisEiPnn1s9Cbt0RGCU2ByVfevHoIu45Nixd3uuYoBPj4gUnRrort+tkytp/Gd2C8Ish9oGDh6FQNnPtpeLIgWaIod6YEVGuO74/LuexCuVccFKxwF6nBHkucV91DNbBlaBWxtEKVc//FPjoZlBlIqGg5WMzh5j95Dh58/0txzpohf01B8PcPj45j9VAx6BeUccRiQVXZc5+uOiJI+BcvOx3//seXSEFGht6CJTbEzluGmLov7c2HefARe08mINmWyUvKPUrue46XRDBVPjapeBjVcpFLNxDOaUDuHg/vZXT2sHn1ILbtnxDb7PntCFNX1y/tFTMRCljnLF+5E/GJgGreFL591fZEcb+ssALlTgKsr4Fyr0i2DL1jEwkEToNQUn2ieLZMJPsl2ERbRpi55PcX/zzyzJ5iS1q5N4X1S3vx2+tfhnPXDSmfyxtnyDf1+HRNKHfX4yLIKE+j01bRyZtR5EwmViHKHcIvP4BADfrnOXPVIPKWIVLzSLFHlbuMF5+5AkCYTUMLjzavGQTnfnEwwP8eeaXpVNXB2iB7pOp4gbfu4ungOk8d8cm9v2CJYmVyvi8QyZYxQlumbLtCiQ8qqZD+fZgMbJnQHpO85oQ8dzqvX6JAXkXrCFtG9tynJAV38clLsay/IF5iGqQf3TculKscj4nOhGg2UnU8lGqhLTPUk8O6Jb3ieENW7oGapb9d3l8QZPXg7hP43U/dg4NSATiCHNxUPPeEIlMUTPWPVUskyJAFS9l2lYCxIPeEVbf0/Ij0okR10rI+jJVsuB6XlLmauvrCTSP4+tsuFX0pZzBMVhz87W2PAQjfn95cuF6j2qRy97/X38OVnnsx52fPpHnuJcmWoXdrLIHco5Ur5QyXKLnTM6L+4PEwzZogbw5EjzRqQ5pSWeR2oqvIHUjeZ5IIxM9zD2/qdNXBU4encEpglWw/6Kt4OQAWfcAEeQMP02CKH07wq0JyTFVDX/qtLzgZ3377c8UUngipHrlffPJS7Pq7K7Eh8DepHszpK/0X6uFRf5VoqerGAmfyIiQKBsqZMoD/Ah6bronjZCieuxWqrXLNlQqeyco93BuzYBmhcpcVq5TnTi/KksBqmijbivos1dyUbJmA3KXvpoDmeLkG1+PYc7yETcE9Uj33ZOVOlk40u4RealPy3KlGDv3tyEABvQHh3ff0UWzbP5G4wlbNlpE89+Bv5VnQsozKXbYa/aBdeH/PWj0A02Ax5U79EkBiLMS/D+F5hC0TWXRmGgzPOXWZOM4yDRyerOLOxw8Hx5Hnbgn173F/kOhL8dzlVbnyeYs5UxmI8maY+390qqrUZBKee04i91ICuUdIVrZe5H7q/85vlyz4okFXGixczhXBR4OGZTA8a/1wLFbUDnQduSeBpuTRVMhj0/5Cnos2+imKRO5y6lpa/WrZc7cMIzG4StkysnLvL1g4Z+0QlgYv7lCPT0jRzIwoGAtfojc/9yQAECVI6eWcqjrCa/zSWy7CK85eiTdcvAGAX+iIsmV2HJmCZTBhDaXtzZm3DEVd5YLyA4BPtNGVmUC40IOmrGuGezBQsJRyqdGXFgizQsbLNip2WPWvVHMl20lS7sE190ovF+WZj5dtHBgvw/H8TTGAUHEaLK7c6RmfiNTjD9sY5n73pij3kYECrGAxUpIFQlCzZaR67kEbaFYGhKuUASmgmlAoS04SmK46ShC4N29hWV8+FlAs1Vxhk00kxEKi9yFaJiJth6KojUnCqa9gKWmUBmOptsyKoK8My7Ecg6GvYIk1BQVL3Xd2y9/eiYs/9GNxvMiWyZti9jlejpeViHr2crZbMZ/sucuDP91rui/0LLwgoAr47y6lEBuM4Ztvf67IRmonsoWrFziE5x5ZxEQLdc5YNQCDAY8fnACgTn2z7MRimkzkoBci2RXkuZ+0TA2kXnXBGlgmw+gJf5/QesqdsH5pL575yO+Kn3vzlrJhdanmCMWyarCIz/3RFhybquK6bz+CquNny3DuZ5FsXN6X2FllDBQsJfhI5QcAP+icrNzV4NErz12Ny84YwU2/3Kt8Ls4ZPJvlAamNlW1UHBdL+vwg2HTNEbOKckD0y/rymKq66MubigqXFRoN4usFuYepetEZsVjIEij3vkJUsQUDg+EHlB3P3zAib6rKHfDJZLycPuVOzJaRAqqrh3rwTLB3rJw6S8cmBRCTlXuoUlcMFhRb5qZf7sHdT4ULwqg2TpSw5RIe8gbZAJQBRIYshm5/5wtw1uoB1FwPLz5zhbJ6OLoWBfBVdtl2MTJYxP7xCoZ7cyLFtZosht0AACAASURBVLdgKsfnTTNxU3GC7LkTyZJy/8SPnsS9Tx3BLX/63Jhyl6uUFnPJ/UAhdyuMKdTKnpKWKsd26D1NWkTXLiwKcqfAhpwtM1C0hCe6tC+PkYGCUkedkLopsZQKJSvBqL/mcY5JSbkTNi7vw59ddhpuuNXfmScLuSdhWX8epSAnelrKliESFos9XE+o3Ef3jePiYLYCqNaGDHmjb8AnwWLOn2KOl20xOA4mrFAFfLIwDIaBYk4Z9FTl7p9/sJiDZbBAubs4aWkv9h4v48BYRQyiB8YreMFHf4KP/sH5fuAzck/JQhor2WJVMK1YFbYMY2CRR0qBMlLu0WeVk2wZeZFW3jLFy0yDU1/erFvLRX7OIs1RynNfNVTEbe98PtYO9yjxjnwdcpcJqlRzxL02xcBZwNGpKrbtH0ep5uK6b6v1d8h7j9oy8iAn6rlThdKUujCyGBgZKIAxhjde4s80ZeKkUg4yijkDZduVlHt4/aeO9IvAuv/9gXJPy3OXbBl6F8bLNm59aD8+9eOnAAC/3nNCrL4lMSD332jtG3oG8n2he92T85/7dNXF1Tf+AlwKqPrXppZGngssCnKnTjVVDfeVXNKbx4Exn9wHeyysGupJJPf6nnuYLRMeL9kyknJPsz7kbJKZYFlfQSx4qbmesh8r4HfItzxvI648dzV2HZkG4AeSN0glcNOCxv0FS+nsOdMQU8zP3bVTfJ6kRum7CSsGiomfyzVJhnpyGCv5tgzZNHuDmU0xZwjvfc+xaUzV4gMmkcFY2cZE2QZjwJqgsJiwZQwWq+OQF7YMKfcouYfZMvSSTlT8ipR0v2XlnoTNqwdx9cXrRc0gILkqZDFniAqbMqIbisiQ862ng4UyD13/cjGILenN4+kjU/iHO7bjYEIfn0gh9yTlTs8u7b2QbZlon5eJ3zQg8twZ8zOj8pYBywh3PJKLzp22oh+P7psQP+fN0HOPVUOdronZD9WRB/xB/7H9ExjqyaFUc3Dn44dQczysHCxi9ERZuU7TYDFLlq6tX7LWSLn3BoS//eCkKPcg80KPJvf2gG7oe255COcHmTRLenPYc9zvAAPFHFYNFvBQwt/mLQM3/tGzMdiTw9U33i8+l7NlZOWuVoX0X8ay7aZaHzQYRFMhs2J5ZLk9lastSiTzgVedDUDd4m9E+ruBhLYNFCysGiwqnZGuU7aCom3PRWwZghx0U0v+hhkIQz05QeB0XfuCl271UA92HfUHp7GSjemqE5txDBQtMasYPVHCqsFiLBBoMr/8gGUwKdspfPmBdOVuGKEdMVF2sGqoKIKSI/3F4N4kP+fevIk3PWej8plSOEyQZvLgUJfco8rdMhViHOrJYWzaxtGemlg5LCPNllGVu5opErUsCPJG2vHl+2FfMg1DzCT7g411LMPAh37vHFy4YQm+9sAeZZazacWA0p68ZSBvmag6Xqzsxu995ud45lgJjFEwk2GwaAWxmApOXt6H/oKFOx87BNvlWCWRO7U5qWJlaMvE61aRmJJtX4Xcg9+bbO7IfVEEVGXyfSjILJGnvIPFnLJYRUbeMvDys1fh0lOWoS9vSoGt0OIx69gy5EunqWM6fqa2zHIpAAeEqzmTOqccfJQDnEkDzyevuQAfe+35ygsZlgpQz90vEVpanR35+ooJqZCmwTDUm8OhwCqjbAIagOXncyIg92i2hREMEOOlGkZPlIXfDqipkNGNIsyg3kyacrckNUcEOFGxUbAM8XyX9IUripOQFJhfO9yDVYNFnDrSLwa8tL+n7022ZSTPverGSHVJbx6TVQeHJytKsgCBirBFF+3I91degeq3p77n3ps3wSJEpih35j+r11y4Fi8MyoOYBsPrL9qATSsHMCCtLAeAlYMFZeCkBXJVx1XKbAAQqp1ziDYM9+YxVqph/3gZa4aLePZJS/D0EX+nLDlzJVoOI+naktJZe3P+ZxNS+Yv5tmUWBbnLN5QUobw4Z6BoYeVQCrlLL+Vwb150OFW5qz4zwWBM+K9J6tg/Pp4q2Ayi13N0qoqcGZ9SAmpesaz4kwae1UM9WNqXVzIcoi84QQ5qqqlk6nGXnOz7/EqQNqLcidxp5enegNxXS89nvFzDZCXuuQOBSi3b2HeirFSIZMHiJf+/ZHU+JrJlojVFZFtG8txNQ9g+lLaYlrsdXQAD+IvR7v/Ll2DzmkHhYRdTlHu98gOyWpyWPHcCDTyHJqpKmi+BlHv0ecn3l36XM+sr9zQBAPiJBwQrWBvyidddgGdv8K0qWYT9yxufjbe+4GTxM2Pq7moFy8CKgQIOjFdi2yJSjX8Z1C/2j5WxeqhHsYwUcrfSr4/uwaqh8Px0HA3K8kIp+XZqW6ZNkEdQypVWlHtPunKXyWr1UBFl28+79guHJXjukWwZ8jPTgpaXnrIML9+8UpSubRaUOrdysIgTJRtHpmqpmyDIqlBW7knxABp0rATipm3oXnX+Gpw6omYByUo/Os3//Ju34PuPHFC2vAv33jQCcvfP3Ze30F+wxHRZvj9jJTso8BW/zuGenH8fJqsYGVQtKyvIcd+8ehATFUepD583ww2qo8RPA5zBQuVO9bo/8prz8OCe46J9aeSeN+u/1Pk6ilH+fVJhsHp57oDa1+X1DoSJiq0sxCPI10L3gPpxWgypnm2TM9R3Izx3OKsiPH/TcvHvNcG9VQYby8BJy3px15NHcCyyofnqoaLybAE/2L77WAkV28Oa4R5loJAXi+XrDE5E/LQ+BFADqkAYv4hCpEJqcm8tVg8V8c6XbMKnfvyU6NSUWWEwP8MhjVxlm+FT1zwLRyaruOrTP4ft8GTPPVIVkhYFpXnu56wdwo1v2jLjayMFPjJQwBMHJ3F0spo6tZentY1sGercKrn7/6ap55ufcxK2SFk3gK+w8qYRK+0L+LOT11+0QflMrvmiZJLkfLKnl1Qh9yArIVG59+axf6yMmuthaa9qWVF9kr97zXk4OF7BbQ8fCNthGUDV7w/RwVFuY7ROyFBvDi8+c6X4rCeYnr/9Rafiwg1L8M8/eQoPjY6nrpcg0L1KtWVy6crdjpB7VIHLs1Qgvv3eZFAqIvadSvVO/x5ccc5qrB7qUQLkMqw6g5ScLSP3K7liZxT3vPcyET9QPHfTwIZlfag6Hh4/oJbzpQyal20On8tQTw73BDuVrRkqKivV5dkSPad6nvuAkueuBlRpFgRASdCg5xpdY9FOLApbhjGGd7/sdOWhUEGs/oIFxliict+wtBenjISj9JrhHjENpzx3g6mjcVS5E9KU+2whK3fAX2aeptxlJSYvEElqm1DuCcFPwoaUTacbZVTIOGftEH7n9BGctqJfaVPRMkWgVl5lCPj56FMJAVW6rj2B50qrXkX7TUMEtKyIkharD/NWzCsWAVWmzkaS1kAQAS3ry+Nlm1dKVRTr34vBHj8YvCQyIInvMrPZMq7H47ZM5JzR/T4mynbis5Lvg6xoLz1lWezY8Lg6yl1OhUwI1CeR+/qlvcKyJHGSD7K2aMX2b/eOKX9Tczy84uyV+LwkmmQbcvVwjzLrky2zfIaAas40sDKYFQrPPR9X7vul2QPdD2MOA6qLQrkTCjkDk1U/9YrIgggkSbnf/CfPiX0uVqIFnntahUFA9dzSPPfZgrJeaHCqOV5qKVX5hZNfrqzKPUqII5FMHYLY0DvFYpCxcrCIf/vvFwNQs25OGekTZZCHenLKrIMygvoTrnO4NyeUW5Jyp8eVizy3XMR2iP6OMZ/siin5+gRSaNS/spL7ioEivvuO54sSvVHQTkRJNWKi5WOjyn24Nzme4wck/X6cZrPI358F4f6w8eNNJdYS71eNVC0NnHTfT0ogd879ssf5yEzkleetFtsGrhkqKiUu8glJA0l9l+5r3jKwbkkvDk1UQ8+dbBnJc5cFSei5173EliLTVzHGLmeMbWeM7WCMXVfnuD9gjHHG2Mx9hjZCBIUMQxDagKQKTlrWq9gVSRUhyXejzTrSKgwCqhJpl3I/bUU//s8rN+O1W9aJz3pSSDXNDy4E+cXqAhs1hRAI798nr74Ab3nexpjCFceJgljZC0MB6stw8vI+kbc+2GMltj2qzKPniCv3sNxvdKCia0uyenImE4pfUe4J10dZE+RzkyrMW40V2zlrh+qS6CvOXoVbto6KIm+nvO82XP+dR2OrLKODTtJs4IpzVuEvrzxL/NwoWyutOmoU9Tx3mbwV5S5lI9UDDfDUN9cu6YHB1IqX/laD8YyhZ0vrC5b3FxRBk7jtY0L7z103hJdtXokzVg2IYD21WNRGCizLz7zxQrz/lZvF3/bks11jK9GQ3BljJoBPA7gCwGYA1zDGNiccNwDgnQAeaHUjWwXKSLBMJshWrq/9/Xe9AO+47DTxc1KGQ04od39Xp6jaUKpCsvrquBVgjOGtzz8ZG5b2ig6ZlmudZtcw5t+PZUEHtQwm7YkpZ8v4/77qgrUidz4J9dRPPRCxXrB+GIyFg42v3P22y/f3rNVxlSuT1NIouRuGIJXoS0ZtTsq0sExDPEtZuSddX29EueczKvcseM/Lz0DN9fDvD+xBxfZrw3zlF7tjFQaj5N6bN2Nq/sVnrsAbLwnjH43WWWRtf5gqmW5rAGpqa7jJTv3voHdILpW8JvK8qJZ8lNwZY7jtnc/HR3//PL+6p/Q+RhfqAcmD0/L+Aj7/pi0Y6smJNNvevImbrr0ULwniLpOBcr/inFXKO0/v3hzsiy2Q5YldDGAH53wn57wG4CYAVyUc9zcAPgogXue0QyBngESVO+CTokyA0ak7/S1A22x5SnoXEK0KGf4urQJeq8AYw5ph/4VJS1OrF6nvL1iCDKP2jVzRLgtC5d4codH3v27LegDhCsXBYmjLyJudnLFqMHYOOTMkZsuYDPS40tI5qdKmjLxpCDtHvjdJ1xe1ZfJie7rZk/vG5X04aVkvnjo0qWSDRGuDR4mVMRazZqiQFz3TRqm4WdtPfSVp4JNnSy+QsmHqee4y5FXXhOeeukwpcVxzPVTteDAfAM5eM4TXXeT3LTlbJmeGM/l6AVUZ1/7OKbjqgjW45uIN/hqYwDI6GsS8orNaskrTyiW0A1me2FoAe6WfR4PPBBhjzwKwnnP+vXonYoxdyxjbyhjbeuTIkXqHtgXyiE8eY3TZf06aPidNRSkbJPTco8pd9tz93/UXrDlJgSIVU69O9v940an4SuBxyzhz1SDOWzcMIGGTAqM59ZmfoXK/9JRl+NFfvBBvCBSlrNzp5TlVCnAnzYYoKGsaLOYj0wIm+rcMyq/ftDI+G7AM2Zap77lfsH4YF6wfxvql/rPI6rlnxcnL+rDr6HS4urpgNVTuQNya6YnMhBqVv4jaWGmgksRJ+fpJi3rkczf6DlLb8qD60T84H09/+Ep88Cp/Jmm7Hqqul7rSN3ouwL9frzp/ddCu9GwfGYPFHD559bPExjkkKiYqTuL7R4NF0m5Q7UKWHpd0x4VUYIwZAP4RwP9sdCLO+Y2c8y2c8y0jIyPZW9kiyD5y2ibI9BIylq4kcibzC4e5cc9dyQgIOvMZKUGyVmNNsLiinup47+Vn4oWnx+/9F968Bde/anNQHEz9+3DxUnuVO6CS66AU9F473IP3XXEm3njphrQ/BRAGD5f05mID6tLefGpwkRbCnJ5A7jkrtHPke5MUNDxn7RD+68+eJ2YaoiZLxnvXCCct68PuYyXsDkoxLOvPK3nuae0a7s0pgyGtViarspFyz/osKw5tbxc/fuWgv6HKZ954ofJ5vVRIGcKai5ybMSbZpR5qTtyWiaInMgP74FXn+GmXQZynWEcgJaEvH25GkjRzJs89bVvAdiCLVzAKYL308zoA+6WfBwCcA+BnwVRkFYBbGWOv5pxvbVVDWwF5H8gkzx2QlJZhpAYMc5aBb/56FBNlG6uHVM9P/hsqaHTB+uHWXEADrA5smahV1AyKlhl7MeSFRlkQeu7NvSBRDEvkzhjDn/zOqUJhX7gh+Z6G5B4PIn7mDy9sSFKbVsRtmZH+ghKPMJi/4USWVM+WK/flvSjbLrbuPgHAtxKjtkzSNb75uRux70QZH7r9cQChcg2Ve2tsGcpCSVLOvXkLv73+5bHPhS3TIE1QToVMOwdt4pJWqptAu2pN11yx+fb6pb3CVkpbKZwGxhiGe3I4Nl1LXKtAg0laieJ2IAu5/wrAJsbYyQD2AbgawBvol5zzcQDCQGOM/QzAezqN2AF5cwR/peHH/uC8WM5udJl1EnJmuCFDvankk8H+rM9KIaJWg2yZpL0is6KQM2OkHN3xvhHCDR1mR2giXTWyVPzjrz0flwVbD0ZBJJWUSZO28EZGUrbM2190Kt70HL9sLQsqQ5Zq8f0zk0CKPSk4PxPQvgC0IKdiu3BcTymEltSuK89djZrjCXKP2zLJ5E4L0rLaMhTDovhPFmTNljENvyJp0vXRZ7RZfJa+11ewAnIPv5f2fm1mf1fCUEDuSbZMcR5smYbkzjl3GGPvAHAHABPAFznn2xhjHwSwlXN+a7sb2SpEF+a8dsv62DHCl6/TOWSFUW8kphKlc6XcaSFT0nZiWdGTN2IvRtZsBkKY/tcaco+m6f3+s9clHa4cGw2mNsLX3nZJ6qBYzJkxOyYzuVutVe4bA3IXm7nXXDguR8Ey4NTqE5vYms71pOwjsmXSd+OqBYNHFrxuy3qYBsNrnrW28cEBsnrugJ/rHs1hB8L7S8o9y6yxr2ABk1XlOVLAM7o3ahZQAkCiLdOhyh2c89sB3B757PqUY180+2a1B6EtU1+Vy/9PgrxXo1xGN4q3PG8jvvTzZxLT69qBJZENomeComXG/FK6X3Ot3Det7MeLz1yBi09e2vjgAAXLRF/exNL+5sj9uacub3xQAP/ltTPl8bfac48q4lLNge35m59T6dt6g05vwUSt5IU547n6yv1V56/B13+5p2GAkmAaTGQ7ZUWYLdO4v/Tmrbq2DJVgLmQYTMWiKOlYUtZJA0gjkLBIinnRTKDTPPeuQSGDiiICy9UZACIWZyo+8Kqzcf0rN6d6963GWasH8XvPWou3veCUGZ9jaV8+5ldTylzW66D0v9mSe2/ewhf/20VN/90/vPZ8sTF2O0DKLItyb7XnbpkGvvCmLTBNhvt3HsMX790Fx+VqimaddvXlLYyV7Ni6gbSA6t9cdTbe/bLTZ2RTZIVcGbQRrjh3lVLKmUCzxVC5ZxsoAPXZEPlmFTIyKEbUKdkyi4rcoxs3JEG8jE0S0/f+/PmiHriMuSJ2wG/7P77+glmd4x9ff0Hs/lgmy+y5Ao03UW43rjh3dVvPT4SYZfBqtS0DAC8NCmI9OjoO2+UoR1Zk1gsa04Km6GKjoZRUSMs0lFXb7UBSVcg0vO+KsxI/p3RdUu5ZsntEbrtsyzik3Gdgy9RR7sVOtWW6BSKgWmf6l0XdJ+GctfGt0RYioiv+AF9R1btnUTTa0GGho9CUcm9tQFWGXEN8mVTnp74tYykqfLb7CbQCYUxn5kKI7vNUE8o9KW9e2DIzGIyHghlvYrZM8NlcLmJaZOTehHLP8HBv+dPniOh6N8MyjOaUe4sCqp2KQhPXl2+x5y6DbIWJio210sYk9drVXzAV26CR5z4XkPctnfE5orZMhlkjrVKVibxdyr1jA6rdgtCWqeO5C+We3tHuee9lAPxypIsBaTs7pR8/v7ZMuyE89wz3JNcGW4ZAJF2xPaW8Rb373l+w1KJZpr9/a1rJirmAaWS3ZdJAM8vpauOgMqFP2DJS9pvbAnKvkwp5xTmrmj7vTLGoyD20Zeop98a1QBYLqROSdoKvh2aU7UIEXV+jJeqAlC3TRlsGUEtW17PD3vWS0zFWDmNDw7351NLNc4VmPPc0EEELWybD/R4oWjBYinKfwWA8XIfcTYPhV3/10hnvlTwTLCpyzxJQzbKIabHBMpuzZbrdcw+Ve2O128qqkFHI9opcZbHeQLJ5jVps7Z0v2YQ/vPSklretGTSTLZMGur9Tley2zBsu3oAzVw0qM/lZ2TK96bYMgLYHpqNYVOSetLtQFO3IbljoyJmsqRdvuDeHnly8jEGn4eOvPX9Gf9fMzKTVqZAyelOUezOqc2lfPlYaea4RKveZ3yNhy9SylR8AgBWDRVwesUmuf9VmXP+dbThrdbziaCMM1/Hc5wOLktzr2zKa3KMwDaOp+/GGSzbgRWeMZK5FM1+ot9K1HsiOyUIgVG2x0U5HM4Fct3/1UDbl3oloSbbMDGyZJDz7pKW47Z0vmNHfnjLSj7e/6FS8OKU0xlxjUZF7loBqs6sxFwNOWd6n7DnZCL15C6etmJtKmPMBKiqVhUCed+py3HTtpYnVJmcLWbmvzGjLdCKyVoXMco7Qlpn7e2AaDP/78jPn/HvTsKjIXS4clgaq166Ve4gbXp2+69JiRKEJ5W4YrO6G0rPBTAKqnYicyfCCTctx/vqZrxUhKyprVcjFgEVG7hS4qf/gm03901hceOGmERybqs3KRmgFZFtGXoS00IiNMYavvvWSWZ0jbst0hu89n1ic5N7AcslbhrZlNFJxySnLcEmb1HgzkAN38kAzkzS+hQ5LBFRdMKZtVSDbTkxdg6yZMBdtXIpzu6ScgEb3Qvaoaa/bvJm+yUw3g8jc9fiivQdRLDLl7iudRtPpG9+0ZS6ao6HRUlgGW3CWTKvAGBMbliy0mEO7sLjIPdc4W0ZDYyHhpWetwJaNfr17g7FFTWw504DjuTOqxd6NWFTkLlYLznMgTEOjVfjCm8N694tZuQO+NVO2F162ULuwqO6CVu4a3Qxz0ZN7UPYiQ82fxYBFdRd03RiNboZpsEWZKUPo9mqkzWJR9YSlfXn88fNPxovO6IzlwRoarYRpGItbuQe57isH57fKZadgUXnujDG8/5Wb57sZGhptwaL33INc93VL5mZD+k7H4u0JGhpdBtNY3NkytLn12uHFtd9CGhZvT9DQ6DL4AdXF6zcfmawC0MqdoMldQ6NLYC3ygCptkbdWkzsATe4aGl2DZf15rNDBRKwb1uQOLLKAqoZGN+MLb7pI2ex5sWL5PO8J2ynQ5K6h0SWgPTwXOwy9Ah1ARnJnjF0O4JMATABf4Jx/JPL7dwP4YwAOgCMA/jvnfHeL26qhoaGRii+95SJMBjsxaWQgd8aYCeDTAF4GYBTArxhjt3LOH5MO+w2ALZzzEmPs7QA+CuD17WiwhoaGRhIu04sTFWQJqF4MYAfnfCfnvAbgJgBXyQdwzn/KOS8FP94PYGY7D2toaGhotARZyH0tgL3Sz6PBZ2l4K4DvJ/2CMXYtY2wrY2zrkSNHsrdSQ0NDQ6MpZCH3pOgETzyQsT8EsAXAx5J+zzm/kXO+hXO+ZWRkJHsrNTQ0NDSaQpaA6iiA9dLP6wDsjx7EGHspgL8C8Duc82prmqehoaGhMRNkUe6/ArCJMXYyYywP4GoAt8oHMMaeBeBzAF7NOT/c+mZqaGhoaDSDhuTOOXcAvAPAHQAeB3Az53wbY+yDjLFXB4d9DEA/gFsYY79ljN2acjoNDQ0NjTlApjx3zvntAG6PfHa99O+XtrhdGhoaGhqzgK4to6GhodGFYJwnJr60/4sZOwJgpqtYlwM42sLmzCf0tXQm9LV0JvS1ACdxzhumG84buc8GjLGtnPMt892OVkBfS2dCX0tnQl9LdmhbRkNDQ6MLocldQ0NDowuxUMn9xvluQAuhr6Uzoa+lM6GvJSMWpOeuoaGhoVEfC1W5a2hoaGjUwYIjd8bY5Yyx7YyxHYyx6+a7Pc2CMfYMY+yRYCXv1uCzpYyxHzHGngr+v2S+25kExtgXGWOHGWOPSp8ltp35+FTwnB5mjF04fy2PI+VabmCM7QuezW8ZY1dKv3tfcC3bGWOvmJ9Wx8EYW88Y+ylj7HHG2DbG2LuCzxfcc6lzLQvxuRQZY79kjD0UXMtfB5+fzBh7IHgu3whKuoAxVgh+3hH8fuOsG8E5XzD/wd8J6mkApwDIA3gIwOb5bleT1/AMgOWRzz4K4Lrg39cB+Pv5bmdK218I4EIAjzZqO4Ar4Zd+ZgAuBfDAfLc/w7XcAOA9CcduDvpaAcDJQR805/sagratBnBh8O8BAE8G7V1wz6XOtSzE58IA9Af/zgF4ILjfNwO4Ovj8swDeHvz7fwD4bPDvqwF8Y7ZtWGjKveHGIQsUVwH4t+Df/wbg/5vHtqSCc343gOORj9PafhWAr3Af9wMYZoytnpuWNkbKtaThKgA3cc6r/6+983eNIoqi8HeRoKJiUETEyoiFjUQRERQLFSHphBRWphBstLAP+B9oJxaijYiFUdFS8UctqDFGRIzYGZIqUTvRY/HuxHXZiZtEnXnD/WCY2TcP9lzO7N159+3Ok/QRmCRdi5UjaUrSCz/+Qnr+01Yy9GWBWMqosy+S9NVf9vgm4DAw6u3tvhR+jQJHzGxZi8HmltwXu3BIHRHwwMyem9lpb9ssaQrSBQ7ktF5YmfZcvTrr5YprLeWxLGLxofxu0l1i1r60xQIZ+mJmK8xsDJgBHpJGFrNKD2OE3/XOx+Ln54CNy3n/3JJ71wuH1JgDkvYAA8AZMztUtaB/RI5eXQa2A/3AFHDB22sfi5mtBW4D5yR9Xqhrh7a6x5KlL5K+S+onrYGxD9jZqZvv/3osuSX3rhYOqTOSPvl+BrhLMn26GBr7Pqdn4pdpz84rSdP+gfwBXOHXEL/WsZhZDykZ3pB0x5uz9KVTLLn6UiBpFnhKqrn3mlnxNN5WvfOx+Pn1dF827Ehuyf2PC4fUGTNbY2brimPgGDBBimHYuw0D96pRuCTKtN8HTvqvM/YDc0WZoK601Z6Pk7yBFMsJ/0XDNmAH8Ox/6+uE12WvAm8lXWw5lZ0vZbFk6ssmM+v149XAUdIcwhNgyLu1+1L4NQQ8ls+uLpmqZ5WXMAs9SJpF/wCMVK1nkdr7SLP7ENukaAAAAK9JREFUr4A3hX5Sbe0R8N73G6rWWqL/JmlY/I10p3GqTDtpmHnJfXoN7K1afxexXHet4/5h29LSf8RjeQcMVK2/RddB0vB9HBjzbTBHXxaIJUdfdgEvXfMEcN7b+0hfQJPALWClt6/y15N+vm+5GuIfqkEQBA0kt7JMEARB0AWR3IMgCBpIJPcgCIIGEsk9CIKggURyD4IgaCCR3IMgCBpIJPcgCIIGEsk9CIKggfwEO0M019QTYfIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "curr_lr = learning_rate\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels,_,hog_features) in enumerate(train_loader):\n",
    "#         if (i+1) % 200 == 0:\n",
    "#             print(images.shape,hog_features.shape)\n",
    "        batch=len(images)\n",
    "        \n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "        hog_features=hog_features.cuda()\n",
    "        \n",
    "        outputs = model(images,hog_features,batch)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         print(outputs[0],labels[0])\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        # Decay learning rate\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            curr_lr /= 2\n",
    "            update_lr(optimizer, curr_lr)\n",
    "            torch.save(model.state_dict(), 'model_training.ckpt')\n",
    "    x.append(epoch)\n",
    "    y.append(loss.item())\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), 'model_training.ckpt')\n",
    "\n",
    "del model, images, labels, hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [1/29], Loss: 1.2348\n",
      "Epoch [1/300], Step [2/29], Loss: 1.2332\n",
      "Epoch [1/300], Step [3/29], Loss: 1.2959\n",
      "Epoch [1/300], Step [4/29], Loss: 1.2158\n",
      "Epoch [1/300], Step [5/29], Loss: 1.5669\n",
      "Epoch [1/300], Step [6/29], Loss: 1.3031\n",
      "Epoch [1/300], Step [7/29], Loss: 1.2099\n",
      "Epoch [1/300], Step [8/29], Loss: 1.2346\n",
      "Epoch [1/300], Step [9/29], Loss: 1.4178\n",
      "Epoch [1/300], Step [10/29], Loss: 1.3104\n",
      "Epoch [1/300], Step [11/29], Loss: 1.5452\n",
      "Epoch [1/300], Step [12/29], Loss: 1.2407\n",
      "Epoch [1/300], Step [13/29], Loss: 1.1656\n",
      "Epoch [1/300], Step [14/29], Loss: 1.1953\n",
      "Epoch [1/300], Step [15/29], Loss: 0.9787\n",
      "Epoch [1/300], Step [16/29], Loss: 1.2298\n",
      "Epoch [1/300], Step [17/29], Loss: 1.2045\n",
      "Epoch [1/300], Step [18/29], Loss: 1.2125\n",
      "Epoch [1/300], Step [19/29], Loss: 1.4532\n",
      "Epoch [1/300], Step [20/29], Loss: 1.5535\n",
      "Epoch [1/300], Step [21/29], Loss: 1.3904\n",
      "Epoch [1/300], Step [22/29], Loss: 1.2996\n",
      "Epoch [1/300], Step [23/29], Loss: 1.4415\n",
      "Epoch [1/300], Step [24/29], Loss: 1.4114\n",
      "Epoch [1/300], Step [25/29], Loss: 1.4713\n",
      "Epoch [1/300], Step [26/29], Loss: 0.9895\n",
      "Epoch [1/300], Step [27/29], Loss: 1.0871\n",
      "Epoch [1/300], Step [28/29], Loss: 1.3258\n",
      "Epoch [1/300], Step [29/29], Loss: 0.7161\n",
      "Epoch [2/300], Step [1/29], Loss: 1.4268\n",
      "Epoch [2/300], Step [2/29], Loss: 1.2849\n",
      "Epoch [2/300], Step [3/29], Loss: 1.0404\n",
      "Epoch [2/300], Step [4/29], Loss: 1.7228\n",
      "Epoch [2/300], Step [5/29], Loss: 1.2638\n",
      "Epoch [2/300], Step [6/29], Loss: 1.2067\n",
      "Epoch [2/300], Step [7/29], Loss: 1.2253\n",
      "Epoch [2/300], Step [8/29], Loss: 1.2126\n",
      "Epoch [2/300], Step [9/29], Loss: 1.2429\n",
      "Epoch [2/300], Step [10/29], Loss: 1.4393\n",
      "Epoch [2/300], Step [11/29], Loss: 1.4659\n",
      "Epoch [2/300], Step [12/29], Loss: 1.1175\n",
      "Epoch [2/300], Step [13/29], Loss: 1.3872\n",
      "Epoch [2/300], Step [14/29], Loss: 1.5034\n",
      "Epoch [2/300], Step [15/29], Loss: 1.5034\n",
      "Epoch [2/300], Step [16/29], Loss: 1.2000\n",
      "Epoch [2/300], Step [17/29], Loss: 1.2779\n",
      "Epoch [2/300], Step [18/29], Loss: 1.3936\n",
      "Epoch [2/300], Step [19/29], Loss: 1.2876\n",
      "Epoch [2/300], Step [20/29], Loss: 1.4851\n",
      "Epoch [2/300], Step [21/29], Loss: 1.2261\n",
      "Epoch [2/300], Step [22/29], Loss: 1.1593\n",
      "Epoch [2/300], Step [23/29], Loss: 1.1078\n",
      "Epoch [2/300], Step [24/29], Loss: 1.3990\n",
      "Epoch [2/300], Step [25/29], Loss: 1.3993\n",
      "Epoch [2/300], Step [26/29], Loss: 1.1180\n",
      "Epoch [2/300], Step [27/29], Loss: 1.2973\n",
      "Epoch [2/300], Step [28/29], Loss: 1.1642\n",
      "Epoch [2/300], Step [29/29], Loss: 1.5035\n",
      "Epoch [3/300], Step [1/29], Loss: 1.3489\n",
      "Epoch [3/300], Step [2/29], Loss: 1.3025\n",
      "Epoch [3/300], Step [3/29], Loss: 1.3956\n",
      "Epoch [3/300], Step [4/29], Loss: 1.3193\n",
      "Epoch [3/300], Step [5/29], Loss: 1.3136\n",
      "Epoch [3/300], Step [6/29], Loss: 1.3343\n",
      "Epoch [3/300], Step [7/29], Loss: 1.2979\n",
      "Epoch [3/300], Step [8/29], Loss: 1.3260\n",
      "Epoch [3/300], Step [9/29], Loss: 1.1218\n",
      "Epoch [3/300], Step [10/29], Loss: 1.6409\n",
      "Epoch [3/300], Step [11/29], Loss: 1.1067\n",
      "Epoch [3/300], Step [12/29], Loss: 1.4600\n",
      "Epoch [3/300], Step [13/29], Loss: 1.1313\n",
      "Epoch [3/300], Step [14/29], Loss: 1.1931\n",
      "Epoch [3/300], Step [15/29], Loss: 1.0793\n",
      "Epoch [3/300], Step [16/29], Loss: 1.3225\n",
      "Epoch [3/300], Step [17/29], Loss: 1.2252\n",
      "Epoch [3/300], Step [18/29], Loss: 1.5729\n",
      "Epoch [3/300], Step [19/29], Loss: 1.6842\n",
      "Epoch [3/300], Step [20/29], Loss: 1.2655\n",
      "Epoch [3/300], Step [21/29], Loss: 1.5393\n",
      "Epoch [3/300], Step [22/29], Loss: 1.4812\n",
      "Epoch [3/300], Step [23/29], Loss: 1.2098\n",
      "Epoch [3/300], Step [24/29], Loss: 1.0093\n",
      "Epoch [3/300], Step [25/29], Loss: 1.0249\n",
      "Epoch [3/300], Step [26/29], Loss: 1.1799\n",
      "Epoch [3/300], Step [27/29], Loss: 1.1239\n",
      "Epoch [3/300], Step [28/29], Loss: 1.3595\n",
      "Epoch [3/300], Step [29/29], Loss: 1.5097\n",
      "Epoch [4/300], Step [1/29], Loss: 1.2916\n",
      "Epoch [4/300], Step [2/29], Loss: 1.1540\n",
      "Epoch [4/300], Step [3/29], Loss: 1.3095\n",
      "Epoch [4/300], Step [4/29], Loss: 1.2459\n",
      "Epoch [4/300], Step [5/29], Loss: 1.2672\n",
      "Epoch [4/300], Step [6/29], Loss: 1.4480\n",
      "Epoch [4/300], Step [7/29], Loss: 1.2512\n",
      "Epoch [4/300], Step [8/29], Loss: 1.2085\n",
      "Epoch [4/300], Step [9/29], Loss: 1.4254\n",
      "Epoch [4/300], Step [10/29], Loss: 1.4340\n",
      "Epoch [4/300], Step [11/29], Loss: 1.3634\n",
      "Epoch [4/300], Step [12/29], Loss: 1.5554\n",
      "Epoch [4/300], Step [13/29], Loss: 1.2256\n",
      "Epoch [4/300], Step [14/29], Loss: 1.3528\n",
      "Epoch [4/300], Step [15/29], Loss: 1.3043\n",
      "Epoch [4/300], Step [16/29], Loss: 1.1075\n",
      "Epoch [4/300], Step [17/29], Loss: 1.2055\n",
      "Epoch [4/300], Step [18/29], Loss: 1.2871\n",
      "Epoch [4/300], Step [19/29], Loss: 1.0205\n",
      "Epoch [4/300], Step [20/29], Loss: 1.2136\n",
      "Epoch [4/300], Step [21/29], Loss: 1.1876\n",
      "Epoch [4/300], Step [22/29], Loss: 1.4173\n",
      "Epoch [4/300], Step [23/29], Loss: 1.7200\n",
      "Epoch [4/300], Step [24/29], Loss: 1.2803\n",
      "Epoch [4/300], Step [25/29], Loss: 1.3736\n",
      "Epoch [4/300], Step [26/29], Loss: 1.5122\n",
      "Epoch [4/300], Step [27/29], Loss: 1.1814\n",
      "Epoch [4/300], Step [28/29], Loss: 1.1721\n",
      "Epoch [4/300], Step [29/29], Loss: 0.8795\n",
      "Epoch [5/300], Step [1/29], Loss: 1.2174\n",
      "Epoch [5/300], Step [2/29], Loss: 1.2499\n",
      "Epoch [5/300], Step [3/29], Loss: 1.1869\n",
      "Epoch [5/300], Step [4/29], Loss: 1.7722\n",
      "Epoch [5/300], Step [5/29], Loss: 1.1928\n",
      "Epoch [5/300], Step [6/29], Loss: 1.4865\n",
      "Epoch [5/300], Step [7/29], Loss: 1.3697\n",
      "Epoch [5/300], Step [8/29], Loss: 1.2881\n",
      "Epoch [5/300], Step [9/29], Loss: 1.0363\n",
      "Epoch [5/300], Step [10/29], Loss: 1.5775\n",
      "Epoch [5/300], Step [11/29], Loss: 1.2146\n",
      "Epoch [5/300], Step [12/29], Loss: 1.3230\n",
      "Epoch [5/300], Step [13/29], Loss: 1.5172\n",
      "Epoch [5/300], Step [14/29], Loss: 1.7021\n",
      "Epoch [5/300], Step [15/29], Loss: 1.4354\n",
      "Epoch [5/300], Step [16/29], Loss: 0.9797\n",
      "Epoch [5/300], Step [17/29], Loss: 1.3455\n",
      "Epoch [5/300], Step [18/29], Loss: 1.0749\n",
      "Epoch [5/300], Step [19/29], Loss: 1.3600\n",
      "Epoch [5/300], Step [20/29], Loss: 1.4164\n",
      "Epoch [5/300], Step [21/29], Loss: 1.2223\n",
      "Epoch [5/300], Step [22/29], Loss: 1.1661\n",
      "Epoch [5/300], Step [23/29], Loss: 1.3088\n",
      "Epoch [5/300], Step [24/29], Loss: 1.2358\n",
      "Epoch [5/300], Step [25/29], Loss: 0.9435\n",
      "Epoch [5/300], Step [26/29], Loss: 1.2449\n",
      "Epoch [5/300], Step [27/29], Loss: 1.5660\n",
      "Epoch [5/300], Step [28/29], Loss: 1.0913\n",
      "Epoch [5/300], Step [29/29], Loss: 1.3882\n",
      "Epoch [6/300], Step [1/29], Loss: 1.2146\n",
      "Epoch [6/300], Step [2/29], Loss: 1.3399\n",
      "Epoch [6/300], Step [3/29], Loss: 1.2934\n",
      "Epoch [6/300], Step [4/29], Loss: 1.3920\n",
      "Epoch [6/300], Step [5/29], Loss: 1.1609\n",
      "Epoch [6/300], Step [6/29], Loss: 1.4360\n",
      "Epoch [6/300], Step [7/29], Loss: 1.2974\n",
      "Epoch [6/300], Step [8/29], Loss: 1.3948\n",
      "Epoch [6/300], Step [9/29], Loss: 1.4925\n",
      "Epoch [6/300], Step [10/29], Loss: 1.4045\n",
      "Epoch [6/300], Step [11/29], Loss: 1.1359\n",
      "Epoch [6/300], Step [12/29], Loss: 1.2624\n",
      "Epoch [6/300], Step [13/29], Loss: 1.1469\n",
      "Epoch [6/300], Step [14/29], Loss: 1.2015\n",
      "Epoch [6/300], Step [15/29], Loss: 1.2236\n",
      "Epoch [6/300], Step [16/29], Loss: 1.1099\n",
      "Epoch [6/300], Step [17/29], Loss: 1.4427\n",
      "Epoch [6/300], Step [18/29], Loss: 1.2822\n",
      "Epoch [6/300], Step [19/29], Loss: 1.2808\n",
      "Epoch [6/300], Step [20/29], Loss: 1.3344\n",
      "Epoch [6/300], Step [21/29], Loss: 1.3836\n",
      "Epoch [6/300], Step [22/29], Loss: 1.3115\n",
      "Epoch [6/300], Step [23/29], Loss: 1.4730\n",
      "Epoch [6/300], Step [24/29], Loss: 1.3117\n",
      "Epoch [6/300], Step [25/29], Loss: 1.1113\n",
      "Epoch [6/300], Step [26/29], Loss: 1.1472\n",
      "Epoch [6/300], Step [27/29], Loss: 1.2995\n",
      "Epoch [6/300], Step [28/29], Loss: 1.1407\n",
      "Epoch [6/300], Step [29/29], Loss: 1.1967\n",
      "Epoch [7/300], Step [1/29], Loss: 1.0921\n",
      "Epoch [7/300], Step [2/29], Loss: 1.3080\n",
      "Epoch [7/300], Step [3/29], Loss: 1.1799\n",
      "Epoch [7/300], Step [4/29], Loss: 1.1553\n",
      "Epoch [7/300], Step [5/29], Loss: 1.3286\n",
      "Epoch [7/300], Step [6/29], Loss: 1.2621\n",
      "Epoch [7/300], Step [7/29], Loss: 1.2286\n",
      "Epoch [7/300], Step [8/29], Loss: 1.2175\n",
      "Epoch [7/300], Step [9/29], Loss: 1.1376\n",
      "Epoch [7/300], Step [10/29], Loss: 1.2493\n",
      "Epoch [7/300], Step [11/29], Loss: 1.2303\n",
      "Epoch [7/300], Step [12/29], Loss: 1.2386\n",
      "Epoch [7/300], Step [13/29], Loss: 1.2490\n",
      "Epoch [7/300], Step [14/29], Loss: 1.3019\n",
      "Epoch [7/300], Step [15/29], Loss: 1.1312\n",
      "Epoch [7/300], Step [16/29], Loss: 1.3754\n",
      "Epoch [7/300], Step [17/29], Loss: 1.4744\n",
      "Epoch [7/300], Step [18/29], Loss: 1.3405\n",
      "Epoch [7/300], Step [19/29], Loss: 1.5516\n",
      "Epoch [7/300], Step [20/29], Loss: 1.2643\n",
      "Epoch [7/300], Step [21/29], Loss: 1.2538\n",
      "Epoch [7/300], Step [22/29], Loss: 1.2730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [23/29], Loss: 1.3143\n",
      "Epoch [7/300], Step [24/29], Loss: 1.5447\n",
      "Epoch [7/300], Step [25/29], Loss: 1.3360\n",
      "Epoch [7/300], Step [26/29], Loss: 1.5849\n",
      "Epoch [7/300], Step [27/29], Loss: 1.2392\n",
      "Epoch [7/300], Step [28/29], Loss: 1.0443\n",
      "Epoch [7/300], Step [29/29], Loss: 4.7120\n",
      "Epoch [8/300], Step [1/29], Loss: 1.2748\n",
      "Epoch [8/300], Step [2/29], Loss: 1.3943\n",
      "Epoch [8/300], Step [3/29], Loss: 1.5148\n",
      "Epoch [8/300], Step [4/29], Loss: 1.2811\n",
      "Epoch [8/300], Step [5/29], Loss: 1.3586\n",
      "Epoch [8/300], Step [6/29], Loss: 1.3146\n",
      "Epoch [8/300], Step [7/29], Loss: 1.4198\n",
      "Epoch [8/300], Step [8/29], Loss: 1.0863\n",
      "Epoch [8/300], Step [9/29], Loss: 1.4448\n",
      "Epoch [8/300], Step [10/29], Loss: 1.2421\n",
      "Epoch [8/300], Step [11/29], Loss: 0.9365\n",
      "Epoch [8/300], Step [12/29], Loss: 1.4601\n",
      "Epoch [8/300], Step [13/29], Loss: 1.3129\n",
      "Epoch [8/300], Step [14/29], Loss: 1.2182\n",
      "Epoch [8/300], Step [15/29], Loss: 1.3724\n",
      "Epoch [8/300], Step [16/29], Loss: 1.1003\n",
      "Epoch [8/300], Step [17/29], Loss: 1.1831\n",
      "Epoch [8/300], Step [18/29], Loss: 1.1186\n",
      "Epoch [8/300], Step [19/29], Loss: 1.5576\n",
      "Epoch [8/300], Step [20/29], Loss: 1.2799\n",
      "Epoch [8/300], Step [21/29], Loss: 1.2041\n",
      "Epoch [8/300], Step [22/29], Loss: 1.2168\n",
      "Epoch [8/300], Step [23/29], Loss: 1.2523\n",
      "Epoch [8/300], Step [24/29], Loss: 1.4091\n",
      "Epoch [8/300], Step [25/29], Loss: 1.7906\n",
      "Epoch [8/300], Step [26/29], Loss: 1.3293\n",
      "Epoch [8/300], Step [27/29], Loss: 1.2189\n",
      "Epoch [8/300], Step [28/29], Loss: 1.2596\n",
      "Epoch [8/300], Step [29/29], Loss: 0.8896\n",
      "Epoch [9/300], Step [1/29], Loss: 1.2637\n",
      "Epoch [9/300], Step [2/29], Loss: 1.3099\n",
      "Epoch [9/300], Step [3/29], Loss: 1.2974\n",
      "Epoch [9/300], Step [4/29], Loss: 1.1313\n",
      "Epoch [9/300], Step [5/29], Loss: 1.6293\n",
      "Epoch [9/300], Step [6/29], Loss: 1.2451\n",
      "Epoch [9/300], Step [7/29], Loss: 1.3194\n",
      "Epoch [9/300], Step [8/29], Loss: 1.1553\n",
      "Epoch [9/300], Step [9/29], Loss: 1.2919\n",
      "Epoch [9/300], Step [10/29], Loss: 1.2373\n",
      "Epoch [9/300], Step [11/29], Loss: 1.3187\n",
      "Epoch [9/300], Step [12/29], Loss: 1.5934\n",
      "Epoch [9/300], Step [13/29], Loss: 1.4135\n",
      "Epoch [9/300], Step [14/29], Loss: 1.4218\n",
      "Epoch [9/300], Step [15/29], Loss: 1.1731\n",
      "Epoch [9/300], Step [16/29], Loss: 1.0253\n",
      "Epoch [9/300], Step [17/29], Loss: 1.3318\n",
      "Epoch [9/300], Step [18/29], Loss: 1.2565\n",
      "Epoch [9/300], Step [19/29], Loss: 1.3199\n",
      "Epoch [9/300], Step [20/29], Loss: 1.2355\n",
      "Epoch [9/300], Step [21/29], Loss: 1.1965\n",
      "Epoch [9/300], Step [22/29], Loss: 1.2049\n",
      "Epoch [9/300], Step [23/29], Loss: 1.1389\n",
      "Epoch [9/300], Step [24/29], Loss: 1.1500\n",
      "Epoch [9/300], Step [25/29], Loss: 1.4554\n",
      "Epoch [9/300], Step [26/29], Loss: 1.3812\n",
      "Epoch [9/300], Step [27/29], Loss: 1.6157\n",
      "Epoch [9/300], Step [28/29], Loss: 1.2662\n",
      "Epoch [9/300], Step [29/29], Loss: 2.8301\n",
      "Epoch [10/300], Step [1/29], Loss: 1.3423\n",
      "Epoch [10/300], Step [2/29], Loss: 1.4414\n",
      "Epoch [10/300], Step [3/29], Loss: 1.0837\n",
      "Epoch [10/300], Step [4/29], Loss: 1.5244\n",
      "Epoch [10/300], Step [5/29], Loss: 1.1292\n",
      "Epoch [10/300], Step [6/29], Loss: 1.2266\n",
      "Epoch [10/300], Step [7/29], Loss: 1.2572\n",
      "Epoch [10/300], Step [8/29], Loss: 1.3505\n",
      "Epoch [10/300], Step [9/29], Loss: 1.2732\n",
      "Epoch [10/300], Step [10/29], Loss: 1.4213\n",
      "Epoch [10/300], Step [11/29], Loss: 1.2092\n",
      "Epoch [10/300], Step [12/29], Loss: 1.2059\n",
      "Epoch [10/300], Step [13/29], Loss: 1.2564\n",
      "Epoch [10/300], Step [14/29], Loss: 1.2852\n",
      "Epoch [10/300], Step [15/29], Loss: 1.1655\n",
      "Epoch [10/300], Step [16/29], Loss: 1.1313\n",
      "Epoch [10/300], Step [17/29], Loss: 1.2224\n",
      "Epoch [10/300], Step [18/29], Loss: 1.4684\n",
      "Epoch [10/300], Step [19/29], Loss: 1.2672\n",
      "Epoch [10/300], Step [20/29], Loss: 1.5677\n",
      "Epoch [10/300], Step [21/29], Loss: 1.1782\n",
      "Epoch [10/300], Step [22/29], Loss: 1.2062\n",
      "Epoch [10/300], Step [23/29], Loss: 1.2111\n",
      "Epoch [10/300], Step [24/29], Loss: 1.0255\n",
      "Epoch [10/300], Step [25/29], Loss: 1.2780\n",
      "Epoch [10/300], Step [26/29], Loss: 1.6314\n",
      "Epoch [10/300], Step [27/29], Loss: 1.6683\n",
      "Epoch [10/300], Step [28/29], Loss: 1.4013\n",
      "Epoch [10/300], Step [29/29], Loss: 2.8171\n",
      "Epoch [11/300], Step [1/29], Loss: 1.1607\n",
      "Epoch [11/300], Step [2/29], Loss: 1.5247\n",
      "Epoch [11/300], Step [3/29], Loss: 1.2895\n",
      "Epoch [11/300], Step [4/29], Loss: 1.2377\n",
      "Epoch [11/300], Step [5/29], Loss: 1.3341\n",
      "Epoch [11/300], Step [6/29], Loss: 1.4859\n",
      "Epoch [11/300], Step [7/29], Loss: 1.3669\n",
      "Epoch [11/300], Step [8/29], Loss: 1.3615\n",
      "Epoch [11/300], Step [9/29], Loss: 1.2902\n",
      "Epoch [11/300], Step [10/29], Loss: 0.9803\n",
      "Epoch [11/300], Step [11/29], Loss: 1.2207\n",
      "Epoch [11/300], Step [12/29], Loss: 1.2270\n",
      "Epoch [11/300], Step [13/29], Loss: 1.4212\n",
      "Epoch [11/300], Step [14/29], Loss: 1.2585\n",
      "Epoch [11/300], Step [15/29], Loss: 1.0670\n",
      "Epoch [11/300], Step [16/29], Loss: 1.0999\n",
      "Epoch [11/300], Step [17/29], Loss: 1.3533\n",
      "Epoch [11/300], Step [18/29], Loss: 1.3242\n",
      "Epoch [11/300], Step [19/29], Loss: 1.2331\n",
      "Epoch [11/300], Step [20/29], Loss: 1.3537\n",
      "Epoch [11/300], Step [21/29], Loss: 1.5753\n",
      "Epoch [11/300], Step [22/29], Loss: 1.1614\n",
      "Epoch [11/300], Step [23/29], Loss: 1.1971\n",
      "Epoch [11/300], Step [24/29], Loss: 1.2514\n",
      "Epoch [11/300], Step [25/29], Loss: 1.2009\n",
      "Epoch [11/300], Step [26/29], Loss: 1.4018\n",
      "Epoch [11/300], Step [27/29], Loss: 1.4752\n",
      "Epoch [11/300], Step [28/29], Loss: 1.5347\n",
      "Epoch [11/300], Step [29/29], Loss: 3.3277\n",
      "Epoch [12/300], Step [1/29], Loss: 1.2892\n",
      "Epoch [12/300], Step [2/29], Loss: 1.1750\n",
      "Epoch [12/300], Step [3/29], Loss: 1.6501\n",
      "Epoch [12/300], Step [4/29], Loss: 1.1751\n",
      "Epoch [12/300], Step [5/29], Loss: 1.1570\n",
      "Epoch [12/300], Step [6/29], Loss: 1.4786\n",
      "Epoch [12/300], Step [7/29], Loss: 1.3370\n",
      "Epoch [12/300], Step [8/29], Loss: 1.2499\n",
      "Epoch [12/300], Step [9/29], Loss: 1.1886\n",
      "Epoch [12/300], Step [10/29], Loss: 1.4699\n",
      "Epoch [12/300], Step [11/29], Loss: 1.2833\n",
      "Epoch [12/300], Step [12/29], Loss: 1.0992\n",
      "Epoch [12/300], Step [13/29], Loss: 1.4289\n",
      "Epoch [12/300], Step [14/29], Loss: 1.1986\n",
      "Epoch [12/300], Step [15/29], Loss: 1.2456\n",
      "Epoch [12/300], Step [16/29], Loss: 1.3066\n",
      "Epoch [12/300], Step [17/29], Loss: 1.0205\n",
      "Epoch [12/300], Step [18/29], Loss: 1.3644\n",
      "Epoch [12/300], Step [19/29], Loss: 1.4044\n",
      "Epoch [12/300], Step [20/29], Loss: 1.2417\n",
      "Epoch [12/300], Step [21/29], Loss: 1.4712\n",
      "Epoch [12/300], Step [22/29], Loss: 1.4719\n",
      "Epoch [12/300], Step [23/29], Loss: 1.6246\n",
      "Epoch [12/300], Step [24/29], Loss: 1.1913\n",
      "Epoch [12/300], Step [25/29], Loss: 1.1712\n",
      "Epoch [12/300], Step [26/29], Loss: 1.1412\n",
      "Epoch [12/300], Step [27/29], Loss: 1.3009\n",
      "Epoch [12/300], Step [28/29], Loss: 1.1968\n",
      "Epoch [12/300], Step [29/29], Loss: 0.9507\n",
      "Epoch [13/300], Step [1/29], Loss: 1.3259\n",
      "Epoch [13/300], Step [2/29], Loss: 1.4385\n",
      "Epoch [13/300], Step [3/29], Loss: 1.4966\n",
      "Epoch [13/300], Step [4/29], Loss: 1.1031\n",
      "Epoch [13/300], Step [5/29], Loss: 1.3244\n",
      "Epoch [13/300], Step [6/29], Loss: 1.1597\n",
      "Epoch [13/300], Step [7/29], Loss: 1.5734\n",
      "Epoch [13/300], Step [8/29], Loss: 1.1335\n",
      "Epoch [13/300], Step [9/29], Loss: 1.4334\n",
      "Epoch [13/300], Step [10/29], Loss: 1.4781\n",
      "Epoch [13/300], Step [11/29], Loss: 1.1436\n",
      "Epoch [13/300], Step [12/29], Loss: 1.4104\n",
      "Epoch [13/300], Step [13/29], Loss: 1.2464\n",
      "Epoch [13/300], Step [14/29], Loss: 1.2685\n",
      "Epoch [13/300], Step [15/29], Loss: 1.3271\n",
      "Epoch [13/300], Step [16/29], Loss: 1.2216\n",
      "Epoch [13/300], Step [17/29], Loss: 1.3194\n",
      "Epoch [13/300], Step [18/29], Loss: 1.1678\n",
      "Epoch [13/300], Step [19/29], Loss: 1.1911\n",
      "Epoch [13/300], Step [20/29], Loss: 1.4687\n",
      "Epoch [13/300], Step [21/29], Loss: 1.2069\n",
      "Epoch [13/300], Step [22/29], Loss: 1.3348\n",
      "Epoch [13/300], Step [23/29], Loss: 1.3363\n",
      "Epoch [13/300], Step [24/29], Loss: 1.0950\n",
      "Epoch [13/300], Step [25/29], Loss: 1.2705\n",
      "Epoch [13/300], Step [26/29], Loss: 1.3610\n",
      "Epoch [13/300], Step [27/29], Loss: 1.3286\n",
      "Epoch [13/300], Step [28/29], Loss: 1.3760\n",
      "Epoch [13/300], Step [29/29], Loss: 2.2943\n",
      "Epoch [14/300], Step [1/29], Loss: 1.4362\n",
      "Epoch [14/300], Step [2/29], Loss: 1.1830\n",
      "Epoch [14/300], Step [3/29], Loss: 1.2081\n",
      "Epoch [14/300], Step [4/29], Loss: 1.3355\n",
      "Epoch [14/300], Step [5/29], Loss: 1.0572\n",
      "Epoch [14/300], Step [6/29], Loss: 1.2323\n",
      "Epoch [14/300], Step [7/29], Loss: 1.4297\n",
      "Epoch [14/300], Step [8/29], Loss: 1.2015\n",
      "Epoch [14/300], Step [9/29], Loss: 1.1034\n",
      "Epoch [14/300], Step [10/29], Loss: 1.2739\n",
      "Epoch [14/300], Step [11/29], Loss: 1.2679\n",
      "Epoch [14/300], Step [12/29], Loss: 1.3961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [13/29], Loss: 1.3361\n",
      "Epoch [14/300], Step [14/29], Loss: 1.4433\n",
      "Epoch [14/300], Step [15/29], Loss: 1.4490\n",
      "Epoch [14/300], Step [16/29], Loss: 1.2924\n",
      "Epoch [14/300], Step [17/29], Loss: 1.3262\n",
      "Epoch [14/300], Step [18/29], Loss: 1.4027\n",
      "Epoch [14/300], Step [19/29], Loss: 1.3442\n",
      "Epoch [14/300], Step [20/29], Loss: 1.3795\n",
      "Epoch [14/300], Step [21/29], Loss: 1.3116\n",
      "Epoch [14/300], Step [22/29], Loss: 1.0071\n",
      "Epoch [14/300], Step [23/29], Loss: 1.4567\n",
      "Epoch [14/300], Step [24/29], Loss: 1.3693\n",
      "Epoch [14/300], Step [25/29], Loss: 1.0610\n",
      "Epoch [14/300], Step [26/29], Loss: 1.2301\n",
      "Epoch [14/300], Step [27/29], Loss: 1.1959\n",
      "Epoch [14/300], Step [28/29], Loss: 1.3383\n",
      "Epoch [14/300], Step [29/29], Loss: 1.6856\n",
      "Epoch [15/300], Step [1/29], Loss: 1.4193\n",
      "Epoch [15/300], Step [2/29], Loss: 1.2162\n",
      "Epoch [15/300], Step [3/29], Loss: 1.3700\n",
      "Epoch [15/300], Step [4/29], Loss: 1.4245\n",
      "Epoch [15/300], Step [5/29], Loss: 0.9123\n",
      "Epoch [15/300], Step [6/29], Loss: 1.3893\n",
      "Epoch [15/300], Step [7/29], Loss: 1.1495\n",
      "Epoch [15/300], Step [8/29], Loss: 1.3161\n",
      "Epoch [15/300], Step [9/29], Loss: 1.6646\n",
      "Epoch [15/300], Step [10/29], Loss: 1.1980\n",
      "Epoch [15/300], Step [11/29], Loss: 1.2537\n",
      "Epoch [15/300], Step [12/29], Loss: 1.4119\n",
      "Epoch [15/300], Step [13/29], Loss: 1.3484\n",
      "Epoch [15/300], Step [14/29], Loss: 1.2667\n",
      "Epoch [15/300], Step [15/29], Loss: 1.3071\n",
      "Epoch [15/300], Step [16/29], Loss: 1.2490\n",
      "Epoch [15/300], Step [17/29], Loss: 1.3046\n",
      "Epoch [15/300], Step [18/29], Loss: 1.1206\n",
      "Epoch [15/300], Step [19/29], Loss: 1.3476\n",
      "Epoch [15/300], Step [20/29], Loss: 1.1941\n",
      "Epoch [15/300], Step [21/29], Loss: 1.2162\n",
      "Epoch [15/300], Step [22/29], Loss: 1.1979\n",
      "Epoch [15/300], Step [23/29], Loss: 1.4443\n",
      "Epoch [15/300], Step [24/29], Loss: 1.4262\n",
      "Epoch [15/300], Step [25/29], Loss: 1.2122\n",
      "Epoch [15/300], Step [26/29], Loss: 1.4436\n",
      "Epoch [15/300], Step [27/29], Loss: 1.1437\n",
      "Epoch [15/300], Step [28/29], Loss: 1.4656\n",
      "Epoch [15/300], Step [29/29], Loss: 1.6890\n",
      "Epoch [16/300], Step [1/29], Loss: 1.1051\n",
      "Epoch [16/300], Step [2/29], Loss: 1.2936\n",
      "Epoch [16/300], Step [3/29], Loss: 1.6379\n",
      "Epoch [16/300], Step [4/29], Loss: 1.2856\n",
      "Epoch [16/300], Step [5/29], Loss: 1.0486\n",
      "Epoch [16/300], Step [6/29], Loss: 1.4491\n",
      "Epoch [16/300], Step [7/29], Loss: 1.3284\n",
      "Epoch [16/300], Step [8/29], Loss: 1.3763\n",
      "Epoch [16/300], Step [9/29], Loss: 1.3366\n",
      "Epoch [16/300], Step [10/29], Loss: 1.0362\n",
      "Epoch [16/300], Step [11/29], Loss: 1.2854\n",
      "Epoch [16/300], Step [12/29], Loss: 0.9965\n",
      "Epoch [16/300], Step [13/29], Loss: 1.3066\n",
      "Epoch [16/300], Step [14/29], Loss: 1.2051\n",
      "Epoch [16/300], Step [15/29], Loss: 1.5088\n",
      "Epoch [16/300], Step [16/29], Loss: 1.4245\n",
      "Epoch [16/300], Step [17/29], Loss: 1.3285\n",
      "Epoch [16/300], Step [18/29], Loss: 1.4530\n",
      "Epoch [16/300], Step [19/29], Loss: 1.0655\n",
      "Epoch [16/300], Step [20/29], Loss: 1.4302\n",
      "Epoch [16/300], Step [21/29], Loss: 1.1127\n",
      "Epoch [16/300], Step [22/29], Loss: 1.2283\n",
      "Epoch [16/300], Step [23/29], Loss: 1.4681\n",
      "Epoch [16/300], Step [24/29], Loss: 1.4329\n",
      "Epoch [16/300], Step [25/29], Loss: 1.3699\n",
      "Epoch [16/300], Step [26/29], Loss: 1.5486\n",
      "Epoch [16/300], Step [27/29], Loss: 1.2200\n",
      "Epoch [16/300], Step [28/29], Loss: 1.1531\n",
      "Epoch [16/300], Step [29/29], Loss: 1.1513\n",
      "Epoch [17/300], Step [1/29], Loss: 1.2659\n",
      "Epoch [17/300], Step [2/29], Loss: 1.1981\n",
      "Epoch [17/300], Step [3/29], Loss: 1.3731\n",
      "Epoch [17/300], Step [4/29], Loss: 1.3041\n",
      "Epoch [17/300], Step [5/29], Loss: 1.7137\n",
      "Epoch [17/300], Step [6/29], Loss: 1.2299\n",
      "Epoch [17/300], Step [7/29], Loss: 1.3047\n",
      "Epoch [17/300], Step [8/29], Loss: 1.2597\n",
      "Epoch [17/300], Step [9/29], Loss: 1.2197\n",
      "Epoch [17/300], Step [10/29], Loss: 1.2241\n",
      "Epoch [17/300], Step [11/29], Loss: 1.3043\n",
      "Epoch [17/300], Step [12/29], Loss: 1.2343\n",
      "Epoch [17/300], Step [13/29], Loss: 1.2615\n",
      "Epoch [17/300], Step [14/29], Loss: 1.0251\n",
      "Epoch [17/300], Step [15/29], Loss: 1.2264\n",
      "Epoch [17/300], Step [16/29], Loss: 1.4421\n",
      "Epoch [17/300], Step [17/29], Loss: 1.2424\n",
      "Epoch [17/300], Step [18/29], Loss: 1.1328\n",
      "Epoch [17/300], Step [19/29], Loss: 1.5252\n",
      "Epoch [17/300], Step [20/29], Loss: 1.2359\n",
      "Epoch [17/300], Step [21/29], Loss: 1.2737\n",
      "Epoch [17/300], Step [22/29], Loss: 1.1641\n",
      "Epoch [17/300], Step [23/29], Loss: 1.2612\n",
      "Epoch [17/300], Step [24/29], Loss: 1.4034\n",
      "Epoch [17/300], Step [25/29], Loss: 1.2562\n",
      "Epoch [17/300], Step [26/29], Loss: 1.2825\n",
      "Epoch [17/300], Step [27/29], Loss: 1.3100\n",
      "Epoch [17/300], Step [28/29], Loss: 1.3123\n",
      "Epoch [17/300], Step [29/29], Loss: 0.5591\n",
      "Epoch [18/300], Step [1/29], Loss: 1.4034\n",
      "Epoch [18/300], Step [2/29], Loss: 1.2423\n",
      "Epoch [18/300], Step [3/29], Loss: 1.5484\n",
      "Epoch [18/300], Step [4/29], Loss: 1.6959\n",
      "Epoch [18/300], Step [5/29], Loss: 1.3704\n",
      "Epoch [18/300], Step [6/29], Loss: 1.3861\n",
      "Epoch [18/300], Step [7/29], Loss: 1.3703\n",
      "Epoch [18/300], Step [8/29], Loss: 1.3385\n",
      "Epoch [18/300], Step [9/29], Loss: 1.4842\n",
      "Epoch [18/300], Step [10/29], Loss: 1.1208\n",
      "Epoch [18/300], Step [11/29], Loss: 1.1757\n",
      "Epoch [18/300], Step [12/29], Loss: 1.1009\n",
      "Epoch [18/300], Step [13/29], Loss: 1.0141\n",
      "Epoch [18/300], Step [14/29], Loss: 1.1742\n",
      "Epoch [18/300], Step [15/29], Loss: 1.2960\n",
      "Epoch [18/300], Step [16/29], Loss: 1.3183\n",
      "Epoch [18/300], Step [17/29], Loss: 1.3947\n",
      "Epoch [18/300], Step [18/29], Loss: 1.1111\n",
      "Epoch [18/300], Step [19/29], Loss: 1.2492\n",
      "Epoch [18/300], Step [20/29], Loss: 1.2530\n",
      "Epoch [18/300], Step [21/29], Loss: 1.4185\n",
      "Epoch [18/300], Step [22/29], Loss: 1.2433\n",
      "Epoch [18/300], Step [23/29], Loss: 1.3965\n",
      "Epoch [18/300], Step [24/29], Loss: 1.2743\n",
      "Epoch [18/300], Step [25/29], Loss: 1.5282\n",
      "Epoch [18/300], Step [26/29], Loss: 1.0997\n",
      "Epoch [18/300], Step [27/29], Loss: 1.0763\n",
      "Epoch [18/300], Step [28/29], Loss: 1.1844\n",
      "Epoch [18/300], Step [29/29], Loss: 2.8472\n",
      "Epoch [19/300], Step [1/29], Loss: 1.2568\n",
      "Epoch [19/300], Step [2/29], Loss: 1.3753\n",
      "Epoch [19/300], Step [3/29], Loss: 1.3641\n",
      "Epoch [19/300], Step [4/29], Loss: 1.2882\n",
      "Epoch [19/300], Step [5/29], Loss: 1.2338\n",
      "Epoch [19/300], Step [6/29], Loss: 1.3439\n",
      "Epoch [19/300], Step [7/29], Loss: 1.1304\n",
      "Epoch [19/300], Step [8/29], Loss: 1.4364\n",
      "Epoch [19/300], Step [9/29], Loss: 1.4747\n",
      "Epoch [19/300], Step [10/29], Loss: 1.3443\n",
      "Epoch [19/300], Step [11/29], Loss: 1.0846\n",
      "Epoch [19/300], Step [12/29], Loss: 1.2705\n",
      "Epoch [19/300], Step [13/29], Loss: 1.6141\n",
      "Epoch [19/300], Step [14/29], Loss: 1.0277\n",
      "Epoch [19/300], Step [15/29], Loss: 1.4696\n",
      "Epoch [19/300], Step [16/29], Loss: 1.2877\n",
      "Epoch [19/300], Step [17/29], Loss: 1.3106\n",
      "Epoch [19/300], Step [18/29], Loss: 1.1804\n",
      "Epoch [19/300], Step [19/29], Loss: 1.4951\n",
      "Epoch [19/300], Step [20/29], Loss: 1.4470\n",
      "Epoch [19/300], Step [21/29], Loss: 1.2990\n",
      "Epoch [19/300], Step [22/29], Loss: 1.3585\n",
      "Epoch [19/300], Step [23/29], Loss: 1.1306\n",
      "Epoch [19/300], Step [24/29], Loss: 1.4158\n",
      "Epoch [19/300], Step [25/29], Loss: 1.1563\n",
      "Epoch [19/300], Step [26/29], Loss: 1.0327\n",
      "Epoch [19/300], Step [27/29], Loss: 1.0423\n",
      "Epoch [19/300], Step [28/29], Loss: 1.0823\n",
      "Epoch [19/300], Step [29/29], Loss: 0.5188\n",
      "Epoch [20/300], Step [1/29], Loss: 1.1620\n",
      "Epoch [20/300], Step [2/29], Loss: 1.5127\n",
      "Epoch [20/300], Step [3/29], Loss: 1.2353\n",
      "Epoch [20/300], Step [4/29], Loss: 1.2454\n",
      "Epoch [20/300], Step [5/29], Loss: 1.2710\n",
      "Epoch [20/300], Step [6/29], Loss: 1.4178\n",
      "Epoch [20/300], Step [7/29], Loss: 1.3856\n",
      "Epoch [20/300], Step [8/29], Loss: 1.2203\n",
      "Epoch [20/300], Step [9/29], Loss: 1.4067\n",
      "Epoch [20/300], Step [10/29], Loss: 0.9869\n",
      "Epoch [20/300], Step [11/29], Loss: 1.1005\n",
      "Epoch [20/300], Step [12/29], Loss: 1.1810\n",
      "Epoch [20/300], Step [13/29], Loss: 1.2214\n",
      "Epoch [20/300], Step [14/29], Loss: 1.1982\n",
      "Epoch [20/300], Step [15/29], Loss: 1.4238\n",
      "Epoch [20/300], Step [16/29], Loss: 1.4767\n",
      "Epoch [20/300], Step [17/29], Loss: 1.4479\n",
      "Epoch [20/300], Step [18/29], Loss: 1.4898\n",
      "Epoch [20/300], Step [19/29], Loss: 1.2428\n",
      "Epoch [20/300], Step [20/29], Loss: 1.3810\n",
      "Epoch [20/300], Step [21/29], Loss: 1.1046\n",
      "Epoch [20/300], Step [22/29], Loss: 1.1512\n",
      "Epoch [20/300], Step [23/29], Loss: 1.4555\n",
      "Epoch [20/300], Step [24/29], Loss: 1.2115\n",
      "Epoch [20/300], Step [25/29], Loss: 1.4104\n",
      "Epoch [20/300], Step [26/29], Loss: 1.2751\n",
      "Epoch [20/300], Step [27/29], Loss: 1.3138\n",
      "Epoch [20/300], Step [28/29], Loss: 1.2365\n",
      "Epoch [20/300], Step [29/29], Loss: 1.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [1/29], Loss: 1.3517\n",
      "Epoch [21/300], Step [2/29], Loss: 1.3144\n",
      "Epoch [21/300], Step [3/29], Loss: 1.3266\n",
      "Epoch [21/300], Step [4/29], Loss: 1.1300\n",
      "Epoch [21/300], Step [5/29], Loss: 1.2400\n",
      "Epoch [21/300], Step [6/29], Loss: 1.2839\n",
      "Epoch [21/300], Step [7/29], Loss: 1.1822\n",
      "Epoch [21/300], Step [8/29], Loss: 1.3052\n",
      "Epoch [21/300], Step [9/29], Loss: 1.4266\n",
      "Epoch [21/300], Step [10/29], Loss: 1.4071\n",
      "Epoch [21/300], Step [11/29], Loss: 1.3331\n",
      "Epoch [21/300], Step [12/29], Loss: 1.4272\n",
      "Epoch [21/300], Step [13/29], Loss: 0.9486\n",
      "Epoch [21/300], Step [14/29], Loss: 1.4996\n",
      "Epoch [21/300], Step [15/29], Loss: 1.2539\n",
      "Epoch [21/300], Step [16/29], Loss: 1.4329\n",
      "Epoch [21/300], Step [17/29], Loss: 1.3642\n",
      "Epoch [21/300], Step [18/29], Loss: 1.2706\n",
      "Epoch [21/300], Step [19/29], Loss: 1.3980\n",
      "Epoch [21/300], Step [20/29], Loss: 1.3921\n",
      "Epoch [21/300], Step [21/29], Loss: 1.1221\n",
      "Epoch [21/300], Step [22/29], Loss: 1.1559\n",
      "Epoch [21/300], Step [23/29], Loss: 1.2513\n",
      "Epoch [21/300], Step [24/29], Loss: 1.3092\n",
      "Epoch [21/300], Step [25/29], Loss: 1.2333\n",
      "Epoch [21/300], Step [26/29], Loss: 1.2301\n",
      "Epoch [21/300], Step [27/29], Loss: 1.1820\n",
      "Epoch [21/300], Step [28/29], Loss: 1.3899\n",
      "Epoch [21/300], Step [29/29], Loss: 0.7022\n",
      "Epoch [22/300], Step [1/29], Loss: 1.6014\n",
      "Epoch [22/300], Step [2/29], Loss: 1.2685\n",
      "Epoch [22/300], Step [3/29], Loss: 1.2500\n",
      "Epoch [22/300], Step [4/29], Loss: 1.5291\n",
      "Epoch [22/300], Step [5/29], Loss: 1.2126\n",
      "Epoch [22/300], Step [6/29], Loss: 1.2671\n",
      "Epoch [22/300], Step [7/29], Loss: 1.2728\n",
      "Epoch [22/300], Step [8/29], Loss: 1.2075\n",
      "Epoch [22/300], Step [9/29], Loss: 1.0848\n",
      "Epoch [22/300], Step [10/29], Loss: 1.2720\n",
      "Epoch [22/300], Step [11/29], Loss: 1.4760\n",
      "Epoch [22/300], Step [12/29], Loss: 1.1008\n",
      "Epoch [22/300], Step [13/29], Loss: 1.3988\n",
      "Epoch [22/300], Step [14/29], Loss: 1.3647\n",
      "Epoch [22/300], Step [15/29], Loss: 1.3426\n",
      "Epoch [22/300], Step [16/29], Loss: 1.3578\n",
      "Epoch [22/300], Step [17/29], Loss: 1.1534\n",
      "Epoch [22/300], Step [18/29], Loss: 1.4161\n",
      "Epoch [22/300], Step [19/29], Loss: 1.2239\n",
      "Epoch [22/300], Step [20/29], Loss: 1.3036\n",
      "Epoch [22/300], Step [21/29], Loss: 1.2287\n",
      "Epoch [22/300], Step [22/29], Loss: 1.2711\n",
      "Epoch [22/300], Step [23/29], Loss: 1.0859\n",
      "Epoch [22/300], Step [24/29], Loss: 1.2121\n",
      "Epoch [22/300], Step [25/29], Loss: 1.4340\n",
      "Epoch [22/300], Step [26/29], Loss: 1.3603\n",
      "Epoch [22/300], Step [27/29], Loss: 1.3766\n",
      "Epoch [22/300], Step [28/29], Loss: 1.1638\n",
      "Epoch [22/300], Step [29/29], Loss: 1.5060\n",
      "Epoch [23/300], Step [1/29], Loss: 1.1273\n",
      "Epoch [23/300], Step [2/29], Loss: 1.3020\n",
      "Epoch [23/300], Step [3/29], Loss: 1.2835\n",
      "Epoch [23/300], Step [4/29], Loss: 1.2840\n",
      "Epoch [23/300], Step [5/29], Loss: 1.4810\n",
      "Epoch [23/300], Step [6/29], Loss: 1.2294\n",
      "Epoch [23/300], Step [7/29], Loss: 1.3082\n",
      "Epoch [23/300], Step [8/29], Loss: 1.1993\n",
      "Epoch [23/300], Step [9/29], Loss: 1.1122\n",
      "Epoch [23/300], Step [10/29], Loss: 1.1886\n",
      "Epoch [23/300], Step [11/29], Loss: 1.4978\n",
      "Epoch [23/300], Step [12/29], Loss: 1.0133\n",
      "Epoch [23/300], Step [13/29], Loss: 1.1625\n",
      "Epoch [23/300], Step [14/29], Loss: 1.1850\n",
      "Epoch [23/300], Step [15/29], Loss: 1.1776\n",
      "Epoch [23/300], Step [16/29], Loss: 1.1904\n",
      "Epoch [23/300], Step [17/29], Loss: 1.2623\n",
      "Epoch [23/300], Step [18/29], Loss: 1.3398\n",
      "Epoch [23/300], Step [19/29], Loss: 1.1990\n",
      "Epoch [23/300], Step [20/29], Loss: 1.3443\n",
      "Epoch [23/300], Step [21/29], Loss: 1.4059\n",
      "Epoch [23/300], Step [22/29], Loss: 1.4597\n",
      "Epoch [23/300], Step [23/29], Loss: 1.1491\n",
      "Epoch [23/300], Step [24/29], Loss: 1.3622\n",
      "Epoch [23/300], Step [25/29], Loss: 1.3534\n",
      "Epoch [23/300], Step [26/29], Loss: 1.4208\n",
      "Epoch [23/300], Step [27/29], Loss: 1.0244\n",
      "Epoch [23/300], Step [28/29], Loss: 1.4353\n",
      "Epoch [23/300], Step [29/29], Loss: 0.8494\n",
      "Epoch [24/300], Step [1/29], Loss: 1.4343\n",
      "Epoch [24/300], Step [2/29], Loss: 1.3515\n",
      "Epoch [24/300], Step [3/29], Loss: 1.2011\n",
      "Epoch [24/300], Step [4/29], Loss: 1.1059\n",
      "Epoch [24/300], Step [5/29], Loss: 1.3077\n",
      "Epoch [24/300], Step [6/29], Loss: 1.1229\n",
      "Epoch [24/300], Step [7/29], Loss: 1.5799\n",
      "Epoch [24/300], Step [8/29], Loss: 1.2484\n",
      "Epoch [24/300], Step [9/29], Loss: 1.3712\n",
      "Epoch [24/300], Step [10/29], Loss: 1.1720\n",
      "Epoch [24/300], Step [11/29], Loss: 1.3504\n",
      "Epoch [24/300], Step [12/29], Loss: 1.2646\n",
      "Epoch [24/300], Step [13/29], Loss: 1.1734\n",
      "Epoch [24/300], Step [14/29], Loss: 1.1284\n",
      "Epoch [24/300], Step [15/29], Loss: 1.6216\n",
      "Epoch [24/300], Step [16/29], Loss: 1.2112\n",
      "Epoch [24/300], Step [17/29], Loss: 1.3844\n",
      "Epoch [24/300], Step [18/29], Loss: 1.0657\n",
      "Epoch [24/300], Step [19/29], Loss: 1.0057\n",
      "Epoch [24/300], Step [20/29], Loss: 1.2266\n",
      "Epoch [24/300], Step [21/29], Loss: 1.5423\n",
      "Epoch [24/300], Step [22/29], Loss: 1.3189\n",
      "Epoch [24/300], Step [23/29], Loss: 1.4239\n",
      "Epoch [24/300], Step [24/29], Loss: 1.2892\n",
      "Epoch [24/300], Step [25/29], Loss: 1.1157\n",
      "Epoch [24/300], Step [26/29], Loss: 1.5710\n",
      "Epoch [24/300], Step [27/29], Loss: 1.2074\n",
      "Epoch [24/300], Step [28/29], Loss: 1.3477\n",
      "Epoch [24/300], Step [29/29], Loss: 2.0970\n",
      "Epoch [25/300], Step [1/29], Loss: 1.4140\n",
      "Epoch [25/300], Step [2/29], Loss: 1.1340\n",
      "Epoch [25/300], Step [3/29], Loss: 1.3617\n",
      "Epoch [25/300], Step [4/29], Loss: 1.2874\n",
      "Epoch [25/300], Step [5/29], Loss: 1.3859\n",
      "Epoch [25/300], Step [6/29], Loss: 1.4790\n",
      "Epoch [25/300], Step [7/29], Loss: 1.1990\n",
      "Epoch [25/300], Step [8/29], Loss: 1.1530\n",
      "Epoch [25/300], Step [9/29], Loss: 1.2509\n",
      "Epoch [25/300], Step [10/29], Loss: 1.3080\n",
      "Epoch [25/300], Step [11/29], Loss: 1.5521\n",
      "Epoch [25/300], Step [12/29], Loss: 1.3241\n",
      "Epoch [25/300], Step [13/29], Loss: 1.1461\n",
      "Epoch [25/300], Step [14/29], Loss: 1.5753\n",
      "Epoch [25/300], Step [15/29], Loss: 1.1895\n",
      "Epoch [25/300], Step [16/29], Loss: 1.0940\n",
      "Epoch [25/300], Step [17/29], Loss: 1.2598\n",
      "Epoch [25/300], Step [18/29], Loss: 1.3383\n",
      "Epoch [25/300], Step [19/29], Loss: 1.2836\n",
      "Epoch [25/300], Step [20/29], Loss: 1.3363\n",
      "Epoch [25/300], Step [21/29], Loss: 1.1887\n",
      "Epoch [25/300], Step [22/29], Loss: 1.3817\n",
      "Epoch [25/300], Step [23/29], Loss: 1.3336\n",
      "Epoch [25/300], Step [24/29], Loss: 0.9355\n",
      "Epoch [25/300], Step [25/29], Loss: 1.3837\n",
      "Epoch [25/300], Step [26/29], Loss: 1.4267\n",
      "Epoch [25/300], Step [27/29], Loss: 1.2914\n",
      "Epoch [25/300], Step [28/29], Loss: 1.1991\n",
      "Epoch [25/300], Step [29/29], Loss: 1.7259\n",
      "Epoch [26/300], Step [1/29], Loss: 1.2565\n",
      "Epoch [26/300], Step [2/29], Loss: 1.5412\n",
      "Epoch [26/300], Step [3/29], Loss: 1.3997\n",
      "Epoch [26/300], Step [4/29], Loss: 1.3256\n",
      "Epoch [26/300], Step [5/29], Loss: 1.3047\n",
      "Epoch [26/300], Step [6/29], Loss: 1.2742\n",
      "Epoch [26/300], Step [7/29], Loss: 1.3485\n",
      "Epoch [26/300], Step [8/29], Loss: 1.0943\n",
      "Epoch [26/300], Step [9/29], Loss: 1.3794\n",
      "Epoch [26/300], Step [10/29], Loss: 1.5586\n",
      "Epoch [26/300], Step [11/29], Loss: 1.3658\n",
      "Epoch [26/300], Step [12/29], Loss: 1.1058\n",
      "Epoch [26/300], Step [13/29], Loss: 1.3519\n",
      "Epoch [26/300], Step [14/29], Loss: 1.1030\n",
      "Epoch [26/300], Step [15/29], Loss: 1.3052\n",
      "Epoch [26/300], Step [16/29], Loss: 1.2066\n",
      "Epoch [26/300], Step [17/29], Loss: 1.3317\n",
      "Epoch [26/300], Step [18/29], Loss: 1.2044\n",
      "Epoch [26/300], Step [19/29], Loss: 1.2505\n",
      "Epoch [26/300], Step [20/29], Loss: 1.2665\n",
      "Epoch [26/300], Step [21/29], Loss: 1.3775\n",
      "Epoch [26/300], Step [22/29], Loss: 1.4325\n",
      "Epoch [26/300], Step [23/29], Loss: 1.3136\n",
      "Epoch [26/300], Step [24/29], Loss: 1.3336\n",
      "Epoch [26/300], Step [25/29], Loss: 1.2566\n",
      "Epoch [26/300], Step [26/29], Loss: 1.2453\n",
      "Epoch [26/300], Step [27/29], Loss: 1.1517\n",
      "Epoch [26/300], Step [28/29], Loss: 1.3389\n",
      "Epoch [26/300], Step [29/29], Loss: 2.9038\n",
      "Epoch [27/300], Step [1/29], Loss: 1.2758\n",
      "Epoch [27/300], Step [2/29], Loss: 1.1816\n",
      "Epoch [27/300], Step [3/29], Loss: 1.1656\n",
      "Epoch [27/300], Step [4/29], Loss: 1.2312\n",
      "Epoch [27/300], Step [5/29], Loss: 1.2192\n",
      "Epoch [27/300], Step [6/29], Loss: 1.3594\n",
      "Epoch [27/300], Step [7/29], Loss: 1.3808\n",
      "Epoch [27/300], Step [8/29], Loss: 1.1728\n",
      "Epoch [27/300], Step [9/29], Loss: 1.4201\n",
      "Epoch [27/300], Step [10/29], Loss: 1.2355\n",
      "Epoch [27/300], Step [11/29], Loss: 1.1828\n",
      "Epoch [27/300], Step [12/29], Loss: 1.4038\n",
      "Epoch [27/300], Step [13/29], Loss: 1.2164\n",
      "Epoch [27/300], Step [14/29], Loss: 1.2337\n",
      "Epoch [27/300], Step [15/29], Loss: 1.3337\n",
      "Epoch [27/300], Step [16/29], Loss: 1.3246\n",
      "Epoch [27/300], Step [17/29], Loss: 1.3534\n",
      "Epoch [27/300], Step [18/29], Loss: 1.3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [19/29], Loss: 1.5007\n",
      "Epoch [27/300], Step [20/29], Loss: 1.2886\n",
      "Epoch [27/300], Step [21/29], Loss: 1.0714\n",
      "Epoch [27/300], Step [22/29], Loss: 1.3707\n",
      "Epoch [27/300], Step [23/29], Loss: 1.3179\n",
      "Epoch [27/300], Step [24/29], Loss: 1.2923\n",
      "Epoch [27/300], Step [25/29], Loss: 1.1597\n",
      "Epoch [27/300], Step [26/29], Loss: 1.3015\n",
      "Epoch [27/300], Step [27/29], Loss: 1.3121\n",
      "Epoch [27/300], Step [28/29], Loss: 1.2056\n",
      "Epoch [27/300], Step [29/29], Loss: 1.5996\n",
      "Epoch [28/300], Step [1/29], Loss: 1.3486\n",
      "Epoch [28/300], Step [2/29], Loss: 1.1710\n",
      "Epoch [28/300], Step [3/29], Loss: 1.4043\n",
      "Epoch [28/300], Step [4/29], Loss: 1.3039\n",
      "Epoch [28/300], Step [5/29], Loss: 1.4908\n",
      "Epoch [28/300], Step [6/29], Loss: 1.4124\n",
      "Epoch [28/300], Step [7/29], Loss: 1.1557\n",
      "Epoch [28/300], Step [8/29], Loss: 1.3351\n",
      "Epoch [28/300], Step [9/29], Loss: 1.2671\n",
      "Epoch [28/300], Step [10/29], Loss: 1.2637\n",
      "Epoch [28/300], Step [11/29], Loss: 1.1148\n",
      "Epoch [28/300], Step [12/29], Loss: 1.3539\n",
      "Epoch [28/300], Step [13/29], Loss: 1.3629\n",
      "Epoch [28/300], Step [14/29], Loss: 1.1902\n",
      "Epoch [28/300], Step [15/29], Loss: 1.6596\n",
      "Epoch [28/300], Step [16/29], Loss: 1.0847\n",
      "Epoch [28/300], Step [17/29], Loss: 1.2179\n",
      "Epoch [28/300], Step [18/29], Loss: 1.4065\n",
      "Epoch [28/300], Step [19/29], Loss: 1.5263\n",
      "Epoch [28/300], Step [20/29], Loss: 1.3585\n",
      "Epoch [28/300], Step [21/29], Loss: 1.2213\n",
      "Epoch [28/300], Step [22/29], Loss: 1.2753\n",
      "Epoch [28/300], Step [23/29], Loss: 1.3336\n",
      "Epoch [28/300], Step [24/29], Loss: 1.1865\n",
      "Epoch [28/300], Step [25/29], Loss: 1.4175\n",
      "Epoch [28/300], Step [26/29], Loss: 1.2383\n",
      "Epoch [28/300], Step [27/29], Loss: 1.0623\n",
      "Epoch [28/300], Step [28/29], Loss: 1.1032\n",
      "Epoch [28/300], Step [29/29], Loss: 1.5472\n",
      "Epoch [29/300], Step [1/29], Loss: 1.0187\n",
      "Epoch [29/300], Step [2/29], Loss: 1.4089\n",
      "Epoch [29/300], Step [3/29], Loss: 1.2294\n",
      "Epoch [29/300], Step [4/29], Loss: 1.1638\n",
      "Epoch [29/300], Step [5/29], Loss: 1.2264\n",
      "Epoch [29/300], Step [6/29], Loss: 1.3670\n",
      "Epoch [29/300], Step [7/29], Loss: 1.2650\n",
      "Epoch [29/300], Step [8/29], Loss: 1.4254\n",
      "Epoch [29/300], Step [9/29], Loss: 1.2367\n",
      "Epoch [29/300], Step [10/29], Loss: 1.0073\n",
      "Epoch [29/300], Step [11/29], Loss: 1.2562\n",
      "Epoch [29/300], Step [12/29], Loss: 1.4098\n",
      "Epoch [29/300], Step [13/29], Loss: 1.4725\n",
      "Epoch [29/300], Step [14/29], Loss: 1.2459\n",
      "Epoch [29/300], Step [15/29], Loss: 1.1935\n",
      "Epoch [29/300], Step [16/29], Loss: 1.6153\n",
      "Epoch [29/300], Step [17/29], Loss: 1.1869\n",
      "Epoch [29/300], Step [18/29], Loss: 1.2556\n",
      "Epoch [29/300], Step [19/29], Loss: 1.4370\n",
      "Epoch [29/300], Step [20/29], Loss: 1.2408\n",
      "Epoch [29/300], Step [21/29], Loss: 1.2782\n",
      "Epoch [29/300], Step [22/29], Loss: 1.4260\n",
      "Epoch [29/300], Step [23/29], Loss: 1.2118\n",
      "Epoch [29/300], Step [24/29], Loss: 1.1054\n",
      "Epoch [29/300], Step [25/29], Loss: 1.1758\n",
      "Epoch [29/300], Step [26/29], Loss: 1.3090\n",
      "Epoch [29/300], Step [27/29], Loss: 1.5005\n",
      "Epoch [29/300], Step [28/29], Loss: 1.4994\n",
      "Epoch [29/300], Step [29/29], Loss: 1.6350\n",
      "Epoch [30/300], Step [1/29], Loss: 1.2931\n",
      "Epoch [30/300], Step [2/29], Loss: 1.5820\n",
      "Epoch [30/300], Step [3/29], Loss: 1.4284\n",
      "Epoch [30/300], Step [4/29], Loss: 1.2978\n",
      "Epoch [30/300], Step [5/29], Loss: 1.3344\n",
      "Epoch [30/300], Step [6/29], Loss: 1.2268\n",
      "Epoch [30/300], Step [7/29], Loss: 1.1623\n",
      "Epoch [30/300], Step [8/29], Loss: 1.4673\n",
      "Epoch [30/300], Step [9/29], Loss: 1.2493\n",
      "Epoch [30/300], Step [10/29], Loss: 1.1252\n",
      "Epoch [30/300], Step [11/29], Loss: 1.1858\n",
      "Epoch [30/300], Step [12/29], Loss: 1.2798\n",
      "Epoch [30/300], Step [13/29], Loss: 1.1386\n",
      "Epoch [30/300], Step [14/29], Loss: 1.2230\n",
      "Epoch [30/300], Step [15/29], Loss: 1.1594\n",
      "Epoch [30/300], Step [16/29], Loss: 1.2884\n",
      "Epoch [30/300], Step [17/29], Loss: 1.4163\n",
      "Epoch [30/300], Step [18/29], Loss: 1.4515\n",
      "Epoch [30/300], Step [19/29], Loss: 1.3802\n",
      "Epoch [30/300], Step [20/29], Loss: 1.2041\n",
      "Epoch [30/300], Step [21/29], Loss: 1.4333\n",
      "Epoch [30/300], Step [22/29], Loss: 1.3961\n",
      "Epoch [30/300], Step [23/29], Loss: 1.2726\n",
      "Epoch [30/300], Step [24/29], Loss: 1.0917\n",
      "Epoch [30/300], Step [25/29], Loss: 1.4259\n",
      "Epoch [30/300], Step [26/29], Loss: 1.0590\n",
      "Epoch [30/300], Step [27/29], Loss: 1.2592\n",
      "Epoch [30/300], Step [28/29], Loss: 1.3770\n",
      "Epoch [30/300], Step [29/29], Loss: 0.9014\n",
      "Epoch [31/300], Step [1/29], Loss: 1.3903\n",
      "Epoch [31/300], Step [2/29], Loss: 1.3029\n",
      "Epoch [31/300], Step [3/29], Loss: 1.1902\n",
      "Epoch [31/300], Step [4/29], Loss: 1.3209\n",
      "Epoch [31/300], Step [5/29], Loss: 1.4441\n",
      "Epoch [31/300], Step [6/29], Loss: 1.2439\n",
      "Epoch [31/300], Step [7/29], Loss: 1.4438\n",
      "Epoch [31/300], Step [8/29], Loss: 1.3518\n",
      "Epoch [31/300], Step [9/29], Loss: 1.2425\n",
      "Epoch [31/300], Step [10/29], Loss: 1.0084\n",
      "Epoch [31/300], Step [11/29], Loss: 1.2893\n",
      "Epoch [31/300], Step [12/29], Loss: 1.4422\n",
      "Epoch [31/300], Step [13/29], Loss: 1.1905\n",
      "Epoch [31/300], Step [14/29], Loss: 1.4099\n",
      "Epoch [31/300], Step [15/29], Loss: 1.2339\n",
      "Epoch [31/300], Step [16/29], Loss: 1.2107\n",
      "Epoch [31/300], Step [17/29], Loss: 1.3789\n",
      "Epoch [31/300], Step [18/29], Loss: 1.3660\n",
      "Epoch [31/300], Step [19/29], Loss: 1.3873\n",
      "Epoch [31/300], Step [20/29], Loss: 1.4526\n",
      "Epoch [31/300], Step [21/29], Loss: 1.0408\n",
      "Epoch [31/300], Step [22/29], Loss: 1.4008\n",
      "Epoch [31/300], Step [23/29], Loss: 1.1642\n",
      "Epoch [31/300], Step [24/29], Loss: 1.3118\n",
      "Epoch [31/300], Step [25/29], Loss: 1.0686\n",
      "Epoch [31/300], Step [26/29], Loss: 1.3415\n",
      "Epoch [31/300], Step [27/29], Loss: 1.1523\n",
      "Epoch [31/300], Step [28/29], Loss: 1.2522\n",
      "Epoch [31/300], Step [29/29], Loss: 1.2021\n",
      "Epoch [32/300], Step [1/29], Loss: 1.2955\n",
      "Epoch [32/300], Step [2/29], Loss: 1.2990\n",
      "Epoch [32/300], Step [3/29], Loss: 1.2459\n",
      "Epoch [32/300], Step [4/29], Loss: 1.4471\n",
      "Epoch [32/300], Step [5/29], Loss: 1.0773\n",
      "Epoch [32/300], Step [6/29], Loss: 1.4272\n",
      "Epoch [32/300], Step [7/29], Loss: 1.2127\n",
      "Epoch [32/300], Step [8/29], Loss: 1.2290\n",
      "Epoch [32/300], Step [9/29], Loss: 1.6119\n",
      "Epoch [32/300], Step [10/29], Loss: 1.1728\n",
      "Epoch [32/300], Step [11/29], Loss: 1.3406\n",
      "Epoch [32/300], Step [12/29], Loss: 1.1686\n",
      "Epoch [32/300], Step [13/29], Loss: 1.2284\n",
      "Epoch [32/300], Step [14/29], Loss: 1.3487\n",
      "Epoch [32/300], Step [15/29], Loss: 1.0668\n",
      "Epoch [32/300], Step [16/29], Loss: 1.1583\n",
      "Epoch [32/300], Step [17/29], Loss: 1.3754\n",
      "Epoch [32/300], Step [18/29], Loss: 1.2143\n",
      "Epoch [32/300], Step [19/29], Loss: 1.0872\n",
      "Epoch [32/300], Step [20/29], Loss: 1.4502\n",
      "Epoch [32/300], Step [21/29], Loss: 1.2591\n",
      "Epoch [32/300], Step [22/29], Loss: 1.2723\n",
      "Epoch [32/300], Step [23/29], Loss: 1.5158\n",
      "Epoch [32/300], Step [24/29], Loss: 1.7573\n",
      "Epoch [32/300], Step [25/29], Loss: 1.5888\n",
      "Epoch [32/300], Step [26/29], Loss: 1.0890\n",
      "Epoch [32/300], Step [27/29], Loss: 1.2861\n",
      "Epoch [32/300], Step [28/29], Loss: 1.2155\n",
      "Epoch [32/300], Step [29/29], Loss: 0.4786\n",
      "Epoch [33/300], Step [1/29], Loss: 1.1820\n",
      "Epoch [33/300], Step [2/29], Loss: 1.2946\n",
      "Epoch [33/300], Step [3/29], Loss: 1.2219\n",
      "Epoch [33/300], Step [4/29], Loss: 1.6793\n",
      "Epoch [33/300], Step [5/29], Loss: 1.2163\n",
      "Epoch [33/300], Step [6/29], Loss: 1.2315\n",
      "Epoch [33/300], Step [7/29], Loss: 1.0718\n",
      "Epoch [33/300], Step [8/29], Loss: 1.3593\n",
      "Epoch [33/300], Step [9/29], Loss: 1.4670\n",
      "Epoch [33/300], Step [10/29], Loss: 1.2499\n",
      "Epoch [33/300], Step [11/29], Loss: 1.3717\n",
      "Epoch [33/300], Step [12/29], Loss: 1.4043\n",
      "Epoch [33/300], Step [13/29], Loss: 1.1888\n",
      "Epoch [33/300], Step [14/29], Loss: 1.3301\n",
      "Epoch [33/300], Step [15/29], Loss: 1.3165\n",
      "Epoch [33/300], Step [16/29], Loss: 1.4510\n",
      "Epoch [33/300], Step [17/29], Loss: 1.3510\n",
      "Epoch [33/300], Step [18/29], Loss: 1.3563\n",
      "Epoch [33/300], Step [19/29], Loss: 1.3711\n",
      "Epoch [33/300], Step [20/29], Loss: 1.2615\n",
      "Epoch [33/300], Step [21/29], Loss: 1.3007\n",
      "Epoch [33/300], Step [22/29], Loss: 1.3550\n",
      "Epoch [33/300], Step [23/29], Loss: 1.2008\n",
      "Epoch [33/300], Step [24/29], Loss: 1.1285\n",
      "Epoch [33/300], Step [25/29], Loss: 1.0735\n",
      "Epoch [33/300], Step [26/29], Loss: 1.1856\n",
      "Epoch [33/300], Step [27/29], Loss: 1.2334\n",
      "Epoch [33/300], Step [28/29], Loss: 1.2509\n",
      "Epoch [33/300], Step [29/29], Loss: 0.5275\n",
      "Epoch [34/300], Step [1/29], Loss: 1.1035\n",
      "Epoch [34/300], Step [2/29], Loss: 1.3514\n",
      "Epoch [34/300], Step [3/29], Loss: 1.5233\n",
      "Epoch [34/300], Step [4/29], Loss: 1.2862\n",
      "Epoch [34/300], Step [5/29], Loss: 1.1873\n",
      "Epoch [34/300], Step [6/29], Loss: 1.3017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [7/29], Loss: 1.4658\n",
      "Epoch [34/300], Step [8/29], Loss: 1.3689\n",
      "Epoch [34/300], Step [9/29], Loss: 1.4243\n",
      "Epoch [34/300], Step [10/29], Loss: 1.4695\n",
      "Epoch [34/300], Step [11/29], Loss: 1.5179\n",
      "Epoch [34/300], Step [12/29], Loss: 1.1592\n",
      "Epoch [34/300], Step [13/29], Loss: 1.2742\n",
      "Epoch [34/300], Step [14/29], Loss: 1.2115\n",
      "Epoch [34/300], Step [15/29], Loss: 1.2734\n",
      "Epoch [34/300], Step [16/29], Loss: 1.4523\n",
      "Epoch [34/300], Step [17/29], Loss: 1.3452\n",
      "Epoch [34/300], Step [18/29], Loss: 1.2491\n",
      "Epoch [34/300], Step [19/29], Loss: 1.0560\n",
      "Epoch [34/300], Step [20/29], Loss: 1.4785\n",
      "Epoch [34/300], Step [21/29], Loss: 1.2710\n",
      "Epoch [34/300], Step [22/29], Loss: 1.1944\n",
      "Epoch [34/300], Step [23/29], Loss: 1.1817\n",
      "Epoch [34/300], Step [24/29], Loss: 1.0639\n",
      "Epoch [34/300], Step [25/29], Loss: 1.3069\n",
      "Epoch [34/300], Step [26/29], Loss: 1.2563\n",
      "Epoch [34/300], Step [27/29], Loss: 1.2284\n",
      "Epoch [34/300], Step [28/29], Loss: 1.3024\n",
      "Epoch [34/300], Step [29/29], Loss: 0.7850\n",
      "Epoch [35/300], Step [1/29], Loss: 1.4582\n",
      "Epoch [35/300], Step [2/29], Loss: 1.3399\n",
      "Epoch [35/300], Step [3/29], Loss: 1.3351\n",
      "Epoch [35/300], Step [4/29], Loss: 1.2079\n",
      "Epoch [35/300], Step [5/29], Loss: 1.1168\n",
      "Epoch [35/300], Step [6/29], Loss: 1.2204\n",
      "Epoch [35/300], Step [7/29], Loss: 1.1906\n",
      "Epoch [35/300], Step [8/29], Loss: 1.3783\n",
      "Epoch [35/300], Step [9/29], Loss: 1.2179\n",
      "Epoch [35/300], Step [10/29], Loss: 1.3187\n",
      "Epoch [35/300], Step [11/29], Loss: 1.2039\n",
      "Epoch [35/300], Step [12/29], Loss: 1.2884\n",
      "Epoch [35/300], Step [13/29], Loss: 1.3880\n",
      "Epoch [35/300], Step [14/29], Loss: 1.4358\n",
      "Epoch [35/300], Step [15/29], Loss: 1.3543\n",
      "Epoch [35/300], Step [16/29], Loss: 0.9858\n",
      "Epoch [35/300], Step [17/29], Loss: 1.2012\n",
      "Epoch [35/300], Step [18/29], Loss: 1.2403\n",
      "Epoch [35/300], Step [19/29], Loss: 1.3204\n",
      "Epoch [35/300], Step [20/29], Loss: 1.4955\n",
      "Epoch [35/300], Step [21/29], Loss: 1.3239\n",
      "Epoch [35/300], Step [22/29], Loss: 1.2679\n",
      "Epoch [35/300], Step [23/29], Loss: 1.1276\n",
      "Epoch [35/300], Step [24/29], Loss: 1.2422\n",
      "Epoch [35/300], Step [25/29], Loss: 1.4302\n",
      "Epoch [35/300], Step [26/29], Loss: 1.3825\n",
      "Epoch [35/300], Step [27/29], Loss: 1.3948\n",
      "Epoch [35/300], Step [28/29], Loss: 1.3640\n",
      "Epoch [35/300], Step [29/29], Loss: 1.9878\n",
      "Epoch [36/300], Step [1/29], Loss: 1.3203\n",
      "Epoch [36/300], Step [2/29], Loss: 1.2199\n",
      "Epoch [36/300], Step [3/29], Loss: 0.9985\n",
      "Epoch [36/300], Step [4/29], Loss: 1.4439\n",
      "Epoch [36/300], Step [5/29], Loss: 1.2893\n",
      "Epoch [36/300], Step [6/29], Loss: 1.1980\n",
      "Epoch [36/300], Step [7/29], Loss: 1.2871\n",
      "Epoch [36/300], Step [8/29], Loss: 1.3320\n",
      "Epoch [36/300], Step [9/29], Loss: 1.2566\n",
      "Epoch [36/300], Step [10/29], Loss: 1.4409\n",
      "Epoch [36/300], Step [11/29], Loss: 1.2468\n",
      "Epoch [36/300], Step [12/29], Loss: 1.2221\n",
      "Epoch [36/300], Step [13/29], Loss: 1.2906\n",
      "Epoch [36/300], Step [14/29], Loss: 1.2758\n",
      "Epoch [36/300], Step [15/29], Loss: 1.0072\n",
      "Epoch [36/300], Step [16/29], Loss: 1.4523\n",
      "Epoch [36/300], Step [17/29], Loss: 1.4520\n",
      "Epoch [36/300], Step [18/29], Loss: 1.2938\n",
      "Epoch [36/300], Step [19/29], Loss: 1.1430\n",
      "Epoch [36/300], Step [20/29], Loss: 1.2775\n",
      "Epoch [36/300], Step [21/29], Loss: 1.3423\n",
      "Epoch [36/300], Step [22/29], Loss: 1.4550\n",
      "Epoch [36/300], Step [23/29], Loss: 1.0263\n",
      "Epoch [36/300], Step [24/29], Loss: 1.1143\n",
      "Epoch [36/300], Step [25/29], Loss: 1.1871\n",
      "Epoch [36/300], Step [26/29], Loss: 1.4113\n",
      "Epoch [36/300], Step [27/29], Loss: 1.6431\n",
      "Epoch [36/300], Step [28/29], Loss: 1.2778\n",
      "Epoch [36/300], Step [29/29], Loss: 0.4197\n",
      "Epoch [37/300], Step [1/29], Loss: 1.3592\n",
      "Epoch [37/300], Step [2/29], Loss: 1.3502\n",
      "Epoch [37/300], Step [3/29], Loss: 1.2969\n",
      "Epoch [37/300], Step [4/29], Loss: 1.1550\n",
      "Epoch [37/300], Step [5/29], Loss: 1.1468\n",
      "Epoch [37/300], Step [6/29], Loss: 1.3186\n",
      "Epoch [37/300], Step [7/29], Loss: 1.3387\n",
      "Epoch [37/300], Step [8/29], Loss: 1.3024\n",
      "Epoch [37/300], Step [9/29], Loss: 1.0676\n",
      "Epoch [37/300], Step [10/29], Loss: 1.4492\n",
      "Epoch [37/300], Step [11/29], Loss: 1.5558\n",
      "Epoch [37/300], Step [12/29], Loss: 1.1642\n",
      "Epoch [37/300], Step [13/29], Loss: 1.1785\n",
      "Epoch [37/300], Step [14/29], Loss: 1.4118\n",
      "Epoch [37/300], Step [15/29], Loss: 1.1283\n",
      "Epoch [37/300], Step [16/29], Loss: 1.5050\n",
      "Epoch [37/300], Step [17/29], Loss: 1.5541\n",
      "Epoch [37/300], Step [18/29], Loss: 1.3260\n",
      "Epoch [37/300], Step [19/29], Loss: 1.4242\n",
      "Epoch [37/300], Step [20/29], Loss: 1.0282\n",
      "Epoch [37/300], Step [21/29], Loss: 1.2508\n",
      "Epoch [37/300], Step [22/29], Loss: 1.1647\n",
      "Epoch [37/300], Step [23/29], Loss: 1.2518\n",
      "Epoch [37/300], Step [24/29], Loss: 1.5547\n",
      "Epoch [37/300], Step [25/29], Loss: 1.3455\n",
      "Epoch [37/300], Step [26/29], Loss: 1.2362\n",
      "Epoch [37/300], Step [27/29], Loss: 1.3014\n",
      "Epoch [37/300], Step [28/29], Loss: 1.3106\n",
      "Epoch [37/300], Step [29/29], Loss: 1.2917\n",
      "Epoch [38/300], Step [1/29], Loss: 1.1723\n",
      "Epoch [38/300], Step [2/29], Loss: 1.0944\n",
      "Epoch [38/300], Step [3/29], Loss: 1.1646\n",
      "Epoch [38/300], Step [4/29], Loss: 1.0895\n",
      "Epoch [38/300], Step [5/29], Loss: 1.1743\n",
      "Epoch [38/300], Step [6/29], Loss: 1.1446\n",
      "Epoch [38/300], Step [7/29], Loss: 1.3905\n",
      "Epoch [38/300], Step [8/29], Loss: 1.4350\n",
      "Epoch [38/300], Step [9/29], Loss: 1.0652\n",
      "Epoch [38/300], Step [10/29], Loss: 1.5043\n",
      "Epoch [38/300], Step [11/29], Loss: 1.4539\n",
      "Epoch [38/300], Step [12/29], Loss: 1.1954\n",
      "Epoch [38/300], Step [13/29], Loss: 1.3973\n",
      "Epoch [38/300], Step [14/29], Loss: 1.3960\n",
      "Epoch [38/300], Step [15/29], Loss: 1.1967\n",
      "Epoch [38/300], Step [16/29], Loss: 1.3988\n",
      "Epoch [38/300], Step [17/29], Loss: 1.4315\n",
      "Epoch [38/300], Step [18/29], Loss: 1.2505\n",
      "Epoch [38/300], Step [19/29], Loss: 1.1730\n",
      "Epoch [38/300], Step [20/29], Loss: 1.5430\n",
      "Epoch [38/300], Step [21/29], Loss: 1.4914\n",
      "Epoch [38/300], Step [22/29], Loss: 1.2728\n",
      "Epoch [38/300], Step [23/29], Loss: 1.2529\n",
      "Epoch [38/300], Step [24/29], Loss: 1.2432\n",
      "Epoch [38/300], Step [25/29], Loss: 1.3847\n",
      "Epoch [38/300], Step [26/29], Loss: 1.5918\n",
      "Epoch [38/300], Step [27/29], Loss: 1.1463\n",
      "Epoch [38/300], Step [28/29], Loss: 1.3752\n",
      "Epoch [38/300], Step [29/29], Loss: 1.3479\n",
      "Epoch [39/300], Step [1/29], Loss: 0.9524\n",
      "Epoch [39/300], Step [2/29], Loss: 1.6249\n",
      "Epoch [39/300], Step [3/29], Loss: 1.3060\n",
      "Epoch [39/300], Step [4/29], Loss: 1.3886\n",
      "Epoch [39/300], Step [5/29], Loss: 1.3430\n",
      "Epoch [39/300], Step [6/29], Loss: 1.4130\n",
      "Epoch [39/300], Step [7/29], Loss: 1.3488\n",
      "Epoch [39/300], Step [8/29], Loss: 1.2687\n",
      "Epoch [39/300], Step [9/29], Loss: 1.5051\n",
      "Epoch [39/300], Step [10/29], Loss: 1.0702\n",
      "Epoch [39/300], Step [11/29], Loss: 1.1424\n",
      "Epoch [39/300], Step [12/29], Loss: 1.4029\n",
      "Epoch [39/300], Step [13/29], Loss: 1.1700\n",
      "Epoch [39/300], Step [14/29], Loss: 1.1520\n",
      "Epoch [39/300], Step [15/29], Loss: 1.1773\n",
      "Epoch [39/300], Step [16/29], Loss: 1.2589\n",
      "Epoch [39/300], Step [17/29], Loss: 1.5032\n",
      "Epoch [39/300], Step [18/29], Loss: 1.2692\n",
      "Epoch [39/300], Step [19/29], Loss: 1.3255\n",
      "Epoch [39/300], Step [20/29], Loss: 1.3960\n",
      "Epoch [39/300], Step [21/29], Loss: 1.4221\n",
      "Epoch [39/300], Step [22/29], Loss: 1.1214\n",
      "Epoch [39/300], Step [23/29], Loss: 1.3457\n",
      "Epoch [39/300], Step [24/29], Loss: 1.1615\n",
      "Epoch [39/300], Step [25/29], Loss: 1.1718\n",
      "Epoch [39/300], Step [26/29], Loss: 1.2196\n",
      "Epoch [39/300], Step [27/29], Loss: 1.3539\n",
      "Epoch [39/300], Step [28/29], Loss: 1.2518\n",
      "Epoch [39/300], Step [29/29], Loss: 1.7082\n",
      "Epoch [40/300], Step [1/29], Loss: 1.1832\n",
      "Epoch [40/300], Step [2/29], Loss: 1.2028\n",
      "Epoch [40/300], Step [3/29], Loss: 1.2506\n",
      "Epoch [40/300], Step [4/29], Loss: 1.3008\n",
      "Epoch [40/300], Step [5/29], Loss: 1.5217\n",
      "Epoch [40/300], Step [6/29], Loss: 1.4537\n",
      "Epoch [40/300], Step [7/29], Loss: 1.3959\n",
      "Epoch [40/300], Step [8/29], Loss: 1.0983\n",
      "Epoch [40/300], Step [9/29], Loss: 1.2333\n",
      "Epoch [40/300], Step [10/29], Loss: 1.2835\n",
      "Epoch [40/300], Step [11/29], Loss: 1.4590\n",
      "Epoch [40/300], Step [12/29], Loss: 1.0352\n",
      "Epoch [40/300], Step [13/29], Loss: 1.2509\n",
      "Epoch [40/300], Step [14/29], Loss: 1.3365\n",
      "Epoch [40/300], Step [15/29], Loss: 1.2556\n",
      "Epoch [40/300], Step [16/29], Loss: 1.4730\n",
      "Epoch [40/300], Step [17/29], Loss: 1.4369\n",
      "Epoch [40/300], Step [18/29], Loss: 1.6350\n",
      "Epoch [40/300], Step [19/29], Loss: 1.0768\n",
      "Epoch [40/300], Step [20/29], Loss: 1.0191\n",
      "Epoch [40/300], Step [21/29], Loss: 1.3801\n",
      "Epoch [40/300], Step [22/29], Loss: 1.4993\n",
      "Epoch [40/300], Step [23/29], Loss: 1.3267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [24/29], Loss: 1.4545\n",
      "Epoch [40/300], Step [25/29], Loss: 1.2671\n",
      "Epoch [40/300], Step [26/29], Loss: 1.1412\n",
      "Epoch [40/300], Step [27/29], Loss: 1.2863\n",
      "Epoch [40/300], Step [28/29], Loss: 1.2051\n",
      "Epoch [40/300], Step [29/29], Loss: 1.7996\n",
      "Epoch [41/300], Step [1/29], Loss: 1.1272\n",
      "Epoch [41/300], Step [2/29], Loss: 1.2357\n",
      "Epoch [41/300], Step [3/29], Loss: 1.7859\n",
      "Epoch [41/300], Step [4/29], Loss: 1.3081\n",
      "Epoch [41/300], Step [5/29], Loss: 1.1541\n",
      "Epoch [41/300], Step [6/29], Loss: 1.5719\n",
      "Epoch [41/300], Step [7/29], Loss: 1.1841\n",
      "Epoch [41/300], Step [8/29], Loss: 1.1843\n",
      "Epoch [41/300], Step [9/29], Loss: 1.4533\n",
      "Epoch [41/300], Step [10/29], Loss: 1.2888\n",
      "Epoch [41/300], Step [11/29], Loss: 1.3677\n",
      "Epoch [41/300], Step [12/29], Loss: 1.3209\n",
      "Epoch [41/300], Step [13/29], Loss: 1.0425\n",
      "Epoch [41/300], Step [14/29], Loss: 1.1043\n",
      "Epoch [41/300], Step [15/29], Loss: 1.3898\n",
      "Epoch [41/300], Step [16/29], Loss: 1.3379\n",
      "Epoch [41/300], Step [17/29], Loss: 1.4197\n",
      "Epoch [41/300], Step [18/29], Loss: 1.1982\n",
      "Epoch [41/300], Step [19/29], Loss: 1.2484\n",
      "Epoch [41/300], Step [20/29], Loss: 1.5136\n",
      "Epoch [41/300], Step [21/29], Loss: 1.1743\n",
      "Epoch [41/300], Step [22/29], Loss: 1.1855\n",
      "Epoch [41/300], Step [23/29], Loss: 1.2778\n",
      "Epoch [41/300], Step [24/29], Loss: 1.2107\n",
      "Epoch [41/300], Step [25/29], Loss: 1.3252\n",
      "Epoch [41/300], Step [26/29], Loss: 1.1714\n",
      "Epoch [41/300], Step [27/29], Loss: 1.2893\n",
      "Epoch [41/300], Step [28/29], Loss: 1.3973\n",
      "Epoch [41/300], Step [29/29], Loss: 0.6500\n",
      "Epoch [42/300], Step [1/29], Loss: 1.4654\n",
      "Epoch [42/300], Step [2/29], Loss: 1.2873\n",
      "Epoch [42/300], Step [3/29], Loss: 1.0735\n",
      "Epoch [42/300], Step [4/29], Loss: 1.2171\n",
      "Epoch [42/300], Step [5/29], Loss: 1.0471\n",
      "Epoch [42/300], Step [6/29], Loss: 1.4035\n",
      "Epoch [42/300], Step [7/29], Loss: 1.3125\n",
      "Epoch [42/300], Step [8/29], Loss: 1.2901\n",
      "Epoch [42/300], Step [9/29], Loss: 1.0937\n",
      "Epoch [42/300], Step [10/29], Loss: 1.4586\n",
      "Epoch [42/300], Step [11/29], Loss: 1.1532\n",
      "Epoch [42/300], Step [12/29], Loss: 1.5243\n",
      "Epoch [42/300], Step [13/29], Loss: 1.0808\n",
      "Epoch [42/300], Step [14/29], Loss: 1.1855\n",
      "Epoch [42/300], Step [15/29], Loss: 1.2413\n",
      "Epoch [42/300], Step [16/29], Loss: 1.2210\n",
      "Epoch [42/300], Step [17/29], Loss: 1.1145\n",
      "Epoch [42/300], Step [18/29], Loss: 1.2846\n",
      "Epoch [42/300], Step [19/29], Loss: 1.5440\n",
      "Epoch [42/300], Step [20/29], Loss: 1.3144\n",
      "Epoch [42/300], Step [21/29], Loss: 1.2339\n",
      "Epoch [42/300], Step [22/29], Loss: 1.2414\n",
      "Epoch [42/300], Step [23/29], Loss: 1.5859\n",
      "Epoch [42/300], Step [24/29], Loss: 1.3263\n",
      "Epoch [42/300], Step [25/29], Loss: 1.2908\n",
      "Epoch [42/300], Step [26/29], Loss: 1.6181\n",
      "Epoch [42/300], Step [27/29], Loss: 1.2773\n",
      "Epoch [42/300], Step [28/29], Loss: 1.5012\n",
      "Epoch [42/300], Step [29/29], Loss: 0.6785\n",
      "Epoch [43/300], Step [1/29], Loss: 1.3258\n",
      "Epoch [43/300], Step [2/29], Loss: 1.4831\n",
      "Epoch [43/300], Step [3/29], Loss: 1.2541\n",
      "Epoch [43/300], Step [4/29], Loss: 1.3000\n",
      "Epoch [43/300], Step [5/29], Loss: 1.2848\n",
      "Epoch [43/300], Step [6/29], Loss: 1.3479\n",
      "Epoch [43/300], Step [7/29], Loss: 1.4113\n",
      "Epoch [43/300], Step [8/29], Loss: 1.3145\n",
      "Epoch [43/300], Step [9/29], Loss: 1.3496\n",
      "Epoch [43/300], Step [10/29], Loss: 1.0967\n",
      "Epoch [43/300], Step [11/29], Loss: 1.3982\n",
      "Epoch [43/300], Step [12/29], Loss: 1.1830\n",
      "Epoch [43/300], Step [13/29], Loss: 1.2908\n",
      "Epoch [43/300], Step [14/29], Loss: 1.5507\n",
      "Epoch [43/300], Step [15/29], Loss: 0.9530\n",
      "Epoch [43/300], Step [16/29], Loss: 1.4207\n",
      "Epoch [43/300], Step [17/29], Loss: 1.3354\n",
      "Epoch [43/300], Step [18/29], Loss: 1.3178\n",
      "Epoch [43/300], Step [19/29], Loss: 1.2896\n",
      "Epoch [43/300], Step [20/29], Loss: 1.3701\n",
      "Epoch [43/300], Step [21/29], Loss: 1.1297\n",
      "Epoch [43/300], Step [22/29], Loss: 1.3472\n",
      "Epoch [43/300], Step [23/29], Loss: 1.3350\n",
      "Epoch [43/300], Step [24/29], Loss: 1.3557\n",
      "Epoch [43/300], Step [25/29], Loss: 1.2573\n",
      "Epoch [43/300], Step [26/29], Loss: 1.1062\n",
      "Epoch [43/300], Step [27/29], Loss: 1.4004\n",
      "Epoch [43/300], Step [28/29], Loss: 1.1865\n",
      "Epoch [43/300], Step [29/29], Loss: 1.0723\n",
      "Epoch [44/300], Step [1/29], Loss: 1.3345\n",
      "Epoch [44/300], Step [2/29], Loss: 1.5145\n",
      "Epoch [44/300], Step [3/29], Loss: 1.2079\n",
      "Epoch [44/300], Step [4/29], Loss: 1.3133\n",
      "Epoch [44/300], Step [5/29], Loss: 1.3923\n",
      "Epoch [44/300], Step [6/29], Loss: 1.1231\n",
      "Epoch [44/300], Step [7/29], Loss: 1.2839\n",
      "Epoch [44/300], Step [8/29], Loss: 1.4499\n",
      "Epoch [44/300], Step [9/29], Loss: 1.4484\n",
      "Epoch [44/300], Step [10/29], Loss: 1.1886\n",
      "Epoch [44/300], Step [11/29], Loss: 0.9978\n",
      "Epoch [44/300], Step [12/29], Loss: 1.2882\n",
      "Epoch [44/300], Step [13/29], Loss: 1.0417\n",
      "Epoch [44/300], Step [14/29], Loss: 1.2387\n",
      "Epoch [44/300], Step [15/29], Loss: 1.5938\n",
      "Epoch [44/300], Step [16/29], Loss: 1.3606\n",
      "Epoch [44/300], Step [17/29], Loss: 1.0369\n",
      "Epoch [44/300], Step [18/29], Loss: 1.4023\n",
      "Epoch [44/300], Step [19/29], Loss: 1.2648\n",
      "Epoch [44/300], Step [20/29], Loss: 1.4478\n",
      "Epoch [44/300], Step [21/29], Loss: 1.0689\n",
      "Epoch [44/300], Step [22/29], Loss: 1.2950\n",
      "Epoch [44/300], Step [23/29], Loss: 1.1515\n",
      "Epoch [44/300], Step [24/29], Loss: 1.6957\n",
      "Epoch [44/300], Step [25/29], Loss: 1.2024\n",
      "Epoch [44/300], Step [26/29], Loss: 1.1830\n",
      "Epoch [44/300], Step [27/29], Loss: 1.4009\n",
      "Epoch [44/300], Step [28/29], Loss: 1.4187\n",
      "Epoch [44/300], Step [29/29], Loss: 2.3060\n",
      "Epoch [45/300], Step [1/29], Loss: 1.4292\n",
      "Epoch [45/300], Step [2/29], Loss: 1.3017\n",
      "Epoch [45/300], Step [3/29], Loss: 1.2249\n",
      "Epoch [45/300], Step [4/29], Loss: 1.2624\n",
      "Epoch [45/300], Step [5/29], Loss: 1.1836\n",
      "Epoch [45/300], Step [6/29], Loss: 1.4116\n",
      "Epoch [45/300], Step [7/29], Loss: 1.0816\n",
      "Epoch [45/300], Step [8/29], Loss: 1.2468\n",
      "Epoch [45/300], Step [9/29], Loss: 1.3605\n",
      "Epoch [45/300], Step [10/29], Loss: 1.1169\n",
      "Epoch [45/300], Step [11/29], Loss: 1.5302\n",
      "Epoch [45/300], Step [12/29], Loss: 1.3044\n",
      "Epoch [45/300], Step [13/29], Loss: 1.3161\n",
      "Epoch [45/300], Step [14/29], Loss: 1.3691\n",
      "Epoch [45/300], Step [15/29], Loss: 1.3296\n",
      "Epoch [45/300], Step [16/29], Loss: 1.3558\n",
      "Epoch [45/300], Step [17/29], Loss: 1.2519\n",
      "Epoch [45/300], Step [18/29], Loss: 1.4407\n",
      "Epoch [45/300], Step [19/29], Loss: 1.1724\n",
      "Epoch [45/300], Step [20/29], Loss: 1.4452\n",
      "Epoch [45/300], Step [21/29], Loss: 1.1498\n",
      "Epoch [45/300], Step [22/29], Loss: 1.1200\n",
      "Epoch [45/300], Step [23/29], Loss: 1.3889\n",
      "Epoch [45/300], Step [24/29], Loss: 1.2990\n",
      "Epoch [45/300], Step [25/29], Loss: 1.4694\n",
      "Epoch [45/300], Step [26/29], Loss: 1.2780\n",
      "Epoch [45/300], Step [27/29], Loss: 1.1896\n",
      "Epoch [45/300], Step [28/29], Loss: 1.2659\n",
      "Epoch [45/300], Step [29/29], Loss: 1.4354\n",
      "Epoch [46/300], Step [1/29], Loss: 1.1993\n",
      "Epoch [46/300], Step [2/29], Loss: 1.3032\n",
      "Epoch [46/300], Step [3/29], Loss: 1.1661\n",
      "Epoch [46/300], Step [4/29], Loss: 1.3629\n",
      "Epoch [46/300], Step [5/29], Loss: 1.2886\n",
      "Epoch [46/300], Step [6/29], Loss: 1.3104\n",
      "Epoch [46/300], Step [7/29], Loss: 1.2584\n",
      "Epoch [46/300], Step [8/29], Loss: 1.1363\n",
      "Epoch [46/300], Step [9/29], Loss: 1.1208\n",
      "Epoch [46/300], Step [10/29], Loss: 1.2856\n",
      "Epoch [46/300], Step [11/29], Loss: 1.3318\n",
      "Epoch [46/300], Step [12/29], Loss: 1.3386\n",
      "Epoch [46/300], Step [13/29], Loss: 1.4681\n",
      "Epoch [46/300], Step [14/29], Loss: 1.2202\n",
      "Epoch [46/300], Step [15/29], Loss: 1.5256\n",
      "Epoch [46/300], Step [16/29], Loss: 1.3743\n",
      "Epoch [46/300], Step [17/29], Loss: 1.1039\n",
      "Epoch [46/300], Step [18/29], Loss: 1.2427\n",
      "Epoch [46/300], Step [19/29], Loss: 1.1737\n",
      "Epoch [46/300], Step [20/29], Loss: 1.2845\n",
      "Epoch [46/300], Step [21/29], Loss: 1.2443\n",
      "Epoch [46/300], Step [22/29], Loss: 1.2952\n",
      "Epoch [46/300], Step [23/29], Loss: 1.1874\n",
      "Epoch [46/300], Step [24/29], Loss: 1.6221\n",
      "Epoch [46/300], Step [25/29], Loss: 1.4498\n",
      "Epoch [46/300], Step [26/29], Loss: 1.2648\n",
      "Epoch [46/300], Step [27/29], Loss: 1.3617\n",
      "Epoch [46/300], Step [28/29], Loss: 1.3154\n",
      "Epoch [46/300], Step [29/29], Loss: 0.9959\n",
      "Epoch [47/300], Step [1/29], Loss: 1.5298\n",
      "Epoch [47/300], Step [2/29], Loss: 1.1341\n",
      "Epoch [47/300], Step [3/29], Loss: 1.3080\n",
      "Epoch [47/300], Step [4/29], Loss: 1.2685\n",
      "Epoch [47/300], Step [5/29], Loss: 1.4780\n",
      "Epoch [47/300], Step [6/29], Loss: 1.3976\n",
      "Epoch [47/300], Step [7/29], Loss: 1.1104\n",
      "Epoch [47/300], Step [8/29], Loss: 1.6319\n",
      "Epoch [47/300], Step [9/29], Loss: 1.3833\n",
      "Epoch [47/300], Step [10/29], Loss: 1.0887\n",
      "Epoch [47/300], Step [11/29], Loss: 1.3796\n",
      "Epoch [47/300], Step [12/29], Loss: 1.4355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [13/29], Loss: 1.4512\n",
      "Epoch [47/300], Step [14/29], Loss: 1.2821\n",
      "Epoch [47/300], Step [15/29], Loss: 1.3218\n",
      "Epoch [47/300], Step [16/29], Loss: 1.3775\n",
      "Epoch [47/300], Step [17/29], Loss: 1.1985\n",
      "Epoch [47/300], Step [18/29], Loss: 1.1354\n",
      "Epoch [47/300], Step [19/29], Loss: 1.2544\n",
      "Epoch [47/300], Step [20/29], Loss: 1.5297\n",
      "Epoch [47/300], Step [21/29], Loss: 1.1283\n",
      "Epoch [47/300], Step [22/29], Loss: 1.1691\n",
      "Epoch [47/300], Step [23/29], Loss: 1.0957\n",
      "Epoch [47/300], Step [24/29], Loss: 1.2593\n",
      "Epoch [47/300], Step [25/29], Loss: 1.0563\n",
      "Epoch [47/300], Step [26/29], Loss: 1.4063\n",
      "Epoch [47/300], Step [27/29], Loss: 1.1061\n",
      "Epoch [47/300], Step [28/29], Loss: 1.4013\n",
      "Epoch [47/300], Step [29/29], Loss: 1.8770\n",
      "Epoch [48/300], Step [1/29], Loss: 1.3277\n",
      "Epoch [48/300], Step [2/29], Loss: 1.1654\n",
      "Epoch [48/300], Step [3/29], Loss: 1.2454\n",
      "Epoch [48/300], Step [4/29], Loss: 1.2599\n",
      "Epoch [48/300], Step [5/29], Loss: 1.2644\n",
      "Epoch [48/300], Step [6/29], Loss: 1.5409\n",
      "Epoch [48/300], Step [7/29], Loss: 1.2739\n",
      "Epoch [48/300], Step [8/29], Loss: 1.5735\n",
      "Epoch [48/300], Step [9/29], Loss: 1.0330\n",
      "Epoch [48/300], Step [10/29], Loss: 1.4247\n",
      "Epoch [48/300], Step [11/29], Loss: 1.3227\n",
      "Epoch [48/300], Step [12/29], Loss: 1.4502\n",
      "Epoch [48/300], Step [13/29], Loss: 1.3610\n",
      "Epoch [48/300], Step [14/29], Loss: 1.0517\n",
      "Epoch [48/300], Step [15/29], Loss: 1.1430\n",
      "Epoch [48/300], Step [16/29], Loss: 1.4924\n",
      "Epoch [48/300], Step [17/29], Loss: 1.0866\n",
      "Epoch [48/300], Step [18/29], Loss: 1.2999\n",
      "Epoch [48/300], Step [19/29], Loss: 1.3719\n",
      "Epoch [48/300], Step [20/29], Loss: 1.4021\n",
      "Epoch [48/300], Step [21/29], Loss: 1.2278\n",
      "Epoch [48/300], Step [22/29], Loss: 1.4004\n",
      "Epoch [48/300], Step [23/29], Loss: 1.2229\n",
      "Epoch [48/300], Step [24/29], Loss: 1.3085\n",
      "Epoch [48/300], Step [25/29], Loss: 1.2796\n",
      "Epoch [48/300], Step [26/29], Loss: 1.2452\n",
      "Epoch [48/300], Step [27/29], Loss: 1.3249\n",
      "Epoch [48/300], Step [28/29], Loss: 1.2800\n",
      "Epoch [48/300], Step [29/29], Loss: 0.9073\n",
      "Epoch [49/300], Step [1/29], Loss: 1.2274\n",
      "Epoch [49/300], Step [2/29], Loss: 1.0807\n",
      "Epoch [49/300], Step [3/29], Loss: 1.2660\n",
      "Epoch [49/300], Step [4/29], Loss: 1.2411\n",
      "Epoch [49/300], Step [5/29], Loss: 1.1053\n",
      "Epoch [49/300], Step [6/29], Loss: 1.2719\n",
      "Epoch [49/300], Step [7/29], Loss: 1.2725\n",
      "Epoch [49/300], Step [8/29], Loss: 1.6881\n",
      "Epoch [49/300], Step [9/29], Loss: 1.1324\n",
      "Epoch [49/300], Step [10/29], Loss: 1.5699\n",
      "Epoch [49/300], Step [11/29], Loss: 1.5045\n",
      "Epoch [49/300], Step [12/29], Loss: 1.1163\n",
      "Epoch [49/300], Step [13/29], Loss: 1.1411\n",
      "Epoch [49/300], Step [14/29], Loss: 1.1596\n",
      "Epoch [49/300], Step [15/29], Loss: 1.3646\n",
      "Epoch [49/300], Step [16/29], Loss: 1.2379\n",
      "Epoch [49/300], Step [17/29], Loss: 1.4141\n",
      "Epoch [49/300], Step [18/29], Loss: 1.3582\n",
      "Epoch [49/300], Step [19/29], Loss: 1.2826\n",
      "Epoch [49/300], Step [20/29], Loss: 1.3183\n",
      "Epoch [49/300], Step [21/29], Loss: 1.3233\n",
      "Epoch [49/300], Step [22/29], Loss: 1.2854\n",
      "Epoch [49/300], Step [23/29], Loss: 1.2913\n",
      "Epoch [49/300], Step [24/29], Loss: 1.2115\n",
      "Epoch [49/300], Step [25/29], Loss: 1.4339\n",
      "Epoch [49/300], Step [26/29], Loss: 1.4157\n",
      "Epoch [49/300], Step [27/29], Loss: 1.2757\n",
      "Epoch [49/300], Step [28/29], Loss: 1.5783\n",
      "Epoch [49/300], Step [29/29], Loss: 2.9635\n",
      "Epoch [50/300], Step [1/29], Loss: 1.0749\n",
      "Epoch [50/300], Step [2/29], Loss: 1.1736\n",
      "Epoch [50/300], Step [3/29], Loss: 1.6514\n",
      "Epoch [50/300], Step [4/29], Loss: 1.2324\n",
      "Epoch [50/300], Step [5/29], Loss: 1.0975\n",
      "Epoch [50/300], Step [6/29], Loss: 1.2616\n",
      "Epoch [50/300], Step [7/29], Loss: 1.3243\n",
      "Epoch [50/300], Step [8/29], Loss: 1.2727\n",
      "Epoch [50/300], Step [9/29], Loss: 1.2715\n",
      "Epoch [50/300], Step [10/29], Loss: 1.3657\n",
      "Epoch [50/300], Step [11/29], Loss: 1.3068\n",
      "Epoch [50/300], Step [12/29], Loss: 1.1353\n",
      "Epoch [50/300], Step [13/29], Loss: 1.4524\n",
      "Epoch [50/300], Step [14/29], Loss: 1.2967\n",
      "Epoch [50/300], Step [15/29], Loss: 1.4102\n",
      "Epoch [50/300], Step [16/29], Loss: 1.4377\n",
      "Epoch [50/300], Step [17/29], Loss: 1.2820\n",
      "Epoch [50/300], Step [18/29], Loss: 1.2256\n",
      "Epoch [50/300], Step [19/29], Loss: 1.5422\n",
      "Epoch [50/300], Step [20/29], Loss: 1.4929\n",
      "Epoch [50/300], Step [21/29], Loss: 1.3713\n",
      "Epoch [50/300], Step [22/29], Loss: 1.0336\n",
      "Epoch [50/300], Step [23/29], Loss: 1.3658\n",
      "Epoch [50/300], Step [24/29], Loss: 1.3016\n",
      "Epoch [50/300], Step [25/29], Loss: 1.1981\n",
      "Epoch [50/300], Step [26/29], Loss: 1.2125\n",
      "Epoch [50/300], Step [27/29], Loss: 1.1047\n",
      "Epoch [50/300], Step [28/29], Loss: 1.1304\n",
      "Epoch [50/300], Step [29/29], Loss: 1.5285\n",
      "Epoch [51/300], Step [1/29], Loss: 1.1924\n",
      "Epoch [51/300], Step [2/29], Loss: 1.1482\n",
      "Epoch [51/300], Step [3/29], Loss: 1.1903\n",
      "Epoch [51/300], Step [4/29], Loss: 1.1803\n",
      "Epoch [51/300], Step [5/29], Loss: 1.3228\n",
      "Epoch [51/300], Step [6/29], Loss: 1.4712\n",
      "Epoch [51/300], Step [7/29], Loss: 1.2191\n",
      "Epoch [51/300], Step [8/29], Loss: 1.2182\n",
      "Epoch [51/300], Step [9/29], Loss: 1.3647\n",
      "Epoch [51/300], Step [10/29], Loss: 1.1083\n",
      "Epoch [51/300], Step [11/29], Loss: 1.4381\n",
      "Epoch [51/300], Step [12/29], Loss: 1.4434\n",
      "Epoch [51/300], Step [13/29], Loss: 1.1924\n",
      "Epoch [51/300], Step [14/29], Loss: 1.2815\n",
      "Epoch [51/300], Step [15/29], Loss: 1.3326\n",
      "Epoch [51/300], Step [16/29], Loss: 1.3232\n",
      "Epoch [51/300], Step [17/29], Loss: 1.4112\n",
      "Epoch [51/300], Step [18/29], Loss: 1.0350\n",
      "Epoch [51/300], Step [19/29], Loss: 1.3467\n",
      "Epoch [51/300], Step [20/29], Loss: 1.0359\n",
      "Epoch [51/300], Step [21/29], Loss: 1.4321\n",
      "Epoch [51/300], Step [22/29], Loss: 1.3603\n",
      "Epoch [51/300], Step [23/29], Loss: 1.2635\n",
      "Epoch [51/300], Step [24/29], Loss: 1.3150\n",
      "Epoch [51/300], Step [25/29], Loss: 1.4210\n",
      "Epoch [51/300], Step [26/29], Loss: 1.5344\n",
      "Epoch [51/300], Step [27/29], Loss: 1.5120\n",
      "Epoch [51/300], Step [28/29], Loss: 1.2796\n",
      "Epoch [51/300], Step [29/29], Loss: 3.0882\n",
      "Epoch [52/300], Step [1/29], Loss: 1.3257\n",
      "Epoch [52/300], Step [2/29], Loss: 1.2169\n",
      "Epoch [52/300], Step [3/29], Loss: 1.2961\n",
      "Epoch [52/300], Step [4/29], Loss: 1.6875\n",
      "Epoch [52/300], Step [5/29], Loss: 1.0358\n",
      "Epoch [52/300], Step [6/29], Loss: 1.2946\n",
      "Epoch [52/300], Step [7/29], Loss: 1.5931\n",
      "Epoch [52/300], Step [8/29], Loss: 1.4699\n",
      "Epoch [52/300], Step [9/29], Loss: 1.2100\n",
      "Epoch [52/300], Step [10/29], Loss: 1.2539\n",
      "Epoch [52/300], Step [11/29], Loss: 1.1312\n",
      "Epoch [52/300], Step [12/29], Loss: 1.3469\n",
      "Epoch [52/300], Step [13/29], Loss: 1.5016\n",
      "Epoch [52/300], Step [14/29], Loss: 1.4000\n",
      "Epoch [52/300], Step [15/29], Loss: 1.2380\n",
      "Epoch [52/300], Step [16/29], Loss: 1.4660\n",
      "Epoch [52/300], Step [17/29], Loss: 1.2597\n",
      "Epoch [52/300], Step [18/29], Loss: 1.0985\n",
      "Epoch [52/300], Step [19/29], Loss: 1.2031\n",
      "Epoch [52/300], Step [20/29], Loss: 1.0952\n",
      "Epoch [52/300], Step [21/29], Loss: 1.0957\n",
      "Epoch [52/300], Step [22/29], Loss: 1.1549\n",
      "Epoch [52/300], Step [23/29], Loss: 1.1633\n",
      "Epoch [52/300], Step [24/29], Loss: 1.2763\n",
      "Epoch [52/300], Step [25/29], Loss: 1.5819\n",
      "Epoch [52/300], Step [26/29], Loss: 1.3248\n",
      "Epoch [52/300], Step [27/29], Loss: 1.5519\n",
      "Epoch [52/300], Step [28/29], Loss: 1.2364\n",
      "Epoch [52/300], Step [29/29], Loss: 1.0331\n",
      "Epoch [53/300], Step [1/29], Loss: 1.2589\n",
      "Epoch [53/300], Step [2/29], Loss: 1.1774\n",
      "Epoch [53/300], Step [3/29], Loss: 1.1326\n",
      "Epoch [53/300], Step [4/29], Loss: 1.3005\n",
      "Epoch [53/300], Step [5/29], Loss: 1.4596\n",
      "Epoch [53/300], Step [6/29], Loss: 1.3580\n",
      "Epoch [53/300], Step [7/29], Loss: 1.4383\n",
      "Epoch [53/300], Step [8/29], Loss: 1.4603\n",
      "Epoch [53/300], Step [9/29], Loss: 1.5617\n",
      "Epoch [53/300], Step [10/29], Loss: 1.1061\n",
      "Epoch [53/300], Step [11/29], Loss: 1.1112\n",
      "Epoch [53/300], Step [12/29], Loss: 0.9820\n",
      "Epoch [53/300], Step [13/29], Loss: 1.0811\n",
      "Epoch [53/300], Step [14/29], Loss: 1.3626\n",
      "Epoch [53/300], Step [15/29], Loss: 1.5958\n",
      "Epoch [53/300], Step [16/29], Loss: 1.4863\n",
      "Epoch [53/300], Step [17/29], Loss: 1.3207\n",
      "Epoch [53/300], Step [18/29], Loss: 1.2714\n",
      "Epoch [53/300], Step [19/29], Loss: 1.1922\n",
      "Epoch [53/300], Step [20/29], Loss: 1.2844\n",
      "Epoch [53/300], Step [21/29], Loss: 1.2831\n",
      "Epoch [53/300], Step [22/29], Loss: 1.3969\n",
      "Epoch [53/300], Step [23/29], Loss: 1.2588\n",
      "Epoch [53/300], Step [24/29], Loss: 1.4755\n",
      "Epoch [53/300], Step [25/29], Loss: 1.4343\n",
      "Epoch [53/300], Step [26/29], Loss: 1.0331\n",
      "Epoch [53/300], Step [27/29], Loss: 1.3536\n",
      "Epoch [53/300], Step [28/29], Loss: 1.4286\n",
      "Epoch [53/300], Step [29/29], Loss: 0.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [1/29], Loss: 1.3841\n",
      "Epoch [54/300], Step [2/29], Loss: 1.1134\n",
      "Epoch [54/300], Step [3/29], Loss: 1.3749\n",
      "Epoch [54/300], Step [4/29], Loss: 1.2420\n",
      "Epoch [54/300], Step [5/29], Loss: 1.2220\n",
      "Epoch [54/300], Step [6/29], Loss: 1.1283\n",
      "Epoch [54/300], Step [7/29], Loss: 1.2452\n",
      "Epoch [54/300], Step [8/29], Loss: 1.4063\n",
      "Epoch [54/300], Step [9/29], Loss: 1.2479\n",
      "Epoch [54/300], Step [10/29], Loss: 1.2737\n",
      "Epoch [54/300], Step [11/29], Loss: 1.2220\n",
      "Epoch [54/300], Step [12/29], Loss: 1.5032\n",
      "Epoch [54/300], Step [13/29], Loss: 1.4470\n",
      "Epoch [54/300], Step [14/29], Loss: 1.1966\n",
      "Epoch [54/300], Step [15/29], Loss: 1.3008\n",
      "Epoch [54/300], Step [16/29], Loss: 1.4796\n",
      "Epoch [54/300], Step [17/29], Loss: 1.3753\n",
      "Epoch [54/300], Step [18/29], Loss: 1.2887\n",
      "Epoch [54/300], Step [19/29], Loss: 1.1276\n",
      "Epoch [54/300], Step [20/29], Loss: 1.3515\n",
      "Epoch [54/300], Step [21/29], Loss: 1.4265\n",
      "Epoch [54/300], Step [22/29], Loss: 1.5849\n",
      "Epoch [54/300], Step [23/29], Loss: 0.9961\n",
      "Epoch [54/300], Step [24/29], Loss: 1.5172\n",
      "Epoch [54/300], Step [25/29], Loss: 1.2121\n",
      "Epoch [54/300], Step [26/29], Loss: 1.3871\n",
      "Epoch [54/300], Step [27/29], Loss: 1.2902\n",
      "Epoch [54/300], Step [28/29], Loss: 1.1938\n",
      "Epoch [54/300], Step [29/29], Loss: 2.5220\n",
      "Epoch [55/300], Step [1/29], Loss: 1.3112\n",
      "Epoch [55/300], Step [2/29], Loss: 1.2075\n",
      "Epoch [55/300], Step [3/29], Loss: 1.5532\n",
      "Epoch [55/300], Step [4/29], Loss: 1.0711\n",
      "Epoch [55/300], Step [5/29], Loss: 1.0929\n",
      "Epoch [55/300], Step [6/29], Loss: 1.3462\n",
      "Epoch [55/300], Step [7/29], Loss: 1.4647\n",
      "Epoch [55/300], Step [8/29], Loss: 1.2598\n",
      "Epoch [55/300], Step [9/29], Loss: 1.3581\n",
      "Epoch [55/300], Step [10/29], Loss: 1.3368\n",
      "Epoch [55/300], Step [11/29], Loss: 1.3793\n",
      "Epoch [55/300], Step [12/29], Loss: 1.2913\n",
      "Epoch [55/300], Step [13/29], Loss: 1.4171\n",
      "Epoch [55/300], Step [14/29], Loss: 1.3494\n",
      "Epoch [55/300], Step [15/29], Loss: 1.5269\n",
      "Epoch [55/300], Step [16/29], Loss: 1.1917\n",
      "Epoch [55/300], Step [17/29], Loss: 1.1183\n",
      "Epoch [55/300], Step [18/29], Loss: 1.2585\n",
      "Epoch [55/300], Step [19/29], Loss: 1.4358\n",
      "Epoch [55/300], Step [20/29], Loss: 1.2048\n",
      "Epoch [55/300], Step [21/29], Loss: 1.0547\n",
      "Epoch [55/300], Step [22/29], Loss: 1.3992\n",
      "Epoch [55/300], Step [23/29], Loss: 1.1500\n",
      "Epoch [55/300], Step [24/29], Loss: 0.9138\n",
      "Epoch [55/300], Step [25/29], Loss: 1.4571\n",
      "Epoch [55/300], Step [26/29], Loss: 1.3673\n",
      "Epoch [55/300], Step [27/29], Loss: 1.6347\n",
      "Epoch [55/300], Step [28/29], Loss: 1.2149\n",
      "Epoch [55/300], Step [29/29], Loss: 1.6267\n",
      "Epoch [56/300], Step [1/29], Loss: 1.4762\n",
      "Epoch [56/300], Step [2/29], Loss: 1.3710\n",
      "Epoch [56/300], Step [3/29], Loss: 1.5391\n",
      "Epoch [56/300], Step [4/29], Loss: 1.5071\n",
      "Epoch [56/300], Step [5/29], Loss: 1.1901\n",
      "Epoch [56/300], Step [6/29], Loss: 1.2291\n",
      "Epoch [56/300], Step [7/29], Loss: 1.2868\n",
      "Epoch [56/300], Step [8/29], Loss: 1.5504\n",
      "Epoch [56/300], Step [9/29], Loss: 1.2391\n",
      "Epoch [56/300], Step [10/29], Loss: 1.3284\n",
      "Epoch [56/300], Step [11/29], Loss: 1.2169\n",
      "Epoch [56/300], Step [12/29], Loss: 1.1094\n",
      "Epoch [56/300], Step [13/29], Loss: 1.0596\n",
      "Epoch [56/300], Step [14/29], Loss: 1.2455\n",
      "Epoch [56/300], Step [15/29], Loss: 1.1938\n",
      "Epoch [56/300], Step [16/29], Loss: 1.2150\n",
      "Epoch [56/300], Step [17/29], Loss: 1.3222\n",
      "Epoch [56/300], Step [18/29], Loss: 1.0741\n",
      "Epoch [56/300], Step [19/29], Loss: 1.1410\n",
      "Epoch [56/300], Step [20/29], Loss: 1.3307\n",
      "Epoch [56/300], Step [21/29], Loss: 1.3041\n",
      "Epoch [56/300], Step [22/29], Loss: 1.3096\n",
      "Epoch [56/300], Step [23/29], Loss: 1.3042\n",
      "Epoch [56/300], Step [24/29], Loss: 1.4908\n",
      "Epoch [56/300], Step [25/29], Loss: 1.2736\n",
      "Epoch [56/300], Step [26/29], Loss: 1.3109\n",
      "Epoch [56/300], Step [27/29], Loss: 1.2455\n",
      "Epoch [56/300], Step [28/29], Loss: 1.1491\n",
      "Epoch [56/300], Step [29/29], Loss: 2.2257\n",
      "Epoch [57/300], Step [1/29], Loss: 1.2091\n",
      "Epoch [57/300], Step [2/29], Loss: 1.3491\n",
      "Epoch [57/300], Step [3/29], Loss: 1.4812\n",
      "Epoch [57/300], Step [4/29], Loss: 1.1289\n",
      "Epoch [57/300], Step [5/29], Loss: 1.2014\n",
      "Epoch [57/300], Step [6/29], Loss: 1.2133\n",
      "Epoch [57/300], Step [7/29], Loss: 1.2540\n",
      "Epoch [57/300], Step [8/29], Loss: 1.2894\n",
      "Epoch [57/300], Step [9/29], Loss: 1.3524\n",
      "Epoch [57/300], Step [10/29], Loss: 1.3247\n",
      "Epoch [57/300], Step [11/29], Loss: 1.2833\n",
      "Epoch [57/300], Step [12/29], Loss: 1.3344\n",
      "Epoch [57/300], Step [13/29], Loss: 1.4273\n",
      "Epoch [57/300], Step [14/29], Loss: 1.3686\n",
      "Epoch [57/300], Step [15/29], Loss: 1.4980\n",
      "Epoch [57/300], Step [16/29], Loss: 1.2688\n",
      "Epoch [57/300], Step [17/29], Loss: 1.2871\n",
      "Epoch [57/300], Step [18/29], Loss: 1.2797\n",
      "Epoch [57/300], Step [19/29], Loss: 1.2273\n",
      "Epoch [57/300], Step [20/29], Loss: 0.9782\n",
      "Epoch [57/300], Step [21/29], Loss: 1.2518\n",
      "Epoch [57/300], Step [22/29], Loss: 1.0983\n",
      "Epoch [57/300], Step [23/29], Loss: 1.5032\n",
      "Epoch [57/300], Step [24/29], Loss: 1.3554\n",
      "Epoch [57/300], Step [25/29], Loss: 1.3289\n",
      "Epoch [57/300], Step [26/29], Loss: 1.1844\n",
      "Epoch [57/300], Step [27/29], Loss: 1.0845\n",
      "Epoch [57/300], Step [28/29], Loss: 1.4105\n",
      "Epoch [57/300], Step [29/29], Loss: 0.4599\n",
      "Epoch [58/300], Step [1/29], Loss: 1.1518\n",
      "Epoch [58/300], Step [2/29], Loss: 1.1625\n",
      "Epoch [58/300], Step [3/29], Loss: 1.2804\n",
      "Epoch [58/300], Step [4/29], Loss: 1.4085\n",
      "Epoch [58/300], Step [5/29], Loss: 1.1794\n",
      "Epoch [58/300], Step [6/29], Loss: 1.3665\n",
      "Epoch [58/300], Step [7/29], Loss: 1.1593\n",
      "Epoch [58/300], Step [8/29], Loss: 1.4710\n",
      "Epoch [58/300], Step [9/29], Loss: 1.3110\n",
      "Epoch [58/300], Step [10/29], Loss: 1.4090\n",
      "Epoch [58/300], Step [11/29], Loss: 1.1008\n",
      "Epoch [58/300], Step [12/29], Loss: 1.3921\n",
      "Epoch [58/300], Step [13/29], Loss: 1.5083\n",
      "Epoch [58/300], Step [14/29], Loss: 1.1683\n",
      "Epoch [58/300], Step [15/29], Loss: 1.1878\n",
      "Epoch [58/300], Step [16/29], Loss: 1.4185\n",
      "Epoch [58/300], Step [17/29], Loss: 1.2294\n",
      "Epoch [58/300], Step [18/29], Loss: 1.4411\n",
      "Epoch [58/300], Step [19/29], Loss: 1.5134\n",
      "Epoch [58/300], Step [20/29], Loss: 1.1770\n",
      "Epoch [58/300], Step [21/29], Loss: 1.3024\n",
      "Epoch [58/300], Step [22/29], Loss: 1.0514\n",
      "Epoch [58/300], Step [23/29], Loss: 1.4066\n",
      "Epoch [58/300], Step [24/29], Loss: 1.3853\n",
      "Epoch [58/300], Step [25/29], Loss: 1.3201\n",
      "Epoch [58/300], Step [26/29], Loss: 1.1280\n",
      "Epoch [58/300], Step [27/29], Loss: 1.1384\n",
      "Epoch [58/300], Step [28/29], Loss: 1.5410\n",
      "Epoch [58/300], Step [29/29], Loss: 1.3553\n",
      "Epoch [59/300], Step [1/29], Loss: 1.3989\n",
      "Epoch [59/300], Step [2/29], Loss: 1.3690\n",
      "Epoch [59/300], Step [3/29], Loss: 1.2733\n",
      "Epoch [59/300], Step [4/29], Loss: 1.5493\n",
      "Epoch [59/300], Step [5/29], Loss: 1.2643\n",
      "Epoch [59/300], Step [6/29], Loss: 1.4565\n",
      "Epoch [59/300], Step [7/29], Loss: 1.4318\n",
      "Epoch [59/300], Step [8/29], Loss: 1.2164\n",
      "Epoch [59/300], Step [9/29], Loss: 1.5534\n",
      "Epoch [59/300], Step [10/29], Loss: 1.2818\n",
      "Epoch [59/300], Step [11/29], Loss: 1.2637\n",
      "Epoch [59/300], Step [12/29], Loss: 1.2975\n",
      "Epoch [59/300], Step [13/29], Loss: 1.4814\n",
      "Epoch [59/300], Step [14/29], Loss: 1.3220\n",
      "Epoch [59/300], Step [15/29], Loss: 1.3230\n",
      "Epoch [59/300], Step [16/29], Loss: 1.1298\n",
      "Epoch [59/300], Step [17/29], Loss: 1.1985\n",
      "Epoch [59/300], Step [18/29], Loss: 1.4720\n",
      "Epoch [59/300], Step [19/29], Loss: 1.3585\n",
      "Epoch [59/300], Step [20/29], Loss: 1.2154\n",
      "Epoch [59/300], Step [21/29], Loss: 0.9211\n",
      "Epoch [59/300], Step [22/29], Loss: 1.1772\n",
      "Epoch [59/300], Step [23/29], Loss: 1.2752\n",
      "Epoch [59/300], Step [24/29], Loss: 1.1746\n",
      "Epoch [59/300], Step [25/29], Loss: 1.3295\n",
      "Epoch [59/300], Step [26/29], Loss: 1.2797\n",
      "Epoch [59/300], Step [27/29], Loss: 1.0753\n",
      "Epoch [59/300], Step [28/29], Loss: 1.4358\n",
      "Epoch [59/300], Step [29/29], Loss: 1.2625\n",
      "Epoch [60/300], Step [1/29], Loss: 1.2132\n",
      "Epoch [60/300], Step [2/29], Loss: 1.4881\n",
      "Epoch [60/300], Step [3/29], Loss: 1.2171\n",
      "Epoch [60/300], Step [4/29], Loss: 1.4194\n",
      "Epoch [60/300], Step [5/29], Loss: 1.4422\n",
      "Epoch [60/300], Step [6/29], Loss: 1.1320\n",
      "Epoch [60/300], Step [7/29], Loss: 1.5416\n",
      "Epoch [60/300], Step [8/29], Loss: 1.1942\n",
      "Epoch [60/300], Step [9/29], Loss: 1.2049\n",
      "Epoch [60/300], Step [10/29], Loss: 1.3835\n",
      "Epoch [60/300], Step [11/29], Loss: 1.2586\n",
      "Epoch [60/300], Step [12/29], Loss: 1.3538\n",
      "Epoch [60/300], Step [13/29], Loss: 1.1862\n",
      "Epoch [60/300], Step [14/29], Loss: 1.2339\n",
      "Epoch [60/300], Step [15/29], Loss: 1.5991\n",
      "Epoch [60/300], Step [16/29], Loss: 0.9368\n",
      "Epoch [60/300], Step [17/29], Loss: 1.0507\n",
      "Epoch [60/300], Step [18/29], Loss: 1.3954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [19/29], Loss: 1.2975\n",
      "Epoch [60/300], Step [20/29], Loss: 1.0586\n",
      "Epoch [60/300], Step [21/29], Loss: 1.1902\n",
      "Epoch [60/300], Step [22/29], Loss: 1.4284\n",
      "Epoch [60/300], Step [23/29], Loss: 1.3470\n",
      "Epoch [60/300], Step [24/29], Loss: 1.3252\n",
      "Epoch [60/300], Step [25/29], Loss: 1.5207\n",
      "Epoch [60/300], Step [26/29], Loss: 1.0952\n",
      "Epoch [60/300], Step [27/29], Loss: 1.3852\n",
      "Epoch [60/300], Step [28/29], Loss: 1.3536\n",
      "Epoch [60/300], Step [29/29], Loss: 0.6745\n",
      "Epoch [61/300], Step [1/29], Loss: 1.1419\n",
      "Epoch [61/300], Step [2/29], Loss: 1.7277\n",
      "Epoch [61/300], Step [3/29], Loss: 1.3932\n",
      "Epoch [61/300], Step [4/29], Loss: 1.1016\n",
      "Epoch [61/300], Step [5/29], Loss: 1.4529\n",
      "Epoch [61/300], Step [6/29], Loss: 1.3432\n",
      "Epoch [61/300], Step [7/29], Loss: 1.2111\n",
      "Epoch [61/300], Step [8/29], Loss: 1.3217\n",
      "Epoch [61/300], Step [9/29], Loss: 0.9494\n",
      "Epoch [61/300], Step [10/29], Loss: 1.4122\n",
      "Epoch [61/300], Step [11/29], Loss: 1.0756\n",
      "Epoch [61/300], Step [12/29], Loss: 1.1176\n",
      "Epoch [61/300], Step [13/29], Loss: 1.3444\n",
      "Epoch [61/300], Step [14/29], Loss: 1.0846\n",
      "Epoch [61/300], Step [15/29], Loss: 1.3844\n",
      "Epoch [61/300], Step [16/29], Loss: 1.1212\n",
      "Epoch [61/300], Step [17/29], Loss: 1.2568\n",
      "Epoch [61/300], Step [18/29], Loss: 1.4186\n",
      "Epoch [61/300], Step [19/29], Loss: 1.4791\n",
      "Epoch [61/300], Step [20/29], Loss: 1.0478\n",
      "Epoch [61/300], Step [21/29], Loss: 1.4489\n",
      "Epoch [61/300], Step [22/29], Loss: 1.3932\n",
      "Epoch [61/300], Step [23/29], Loss: 1.4275\n",
      "Epoch [61/300], Step [24/29], Loss: 1.2261\n",
      "Epoch [61/300], Step [25/29], Loss: 1.2728\n",
      "Epoch [61/300], Step [26/29], Loss: 1.1034\n",
      "Epoch [61/300], Step [27/29], Loss: 1.1419\n",
      "Epoch [61/300], Step [28/29], Loss: 1.3217\n",
      "Epoch [61/300], Step [29/29], Loss: 3.1669\n",
      "Epoch [62/300], Step [1/29], Loss: 1.1400\n",
      "Epoch [62/300], Step [2/29], Loss: 1.2645\n",
      "Epoch [62/300], Step [3/29], Loss: 1.7252\n",
      "Epoch [62/300], Step [4/29], Loss: 1.0980\n",
      "Epoch [62/300], Step [5/29], Loss: 1.2247\n",
      "Epoch [62/300], Step [6/29], Loss: 1.3589\n",
      "Epoch [62/300], Step [7/29], Loss: 1.4836\n",
      "Epoch [62/300], Step [8/29], Loss: 1.4941\n",
      "Epoch [62/300], Step [9/29], Loss: 1.1637\n",
      "Epoch [62/300], Step [10/29], Loss: 1.0305\n",
      "Epoch [62/300], Step [11/29], Loss: 1.0960\n",
      "Epoch [62/300], Step [12/29], Loss: 1.5327\n",
      "Epoch [62/300], Step [13/29], Loss: 1.4058\n",
      "Epoch [62/300], Step [14/29], Loss: 1.4453\n",
      "Epoch [62/300], Step [15/29], Loss: 1.5270\n",
      "Epoch [62/300], Step [16/29], Loss: 1.2074\n",
      "Epoch [62/300], Step [17/29], Loss: 1.1916\n",
      "Epoch [62/300], Step [18/29], Loss: 1.2473\n",
      "Epoch [62/300], Step [19/29], Loss: 1.5718\n",
      "Epoch [62/300], Step [20/29], Loss: 1.4978\n",
      "Epoch [62/300], Step [21/29], Loss: 1.3776\n",
      "Epoch [62/300], Step [22/29], Loss: 1.1318\n",
      "Epoch [62/300], Step [23/29], Loss: 1.2769\n",
      "Epoch [62/300], Step [24/29], Loss: 1.1570\n",
      "Epoch [62/300], Step [25/29], Loss: 1.3064\n",
      "Epoch [62/300], Step [26/29], Loss: 1.2743\n",
      "Epoch [62/300], Step [27/29], Loss: 1.1129\n",
      "Epoch [62/300], Step [28/29], Loss: 1.2765\n",
      "Epoch [62/300], Step [29/29], Loss: 1.6020\n",
      "Epoch [63/300], Step [1/29], Loss: 1.2087\n",
      "Epoch [63/300], Step [2/29], Loss: 1.3193\n",
      "Epoch [63/300], Step [3/29], Loss: 1.3306\n",
      "Epoch [63/300], Step [4/29], Loss: 1.3627\n",
      "Epoch [63/300], Step [5/29], Loss: 1.3837\n",
      "Epoch [63/300], Step [6/29], Loss: 1.4239\n",
      "Epoch [63/300], Step [7/29], Loss: 1.1334\n",
      "Epoch [63/300], Step [8/29], Loss: 1.2674\n",
      "Epoch [63/300], Step [9/29], Loss: 1.2606\n",
      "Epoch [63/300], Step [10/29], Loss: 1.3277\n",
      "Epoch [63/300], Step [11/29], Loss: 1.4002\n",
      "Epoch [63/300], Step [12/29], Loss: 1.1884\n",
      "Epoch [63/300], Step [13/29], Loss: 1.1984\n",
      "Epoch [63/300], Step [14/29], Loss: 1.2200\n",
      "Epoch [63/300], Step [15/29], Loss: 1.2844\n",
      "Epoch [63/300], Step [16/29], Loss: 1.3484\n",
      "Epoch [63/300], Step [17/29], Loss: 1.3842\n",
      "Epoch [63/300], Step [18/29], Loss: 1.4587\n",
      "Epoch [63/300], Step [19/29], Loss: 1.1080\n",
      "Epoch [63/300], Step [20/29], Loss: 1.3669\n",
      "Epoch [63/300], Step [21/29], Loss: 1.2110\n",
      "Epoch [63/300], Step [22/29], Loss: 1.2187\n",
      "Epoch [63/300], Step [23/29], Loss: 1.3406\n",
      "Epoch [63/300], Step [24/29], Loss: 0.9879\n",
      "Epoch [63/300], Step [25/29], Loss: 1.2947\n",
      "Epoch [63/300], Step [26/29], Loss: 1.4473\n",
      "Epoch [63/300], Step [27/29], Loss: 1.4124\n",
      "Epoch [63/300], Step [28/29], Loss: 1.3928\n",
      "Epoch [63/300], Step [29/29], Loss: 1.3165\n",
      "Epoch [64/300], Step [1/29], Loss: 1.2511\n",
      "Epoch [64/300], Step [2/29], Loss: 1.0194\n",
      "Epoch [64/300], Step [3/29], Loss: 1.5513\n",
      "Epoch [64/300], Step [4/29], Loss: 1.3478\n",
      "Epoch [64/300], Step [5/29], Loss: 1.4972\n",
      "Epoch [64/300], Step [6/29], Loss: 1.1809\n",
      "Epoch [64/300], Step [7/29], Loss: 1.3032\n",
      "Epoch [64/300], Step [8/29], Loss: 1.2662\n",
      "Epoch [64/300], Step [9/29], Loss: 1.2476\n",
      "Epoch [64/300], Step [10/29], Loss: 1.0493\n",
      "Epoch [64/300], Step [11/29], Loss: 0.9588\n",
      "Epoch [64/300], Step [12/29], Loss: 1.1613\n",
      "Epoch [64/300], Step [13/29], Loss: 1.4047\n",
      "Epoch [64/300], Step [14/29], Loss: 1.2780\n",
      "Epoch [64/300], Step [15/29], Loss: 1.4704\n",
      "Epoch [64/300], Step [16/29], Loss: 1.4176\n",
      "Epoch [64/300], Step [17/29], Loss: 1.4418\n",
      "Epoch [64/300], Step [18/29], Loss: 1.4632\n",
      "Epoch [64/300], Step [19/29], Loss: 1.0893\n",
      "Epoch [64/300], Step [20/29], Loss: 1.1293\n",
      "Epoch [64/300], Step [21/29], Loss: 1.4003\n",
      "Epoch [64/300], Step [22/29], Loss: 1.3818\n",
      "Epoch [64/300], Step [23/29], Loss: 1.2933\n",
      "Epoch [64/300], Step [24/29], Loss: 1.2794\n",
      "Epoch [64/300], Step [25/29], Loss: 1.1758\n",
      "Epoch [64/300], Step [26/29], Loss: 1.3344\n",
      "Epoch [64/300], Step [27/29], Loss: 1.3929\n",
      "Epoch [64/300], Step [28/29], Loss: 1.1179\n",
      "Epoch [64/300], Step [29/29], Loss: 2.1079\n",
      "Epoch [65/300], Step [1/29], Loss: 1.2381\n",
      "Epoch [65/300], Step [2/29], Loss: 1.2762\n",
      "Epoch [65/300], Step [3/29], Loss: 1.0802\n",
      "Epoch [65/300], Step [4/29], Loss: 1.4467\n",
      "Epoch [65/300], Step [5/29], Loss: 1.3952\n",
      "Epoch [65/300], Step [6/29], Loss: 1.6804\n",
      "Epoch [65/300], Step [7/29], Loss: 1.4320\n",
      "Epoch [65/300], Step [8/29], Loss: 1.1677\n",
      "Epoch [65/300], Step [9/29], Loss: 1.4592\n",
      "Epoch [65/300], Step [10/29], Loss: 1.2872\n",
      "Epoch [65/300], Step [11/29], Loss: 1.2183\n",
      "Epoch [65/300], Step [12/29], Loss: 1.1299\n",
      "Epoch [65/300], Step [13/29], Loss: 1.2189\n",
      "Epoch [65/300], Step [14/29], Loss: 1.2319\n",
      "Epoch [65/300], Step [15/29], Loss: 1.2394\n",
      "Epoch [65/300], Step [16/29], Loss: 1.0295\n",
      "Epoch [65/300], Step [17/29], Loss: 1.3700\n",
      "Epoch [65/300], Step [18/29], Loss: 1.1504\n",
      "Epoch [65/300], Step [19/29], Loss: 1.2442\n",
      "Epoch [65/300], Step [20/29], Loss: 1.4680\n",
      "Epoch [65/300], Step [21/29], Loss: 1.4040\n",
      "Epoch [65/300], Step [22/29], Loss: 1.2269\n",
      "Epoch [65/300], Step [23/29], Loss: 1.4398\n",
      "Epoch [65/300], Step [24/29], Loss: 1.2328\n",
      "Epoch [65/300], Step [25/29], Loss: 1.6386\n",
      "Epoch [65/300], Step [26/29], Loss: 1.3695\n",
      "Epoch [65/300], Step [27/29], Loss: 1.3510\n",
      "Epoch [65/300], Step [28/29], Loss: 1.0553\n",
      "Epoch [65/300], Step [29/29], Loss: 0.7230\n",
      "Epoch [66/300], Step [1/29], Loss: 1.1695\n",
      "Epoch [66/300], Step [2/29], Loss: 1.1863\n",
      "Epoch [66/300], Step [3/29], Loss: 1.4013\n",
      "Epoch [66/300], Step [4/29], Loss: 1.3193\n",
      "Epoch [66/300], Step [5/29], Loss: 1.3386\n",
      "Epoch [66/300], Step [6/29], Loss: 1.2693\n",
      "Epoch [66/300], Step [7/29], Loss: 1.3565\n",
      "Epoch [66/300], Step [8/29], Loss: 1.4288\n",
      "Epoch [66/300], Step [9/29], Loss: 1.0863\n",
      "Epoch [66/300], Step [10/29], Loss: 1.2396\n",
      "Epoch [66/300], Step [11/29], Loss: 1.3286\n",
      "Epoch [66/300], Step [12/29], Loss: 1.1999\n",
      "Epoch [66/300], Step [13/29], Loss: 1.3466\n",
      "Epoch [66/300], Step [14/29], Loss: 1.2859\n",
      "Epoch [66/300], Step [15/29], Loss: 1.3951\n",
      "Epoch [66/300], Step [16/29], Loss: 1.3538\n",
      "Epoch [66/300], Step [17/29], Loss: 1.2264\n",
      "Epoch [66/300], Step [18/29], Loss: 1.1832\n",
      "Epoch [66/300], Step [19/29], Loss: 1.5310\n",
      "Epoch [66/300], Step [20/29], Loss: 1.4296\n",
      "Epoch [66/300], Step [21/29], Loss: 1.3091\n",
      "Epoch [66/300], Step [22/29], Loss: 1.4533\n",
      "Epoch [66/300], Step [23/29], Loss: 1.2051\n",
      "Epoch [66/300], Step [24/29], Loss: 1.1542\n",
      "Epoch [66/300], Step [25/29], Loss: 1.1872\n",
      "Epoch [66/300], Step [26/29], Loss: 1.3369\n",
      "Epoch [66/300], Step [27/29], Loss: 1.1383\n",
      "Epoch [66/300], Step [28/29], Loss: 1.2784\n",
      "Epoch [66/300], Step [29/29], Loss: 1.7927\n",
      "Epoch [67/300], Step [1/29], Loss: 1.5250\n",
      "Epoch [67/300], Step [2/29], Loss: 1.2389\n",
      "Epoch [67/300], Step [3/29], Loss: 1.3340\n",
      "Epoch [67/300], Step [4/29], Loss: 1.0563\n",
      "Epoch [67/300], Step [5/29], Loss: 1.3233\n",
      "Epoch [67/300], Step [6/29], Loss: 1.2341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/300], Step [7/29], Loss: 1.4170\n",
      "Epoch [67/300], Step [8/29], Loss: 1.5201\n",
      "Epoch [67/300], Step [9/29], Loss: 1.1105\n",
      "Epoch [67/300], Step [10/29], Loss: 1.3726\n",
      "Epoch [67/300], Step [11/29], Loss: 1.1764\n",
      "Epoch [67/300], Step [12/29], Loss: 1.1782\n",
      "Epoch [67/300], Step [13/29], Loss: 1.4258\n",
      "Epoch [67/300], Step [14/29], Loss: 1.1940\n",
      "Epoch [67/300], Step [15/29], Loss: 1.2903\n",
      "Epoch [67/300], Step [16/29], Loss: 1.2436\n",
      "Epoch [67/300], Step [17/29], Loss: 1.3555\n",
      "Epoch [67/300], Step [18/29], Loss: 1.3118\n",
      "Epoch [67/300], Step [19/29], Loss: 1.2836\n",
      "Epoch [67/300], Step [20/29], Loss: 1.3305\n",
      "Epoch [67/300], Step [21/29], Loss: 1.2951\n",
      "Epoch [67/300], Step [22/29], Loss: 1.3800\n",
      "Epoch [67/300], Step [23/29], Loss: 1.0052\n",
      "Epoch [67/300], Step [24/29], Loss: 1.1455\n",
      "Epoch [67/300], Step [25/29], Loss: 1.1557\n",
      "Epoch [67/300], Step [26/29], Loss: 1.5299\n",
      "Epoch [67/300], Step [27/29], Loss: 1.5383\n",
      "Epoch [67/300], Step [28/29], Loss: 1.3704\n",
      "Epoch [67/300], Step [29/29], Loss: 1.1170\n",
      "Epoch [68/300], Step [1/29], Loss: 1.2871\n",
      "Epoch [68/300], Step [2/29], Loss: 0.9919\n",
      "Epoch [68/300], Step [3/29], Loss: 1.3242\n",
      "Epoch [68/300], Step [4/29], Loss: 1.1422\n",
      "Epoch [68/300], Step [5/29], Loss: 1.1450\n",
      "Epoch [68/300], Step [6/29], Loss: 1.2248\n",
      "Epoch [68/300], Step [7/29], Loss: 1.0732\n",
      "Epoch [68/300], Step [8/29], Loss: 1.3153\n",
      "Epoch [68/300], Step [9/29], Loss: 1.5930\n",
      "Epoch [68/300], Step [10/29], Loss: 1.0982\n",
      "Epoch [68/300], Step [11/29], Loss: 1.4023\n",
      "Epoch [68/300], Step [12/29], Loss: 1.2607\n",
      "Epoch [68/300], Step [13/29], Loss: 1.2500\n",
      "Epoch [68/300], Step [14/29], Loss: 1.3073\n",
      "Epoch [68/300], Step [15/29], Loss: 1.1674\n",
      "Epoch [68/300], Step [16/29], Loss: 1.4399\n",
      "Epoch [68/300], Step [17/29], Loss: 1.4206\n",
      "Epoch [68/300], Step [18/29], Loss: 1.3105\n",
      "Epoch [68/300], Step [19/29], Loss: 1.3738\n",
      "Epoch [68/300], Step [20/29], Loss: 1.5666\n",
      "Epoch [68/300], Step [21/29], Loss: 1.1658\n",
      "Epoch [68/300], Step [22/29], Loss: 1.0529\n",
      "Epoch [68/300], Step [23/29], Loss: 1.3165\n",
      "Epoch [68/300], Step [24/29], Loss: 1.5047\n",
      "Epoch [68/300], Step [25/29], Loss: 1.4003\n",
      "Epoch [68/300], Step [26/29], Loss: 1.2684\n",
      "Epoch [68/300], Step [27/29], Loss: 1.5019\n",
      "Epoch [68/300], Step [28/29], Loss: 1.0468\n",
      "Epoch [68/300], Step [29/29], Loss: 2.9010\n",
      "Epoch [69/300], Step [1/29], Loss: 1.4733\n",
      "Epoch [69/300], Step [2/29], Loss: 1.3011\n",
      "Epoch [69/300], Step [3/29], Loss: 1.2823\n",
      "Epoch [69/300], Step [4/29], Loss: 1.4222\n",
      "Epoch [69/300], Step [5/29], Loss: 1.2676\n",
      "Epoch [69/300], Step [6/29], Loss: 1.2792\n",
      "Epoch [69/300], Step [7/29], Loss: 1.3498\n",
      "Epoch [69/300], Step [8/29], Loss: 1.4306\n",
      "Epoch [69/300], Step [9/29], Loss: 1.1755\n",
      "Epoch [69/300], Step [10/29], Loss: 1.2975\n",
      "Epoch [69/300], Step [11/29], Loss: 1.1355\n",
      "Epoch [69/300], Step [12/29], Loss: 1.3884\n",
      "Epoch [69/300], Step [13/29], Loss: 1.5411\n",
      "Epoch [69/300], Step [14/29], Loss: 1.1430\n",
      "Epoch [69/300], Step [15/29], Loss: 1.3504\n",
      "Epoch [69/300], Step [16/29], Loss: 1.2075\n",
      "Epoch [69/300], Step [17/29], Loss: 1.1639\n",
      "Epoch [69/300], Step [18/29], Loss: 1.4042\n",
      "Epoch [69/300], Step [19/29], Loss: 1.2140\n",
      "Epoch [69/300], Step [20/29], Loss: 1.2784\n",
      "Epoch [69/300], Step [21/29], Loss: 1.4009\n",
      "Epoch [69/300], Step [22/29], Loss: 1.1826\n",
      "Epoch [69/300], Step [23/29], Loss: 1.2821\n",
      "Epoch [69/300], Step [24/29], Loss: 1.5799\n",
      "Epoch [69/300], Step [25/29], Loss: 1.0948\n",
      "Epoch [69/300], Step [26/29], Loss: 0.9615\n",
      "Epoch [69/300], Step [27/29], Loss: 1.2444\n",
      "Epoch [69/300], Step [28/29], Loss: 1.4650\n",
      "Epoch [69/300], Step [29/29], Loss: 1.5192\n",
      "Epoch [70/300], Step [1/29], Loss: 1.5290\n",
      "Epoch [70/300], Step [2/29], Loss: 1.1781\n",
      "Epoch [70/300], Step [3/29], Loss: 1.3772\n",
      "Epoch [70/300], Step [4/29], Loss: 1.3098\n",
      "Epoch [70/300], Step [5/29], Loss: 1.1866\n",
      "Epoch [70/300], Step [6/29], Loss: 1.3547\n",
      "Epoch [70/300], Step [7/29], Loss: 1.2172\n",
      "Epoch [70/300], Step [8/29], Loss: 1.4135\n",
      "Epoch [70/300], Step [9/29], Loss: 1.5365\n",
      "Epoch [70/300], Step [10/29], Loss: 1.3244\n",
      "Epoch [70/300], Step [11/29], Loss: 1.0915\n",
      "Epoch [70/300], Step [12/29], Loss: 1.1450\n",
      "Epoch [70/300], Step [13/29], Loss: 1.2434\n",
      "Epoch [70/300], Step [14/29], Loss: 1.3480\n",
      "Epoch [70/300], Step [15/29], Loss: 1.3507\n",
      "Epoch [70/300], Step [16/29], Loss: 1.3428\n",
      "Epoch [70/300], Step [17/29], Loss: 1.3570\n",
      "Epoch [70/300], Step [18/29], Loss: 1.1625\n",
      "Epoch [70/300], Step [19/29], Loss: 1.2356\n",
      "Epoch [70/300], Step [20/29], Loss: 1.2317\n",
      "Epoch [70/300], Step [21/29], Loss: 1.2841\n",
      "Epoch [70/300], Step [22/29], Loss: 1.3583\n",
      "Epoch [70/300], Step [23/29], Loss: 1.1975\n",
      "Epoch [70/300], Step [24/29], Loss: 1.2443\n",
      "Epoch [70/300], Step [25/29], Loss: 1.2270\n",
      "Epoch [70/300], Step [26/29], Loss: 1.3695\n",
      "Epoch [70/300], Step [27/29], Loss: 1.3709\n",
      "Epoch [70/300], Step [28/29], Loss: 1.3392\n",
      "Epoch [70/300], Step [29/29], Loss: 1.1252\n",
      "Epoch [71/300], Step [1/29], Loss: 1.3315\n",
      "Epoch [71/300], Step [2/29], Loss: 1.2222\n",
      "Epoch [71/300], Step [3/29], Loss: 1.1491\n",
      "Epoch [71/300], Step [4/29], Loss: 1.2861\n",
      "Epoch [71/300], Step [5/29], Loss: 1.5465\n",
      "Epoch [71/300], Step [6/29], Loss: 1.1346\n",
      "Epoch [71/300], Step [7/29], Loss: 1.2432\n",
      "Epoch [71/300], Step [8/29], Loss: 1.1271\n",
      "Epoch [71/300], Step [9/29], Loss: 1.5317\n",
      "Epoch [71/300], Step [10/29], Loss: 1.2256\n",
      "Epoch [71/300], Step [11/29], Loss: 1.0781\n",
      "Epoch [71/300], Step [12/29], Loss: 1.4650\n",
      "Epoch [71/300], Step [13/29], Loss: 1.2324\n",
      "Epoch [71/300], Step [14/29], Loss: 1.1291\n",
      "Epoch [71/300], Step [15/29], Loss: 1.2029\n",
      "Epoch [71/300], Step [16/29], Loss: 1.4345\n",
      "Epoch [71/300], Step [17/29], Loss: 1.3088\n",
      "Epoch [71/300], Step [18/29], Loss: 1.2926\n",
      "Epoch [71/300], Step [19/29], Loss: 1.3285\n",
      "Epoch [71/300], Step [20/29], Loss: 1.1799\n",
      "Epoch [71/300], Step [21/29], Loss: 1.2906\n",
      "Epoch [71/300], Step [22/29], Loss: 1.5609\n",
      "Epoch [71/300], Step [23/29], Loss: 1.2605\n",
      "Epoch [71/300], Step [24/29], Loss: 1.1785\n",
      "Epoch [71/300], Step [25/29], Loss: 1.1993\n",
      "Epoch [71/300], Step [26/29], Loss: 1.3690\n",
      "Epoch [71/300], Step [27/29], Loss: 1.4164\n",
      "Epoch [71/300], Step [28/29], Loss: 1.4413\n",
      "Epoch [71/300], Step [29/29], Loss: 0.9794\n",
      "Epoch [72/300], Step [1/29], Loss: 1.0307\n",
      "Epoch [72/300], Step [2/29], Loss: 1.2608\n",
      "Epoch [72/300], Step [3/29], Loss: 1.2678\n",
      "Epoch [72/300], Step [4/29], Loss: 1.1324\n",
      "Epoch [72/300], Step [5/29], Loss: 1.1709\n",
      "Epoch [72/300], Step [6/29], Loss: 1.5226\n",
      "Epoch [72/300], Step [7/29], Loss: 1.1326\n",
      "Epoch [72/300], Step [8/29], Loss: 1.7971\n",
      "Epoch [72/300], Step [9/29], Loss: 1.6373\n",
      "Epoch [72/300], Step [10/29], Loss: 1.3537\n",
      "Epoch [72/300], Step [11/29], Loss: 1.5778\n",
      "Epoch [72/300], Step [12/29], Loss: 1.2377\n",
      "Epoch [72/300], Step [13/29], Loss: 1.2225\n",
      "Epoch [72/300], Step [14/29], Loss: 1.3202\n",
      "Epoch [72/300], Step [15/29], Loss: 1.3011\n",
      "Epoch [72/300], Step [16/29], Loss: 1.2001\n",
      "Epoch [72/300], Step [17/29], Loss: 1.5211\n",
      "Epoch [72/300], Step [18/29], Loss: 1.4569\n",
      "Epoch [72/300], Step [19/29], Loss: 1.2514\n",
      "Epoch [72/300], Step [20/29], Loss: 1.3486\n",
      "Epoch [72/300], Step [21/29], Loss: 1.3385\n",
      "Epoch [72/300], Step [22/29], Loss: 1.2099\n",
      "Epoch [72/300], Step [23/29], Loss: 1.0677\n",
      "Epoch [72/300], Step [24/29], Loss: 1.2557\n",
      "Epoch [72/300], Step [25/29], Loss: 1.2176\n",
      "Epoch [72/300], Step [26/29], Loss: 1.2793\n",
      "Epoch [72/300], Step [27/29], Loss: 1.1814\n",
      "Epoch [72/300], Step [28/29], Loss: 1.2124\n",
      "Epoch [72/300], Step [29/29], Loss: 0.8247\n",
      "Epoch [73/300], Step [1/29], Loss: 1.4325\n",
      "Epoch [73/300], Step [2/29], Loss: 1.2595\n",
      "Epoch [73/300], Step [3/29], Loss: 1.2822\n",
      "Epoch [73/300], Step [4/29], Loss: 1.0310\n",
      "Epoch [73/300], Step [5/29], Loss: 1.0154\n",
      "Epoch [73/300], Step [6/29], Loss: 1.3464\n",
      "Epoch [73/300], Step [7/29], Loss: 1.2709\n",
      "Epoch [73/300], Step [8/29], Loss: 1.1726\n",
      "Epoch [73/300], Step [9/29], Loss: 1.2178\n",
      "Epoch [73/300], Step [10/29], Loss: 1.3625\n",
      "Epoch [73/300], Step [11/29], Loss: 1.0672\n",
      "Epoch [73/300], Step [12/29], Loss: 1.2750\n",
      "Epoch [73/300], Step [13/29], Loss: 1.4298\n",
      "Epoch [73/300], Step [14/29], Loss: 1.3758\n",
      "Epoch [73/300], Step [15/29], Loss: 1.3985\n",
      "Epoch [73/300], Step [16/29], Loss: 1.4049\n",
      "Epoch [73/300], Step [17/29], Loss: 1.3203\n",
      "Epoch [73/300], Step [18/29], Loss: 1.2601\n",
      "Epoch [73/300], Step [19/29], Loss: 1.3300\n",
      "Epoch [73/300], Step [20/29], Loss: 1.2262\n",
      "Epoch [73/300], Step [21/29], Loss: 1.3460\n",
      "Epoch [73/300], Step [22/29], Loss: 1.4360\n",
      "Epoch [73/300], Step [23/29], Loss: 1.1207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/300], Step [24/29], Loss: 1.2814\n",
      "Epoch [73/300], Step [25/29], Loss: 1.3818\n",
      "Epoch [73/300], Step [26/29], Loss: 1.2440\n",
      "Epoch [73/300], Step [27/29], Loss: 1.4361\n",
      "Epoch [73/300], Step [28/29], Loss: 1.0812\n",
      "Epoch [73/300], Step [29/29], Loss: 2.9485\n",
      "Epoch [74/300], Step [1/29], Loss: 1.2164\n",
      "Epoch [74/300], Step [2/29], Loss: 1.4202\n",
      "Epoch [74/300], Step [3/29], Loss: 1.0994\n",
      "Epoch [74/300], Step [4/29], Loss: 1.4771\n",
      "Epoch [74/300], Step [5/29], Loss: 1.2380\n",
      "Epoch [74/300], Step [6/29], Loss: 1.5143\n",
      "Epoch [74/300], Step [7/29], Loss: 0.9739\n",
      "Epoch [74/300], Step [8/29], Loss: 1.4289\n",
      "Epoch [74/300], Step [9/29], Loss: 1.3295\n",
      "Epoch [74/300], Step [10/29], Loss: 1.4879\n",
      "Epoch [74/300], Step [11/29], Loss: 1.1469\n",
      "Epoch [74/300], Step [12/29], Loss: 1.1292\n",
      "Epoch [74/300], Step [13/29], Loss: 1.0354\n",
      "Epoch [74/300], Step [14/29], Loss: 1.4753\n",
      "Epoch [74/300], Step [15/29], Loss: 1.1215\n",
      "Epoch [74/300], Step [16/29], Loss: 1.4838\n",
      "Epoch [74/300], Step [17/29], Loss: 1.2187\n",
      "Epoch [74/300], Step [18/29], Loss: 1.5542\n",
      "Epoch [74/300], Step [19/29], Loss: 1.5725\n",
      "Epoch [74/300], Step [20/29], Loss: 1.2270\n",
      "Epoch [74/300], Step [21/29], Loss: 1.4765\n",
      "Epoch [74/300], Step [22/29], Loss: 1.0801\n",
      "Epoch [74/300], Step [23/29], Loss: 1.3728\n",
      "Epoch [74/300], Step [24/29], Loss: 1.2155\n",
      "Epoch [74/300], Step [25/29], Loss: 1.4279\n",
      "Epoch [74/300], Step [26/29], Loss: 1.0384\n",
      "Epoch [74/300], Step [27/29], Loss: 1.6023\n",
      "Epoch [74/300], Step [28/29], Loss: 1.1382\n",
      "Epoch [74/300], Step [29/29], Loss: 1.0667\n",
      "Epoch [75/300], Step [1/29], Loss: 1.4446\n",
      "Epoch [75/300], Step [2/29], Loss: 1.3265\n",
      "Epoch [75/300], Step [3/29], Loss: 1.0899\n",
      "Epoch [75/300], Step [4/29], Loss: 1.6194\n",
      "Epoch [75/300], Step [5/29], Loss: 1.1614\n",
      "Epoch [75/300], Step [6/29], Loss: 1.0334\n",
      "Epoch [75/300], Step [7/29], Loss: 1.2969\n",
      "Epoch [75/300], Step [8/29], Loss: 1.4986\n",
      "Epoch [75/300], Step [9/29], Loss: 1.1424\n",
      "Epoch [75/300], Step [10/29], Loss: 1.3336\n",
      "Epoch [75/300], Step [11/29], Loss: 1.4585\n",
      "Epoch [75/300], Step [12/29], Loss: 1.1751\n",
      "Epoch [75/300], Step [13/29], Loss: 1.1046\n",
      "Epoch [75/300], Step [14/29], Loss: 1.3541\n",
      "Epoch [75/300], Step [15/29], Loss: 1.4982\n",
      "Epoch [75/300], Step [16/29], Loss: 1.3255\n",
      "Epoch [75/300], Step [17/29], Loss: 1.2086\n",
      "Epoch [75/300], Step [18/29], Loss: 1.2901\n",
      "Epoch [75/300], Step [19/29], Loss: 1.2319\n",
      "Epoch [75/300], Step [20/29], Loss: 1.2213\n",
      "Epoch [75/300], Step [21/29], Loss: 1.5661\n",
      "Epoch [75/300], Step [22/29], Loss: 1.2035\n",
      "Epoch [75/300], Step [23/29], Loss: 1.1756\n",
      "Epoch [75/300], Step [24/29], Loss: 1.3779\n",
      "Epoch [75/300], Step [25/29], Loss: 1.3397\n",
      "Epoch [75/300], Step [26/29], Loss: 1.2940\n",
      "Epoch [75/300], Step [27/29], Loss: 1.4866\n",
      "Epoch [75/300], Step [28/29], Loss: 1.3810\n",
      "Epoch [75/300], Step [29/29], Loss: 1.4051\n",
      "Epoch [76/300], Step [1/29], Loss: 1.0911\n",
      "Epoch [76/300], Step [2/29], Loss: 1.4277\n",
      "Epoch [76/300], Step [3/29], Loss: 1.2969\n",
      "Epoch [76/300], Step [4/29], Loss: 1.4845\n",
      "Epoch [76/300], Step [5/29], Loss: 1.4056\n",
      "Epoch [76/300], Step [6/29], Loss: 1.4329\n",
      "Epoch [76/300], Step [7/29], Loss: 1.2916\n",
      "Epoch [76/300], Step [8/29], Loss: 1.1240\n",
      "Epoch [76/300], Step [9/29], Loss: 1.3687\n",
      "Epoch [76/300], Step [10/29], Loss: 1.3463\n",
      "Epoch [76/300], Step [11/29], Loss: 1.2949\n",
      "Epoch [76/300], Step [12/29], Loss: 1.2031\n",
      "Epoch [76/300], Step [13/29], Loss: 1.3056\n",
      "Epoch [76/300], Step [14/29], Loss: 1.4574\n",
      "Epoch [76/300], Step [15/29], Loss: 1.1098\n",
      "Epoch [76/300], Step [16/29], Loss: 1.3819\n",
      "Epoch [76/300], Step [17/29], Loss: 1.3258\n",
      "Epoch [76/300], Step [18/29], Loss: 1.2229\n",
      "Epoch [76/300], Step [19/29], Loss: 1.4274\n",
      "Epoch [76/300], Step [20/29], Loss: 1.3394\n",
      "Epoch [76/300], Step [21/29], Loss: 1.2947\n",
      "Epoch [76/300], Step [22/29], Loss: 1.0958\n",
      "Epoch [76/300], Step [23/29], Loss: 1.1084\n",
      "Epoch [76/300], Step [24/29], Loss: 1.2385\n",
      "Epoch [76/300], Step [25/29], Loss: 1.5579\n",
      "Epoch [76/300], Step [26/29], Loss: 1.1430\n",
      "Epoch [76/300], Step [27/29], Loss: 1.1128\n",
      "Epoch [76/300], Step [28/29], Loss: 1.3925\n",
      "Epoch [76/300], Step [29/29], Loss: 1.1609\n",
      "Epoch [77/300], Step [1/29], Loss: 1.1119\n",
      "Epoch [77/300], Step [2/29], Loss: 1.5899\n",
      "Epoch [77/300], Step [3/29], Loss: 1.2375\n",
      "Epoch [77/300], Step [4/29], Loss: 1.3083\n",
      "Epoch [77/300], Step [5/29], Loss: 1.4018\n",
      "Epoch [77/300], Step [6/29], Loss: 1.3122\n",
      "Epoch [77/300], Step [7/29], Loss: 1.2064\n",
      "Epoch [77/300], Step [8/29], Loss: 1.3320\n",
      "Epoch [77/300], Step [9/29], Loss: 1.4326\n",
      "Epoch [77/300], Step [10/29], Loss: 1.2265\n",
      "Epoch [77/300], Step [11/29], Loss: 1.1904\n",
      "Epoch [77/300], Step [12/29], Loss: 1.3105\n",
      "Epoch [77/300], Step [13/29], Loss: 1.2064\n",
      "Epoch [77/300], Step [14/29], Loss: 1.3774\n",
      "Epoch [77/300], Step [15/29], Loss: 1.1677\n",
      "Epoch [77/300], Step [16/29], Loss: 1.3128\n",
      "Epoch [77/300], Step [17/29], Loss: 1.4094\n",
      "Epoch [77/300], Step [18/29], Loss: 1.1842\n",
      "Epoch [77/300], Step [19/29], Loss: 1.2032\n",
      "Epoch [77/300], Step [20/29], Loss: 1.4575\n",
      "Epoch [77/300], Step [21/29], Loss: 1.1681\n",
      "Epoch [77/300], Step [22/29], Loss: 1.2912\n",
      "Epoch [77/300], Step [23/29], Loss: 1.2122\n",
      "Epoch [77/300], Step [24/29], Loss: 1.1832\n",
      "Epoch [77/300], Step [25/29], Loss: 1.6100\n",
      "Epoch [77/300], Step [26/29], Loss: 1.4567\n",
      "Epoch [77/300], Step [27/29], Loss: 1.0178\n",
      "Epoch [77/300], Step [28/29], Loss: 1.3864\n",
      "Epoch [77/300], Step [29/29], Loss: 1.9502\n",
      "Epoch [78/300], Step [1/29], Loss: 1.4368\n",
      "Epoch [78/300], Step [2/29], Loss: 1.4007\n",
      "Epoch [78/300], Step [3/29], Loss: 0.9851\n",
      "Epoch [78/300], Step [4/29], Loss: 1.1301\n",
      "Epoch [78/300], Step [5/29], Loss: 1.2404\n",
      "Epoch [78/300], Step [6/29], Loss: 1.3261\n",
      "Epoch [78/300], Step [7/29], Loss: 1.5017\n",
      "Epoch [78/300], Step [8/29], Loss: 1.3218\n",
      "Epoch [78/300], Step [9/29], Loss: 1.1500\n",
      "Epoch [78/300], Step [10/29], Loss: 1.3267\n",
      "Epoch [78/300], Step [11/29], Loss: 1.3568\n",
      "Epoch [78/300], Step [12/29], Loss: 1.3515\n",
      "Epoch [78/300], Step [13/29], Loss: 1.2688\n",
      "Epoch [78/300], Step [14/29], Loss: 1.4156\n",
      "Epoch [78/300], Step [15/29], Loss: 1.0614\n",
      "Epoch [78/300], Step [16/29], Loss: 1.2460\n",
      "Epoch [78/300], Step [17/29], Loss: 1.1732\n",
      "Epoch [78/300], Step [18/29], Loss: 1.2944\n",
      "Epoch [78/300], Step [19/29], Loss: 1.2956\n",
      "Epoch [78/300], Step [20/29], Loss: 1.3032\n",
      "Epoch [78/300], Step [21/29], Loss: 1.3182\n",
      "Epoch [78/300], Step [22/29], Loss: 1.2480\n",
      "Epoch [78/300], Step [23/29], Loss: 1.0749\n",
      "Epoch [78/300], Step [24/29], Loss: 1.3581\n",
      "Epoch [78/300], Step [25/29], Loss: 1.4238\n",
      "Epoch [78/300], Step [26/29], Loss: 1.4931\n",
      "Epoch [78/300], Step [27/29], Loss: 1.2108\n",
      "Epoch [78/300], Step [28/29], Loss: 1.3776\n",
      "Epoch [78/300], Step [29/29], Loss: 1.6993\n",
      "Epoch [79/300], Step [1/29], Loss: 1.2531\n",
      "Epoch [79/300], Step [2/29], Loss: 1.2629\n",
      "Epoch [79/300], Step [3/29], Loss: 1.2621\n",
      "Epoch [79/300], Step [4/29], Loss: 1.1750\n",
      "Epoch [79/300], Step [5/29], Loss: 1.2644\n",
      "Epoch [79/300], Step [6/29], Loss: 1.3609\n",
      "Epoch [79/300], Step [7/29], Loss: 1.2967\n",
      "Epoch [79/300], Step [8/29], Loss: 1.4473\n",
      "Epoch [79/300], Step [9/29], Loss: 1.2762\n",
      "Epoch [79/300], Step [10/29], Loss: 1.4759\n",
      "Epoch [79/300], Step [11/29], Loss: 1.5574\n",
      "Epoch [79/300], Step [12/29], Loss: 1.2194\n",
      "Epoch [79/300], Step [13/29], Loss: 1.4135\n",
      "Epoch [79/300], Step [14/29], Loss: 1.2430\n",
      "Epoch [79/300], Step [15/29], Loss: 0.9954\n",
      "Epoch [79/300], Step [16/29], Loss: 1.4372\n",
      "Epoch [79/300], Step [17/29], Loss: 1.2562\n",
      "Epoch [79/300], Step [18/29], Loss: 1.3191\n",
      "Epoch [79/300], Step [19/29], Loss: 1.0965\n",
      "Epoch [79/300], Step [20/29], Loss: 1.3601\n",
      "Epoch [79/300], Step [21/29], Loss: 1.4078\n",
      "Epoch [79/300], Step [22/29], Loss: 1.2307\n",
      "Epoch [79/300], Step [23/29], Loss: 1.3687\n",
      "Epoch [79/300], Step [24/29], Loss: 1.3232\n",
      "Epoch [79/300], Step [25/29], Loss: 1.5471\n",
      "Epoch [79/300], Step [26/29], Loss: 1.3706\n",
      "Epoch [79/300], Step [27/29], Loss: 1.0689\n",
      "Epoch [79/300], Step [28/29], Loss: 1.0429\n",
      "Epoch [79/300], Step [29/29], Loss: 1.8349\n",
      "Epoch [80/300], Step [1/29], Loss: 1.4716\n",
      "Epoch [80/300], Step [2/29], Loss: 1.1227\n",
      "Epoch [80/300], Step [3/29], Loss: 1.6661\n",
      "Epoch [80/300], Step [4/29], Loss: 1.6333\n",
      "Epoch [80/300], Step [5/29], Loss: 1.1577\n",
      "Epoch [80/300], Step [6/29], Loss: 1.6767\n",
      "Epoch [80/300], Step [7/29], Loss: 1.1565\n",
      "Epoch [80/300], Step [8/29], Loss: 1.1730\n",
      "Epoch [80/300], Step [9/29], Loss: 1.2681\n",
      "Epoch [80/300], Step [10/29], Loss: 1.1638\n",
      "Epoch [80/300], Step [11/29], Loss: 1.3113\n",
      "Epoch [80/300], Step [12/29], Loss: 1.1601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/300], Step [13/29], Loss: 1.3811\n",
      "Epoch [80/300], Step [14/29], Loss: 1.3228\n",
      "Epoch [80/300], Step [15/29], Loss: 1.1600\n",
      "Epoch [80/300], Step [16/29], Loss: 1.1064\n",
      "Epoch [80/300], Step [17/29], Loss: 1.3052\n",
      "Epoch [80/300], Step [18/29], Loss: 1.2643\n",
      "Epoch [80/300], Step [19/29], Loss: 1.2315\n",
      "Epoch [80/300], Step [20/29], Loss: 1.3884\n",
      "Epoch [80/300], Step [21/29], Loss: 1.1562\n",
      "Epoch [80/300], Step [22/29], Loss: 1.4323\n",
      "Epoch [80/300], Step [23/29], Loss: 1.1780\n",
      "Epoch [80/300], Step [24/29], Loss: 1.3188\n",
      "Epoch [80/300], Step [25/29], Loss: 1.4011\n",
      "Epoch [80/300], Step [26/29], Loss: 1.2224\n",
      "Epoch [80/300], Step [27/29], Loss: 0.9934\n",
      "Epoch [80/300], Step [28/29], Loss: 1.4487\n",
      "Epoch [80/300], Step [29/29], Loss: 1.2287\n",
      "Epoch [81/300], Step [1/29], Loss: 1.2088\n",
      "Epoch [81/300], Step [2/29], Loss: 1.5076\n",
      "Epoch [81/300], Step [3/29], Loss: 1.2551\n",
      "Epoch [81/300], Step [4/29], Loss: 1.3006\n",
      "Epoch [81/300], Step [5/29], Loss: 1.2748\n",
      "Epoch [81/300], Step [6/29], Loss: 1.0444\n",
      "Epoch [81/300], Step [7/29], Loss: 1.2193\n",
      "Epoch [81/300], Step [8/29], Loss: 1.4430\n",
      "Epoch [81/300], Step [9/29], Loss: 1.4867\n",
      "Epoch [81/300], Step [10/29], Loss: 1.3522\n",
      "Epoch [81/300], Step [11/29], Loss: 1.2041\n",
      "Epoch [81/300], Step [12/29], Loss: 1.3167\n",
      "Epoch [81/300], Step [13/29], Loss: 1.0733\n",
      "Epoch [81/300], Step [14/29], Loss: 1.2686\n",
      "Epoch [81/300], Step [15/29], Loss: 1.2924\n",
      "Epoch [81/300], Step [16/29], Loss: 1.2601\n",
      "Epoch [81/300], Step [17/29], Loss: 1.8268\n",
      "Epoch [81/300], Step [18/29], Loss: 1.2205\n",
      "Epoch [81/300], Step [19/29], Loss: 1.4080\n",
      "Epoch [81/300], Step [20/29], Loss: 1.3043\n",
      "Epoch [81/300], Step [21/29], Loss: 1.3659\n",
      "Epoch [81/300], Step [22/29], Loss: 1.3531\n",
      "Epoch [81/300], Step [23/29], Loss: 1.2130\n",
      "Epoch [81/300], Step [24/29], Loss: 1.3145\n",
      "Epoch [81/300], Step [25/29], Loss: 1.1064\n",
      "Epoch [81/300], Step [26/29], Loss: 1.2488\n",
      "Epoch [81/300], Step [27/29], Loss: 1.1981\n",
      "Epoch [81/300], Step [28/29], Loss: 1.0353\n",
      "Epoch [81/300], Step [29/29], Loss: 0.8603\n",
      "Epoch [82/300], Step [1/29], Loss: 1.2927\n",
      "Epoch [82/300], Step [2/29], Loss: 1.0952\n",
      "Epoch [82/300], Step [3/29], Loss: 1.4845\n",
      "Epoch [82/300], Step [4/29], Loss: 1.2178\n",
      "Epoch [82/300], Step [5/29], Loss: 1.1331\n",
      "Epoch [82/300], Step [6/29], Loss: 1.0857\n",
      "Epoch [82/300], Step [7/29], Loss: 1.2634\n",
      "Epoch [82/300], Step [8/29], Loss: 1.3795\n",
      "Epoch [82/300], Step [9/29], Loss: 1.2071\n",
      "Epoch [82/300], Step [10/29], Loss: 1.4720\n",
      "Epoch [82/300], Step [11/29], Loss: 1.2139\n",
      "Epoch [82/300], Step [12/29], Loss: 1.4709\n",
      "Epoch [82/300], Step [13/29], Loss: 1.3925\n",
      "Epoch [82/300], Step [14/29], Loss: 1.1625\n",
      "Epoch [82/300], Step [15/29], Loss: 1.3247\n",
      "Epoch [82/300], Step [16/29], Loss: 1.5072\n",
      "Epoch [82/300], Step [17/29], Loss: 1.0441\n",
      "Epoch [82/300], Step [18/29], Loss: 1.3267\n",
      "Epoch [82/300], Step [19/29], Loss: 1.0810\n",
      "Epoch [82/300], Step [20/29], Loss: 1.3721\n",
      "Epoch [82/300], Step [21/29], Loss: 1.4049\n",
      "Epoch [82/300], Step [22/29], Loss: 1.6484\n",
      "Epoch [82/300], Step [23/29], Loss: 1.4130\n",
      "Epoch [82/300], Step [24/29], Loss: 1.3116\n",
      "Epoch [82/300], Step [25/29], Loss: 1.2359\n",
      "Epoch [82/300], Step [26/29], Loss: 1.1492\n",
      "Epoch [82/300], Step [27/29], Loss: 1.5228\n",
      "Epoch [82/300], Step [28/29], Loss: 1.3135\n",
      "Epoch [82/300], Step [29/29], Loss: 0.4563\n",
      "Epoch [83/300], Step [1/29], Loss: 1.2956\n",
      "Epoch [83/300], Step [2/29], Loss: 1.2120\n",
      "Epoch [83/300], Step [3/29], Loss: 1.1754\n",
      "Epoch [83/300], Step [4/29], Loss: 1.2697\n",
      "Epoch [83/300], Step [5/29], Loss: 1.3895\n",
      "Epoch [83/300], Step [6/29], Loss: 1.3281\n",
      "Epoch [83/300], Step [7/29], Loss: 1.4075\n",
      "Epoch [83/300], Step [8/29], Loss: 1.3534\n",
      "Epoch [83/300], Step [9/29], Loss: 1.5228\n",
      "Epoch [83/300], Step [10/29], Loss: 1.2840\n",
      "Epoch [83/300], Step [11/29], Loss: 1.4159\n",
      "Epoch [83/300], Step [12/29], Loss: 1.2355\n",
      "Epoch [83/300], Step [13/29], Loss: 1.2592\n",
      "Epoch [83/300], Step [14/29], Loss: 1.1350\n",
      "Epoch [83/300], Step [15/29], Loss: 1.1761\n",
      "Epoch [83/300], Step [16/29], Loss: 1.4737\n",
      "Epoch [83/300], Step [17/29], Loss: 1.1412\n",
      "Epoch [83/300], Step [18/29], Loss: 1.1845\n",
      "Epoch [83/300], Step [19/29], Loss: 1.5682\n",
      "Epoch [83/300], Step [20/29], Loss: 1.1767\n",
      "Epoch [83/300], Step [21/29], Loss: 1.1153\n",
      "Epoch [83/300], Step [22/29], Loss: 1.3612\n",
      "Epoch [83/300], Step [23/29], Loss: 1.2286\n",
      "Epoch [83/300], Step [24/29], Loss: 1.3768\n",
      "Epoch [83/300], Step [25/29], Loss: 1.2740\n",
      "Epoch [83/300], Step [26/29], Loss: 1.0557\n",
      "Epoch [83/300], Step [27/29], Loss: 1.2186\n",
      "Epoch [83/300], Step [28/29], Loss: 1.5040\n",
      "Epoch [83/300], Step [29/29], Loss: 1.4501\n",
      "Epoch [84/300], Step [1/29], Loss: 1.3445\n",
      "Epoch [84/300], Step [2/29], Loss: 1.4207\n",
      "Epoch [84/300], Step [3/29], Loss: 1.1530\n",
      "Epoch [84/300], Step [4/29], Loss: 1.2478\n",
      "Epoch [84/300], Step [5/29], Loss: 1.2385\n",
      "Epoch [84/300], Step [6/29], Loss: 1.1381\n",
      "Epoch [84/300], Step [7/29], Loss: 1.4726\n",
      "Epoch [84/300], Step [8/29], Loss: 1.4053\n",
      "Epoch [84/300], Step [9/29], Loss: 1.4658\n",
      "Epoch [84/300], Step [10/29], Loss: 1.3770\n",
      "Epoch [84/300], Step [11/29], Loss: 1.3684\n",
      "Epoch [84/300], Step [12/29], Loss: 1.4322\n",
      "Epoch [84/300], Step [13/29], Loss: 1.2810\n",
      "Epoch [84/300], Step [14/29], Loss: 1.2849\n",
      "Epoch [84/300], Step [15/29], Loss: 1.2775\n",
      "Epoch [84/300], Step [16/29], Loss: 1.0914\n",
      "Epoch [84/300], Step [17/29], Loss: 1.2419\n",
      "Epoch [84/300], Step [18/29], Loss: 1.2690\n",
      "Epoch [84/300], Step [19/29], Loss: 1.4402\n",
      "Epoch [84/300], Step [20/29], Loss: 1.2813\n",
      "Epoch [84/300], Step [21/29], Loss: 1.2164\n",
      "Epoch [84/300], Step [22/29], Loss: 1.2500\n",
      "Epoch [84/300], Step [23/29], Loss: 1.1975\n",
      "Epoch [84/300], Step [24/29], Loss: 1.0750\n",
      "Epoch [84/300], Step [25/29], Loss: 1.2322\n",
      "Epoch [84/300], Step [26/29], Loss: 1.1923\n",
      "Epoch [84/300], Step [27/29], Loss: 1.3190\n",
      "Epoch [84/300], Step [28/29], Loss: 1.4024\n",
      "Epoch [84/300], Step [29/29], Loss: 1.5707\n",
      "Epoch [85/300], Step [1/29], Loss: 1.5010\n",
      "Epoch [85/300], Step [2/29], Loss: 1.4507\n",
      "Epoch [85/300], Step [3/29], Loss: 1.1663\n",
      "Epoch [85/300], Step [4/29], Loss: 1.2230\n",
      "Epoch [85/300], Step [5/29], Loss: 1.3908\n",
      "Epoch [85/300], Step [6/29], Loss: 1.1676\n",
      "Epoch [85/300], Step [7/29], Loss: 0.9767\n",
      "Epoch [85/300], Step [8/29], Loss: 1.1536\n",
      "Epoch [85/300], Step [9/29], Loss: 1.5268\n",
      "Epoch [85/300], Step [10/29], Loss: 1.0856\n",
      "Epoch [85/300], Step [11/29], Loss: 1.2711\n",
      "Epoch [85/300], Step [12/29], Loss: 1.3781\n",
      "Epoch [85/300], Step [13/29], Loss: 1.3241\n",
      "Epoch [85/300], Step [14/29], Loss: 1.3683\n",
      "Epoch [85/300], Step [15/29], Loss: 1.1913\n",
      "Epoch [85/300], Step [16/29], Loss: 1.1094\n",
      "Epoch [85/300], Step [17/29], Loss: 1.4537\n",
      "Epoch [85/300], Step [18/29], Loss: 1.3712\n",
      "Epoch [85/300], Step [19/29], Loss: 1.1701\n",
      "Epoch [85/300], Step [20/29], Loss: 1.1902\n",
      "Epoch [85/300], Step [21/29], Loss: 1.2739\n",
      "Epoch [85/300], Step [22/29], Loss: 1.3428\n",
      "Epoch [85/300], Step [23/29], Loss: 1.6162\n",
      "Epoch [85/300], Step [24/29], Loss: 1.1326\n",
      "Epoch [85/300], Step [25/29], Loss: 1.2118\n",
      "Epoch [85/300], Step [26/29], Loss: 1.2690\n",
      "Epoch [85/300], Step [27/29], Loss: 1.3288\n",
      "Epoch [85/300], Step [28/29], Loss: 1.6163\n",
      "Epoch [85/300], Step [29/29], Loss: 2.8597\n",
      "Epoch [86/300], Step [1/29], Loss: 1.2370\n",
      "Epoch [86/300], Step [2/29], Loss: 1.1963\n",
      "Epoch [86/300], Step [3/29], Loss: 1.2251\n",
      "Epoch [86/300], Step [4/29], Loss: 1.1547\n",
      "Epoch [86/300], Step [5/29], Loss: 1.1803\n",
      "Epoch [86/300], Step [6/29], Loss: 1.2519\n",
      "Epoch [86/300], Step [7/29], Loss: 1.2713\n",
      "Epoch [86/300], Step [8/29], Loss: 1.3442\n",
      "Epoch [86/300], Step [9/29], Loss: 1.2777\n",
      "Epoch [86/300], Step [10/29], Loss: 1.1761\n",
      "Epoch [86/300], Step [11/29], Loss: 1.0794\n",
      "Epoch [86/300], Step [12/29], Loss: 1.2473\n",
      "Epoch [86/300], Step [13/29], Loss: 1.5985\n",
      "Epoch [86/300], Step [14/29], Loss: 1.2010\n",
      "Epoch [86/300], Step [15/29], Loss: 1.3336\n",
      "Epoch [86/300], Step [16/29], Loss: 1.5018\n",
      "Epoch [86/300], Step [17/29], Loss: 1.2357\n",
      "Epoch [86/300], Step [18/29], Loss: 1.5024\n",
      "Epoch [86/300], Step [19/29], Loss: 1.2408\n",
      "Epoch [86/300], Step [20/29], Loss: 1.2445\n",
      "Epoch [86/300], Step [21/29], Loss: 1.4265\n",
      "Epoch [86/300], Step [22/29], Loss: 1.6289\n",
      "Epoch [86/300], Step [23/29], Loss: 1.2169\n",
      "Epoch [86/300], Step [24/29], Loss: 1.2376\n",
      "Epoch [86/300], Step [25/29], Loss: 1.1635\n",
      "Epoch [86/300], Step [26/29], Loss: 1.4305\n",
      "Epoch [86/300], Step [27/29], Loss: 1.2190\n",
      "Epoch [86/300], Step [28/29], Loss: 1.3460\n",
      "Epoch [86/300], Step [29/29], Loss: 1.7564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/300], Step [1/29], Loss: 1.2169\n",
      "Epoch [87/300], Step [2/29], Loss: 1.1071\n",
      "Epoch [87/300], Step [3/29], Loss: 1.4939\n",
      "Epoch [87/300], Step [4/29], Loss: 1.6895\n",
      "Epoch [87/300], Step [5/29], Loss: 1.0233\n",
      "Epoch [87/300], Step [6/29], Loss: 1.1701\n",
      "Epoch [87/300], Step [7/29], Loss: 1.4676\n",
      "Epoch [87/300], Step [8/29], Loss: 1.2892\n",
      "Epoch [87/300], Step [9/29], Loss: 1.5692\n",
      "Epoch [87/300], Step [10/29], Loss: 1.2492\n",
      "Epoch [87/300], Step [11/29], Loss: 1.3693\n",
      "Epoch [87/300], Step [12/29], Loss: 1.3667\n",
      "Epoch [87/300], Step [13/29], Loss: 1.0414\n",
      "Epoch [87/300], Step [14/29], Loss: 1.2318\n",
      "Epoch [87/300], Step [15/29], Loss: 1.1422\n",
      "Epoch [87/300], Step [16/29], Loss: 1.2246\n",
      "Epoch [87/300], Step [17/29], Loss: 1.1998\n",
      "Epoch [87/300], Step [18/29], Loss: 1.1019\n",
      "Epoch [87/300], Step [19/29], Loss: 1.4032\n",
      "Epoch [87/300], Step [20/29], Loss: 1.4866\n",
      "Epoch [87/300], Step [21/29], Loss: 1.5518\n",
      "Epoch [87/300], Step [22/29], Loss: 1.3223\n",
      "Epoch [87/300], Step [23/29], Loss: 1.3967\n",
      "Epoch [87/300], Step [24/29], Loss: 1.0854\n",
      "Epoch [87/300], Step [25/29], Loss: 1.1982\n",
      "Epoch [87/300], Step [26/29], Loss: 1.2772\n",
      "Epoch [87/300], Step [27/29], Loss: 1.2491\n",
      "Epoch [87/300], Step [28/29], Loss: 1.3194\n",
      "Epoch [87/300], Step [29/29], Loss: 0.9875\n",
      "Epoch [88/300], Step [1/29], Loss: 0.9786\n",
      "Epoch [88/300], Step [2/29], Loss: 1.5889\n",
      "Epoch [88/300], Step [3/29], Loss: 1.0875\n",
      "Epoch [88/300], Step [4/29], Loss: 1.1320\n",
      "Epoch [88/300], Step [5/29], Loss: 1.3536\n",
      "Epoch [88/300], Step [6/29], Loss: 1.3874\n",
      "Epoch [88/300], Step [7/29], Loss: 1.0524\n",
      "Epoch [88/300], Step [8/29], Loss: 1.7202\n",
      "Epoch [88/300], Step [9/29], Loss: 1.3313\n",
      "Epoch [88/300], Step [10/29], Loss: 1.4353\n",
      "Epoch [88/300], Step [11/29], Loss: 1.4295\n",
      "Epoch [88/300], Step [12/29], Loss: 1.1459\n",
      "Epoch [88/300], Step [13/29], Loss: 1.5295\n",
      "Epoch [88/300], Step [14/29], Loss: 1.2496\n",
      "Epoch [88/300], Step [15/29], Loss: 1.2719\n",
      "Epoch [88/300], Step [16/29], Loss: 1.4951\n",
      "Epoch [88/300], Step [17/29], Loss: 1.3717\n",
      "Epoch [88/300], Step [18/29], Loss: 1.0110\n",
      "Epoch [88/300], Step [19/29], Loss: 1.0268\n",
      "Epoch [88/300], Step [20/29], Loss: 1.1871\n",
      "Epoch [88/300], Step [21/29], Loss: 1.4729\n",
      "Epoch [88/300], Step [22/29], Loss: 1.3152\n",
      "Epoch [88/300], Step [23/29], Loss: 1.2538\n",
      "Epoch [88/300], Step [24/29], Loss: 1.0875\n",
      "Epoch [88/300], Step [25/29], Loss: 1.2739\n",
      "Epoch [88/300], Step [26/29], Loss: 1.4042\n",
      "Epoch [88/300], Step [27/29], Loss: 1.2489\n",
      "Epoch [88/300], Step [28/29], Loss: 1.2106\n",
      "Epoch [88/300], Step [29/29], Loss: 1.5105\n",
      "Epoch [89/300], Step [1/29], Loss: 1.1377\n",
      "Epoch [89/300], Step [2/29], Loss: 1.1768\n",
      "Epoch [89/300], Step [3/29], Loss: 1.1919\n",
      "Epoch [89/300], Step [4/29], Loss: 1.3530\n",
      "Epoch [89/300], Step [5/29], Loss: 1.1817\n",
      "Epoch [89/300], Step [6/29], Loss: 1.2547\n",
      "Epoch [89/300], Step [7/29], Loss: 1.4257\n",
      "Epoch [89/300], Step [8/29], Loss: 1.3434\n",
      "Epoch [89/300], Step [9/29], Loss: 1.3267\n",
      "Epoch [89/300], Step [10/29], Loss: 1.4991\n",
      "Epoch [89/300], Step [11/29], Loss: 1.1922\n",
      "Epoch [89/300], Step [12/29], Loss: 1.3704\n",
      "Epoch [89/300], Step [13/29], Loss: 1.3682\n",
      "Epoch [89/300], Step [14/29], Loss: 1.1523\n",
      "Epoch [89/300], Step [15/29], Loss: 1.4686\n",
      "Epoch [89/300], Step [16/29], Loss: 1.3204\n",
      "Epoch [89/300], Step [17/29], Loss: 1.3047\n",
      "Epoch [89/300], Step [18/29], Loss: 1.3364\n",
      "Epoch [89/300], Step [19/29], Loss: 1.2092\n",
      "Epoch [89/300], Step [20/29], Loss: 1.4168\n",
      "Epoch [89/300], Step [21/29], Loss: 1.1949\n",
      "Epoch [89/300], Step [22/29], Loss: 1.3623\n",
      "Epoch [89/300], Step [23/29], Loss: 1.1056\n",
      "Epoch [89/300], Step [24/29], Loss: 1.3644\n",
      "Epoch [89/300], Step [25/29], Loss: 1.3204\n",
      "Epoch [89/300], Step [26/29], Loss: 1.3148\n",
      "Epoch [89/300], Step [27/29], Loss: 1.4994\n",
      "Epoch [89/300], Step [28/29], Loss: 1.3052\n",
      "Epoch [89/300], Step [29/29], Loss: 1.4671\n",
      "Epoch [90/300], Step [1/29], Loss: 1.3105\n",
      "Epoch [90/300], Step [2/29], Loss: 1.0730\n",
      "Epoch [90/300], Step [3/29], Loss: 1.1869\n",
      "Epoch [90/300], Step [4/29], Loss: 1.2416\n",
      "Epoch [90/300], Step [5/29], Loss: 1.5017\n",
      "Epoch [90/300], Step [6/29], Loss: 1.3312\n",
      "Epoch [90/300], Step [7/29], Loss: 1.3226\n",
      "Epoch [90/300], Step [8/29], Loss: 1.2206\n",
      "Epoch [90/300], Step [9/29], Loss: 1.0467\n",
      "Epoch [90/300], Step [10/29], Loss: 1.2226\n",
      "Epoch [90/300], Step [11/29], Loss: 1.2343\n",
      "Epoch [90/300], Step [12/29], Loss: 1.3308\n",
      "Epoch [90/300], Step [13/29], Loss: 1.5357\n",
      "Epoch [90/300], Step [14/29], Loss: 1.3560\n",
      "Epoch [90/300], Step [15/29], Loss: 1.3072\n",
      "Epoch [90/300], Step [16/29], Loss: 1.1777\n",
      "Epoch [90/300], Step [17/29], Loss: 1.1746\n",
      "Epoch [90/300], Step [18/29], Loss: 0.9741\n",
      "Epoch [90/300], Step [19/29], Loss: 1.2745\n",
      "Epoch [90/300], Step [20/29], Loss: 1.3633\n",
      "Epoch [90/300], Step [21/29], Loss: 1.4654\n",
      "Epoch [90/300], Step [22/29], Loss: 1.2961\n",
      "Epoch [90/300], Step [23/29], Loss: 1.5163\n",
      "Epoch [90/300], Step [24/29], Loss: 1.3308\n",
      "Epoch [90/300], Step [25/29], Loss: 1.5709\n",
      "Epoch [90/300], Step [26/29], Loss: 1.3506\n",
      "Epoch [90/300], Step [27/29], Loss: 1.1530\n",
      "Epoch [90/300], Step [28/29], Loss: 1.3899\n",
      "Epoch [90/300], Step [29/29], Loss: 1.3777\n",
      "Epoch [91/300], Step [1/29], Loss: 1.2973\n",
      "Epoch [91/300], Step [2/29], Loss: 1.3485\n",
      "Epoch [91/300], Step [3/29], Loss: 1.3903\n",
      "Epoch [91/300], Step [4/29], Loss: 1.2061\n",
      "Epoch [91/300], Step [5/29], Loss: 1.4524\n",
      "Epoch [91/300], Step [6/29], Loss: 1.2606\n",
      "Epoch [91/300], Step [7/29], Loss: 1.1635\n",
      "Epoch [91/300], Step [8/29], Loss: 1.2546\n",
      "Epoch [91/300], Step [9/29], Loss: 1.3629\n",
      "Epoch [91/300], Step [10/29], Loss: 1.3185\n",
      "Epoch [91/300], Step [11/29], Loss: 1.3411\n",
      "Epoch [91/300], Step [12/29], Loss: 0.9811\n",
      "Epoch [91/300], Step [13/29], Loss: 1.2722\n",
      "Epoch [91/300], Step [14/29], Loss: 1.2120\n",
      "Epoch [91/300], Step [15/29], Loss: 1.4461\n",
      "Epoch [91/300], Step [16/29], Loss: 1.3090\n",
      "Epoch [91/300], Step [17/29], Loss: 1.4058\n",
      "Epoch [91/300], Step [18/29], Loss: 1.3388\n",
      "Epoch [91/300], Step [19/29], Loss: 1.3291\n",
      "Epoch [91/300], Step [20/29], Loss: 1.4113\n",
      "Epoch [91/300], Step [21/29], Loss: 1.1112\n",
      "Epoch [91/300], Step [22/29], Loss: 1.0876\n",
      "Epoch [91/300], Step [23/29], Loss: 1.0900\n",
      "Epoch [91/300], Step [24/29], Loss: 1.2518\n",
      "Epoch [91/300], Step [25/29], Loss: 1.5092\n",
      "Epoch [91/300], Step [26/29], Loss: 1.4889\n",
      "Epoch [91/300], Step [27/29], Loss: 1.2886\n",
      "Epoch [91/300], Step [28/29], Loss: 1.2402\n",
      "Epoch [91/300], Step [29/29], Loss: 0.3552\n",
      "Epoch [92/300], Step [1/29], Loss: 1.1422\n",
      "Epoch [92/300], Step [2/29], Loss: 1.3477\n",
      "Epoch [92/300], Step [3/29], Loss: 1.1914\n",
      "Epoch [92/300], Step [4/29], Loss: 1.4311\n",
      "Epoch [92/300], Step [5/29], Loss: 1.0493\n",
      "Epoch [92/300], Step [6/29], Loss: 1.5234\n",
      "Epoch [92/300], Step [7/29], Loss: 1.5705\n",
      "Epoch [92/300], Step [8/29], Loss: 1.2654\n",
      "Epoch [92/300], Step [9/29], Loss: 1.1502\n",
      "Epoch [92/300], Step [10/29], Loss: 1.4620\n",
      "Epoch [92/300], Step [11/29], Loss: 1.5228\n",
      "Epoch [92/300], Step [12/29], Loss: 1.2740\n",
      "Epoch [92/300], Step [13/29], Loss: 1.5104\n",
      "Epoch [92/300], Step [14/29], Loss: 1.1888\n",
      "Epoch [92/300], Step [15/29], Loss: 1.1401\n",
      "Epoch [92/300], Step [16/29], Loss: 1.1029\n",
      "Epoch [92/300], Step [17/29], Loss: 1.3067\n",
      "Epoch [92/300], Step [18/29], Loss: 1.2381\n",
      "Epoch [92/300], Step [19/29], Loss: 1.4896\n",
      "Epoch [92/300], Step [20/29], Loss: 1.1971\n",
      "Epoch [92/300], Step [21/29], Loss: 1.5884\n",
      "Epoch [92/300], Step [22/29], Loss: 1.1493\n",
      "Epoch [92/300], Step [23/29], Loss: 1.3147\n",
      "Epoch [92/300], Step [24/29], Loss: 1.4645\n",
      "Epoch [92/300], Step [25/29], Loss: 1.0803\n",
      "Epoch [92/300], Step [26/29], Loss: 1.2945\n",
      "Epoch [92/300], Step [27/29], Loss: 1.3007\n",
      "Epoch [92/300], Step [28/29], Loss: 1.2443\n",
      "Epoch [92/300], Step [29/29], Loss: 0.7329\n",
      "Epoch [93/300], Step [1/29], Loss: 1.2720\n",
      "Epoch [93/300], Step [2/29], Loss: 1.2493\n",
      "Epoch [93/300], Step [3/29], Loss: 1.2703\n",
      "Epoch [93/300], Step [4/29], Loss: 1.4935\n",
      "Epoch [93/300], Step [5/29], Loss: 1.2493\n",
      "Epoch [93/300], Step [6/29], Loss: 1.1692\n",
      "Epoch [93/300], Step [7/29], Loss: 1.2740\n",
      "Epoch [93/300], Step [8/29], Loss: 1.2957\n",
      "Epoch [93/300], Step [9/29], Loss: 1.3294\n",
      "Epoch [93/300], Step [10/29], Loss: 1.2460\n",
      "Epoch [93/300], Step [11/29], Loss: 1.3386\n",
      "Epoch [93/300], Step [12/29], Loss: 1.1299\n",
      "Epoch [93/300], Step [13/29], Loss: 1.4536\n",
      "Epoch [93/300], Step [14/29], Loss: 1.3355\n",
      "Epoch [93/300], Step [15/29], Loss: 1.2504\n",
      "Epoch [93/300], Step [16/29], Loss: 1.2206\n",
      "Epoch [93/300], Step [17/29], Loss: 0.9897\n",
      "Epoch [93/300], Step [18/29], Loss: 1.3846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/300], Step [19/29], Loss: 1.3403\n",
      "Epoch [93/300], Step [20/29], Loss: 1.1206\n",
      "Epoch [93/300], Step [21/29], Loss: 1.5059\n",
      "Epoch [93/300], Step [22/29], Loss: 1.3344\n",
      "Epoch [93/300], Step [23/29], Loss: 1.3062\n",
      "Epoch [93/300], Step [24/29], Loss: 1.3466\n",
      "Epoch [93/300], Step [25/29], Loss: 1.3788\n",
      "Epoch [93/300], Step [26/29], Loss: 1.2408\n",
      "Epoch [93/300], Step [27/29], Loss: 1.4001\n",
      "Epoch [93/300], Step [28/29], Loss: 1.3582\n",
      "Epoch [93/300], Step [29/29], Loss: 1.0589\n",
      "Epoch [94/300], Step [1/29], Loss: 1.5141\n",
      "Epoch [94/300], Step [2/29], Loss: 1.2872\n",
      "Epoch [94/300], Step [3/29], Loss: 1.1319\n",
      "Epoch [94/300], Step [4/29], Loss: 1.2522\n",
      "Epoch [94/300], Step [5/29], Loss: 1.2487\n",
      "Epoch [94/300], Step [6/29], Loss: 1.1772\n",
      "Epoch [94/300], Step [7/29], Loss: 1.6032\n",
      "Epoch [94/300], Step [8/29], Loss: 1.4412\n",
      "Epoch [94/300], Step [9/29], Loss: 1.0480\n",
      "Epoch [94/300], Step [10/29], Loss: 1.2567\n",
      "Epoch [94/300], Step [11/29], Loss: 1.3067\n",
      "Epoch [94/300], Step [12/29], Loss: 1.3058\n",
      "Epoch [94/300], Step [13/29], Loss: 1.2764\n",
      "Epoch [94/300], Step [14/29], Loss: 1.2935\n",
      "Epoch [94/300], Step [15/29], Loss: 1.3660\n",
      "Epoch [94/300], Step [16/29], Loss: 1.1608\n",
      "Epoch [94/300], Step [17/29], Loss: 1.2585\n",
      "Epoch [94/300], Step [18/29], Loss: 1.1966\n",
      "Epoch [94/300], Step [19/29], Loss: 1.4284\n",
      "Epoch [94/300], Step [20/29], Loss: 1.1689\n",
      "Epoch [94/300], Step [21/29], Loss: 1.2668\n",
      "Epoch [94/300], Step [22/29], Loss: 1.3773\n",
      "Epoch [94/300], Step [23/29], Loss: 1.2751\n",
      "Epoch [94/300], Step [24/29], Loss: 1.6076\n",
      "Epoch [94/300], Step [25/29], Loss: 1.2449\n",
      "Epoch [94/300], Step [26/29], Loss: 1.2163\n",
      "Epoch [94/300], Step [27/29], Loss: 1.2600\n",
      "Epoch [94/300], Step [28/29], Loss: 1.1361\n",
      "Epoch [94/300], Step [29/29], Loss: 1.6346\n",
      "Epoch [95/300], Step [1/29], Loss: 1.2399\n",
      "Epoch [95/300], Step [2/29], Loss: 1.1417\n",
      "Epoch [95/300], Step [3/29], Loss: 1.1938\n",
      "Epoch [95/300], Step [4/29], Loss: 1.2114\n",
      "Epoch [95/300], Step [5/29], Loss: 1.5560\n",
      "Epoch [95/300], Step [6/29], Loss: 1.4205\n",
      "Epoch [95/300], Step [7/29], Loss: 1.4305\n",
      "Epoch [95/300], Step [8/29], Loss: 1.0585\n",
      "Epoch [95/300], Step [9/29], Loss: 1.2136\n",
      "Epoch [95/300], Step [10/29], Loss: 1.2930\n",
      "Epoch [95/300], Step [11/29], Loss: 1.1545\n",
      "Epoch [95/300], Step [12/29], Loss: 1.1961\n",
      "Epoch [95/300], Step [13/29], Loss: 1.1066\n",
      "Epoch [95/300], Step [14/29], Loss: 1.4158\n",
      "Epoch [95/300], Step [15/29], Loss: 1.5448\n",
      "Epoch [95/300], Step [16/29], Loss: 1.1533\n",
      "Epoch [95/300], Step [17/29], Loss: 1.2697\n",
      "Epoch [95/300], Step [18/29], Loss: 1.2467\n",
      "Epoch [95/300], Step [19/29], Loss: 1.2110\n",
      "Epoch [95/300], Step [20/29], Loss: 1.1255\n",
      "Epoch [95/300], Step [21/29], Loss: 1.2914\n",
      "Epoch [95/300], Step [22/29], Loss: 1.5908\n",
      "Epoch [95/300], Step [23/29], Loss: 1.4650\n",
      "Epoch [95/300], Step [24/29], Loss: 1.3892\n",
      "Epoch [95/300], Step [25/29], Loss: 1.1562\n",
      "Epoch [95/300], Step [26/29], Loss: 1.4985\n",
      "Epoch [95/300], Step [27/29], Loss: 1.4598\n",
      "Epoch [95/300], Step [28/29], Loss: 1.4000\n",
      "Epoch [95/300], Step [29/29], Loss: 1.7089\n",
      "Epoch [96/300], Step [1/29], Loss: 1.6079\n",
      "Epoch [96/300], Step [2/29], Loss: 1.5060\n",
      "Epoch [96/300], Step [3/29], Loss: 1.2620\n",
      "Epoch [96/300], Step [4/29], Loss: 1.2528\n",
      "Epoch [96/300], Step [5/29], Loss: 1.1917\n",
      "Epoch [96/300], Step [6/29], Loss: 1.0238\n",
      "Epoch [96/300], Step [7/29], Loss: 1.5695\n",
      "Epoch [96/300], Step [8/29], Loss: 1.2275\n",
      "Epoch [96/300], Step [9/29], Loss: 1.2323\n",
      "Epoch [96/300], Step [10/29], Loss: 1.0871\n",
      "Epoch [96/300], Step [11/29], Loss: 1.3254\n",
      "Epoch [96/300], Step [12/29], Loss: 1.2926\n",
      "Epoch [96/300], Step [13/29], Loss: 1.4968\n",
      "Epoch [96/300], Step [14/29], Loss: 1.2285\n",
      "Epoch [96/300], Step [15/29], Loss: 1.1880\n",
      "Epoch [96/300], Step [16/29], Loss: 1.4025\n",
      "Epoch [96/300], Step [17/29], Loss: 1.1780\n",
      "Epoch [96/300], Step [18/29], Loss: 1.1865\n",
      "Epoch [96/300], Step [19/29], Loss: 1.3419\n",
      "Epoch [96/300], Step [20/29], Loss: 1.3730\n",
      "Epoch [96/300], Step [21/29], Loss: 1.0675\n",
      "Epoch [96/300], Step [22/29], Loss: 1.1628\n",
      "Epoch [96/300], Step [23/29], Loss: 1.4198\n",
      "Epoch [96/300], Step [24/29], Loss: 1.2078\n",
      "Epoch [96/300], Step [25/29], Loss: 1.5426\n",
      "Epoch [96/300], Step [26/29], Loss: 1.0931\n",
      "Epoch [96/300], Step [27/29], Loss: 1.5148\n",
      "Epoch [96/300], Step [28/29], Loss: 0.9921\n",
      "Epoch [96/300], Step [29/29], Loss: 1.4585\n",
      "Epoch [97/300], Step [1/29], Loss: 1.3957\n",
      "Epoch [97/300], Step [2/29], Loss: 1.4343\n",
      "Epoch [97/300], Step [3/29], Loss: 1.2406\n",
      "Epoch [97/300], Step [4/29], Loss: 1.0989\n",
      "Epoch [97/300], Step [5/29], Loss: 0.8913\n",
      "Epoch [97/300], Step [6/29], Loss: 1.2242\n",
      "Epoch [97/300], Step [7/29], Loss: 1.4130\n",
      "Epoch [97/300], Step [8/29], Loss: 1.4414\n",
      "Epoch [97/300], Step [9/29], Loss: 1.2312\n",
      "Epoch [97/300], Step [10/29], Loss: 1.2313\n",
      "Epoch [97/300], Step [11/29], Loss: 1.0619\n",
      "Epoch [97/300], Step [12/29], Loss: 1.2746\n",
      "Epoch [97/300], Step [13/29], Loss: 1.4870\n",
      "Epoch [97/300], Step [14/29], Loss: 1.4845\n",
      "Epoch [97/300], Step [15/29], Loss: 1.2602\n",
      "Epoch [97/300], Step [16/29], Loss: 1.4673\n",
      "Epoch [97/300], Step [17/29], Loss: 1.1593\n",
      "Epoch [97/300], Step [18/29], Loss: 1.2446\n",
      "Epoch [97/300], Step [19/29], Loss: 1.4109\n",
      "Epoch [97/300], Step [20/29], Loss: 1.4953\n",
      "Epoch [97/300], Step [21/29], Loss: 1.4286\n",
      "Epoch [97/300], Step [22/29], Loss: 1.2876\n",
      "Epoch [97/300], Step [23/29], Loss: 1.2472\n",
      "Epoch [97/300], Step [24/29], Loss: 1.4698\n",
      "Epoch [97/300], Step [25/29], Loss: 1.0243\n",
      "Epoch [97/300], Step [26/29], Loss: 1.2604\n",
      "Epoch [97/300], Step [27/29], Loss: 1.3481\n",
      "Epoch [97/300], Step [28/29], Loss: 1.2890\n",
      "Epoch [97/300], Step [29/29], Loss: 2.2948\n",
      "Epoch [98/300], Step [1/29], Loss: 1.3048\n",
      "Epoch [98/300], Step [2/29], Loss: 1.3261\n",
      "Epoch [98/300], Step [3/29], Loss: 1.3253\n",
      "Epoch [98/300], Step [4/29], Loss: 1.3593\n",
      "Epoch [98/300], Step [5/29], Loss: 1.3307\n",
      "Epoch [98/300], Step [6/29], Loss: 1.3084\n",
      "Epoch [98/300], Step [7/29], Loss: 1.3229\n",
      "Epoch [98/300], Step [8/29], Loss: 1.4013\n",
      "Epoch [98/300], Step [9/29], Loss: 1.1893\n",
      "Epoch [98/300], Step [10/29], Loss: 1.1543\n",
      "Epoch [98/300], Step [11/29], Loss: 1.3044\n",
      "Epoch [98/300], Step [12/29], Loss: 1.7968\n",
      "Epoch [98/300], Step [13/29], Loss: 1.4936\n",
      "Epoch [98/300], Step [14/29], Loss: 1.4253\n",
      "Epoch [98/300], Step [15/29], Loss: 1.1194\n",
      "Epoch [98/300], Step [16/29], Loss: 1.2153\n",
      "Epoch [98/300], Step [17/29], Loss: 1.3345\n",
      "Epoch [98/300], Step [18/29], Loss: 1.2427\n",
      "Epoch [98/300], Step [19/29], Loss: 1.5240\n",
      "Epoch [98/300], Step [20/29], Loss: 1.3320\n",
      "Epoch [98/300], Step [21/29], Loss: 1.2955\n",
      "Epoch [98/300], Step [22/29], Loss: 1.2229\n",
      "Epoch [98/300], Step [23/29], Loss: 1.2868\n",
      "Epoch [98/300], Step [24/29], Loss: 1.3024\n",
      "Epoch [98/300], Step [25/29], Loss: 1.0405\n",
      "Epoch [98/300], Step [26/29], Loss: 0.9483\n",
      "Epoch [98/300], Step [27/29], Loss: 1.0816\n",
      "Epoch [98/300], Step [28/29], Loss: 1.3894\n",
      "Epoch [98/300], Step [29/29], Loss: 1.9372\n",
      "Epoch [99/300], Step [1/29], Loss: 1.2735\n",
      "Epoch [99/300], Step [2/29], Loss: 1.1123\n",
      "Epoch [99/300], Step [3/29], Loss: 1.1158\n",
      "Epoch [99/300], Step [4/29], Loss: 1.5215\n",
      "Epoch [99/300], Step [5/29], Loss: 1.4066\n",
      "Epoch [99/300], Step [6/29], Loss: 1.5495\n",
      "Epoch [99/300], Step [7/29], Loss: 1.2022\n",
      "Epoch [99/300], Step [8/29], Loss: 1.2828\n",
      "Epoch [99/300], Step [9/29], Loss: 1.4247\n",
      "Epoch [99/300], Step [10/29], Loss: 1.2798\n",
      "Epoch [99/300], Step [11/29], Loss: 1.3151\n",
      "Epoch [99/300], Step [12/29], Loss: 1.3635\n",
      "Epoch [99/300], Step [13/29], Loss: 1.3152\n",
      "Epoch [99/300], Step [14/29], Loss: 1.4053\n",
      "Epoch [99/300], Step [15/29], Loss: 1.3062\n",
      "Epoch [99/300], Step [16/29], Loss: 1.3300\n",
      "Epoch [99/300], Step [17/29], Loss: 1.3693\n",
      "Epoch [99/300], Step [18/29], Loss: 1.2148\n",
      "Epoch [99/300], Step [19/29], Loss: 1.3533\n",
      "Epoch [99/300], Step [20/29], Loss: 1.0825\n",
      "Epoch [99/300], Step [21/29], Loss: 1.2363\n",
      "Epoch [99/300], Step [22/29], Loss: 1.2738\n",
      "Epoch [99/300], Step [23/29], Loss: 1.3149\n",
      "Epoch [99/300], Step [24/29], Loss: 1.1738\n",
      "Epoch [99/300], Step [25/29], Loss: 1.1534\n",
      "Epoch [99/300], Step [26/29], Loss: 1.4641\n",
      "Epoch [99/300], Step [27/29], Loss: 1.1947\n",
      "Epoch [99/300], Step [28/29], Loss: 1.3120\n",
      "Epoch [99/300], Step [29/29], Loss: 2.2224\n",
      "Epoch [100/300], Step [1/29], Loss: 1.3484\n",
      "Epoch [100/300], Step [2/29], Loss: 1.2994\n",
      "Epoch [100/300], Step [3/29], Loss: 1.3058\n",
      "Epoch [100/300], Step [4/29], Loss: 1.3345\n",
      "Epoch [100/300], Step [5/29], Loss: 1.4856\n",
      "Epoch [100/300], Step [6/29], Loss: 1.3358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/300], Step [7/29], Loss: 1.4861\n",
      "Epoch [100/300], Step [8/29], Loss: 1.4981\n",
      "Epoch [100/300], Step [9/29], Loss: 1.1947\n",
      "Epoch [100/300], Step [10/29], Loss: 1.4238\n",
      "Epoch [100/300], Step [11/29], Loss: 1.2039\n",
      "Epoch [100/300], Step [12/29], Loss: 1.1547\n",
      "Epoch [100/300], Step [13/29], Loss: 1.3896\n",
      "Epoch [100/300], Step [14/29], Loss: 0.9847\n",
      "Epoch [100/300], Step [15/29], Loss: 0.9986\n",
      "Epoch [100/300], Step [16/29], Loss: 1.2340\n",
      "Epoch [100/300], Step [17/29], Loss: 1.3654\n",
      "Epoch [100/300], Step [18/29], Loss: 1.5538\n",
      "Epoch [100/300], Step [19/29], Loss: 1.4033\n",
      "Epoch [100/300], Step [20/29], Loss: 0.9832\n",
      "Epoch [100/300], Step [21/29], Loss: 1.3372\n",
      "Epoch [100/300], Step [22/29], Loss: 1.2223\n",
      "Epoch [100/300], Step [23/29], Loss: 1.2434\n",
      "Epoch [100/300], Step [24/29], Loss: 1.3808\n",
      "Epoch [100/300], Step [25/29], Loss: 1.2791\n",
      "Epoch [100/300], Step [26/29], Loss: 1.2000\n",
      "Epoch [100/300], Step [27/29], Loss: 1.2977\n",
      "Epoch [100/300], Step [28/29], Loss: 1.0474\n",
      "Epoch [100/300], Step [29/29], Loss: 2.9525\n",
      "Epoch [101/300], Step [1/29], Loss: 1.4790\n",
      "Epoch [101/300], Step [2/29], Loss: 1.2990\n",
      "Epoch [101/300], Step [3/29], Loss: 1.2153\n",
      "Epoch [101/300], Step [4/29], Loss: 1.5689\n",
      "Epoch [101/300], Step [5/29], Loss: 1.1370\n",
      "Epoch [101/300], Step [6/29], Loss: 1.0633\n",
      "Epoch [101/300], Step [7/29], Loss: 1.3466\n",
      "Epoch [101/300], Step [8/29], Loss: 1.4007\n",
      "Epoch [101/300], Step [9/29], Loss: 1.3360\n",
      "Epoch [101/300], Step [10/29], Loss: 1.1184\n",
      "Epoch [101/300], Step [11/29], Loss: 1.2942\n",
      "Epoch [101/300], Step [12/29], Loss: 1.1904\n",
      "Epoch [101/300], Step [13/29], Loss: 1.1718\n",
      "Epoch [101/300], Step [14/29], Loss: 1.3173\n",
      "Epoch [101/300], Step [15/29], Loss: 1.1052\n",
      "Epoch [101/300], Step [16/29], Loss: 1.2973\n",
      "Epoch [101/300], Step [17/29], Loss: 1.1214\n",
      "Epoch [101/300], Step [18/29], Loss: 1.5138\n",
      "Epoch [101/300], Step [19/29], Loss: 1.6416\n",
      "Epoch [101/300], Step [20/29], Loss: 1.1401\n",
      "Epoch [101/300], Step [21/29], Loss: 1.2843\n",
      "Epoch [101/300], Step [22/29], Loss: 1.3723\n",
      "Epoch [101/300], Step [23/29], Loss: 1.2540\n",
      "Epoch [101/300], Step [24/29], Loss: 1.0987\n",
      "Epoch [101/300], Step [25/29], Loss: 1.3215\n",
      "Epoch [101/300], Step [26/29], Loss: 1.2650\n",
      "Epoch [101/300], Step [27/29], Loss: 1.3372\n",
      "Epoch [101/300], Step [28/29], Loss: 1.3350\n",
      "Epoch [101/300], Step [29/29], Loss: 2.3056\n",
      "Epoch [102/300], Step [1/29], Loss: 1.3866\n",
      "Epoch [102/300], Step [2/29], Loss: 1.4454\n",
      "Epoch [102/300], Step [3/29], Loss: 1.5953\n",
      "Epoch [102/300], Step [4/29], Loss: 1.5315\n",
      "Epoch [102/300], Step [5/29], Loss: 1.3262\n",
      "Epoch [102/300], Step [6/29], Loss: 1.4002\n",
      "Epoch [102/300], Step [7/29], Loss: 1.2905\n",
      "Epoch [102/300], Step [8/29], Loss: 1.3445\n",
      "Epoch [102/300], Step [9/29], Loss: 1.2360\n",
      "Epoch [102/300], Step [10/29], Loss: 1.2162\n",
      "Epoch [102/300], Step [11/29], Loss: 1.3251\n",
      "Epoch [102/300], Step [12/29], Loss: 1.3121\n",
      "Epoch [102/300], Step [13/29], Loss: 1.5341\n",
      "Epoch [102/300], Step [14/29], Loss: 1.3089\n",
      "Epoch [102/300], Step [15/29], Loss: 1.2285\n",
      "Epoch [102/300], Step [16/29], Loss: 1.3110\n",
      "Epoch [102/300], Step [17/29], Loss: 1.3767\n",
      "Epoch [102/300], Step [18/29], Loss: 1.0788\n",
      "Epoch [102/300], Step [19/29], Loss: 0.9404\n",
      "Epoch [102/300], Step [20/29], Loss: 1.0901\n",
      "Epoch [102/300], Step [21/29], Loss: 0.9840\n",
      "Epoch [102/300], Step [22/29], Loss: 1.1581\n",
      "Epoch [102/300], Step [23/29], Loss: 1.1994\n",
      "Epoch [102/300], Step [24/29], Loss: 1.4487\n",
      "Epoch [102/300], Step [25/29], Loss: 0.9320\n",
      "Epoch [102/300], Step [26/29], Loss: 1.1872\n",
      "Epoch [102/300], Step [27/29], Loss: 1.3994\n",
      "Epoch [102/300], Step [28/29], Loss: 1.4354\n",
      "Epoch [102/300], Step [29/29], Loss: 0.9241\n",
      "Epoch [103/300], Step [1/29], Loss: 1.3683\n",
      "Epoch [103/300], Step [2/29], Loss: 1.6992\n",
      "Epoch [103/300], Step [3/29], Loss: 1.2937\n",
      "Epoch [103/300], Step [4/29], Loss: 1.3038\n",
      "Epoch [103/300], Step [5/29], Loss: 1.1765\n",
      "Epoch [103/300], Step [6/29], Loss: 1.2490\n",
      "Epoch [103/300], Step [7/29], Loss: 1.2398\n",
      "Epoch [103/300], Step [8/29], Loss: 1.2568\n",
      "Epoch [103/300], Step [9/29], Loss: 1.2743\n",
      "Epoch [103/300], Step [10/29], Loss: 1.2013\n",
      "Epoch [103/300], Step [11/29], Loss: 1.1537\n",
      "Epoch [103/300], Step [12/29], Loss: 1.5388\n",
      "Epoch [103/300], Step [13/29], Loss: 1.3402\n",
      "Epoch [103/300], Step [14/29], Loss: 1.2499\n",
      "Epoch [103/300], Step [15/29], Loss: 1.4510\n",
      "Epoch [103/300], Step [16/29], Loss: 1.2150\n",
      "Epoch [103/300], Step [17/29], Loss: 1.4255\n",
      "Epoch [103/300], Step [18/29], Loss: 1.3941\n",
      "Epoch [103/300], Step [19/29], Loss: 1.3646\n",
      "Epoch [103/300], Step [20/29], Loss: 1.0840\n",
      "Epoch [103/300], Step [21/29], Loss: 1.2260\n",
      "Epoch [103/300], Step [22/29], Loss: 1.4270\n",
      "Epoch [103/300], Step [23/29], Loss: 1.2026\n",
      "Epoch [103/300], Step [24/29], Loss: 1.1377\n",
      "Epoch [103/300], Step [25/29], Loss: 1.1732\n",
      "Epoch [103/300], Step [26/29], Loss: 1.1897\n",
      "Epoch [103/300], Step [27/29], Loss: 1.3079\n",
      "Epoch [103/300], Step [28/29], Loss: 1.3178\n",
      "Epoch [103/300], Step [29/29], Loss: 2.1456\n",
      "Epoch [104/300], Step [1/29], Loss: 1.4756\n",
      "Epoch [104/300], Step [2/29], Loss: 1.2571\n",
      "Epoch [104/300], Step [3/29], Loss: 1.2700\n",
      "Epoch [104/300], Step [4/29], Loss: 1.4914\n",
      "Epoch [104/300], Step [5/29], Loss: 1.1964\n",
      "Epoch [104/300], Step [6/29], Loss: 1.2334\n",
      "Epoch [104/300], Step [7/29], Loss: 1.1943\n",
      "Epoch [104/300], Step [8/29], Loss: 1.3406\n",
      "Epoch [104/300], Step [9/29], Loss: 1.1127\n",
      "Epoch [104/300], Step [10/29], Loss: 1.3568\n",
      "Epoch [104/300], Step [11/29], Loss: 1.3072\n",
      "Epoch [104/300], Step [12/29], Loss: 1.5286\n",
      "Epoch [104/300], Step [13/29], Loss: 1.2466\n",
      "Epoch [104/300], Step [14/29], Loss: 1.7003\n",
      "Epoch [104/300], Step [15/29], Loss: 1.1692\n",
      "Epoch [104/300], Step [16/29], Loss: 1.1729\n",
      "Epoch [104/300], Step [17/29], Loss: 1.3276\n",
      "Epoch [104/300], Step [18/29], Loss: 1.3885\n",
      "Epoch [104/300], Step [19/29], Loss: 1.3410\n",
      "Epoch [104/300], Step [20/29], Loss: 1.1570\n",
      "Epoch [104/300], Step [21/29], Loss: 1.0684\n",
      "Epoch [104/300], Step [22/29], Loss: 1.4111\n",
      "Epoch [104/300], Step [23/29], Loss: 1.2522\n",
      "Epoch [104/300], Step [24/29], Loss: 1.2236\n",
      "Epoch [104/300], Step [25/29], Loss: 1.1659\n",
      "Epoch [104/300], Step [26/29], Loss: 1.2427\n",
      "Epoch [104/300], Step [27/29], Loss: 1.3207\n",
      "Epoch [104/300], Step [28/29], Loss: 1.2469\n",
      "Epoch [104/300], Step [29/29], Loss: 1.7321\n",
      "Epoch [105/300], Step [1/29], Loss: 1.3239\n",
      "Epoch [105/300], Step [2/29], Loss: 1.2192\n",
      "Epoch [105/300], Step [3/29], Loss: 1.1327\n",
      "Epoch [105/300], Step [4/29], Loss: 1.5134\n",
      "Epoch [105/300], Step [5/29], Loss: 1.4299\n",
      "Epoch [105/300], Step [6/29], Loss: 1.3974\n",
      "Epoch [105/300], Step [7/29], Loss: 1.4004\n",
      "Epoch [105/300], Step [8/29], Loss: 1.1997\n",
      "Epoch [105/300], Step [9/29], Loss: 1.4130\n",
      "Epoch [105/300], Step [10/29], Loss: 1.2104\n",
      "Epoch [105/300], Step [11/29], Loss: 1.2669\n",
      "Epoch [105/300], Step [12/29], Loss: 1.4889\n",
      "Epoch [105/300], Step [13/29], Loss: 1.2193\n",
      "Epoch [105/300], Step [14/29], Loss: 1.0881\n",
      "Epoch [105/300], Step [15/29], Loss: 1.1916\n",
      "Epoch [105/300], Step [16/29], Loss: 1.1514\n",
      "Epoch [105/300], Step [17/29], Loss: 1.1356\n",
      "Epoch [105/300], Step [18/29], Loss: 1.3544\n",
      "Epoch [105/300], Step [19/29], Loss: 1.1492\n",
      "Epoch [105/300], Step [20/29], Loss: 1.3491\n",
      "Epoch [105/300], Step [21/29], Loss: 1.2526\n",
      "Epoch [105/300], Step [22/29], Loss: 1.4608\n",
      "Epoch [105/300], Step [23/29], Loss: 1.2912\n",
      "Epoch [105/300], Step [24/29], Loss: 1.1696\n",
      "Epoch [105/300], Step [25/29], Loss: 1.3920\n",
      "Epoch [105/300], Step [26/29], Loss: 1.5645\n",
      "Epoch [105/300], Step [27/29], Loss: 1.4143\n",
      "Epoch [105/300], Step [28/29], Loss: 1.1571\n",
      "Epoch [105/300], Step [29/29], Loss: 1.0521\n",
      "Epoch [106/300], Step [1/29], Loss: 1.2227\n",
      "Epoch [106/300], Step [2/29], Loss: 1.2866\n",
      "Epoch [106/300], Step [3/29], Loss: 1.2647\n",
      "Epoch [106/300], Step [4/29], Loss: 1.3164\n",
      "Epoch [106/300], Step [5/29], Loss: 1.2537\n",
      "Epoch [106/300], Step [6/29], Loss: 1.4199\n",
      "Epoch [106/300], Step [7/29], Loss: 1.1888\n",
      "Epoch [106/300], Step [8/29], Loss: 1.3239\n",
      "Epoch [106/300], Step [9/29], Loss: 1.3678\n",
      "Epoch [106/300], Step [10/29], Loss: 1.2274\n",
      "Epoch [106/300], Step [11/29], Loss: 1.2182\n",
      "Epoch [106/300], Step [12/29], Loss: 1.3866\n",
      "Epoch [106/300], Step [13/29], Loss: 1.3668\n",
      "Epoch [106/300], Step [14/29], Loss: 1.1753\n",
      "Epoch [106/300], Step [15/29], Loss: 1.3217\n",
      "Epoch [106/300], Step [16/29], Loss: 1.5126\n",
      "Epoch [106/300], Step [17/29], Loss: 1.0277\n",
      "Epoch [106/300], Step [18/29], Loss: 1.5863\n",
      "Epoch [106/300], Step [19/29], Loss: 1.3103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/300], Step [20/29], Loss: 1.3347\n",
      "Epoch [106/300], Step [21/29], Loss: 1.4552\n",
      "Epoch [106/300], Step [22/29], Loss: 1.2174\n",
      "Epoch [106/300], Step [23/29], Loss: 1.2738\n",
      "Epoch [106/300], Step [24/29], Loss: 1.3430\n",
      "Epoch [106/300], Step [25/29], Loss: 1.1445\n",
      "Epoch [106/300], Step [26/29], Loss: 1.2432\n",
      "Epoch [106/300], Step [27/29], Loss: 1.0796\n",
      "Epoch [106/300], Step [28/29], Loss: 1.2470\n",
      "Epoch [106/300], Step [29/29], Loss: 1.0625\n",
      "Epoch [107/300], Step [1/29], Loss: 1.2395\n",
      "Epoch [107/300], Step [2/29], Loss: 1.2911\n",
      "Epoch [107/300], Step [3/29], Loss: 1.2878\n",
      "Epoch [107/300], Step [4/29], Loss: 1.3573\n",
      "Epoch [107/300], Step [5/29], Loss: 1.0245\n",
      "Epoch [107/300], Step [6/29], Loss: 1.1193\n",
      "Epoch [107/300], Step [7/29], Loss: 1.2260\n",
      "Epoch [107/300], Step [8/29], Loss: 1.6625\n",
      "Epoch [107/300], Step [9/29], Loss: 1.0722\n",
      "Epoch [107/300], Step [10/29], Loss: 1.1078\n",
      "Epoch [107/300], Step [11/29], Loss: 1.0206\n",
      "Epoch [107/300], Step [12/29], Loss: 1.3276\n",
      "Epoch [107/300], Step [13/29], Loss: 1.2796\n",
      "Epoch [107/300], Step [14/29], Loss: 1.4261\n",
      "Epoch [107/300], Step [15/29], Loss: 1.3096\n",
      "Epoch [107/300], Step [16/29], Loss: 1.3442\n",
      "Epoch [107/300], Step [17/29], Loss: 1.6304\n",
      "Epoch [107/300], Step [18/29], Loss: 1.0841\n",
      "Epoch [107/300], Step [19/29], Loss: 1.3765\n",
      "Epoch [107/300], Step [20/29], Loss: 1.2001\n",
      "Epoch [107/300], Step [21/29], Loss: 1.4939\n",
      "Epoch [107/300], Step [22/29], Loss: 1.3449\n",
      "Epoch [107/300], Step [23/29], Loss: 1.1875\n",
      "Epoch [107/300], Step [24/29], Loss: 1.2202\n",
      "Epoch [107/300], Step [25/29], Loss: 1.3639\n",
      "Epoch [107/300], Step [26/29], Loss: 1.3905\n",
      "Epoch [107/300], Step [27/29], Loss: 1.3352\n",
      "Epoch [107/300], Step [28/29], Loss: 1.4077\n",
      "Epoch [107/300], Step [29/29], Loss: 2.9300\n",
      "Epoch [108/300], Step [1/29], Loss: 1.3700\n",
      "Epoch [108/300], Step [2/29], Loss: 1.3234\n",
      "Epoch [108/300], Step [3/29], Loss: 1.4210\n",
      "Epoch [108/300], Step [4/29], Loss: 1.2863\n",
      "Epoch [108/300], Step [5/29], Loss: 1.5275\n",
      "Epoch [108/300], Step [6/29], Loss: 1.2670\n",
      "Epoch [108/300], Step [7/29], Loss: 1.1418\n",
      "Epoch [108/300], Step [8/29], Loss: 1.2123\n",
      "Epoch [108/300], Step [9/29], Loss: 1.5232\n",
      "Epoch [108/300], Step [10/29], Loss: 1.4113\n",
      "Epoch [108/300], Step [11/29], Loss: 1.3198\n",
      "Epoch [108/300], Step [12/29], Loss: 1.0843\n",
      "Epoch [108/300], Step [13/29], Loss: 1.3130\n",
      "Epoch [108/300], Step [14/29], Loss: 1.2919\n",
      "Epoch [108/300], Step [15/29], Loss: 1.4566\n",
      "Epoch [108/300], Step [16/29], Loss: 1.3534\n",
      "Epoch [108/300], Step [17/29], Loss: 1.1663\n",
      "Epoch [108/300], Step [18/29], Loss: 1.3821\n",
      "Epoch [108/300], Step [19/29], Loss: 0.8797\n",
      "Epoch [108/300], Step [20/29], Loss: 1.2126\n",
      "Epoch [108/300], Step [21/29], Loss: 1.2124\n",
      "Epoch [108/300], Step [22/29], Loss: 1.2796\n",
      "Epoch [108/300], Step [23/29], Loss: 1.5601\n",
      "Epoch [108/300], Step [24/29], Loss: 1.6841\n",
      "Epoch [108/300], Step [25/29], Loss: 1.2585\n",
      "Epoch [108/300], Step [26/29], Loss: 1.3408\n",
      "Epoch [108/300], Step [27/29], Loss: 1.0459\n",
      "Epoch [108/300], Step [28/29], Loss: 1.1617\n",
      "Epoch [108/300], Step [29/29], Loss: 2.3075\n",
      "Epoch [109/300], Step [1/29], Loss: 1.5598\n",
      "Epoch [109/300], Step [2/29], Loss: 1.4386\n",
      "Epoch [109/300], Step [3/29], Loss: 1.3193\n",
      "Epoch [109/300], Step [4/29], Loss: 1.2646\n",
      "Epoch [109/300], Step [5/29], Loss: 1.3139\n",
      "Epoch [109/300], Step [6/29], Loss: 1.1501\n",
      "Epoch [109/300], Step [7/29], Loss: 1.2806\n",
      "Epoch [109/300], Step [8/29], Loss: 1.2304\n",
      "Epoch [109/300], Step [9/29], Loss: 1.3623\n",
      "Epoch [109/300], Step [10/29], Loss: 1.3752\n",
      "Epoch [109/300], Step [11/29], Loss: 1.0251\n",
      "Epoch [109/300], Step [12/29], Loss: 1.2564\n",
      "Epoch [109/300], Step [13/29], Loss: 1.3976\n",
      "Epoch [109/300], Step [14/29], Loss: 1.4845\n",
      "Epoch [109/300], Step [15/29], Loss: 1.4519\n",
      "Epoch [109/300], Step [16/29], Loss: 1.6131\n",
      "Epoch [109/300], Step [17/29], Loss: 1.3670\n",
      "Epoch [109/300], Step [18/29], Loss: 1.1713\n",
      "Epoch [109/300], Step [19/29], Loss: 1.3452\n",
      "Epoch [109/300], Step [20/29], Loss: 0.9730\n",
      "Epoch [109/300], Step [21/29], Loss: 1.1537\n",
      "Epoch [109/300], Step [22/29], Loss: 1.1950\n",
      "Epoch [109/300], Step [23/29], Loss: 1.4313\n",
      "Epoch [109/300], Step [24/29], Loss: 1.2482\n",
      "Epoch [109/300], Step [25/29], Loss: 1.1853\n",
      "Epoch [109/300], Step [26/29], Loss: 1.1014\n",
      "Epoch [109/300], Step [27/29], Loss: 1.2920\n",
      "Epoch [109/300], Step [28/29], Loss: 1.4129\n",
      "Epoch [109/300], Step [29/29], Loss: 0.4984\n",
      "Epoch [110/300], Step [1/29], Loss: 0.9687\n",
      "Epoch [110/300], Step [2/29], Loss: 1.5642\n",
      "Epoch [110/300], Step [3/29], Loss: 1.2222\n",
      "Epoch [110/300], Step [4/29], Loss: 1.3613\n",
      "Epoch [110/300], Step [5/29], Loss: 1.2132\n",
      "Epoch [110/300], Step [6/29], Loss: 1.1712\n",
      "Epoch [110/300], Step [7/29], Loss: 1.0898\n",
      "Epoch [110/300], Step [8/29], Loss: 1.3183\n",
      "Epoch [110/300], Step [9/29], Loss: 1.3287\n",
      "Epoch [110/300], Step [10/29], Loss: 1.2085\n",
      "Epoch [110/300], Step [11/29], Loss: 1.3773\n",
      "Epoch [110/300], Step [12/29], Loss: 1.3429\n",
      "Epoch [110/300], Step [13/29], Loss: 1.4111\n",
      "Epoch [110/300], Step [14/29], Loss: 1.3660\n",
      "Epoch [110/300], Step [15/29], Loss: 1.2677\n",
      "Epoch [110/300], Step [16/29], Loss: 1.3516\n",
      "Epoch [110/300], Step [17/29], Loss: 1.0853\n",
      "Epoch [110/300], Step [18/29], Loss: 1.4632\n",
      "Epoch [110/300], Step [19/29], Loss: 1.1168\n",
      "Epoch [110/300], Step [20/29], Loss: 1.4635\n",
      "Epoch [110/300], Step [21/29], Loss: 1.4215\n",
      "Epoch [110/300], Step [22/29], Loss: 1.2287\n",
      "Epoch [110/300], Step [23/29], Loss: 1.0828\n",
      "Epoch [110/300], Step [24/29], Loss: 1.2688\n",
      "Epoch [110/300], Step [25/29], Loss: 1.3748\n",
      "Epoch [110/300], Step [26/29], Loss: 1.4757\n",
      "Epoch [110/300], Step [27/29], Loss: 1.2340\n",
      "Epoch [110/300], Step [28/29], Loss: 1.3043\n",
      "Epoch [110/300], Step [29/29], Loss: 0.6436\n",
      "Epoch [111/300], Step [1/29], Loss: 1.4880\n",
      "Epoch [111/300], Step [2/29], Loss: 1.3301\n",
      "Epoch [111/300], Step [3/29], Loss: 1.0754\n",
      "Epoch [111/300], Step [4/29], Loss: 1.1714\n",
      "Epoch [111/300], Step [5/29], Loss: 1.1278\n",
      "Epoch [111/300], Step [6/29], Loss: 1.2206\n",
      "Epoch [111/300], Step [7/29], Loss: 1.1073\n",
      "Epoch [111/300], Step [8/29], Loss: 1.2618\n",
      "Epoch [111/300], Step [9/29], Loss: 1.3279\n",
      "Epoch [111/300], Step [10/29], Loss: 1.1535\n",
      "Epoch [111/300], Step [11/29], Loss: 1.3910\n",
      "Epoch [111/300], Step [12/29], Loss: 1.3195\n",
      "Epoch [111/300], Step [13/29], Loss: 1.3050\n",
      "Epoch [111/300], Step [14/29], Loss: 1.4690\n",
      "Epoch [111/300], Step [15/29], Loss: 1.4575\n",
      "Epoch [111/300], Step [16/29], Loss: 1.2584\n",
      "Epoch [111/300], Step [17/29], Loss: 1.5268\n",
      "Epoch [111/300], Step [18/29], Loss: 1.3080\n",
      "Epoch [111/300], Step [19/29], Loss: 1.3135\n",
      "Epoch [111/300], Step [20/29], Loss: 1.1534\n",
      "Epoch [111/300], Step [21/29], Loss: 1.3325\n",
      "Epoch [111/300], Step [22/29], Loss: 1.0109\n",
      "Epoch [111/300], Step [23/29], Loss: 1.1526\n",
      "Epoch [111/300], Step [24/29], Loss: 1.3082\n",
      "Epoch [111/300], Step [25/29], Loss: 1.6373\n",
      "Epoch [111/300], Step [26/29], Loss: 1.1264\n",
      "Epoch [111/300], Step [27/29], Loss: 1.2785\n",
      "Epoch [111/300], Step [28/29], Loss: 1.4402\n",
      "Epoch [111/300], Step [29/29], Loss: 0.4982\n",
      "Epoch [112/300], Step [1/29], Loss: 0.9974\n",
      "Epoch [112/300], Step [2/29], Loss: 1.1939\n",
      "Epoch [112/300], Step [3/29], Loss: 1.4691\n",
      "Epoch [112/300], Step [4/29], Loss: 1.4991\n",
      "Epoch [112/300], Step [5/29], Loss: 1.3518\n",
      "Epoch [112/300], Step [6/29], Loss: 1.3430\n",
      "Epoch [112/300], Step [7/29], Loss: 1.2510\n",
      "Epoch [112/300], Step [8/29], Loss: 1.1528\n",
      "Epoch [112/300], Step [9/29], Loss: 1.6581\n",
      "Epoch [112/300], Step [10/29], Loss: 1.2628\n",
      "Epoch [112/300], Step [11/29], Loss: 1.2380\n",
      "Epoch [112/300], Step [12/29], Loss: 1.0832\n",
      "Epoch [112/300], Step [13/29], Loss: 1.5073\n",
      "Epoch [112/300], Step [14/29], Loss: 1.1456\n",
      "Epoch [112/300], Step [15/29], Loss: 1.2334\n",
      "Epoch [112/300], Step [16/29], Loss: 1.2355\n",
      "Epoch [112/300], Step [17/29], Loss: 1.1814\n",
      "Epoch [112/300], Step [18/29], Loss: 1.4228\n",
      "Epoch [112/300], Step [19/29], Loss: 1.3345\n",
      "Epoch [112/300], Step [20/29], Loss: 1.1342\n",
      "Epoch [112/300], Step [21/29], Loss: 1.1945\n",
      "Epoch [112/300], Step [22/29], Loss: 1.4594\n",
      "Epoch [112/300], Step [23/29], Loss: 1.4874\n",
      "Epoch [112/300], Step [24/29], Loss: 1.3876\n",
      "Epoch [112/300], Step [25/29], Loss: 1.5120\n",
      "Epoch [112/300], Step [26/29], Loss: 1.2698\n",
      "Epoch [112/300], Step [27/29], Loss: 0.9362\n",
      "Epoch [112/300], Step [28/29], Loss: 1.4591\n",
      "Epoch [112/300], Step [29/29], Loss: 2.0253\n",
      "Epoch [113/300], Step [1/29], Loss: 1.3105\n",
      "Epoch [113/300], Step [2/29], Loss: 1.3358\n",
      "Epoch [113/300], Step [3/29], Loss: 1.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/300], Step [4/29], Loss: 1.3548\n",
      "Epoch [113/300], Step [5/29], Loss: 1.1897\n",
      "Epoch [113/300], Step [6/29], Loss: 1.4380\n",
      "Epoch [113/300], Step [7/29], Loss: 1.4187\n",
      "Epoch [113/300], Step [8/29], Loss: 1.1711\n",
      "Epoch [113/300], Step [9/29], Loss: 1.6565\n",
      "Epoch [113/300], Step [10/29], Loss: 1.2794\n",
      "Epoch [113/300], Step [11/29], Loss: 1.4012\n",
      "Epoch [113/300], Step [12/29], Loss: 1.1640\n",
      "Epoch [113/300], Step [13/29], Loss: 1.1849\n",
      "Epoch [113/300], Step [14/29], Loss: 1.3194\n",
      "Epoch [113/300], Step [15/29], Loss: 1.0244\n",
      "Epoch [113/300], Step [16/29], Loss: 1.1643\n",
      "Epoch [113/300], Step [17/29], Loss: 1.0357\n",
      "Epoch [113/300], Step [18/29], Loss: 1.5084\n",
      "Epoch [113/300], Step [19/29], Loss: 1.2642\n",
      "Epoch [113/300], Step [20/29], Loss: 1.5073\n",
      "Epoch [113/300], Step [21/29], Loss: 1.6758\n",
      "Epoch [113/300], Step [22/29], Loss: 1.3642\n",
      "Epoch [113/300], Step [23/29], Loss: 1.2419\n",
      "Epoch [113/300], Step [24/29], Loss: 1.1742\n",
      "Epoch [113/300], Step [25/29], Loss: 1.0077\n",
      "Epoch [113/300], Step [26/29], Loss: 1.1873\n",
      "Epoch [113/300], Step [27/29], Loss: 1.2094\n",
      "Epoch [113/300], Step [28/29], Loss: 1.3431\n",
      "Epoch [113/300], Step [29/29], Loss: 2.3282\n",
      "Epoch [114/300], Step [1/29], Loss: 1.1308\n",
      "Epoch [114/300], Step [2/29], Loss: 1.0242\n",
      "Epoch [114/300], Step [3/29], Loss: 1.2834\n",
      "Epoch [114/300], Step [4/29], Loss: 1.4341\n",
      "Epoch [114/300], Step [5/29], Loss: 1.2433\n",
      "Epoch [114/300], Step [6/29], Loss: 1.2952\n",
      "Epoch [114/300], Step [7/29], Loss: 1.3008\n",
      "Epoch [114/300], Step [8/29], Loss: 1.2393\n",
      "Epoch [114/300], Step [9/29], Loss: 1.0197\n",
      "Epoch [114/300], Step [10/29], Loss: 1.3362\n",
      "Epoch [114/300], Step [11/29], Loss: 1.3290\n",
      "Epoch [114/300], Step [12/29], Loss: 1.1807\n",
      "Epoch [114/300], Step [13/29], Loss: 1.3559\n",
      "Epoch [114/300], Step [14/29], Loss: 1.3005\n",
      "Epoch [114/300], Step [15/29], Loss: 1.3570\n",
      "Epoch [114/300], Step [16/29], Loss: 1.4061\n",
      "Epoch [114/300], Step [17/29], Loss: 1.0400\n",
      "Epoch [114/300], Step [18/29], Loss: 1.1709\n",
      "Epoch [114/300], Step [19/29], Loss: 1.2431\n",
      "Epoch [114/300], Step [20/29], Loss: 1.3458\n",
      "Epoch [114/300], Step [21/29], Loss: 1.2061\n",
      "Epoch [114/300], Step [22/29], Loss: 1.4694\n",
      "Epoch [114/300], Step [23/29], Loss: 1.4092\n",
      "Epoch [114/300], Step [24/29], Loss: 1.4992\n",
      "Epoch [114/300], Step [25/29], Loss: 1.2903\n",
      "Epoch [114/300], Step [26/29], Loss: 1.2455\n",
      "Epoch [114/300], Step [27/29], Loss: 1.4052\n",
      "Epoch [114/300], Step [28/29], Loss: 1.6018\n",
      "Epoch [114/300], Step [29/29], Loss: 1.7346\n",
      "Epoch [115/300], Step [1/29], Loss: 1.4222\n",
      "Epoch [115/300], Step [2/29], Loss: 1.4449\n",
      "Epoch [115/300], Step [3/29], Loss: 1.3867\n",
      "Epoch [115/300], Step [4/29], Loss: 1.3358\n",
      "Epoch [115/300], Step [5/29], Loss: 1.3355\n",
      "Epoch [115/300], Step [6/29], Loss: 1.2329\n",
      "Epoch [115/300], Step [7/29], Loss: 1.2527\n",
      "Epoch [115/300], Step [8/29], Loss: 1.1305\n",
      "Epoch [115/300], Step [9/29], Loss: 1.5120\n",
      "Epoch [115/300], Step [10/29], Loss: 1.4517\n",
      "Epoch [115/300], Step [11/29], Loss: 1.4935\n",
      "Epoch [115/300], Step [12/29], Loss: 1.4774\n",
      "Epoch [115/300], Step [13/29], Loss: 1.1012\n",
      "Epoch [115/300], Step [14/29], Loss: 1.3600\n",
      "Epoch [115/300], Step [15/29], Loss: 1.1470\n",
      "Epoch [115/300], Step [16/29], Loss: 1.2255\n",
      "Epoch [115/300], Step [17/29], Loss: 1.1035\n",
      "Epoch [115/300], Step [18/29], Loss: 1.1949\n",
      "Epoch [115/300], Step [19/29], Loss: 1.1033\n",
      "Epoch [115/300], Step [20/29], Loss: 1.2405\n",
      "Epoch [115/300], Step [21/29], Loss: 1.0501\n",
      "Epoch [115/300], Step [22/29], Loss: 1.3723\n",
      "Epoch [115/300], Step [23/29], Loss: 1.2886\n",
      "Epoch [115/300], Step [24/29], Loss: 1.4308\n",
      "Epoch [115/300], Step [25/29], Loss: 1.1279\n",
      "Epoch [115/300], Step [26/29], Loss: 1.2798\n",
      "Epoch [115/300], Step [27/29], Loss: 1.3318\n",
      "Epoch [115/300], Step [28/29], Loss: 1.2775\n",
      "Epoch [115/300], Step [29/29], Loss: 1.0651\n",
      "Epoch [116/300], Step [1/29], Loss: 1.2763\n",
      "Epoch [116/300], Step [2/29], Loss: 1.4958\n",
      "Epoch [116/300], Step [3/29], Loss: 0.9648\n",
      "Epoch [116/300], Step [4/29], Loss: 1.3170\n",
      "Epoch [116/300], Step [5/29], Loss: 1.4617\n",
      "Epoch [116/300], Step [6/29], Loss: 1.4487\n",
      "Epoch [116/300], Step [7/29], Loss: 1.1979\n",
      "Epoch [116/300], Step [8/29], Loss: 1.1280\n",
      "Epoch [116/300], Step [9/29], Loss: 1.2662\n",
      "Epoch [116/300], Step [10/29], Loss: 1.4679\n",
      "Epoch [116/300], Step [11/29], Loss: 1.2874\n",
      "Epoch [116/300], Step [12/29], Loss: 1.3334\n",
      "Epoch [116/300], Step [13/29], Loss: 1.3141\n",
      "Epoch [116/300], Step [14/29], Loss: 1.4142\n",
      "Epoch [116/300], Step [15/29], Loss: 1.4278\n",
      "Epoch [116/300], Step [16/29], Loss: 1.2511\n",
      "Epoch [116/300], Step [17/29], Loss: 1.2191\n",
      "Epoch [116/300], Step [18/29], Loss: 1.3086\n",
      "Epoch [116/300], Step [19/29], Loss: 1.3184\n",
      "Epoch [116/300], Step [20/29], Loss: 1.2531\n",
      "Epoch [116/300], Step [21/29], Loss: 1.1128\n",
      "Epoch [116/300], Step [22/29], Loss: 1.2302\n",
      "Epoch [116/300], Step [23/29], Loss: 1.1965\n",
      "Epoch [116/300], Step [24/29], Loss: 0.9919\n",
      "Epoch [116/300], Step [25/29], Loss: 1.3387\n",
      "Epoch [116/300], Step [26/29], Loss: 1.2848\n",
      "Epoch [116/300], Step [27/29], Loss: 1.3059\n",
      "Epoch [116/300], Step [28/29], Loss: 1.4767\n",
      "Epoch [116/300], Step [29/29], Loss: 1.9414\n",
      "Epoch [117/300], Step [1/29], Loss: 1.1375\n",
      "Epoch [117/300], Step [2/29], Loss: 1.1222\n",
      "Epoch [117/300], Step [3/29], Loss: 1.2548\n",
      "Epoch [117/300], Step [4/29], Loss: 1.3413\n",
      "Epoch [117/300], Step [5/29], Loss: 1.4968\n",
      "Epoch [117/300], Step [6/29], Loss: 1.3112\n",
      "Epoch [117/300], Step [7/29], Loss: 1.4075\n",
      "Epoch [117/300], Step [8/29], Loss: 1.1792\n",
      "Epoch [117/300], Step [9/29], Loss: 1.4538\n",
      "Epoch [117/300], Step [10/29], Loss: 1.1564\n",
      "Epoch [117/300], Step [11/29], Loss: 1.1786\n",
      "Epoch [117/300], Step [12/29], Loss: 1.1506\n",
      "Epoch [117/300], Step [13/29], Loss: 1.3236\n",
      "Epoch [117/300], Step [14/29], Loss: 0.9946\n",
      "Epoch [117/300], Step [15/29], Loss: 1.3813\n",
      "Epoch [117/300], Step [16/29], Loss: 1.5380\n",
      "Epoch [117/300], Step [17/29], Loss: 1.5514\n",
      "Epoch [117/300], Step [18/29], Loss: 1.6109\n",
      "Epoch [117/300], Step [19/29], Loss: 1.3655\n",
      "Epoch [117/300], Step [20/29], Loss: 1.4439\n",
      "Epoch [117/300], Step [21/29], Loss: 1.0617\n",
      "Epoch [117/300], Step [22/29], Loss: 1.2874\n",
      "Epoch [117/300], Step [23/29], Loss: 1.3936\n",
      "Epoch [117/300], Step [24/29], Loss: 1.5431\n",
      "Epoch [117/300], Step [25/29], Loss: 1.1353\n",
      "Epoch [117/300], Step [26/29], Loss: 1.1527\n",
      "Epoch [117/300], Step [27/29], Loss: 1.2980\n",
      "Epoch [117/300], Step [28/29], Loss: 1.1970\n",
      "Epoch [117/300], Step [29/29], Loss: 1.2137\n",
      "Epoch [118/300], Step [1/29], Loss: 1.3076\n",
      "Epoch [118/300], Step [2/29], Loss: 1.5103\n",
      "Epoch [118/300], Step [3/29], Loss: 1.2985\n",
      "Epoch [118/300], Step [4/29], Loss: 1.3712\n",
      "Epoch [118/300], Step [5/29], Loss: 1.2158\n",
      "Epoch [118/300], Step [6/29], Loss: 1.2974\n",
      "Epoch [118/300], Step [7/29], Loss: 1.3750\n",
      "Epoch [118/300], Step [8/29], Loss: 1.2194\n",
      "Epoch [118/300], Step [9/29], Loss: 1.2886\n",
      "Epoch [118/300], Step [10/29], Loss: 1.3232\n",
      "Epoch [118/300], Step [11/29], Loss: 1.1098\n",
      "Epoch [118/300], Step [12/29], Loss: 1.3545\n",
      "Epoch [118/300], Step [13/29], Loss: 1.1758\n",
      "Epoch [118/300], Step [14/29], Loss: 1.2733\n",
      "Epoch [118/300], Step [15/29], Loss: 1.1471\n",
      "Epoch [118/300], Step [16/29], Loss: 1.2810\n",
      "Epoch [118/300], Step [17/29], Loss: 1.2477\n",
      "Epoch [118/300], Step [18/29], Loss: 0.9506\n",
      "Epoch [118/300], Step [19/29], Loss: 1.1166\n",
      "Epoch [118/300], Step [20/29], Loss: 1.4990\n",
      "Epoch [118/300], Step [21/29], Loss: 1.1006\n",
      "Epoch [118/300], Step [22/29], Loss: 1.3541\n",
      "Epoch [118/300], Step [23/29], Loss: 1.2323\n",
      "Epoch [118/300], Step [24/29], Loss: 1.2062\n",
      "Epoch [118/300], Step [25/29], Loss: 1.3747\n",
      "Epoch [118/300], Step [26/29], Loss: 1.1838\n",
      "Epoch [118/300], Step [27/29], Loss: 1.4346\n",
      "Epoch [118/300], Step [28/29], Loss: 1.5944\n",
      "Epoch [118/300], Step [29/29], Loss: 1.4784\n",
      "Epoch [119/300], Step [1/29], Loss: 0.9533\n",
      "Epoch [119/300], Step [2/29], Loss: 1.1290\n",
      "Epoch [119/300], Step [3/29], Loss: 1.2764\n",
      "Epoch [119/300], Step [4/29], Loss: 1.5619\n",
      "Epoch [119/300], Step [5/29], Loss: 1.4473\n",
      "Epoch [119/300], Step [6/29], Loss: 1.2555\n",
      "Epoch [119/300], Step [7/29], Loss: 1.4289\n",
      "Epoch [119/300], Step [8/29], Loss: 1.4592\n",
      "Epoch [119/300], Step [9/29], Loss: 1.3359\n",
      "Epoch [119/300], Step [10/29], Loss: 1.2953\n",
      "Epoch [119/300], Step [11/29], Loss: 1.2886\n",
      "Epoch [119/300], Step [12/29], Loss: 1.3615\n",
      "Epoch [119/300], Step [13/29], Loss: 1.2671\n",
      "Epoch [119/300], Step [14/29], Loss: 1.4931\n",
      "Epoch [119/300], Step [15/29], Loss: 1.3863\n",
      "Epoch [119/300], Step [16/29], Loss: 1.2093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/300], Step [17/29], Loss: 1.4054\n",
      "Epoch [119/300], Step [18/29], Loss: 1.2430\n",
      "Epoch [119/300], Step [19/29], Loss: 1.1713\n",
      "Epoch [119/300], Step [20/29], Loss: 1.1708\n",
      "Epoch [119/300], Step [21/29], Loss: 1.3524\n",
      "Epoch [119/300], Step [22/29], Loss: 1.3338\n",
      "Epoch [119/300], Step [23/29], Loss: 1.4209\n",
      "Epoch [119/300], Step [24/29], Loss: 1.3832\n",
      "Epoch [119/300], Step [25/29], Loss: 1.3029\n",
      "Epoch [119/300], Step [26/29], Loss: 1.1575\n",
      "Epoch [119/300], Step [27/29], Loss: 1.1176\n",
      "Epoch [119/300], Step [28/29], Loss: 1.1165\n",
      "Epoch [119/300], Step [29/29], Loss: 2.7572\n",
      "Epoch [120/300], Step [1/29], Loss: 1.2141\n",
      "Epoch [120/300], Step [2/29], Loss: 1.4319\n",
      "Epoch [120/300], Step [3/29], Loss: 1.4766\n",
      "Epoch [120/300], Step [4/29], Loss: 1.3653\n",
      "Epoch [120/300], Step [5/29], Loss: 1.4153\n",
      "Epoch [120/300], Step [6/29], Loss: 1.3807\n",
      "Epoch [120/300], Step [7/29], Loss: 1.4683\n",
      "Epoch [120/300], Step [8/29], Loss: 1.3274\n",
      "Epoch [120/300], Step [9/29], Loss: 1.6355\n",
      "Epoch [120/300], Step [10/29], Loss: 1.0690\n",
      "Epoch [120/300], Step [11/29], Loss: 1.3560\n",
      "Epoch [120/300], Step [12/29], Loss: 1.5273\n",
      "Epoch [120/300], Step [13/29], Loss: 1.4304\n",
      "Epoch [120/300], Step [14/29], Loss: 1.2797\n",
      "Epoch [120/300], Step [15/29], Loss: 1.2509\n",
      "Epoch [120/300], Step [16/29], Loss: 1.1199\n",
      "Epoch [120/300], Step [17/29], Loss: 1.3516\n",
      "Epoch [120/300], Step [18/29], Loss: 0.9344\n",
      "Epoch [120/300], Step [19/29], Loss: 1.3058\n",
      "Epoch [120/300], Step [20/29], Loss: 1.3731\n",
      "Epoch [120/300], Step [21/29], Loss: 1.2660\n",
      "Epoch [120/300], Step [22/29], Loss: 1.3677\n",
      "Epoch [120/300], Step [23/29], Loss: 1.3406\n",
      "Epoch [120/300], Step [24/29], Loss: 1.2752\n",
      "Epoch [120/300], Step [25/29], Loss: 1.0077\n",
      "Epoch [120/300], Step [26/29], Loss: 1.2464\n",
      "Epoch [120/300], Step [27/29], Loss: 1.0929\n",
      "Epoch [120/300], Step [28/29], Loss: 1.4518\n",
      "Epoch [120/300], Step [29/29], Loss: 2.3434\n",
      "Epoch [121/300], Step [1/29], Loss: 1.1546\n",
      "Epoch [121/300], Step [2/29], Loss: 1.3589\n",
      "Epoch [121/300], Step [3/29], Loss: 1.1593\n",
      "Epoch [121/300], Step [4/29], Loss: 1.0856\n",
      "Epoch [121/300], Step [5/29], Loss: 1.2593\n",
      "Epoch [121/300], Step [6/29], Loss: 1.4633\n",
      "Epoch [121/300], Step [7/29], Loss: 1.3594\n",
      "Epoch [121/300], Step [8/29], Loss: 1.2789\n",
      "Epoch [121/300], Step [9/29], Loss: 1.0629\n",
      "Epoch [121/300], Step [10/29], Loss: 0.9888\n",
      "Epoch [121/300], Step [11/29], Loss: 1.3672\n",
      "Epoch [121/300], Step [12/29], Loss: 1.4230\n",
      "Epoch [121/300], Step [13/29], Loss: 1.0969\n",
      "Epoch [121/300], Step [14/29], Loss: 1.4746\n",
      "Epoch [121/300], Step [15/29], Loss: 1.6522\n",
      "Epoch [121/300], Step [16/29], Loss: 1.3700\n",
      "Epoch [121/300], Step [17/29], Loss: 1.5663\n",
      "Epoch [121/300], Step [18/29], Loss: 1.2431\n",
      "Epoch [121/300], Step [19/29], Loss: 1.1704\n",
      "Epoch [121/300], Step [20/29], Loss: 1.4957\n",
      "Epoch [121/300], Step [21/29], Loss: 1.3547\n",
      "Epoch [121/300], Step [22/29], Loss: 1.2143\n",
      "Epoch [121/300], Step [23/29], Loss: 1.3555\n",
      "Epoch [121/300], Step [24/29], Loss: 1.3897\n",
      "Epoch [121/300], Step [25/29], Loss: 1.2324\n",
      "Epoch [121/300], Step [26/29], Loss: 1.4070\n",
      "Epoch [121/300], Step [27/29], Loss: 1.1210\n",
      "Epoch [121/300], Step [28/29], Loss: 1.1182\n",
      "Epoch [121/300], Step [29/29], Loss: 0.8682\n",
      "Epoch [122/300], Step [1/29], Loss: 1.4570\n",
      "Epoch [122/300], Step [2/29], Loss: 1.3083\n",
      "Epoch [122/300], Step [3/29], Loss: 1.3532\n",
      "Epoch [122/300], Step [4/29], Loss: 1.0191\n",
      "Epoch [122/300], Step [5/29], Loss: 1.2776\n",
      "Epoch [122/300], Step [6/29], Loss: 1.2195\n",
      "Epoch [122/300], Step [7/29], Loss: 1.4644\n",
      "Epoch [122/300], Step [8/29], Loss: 1.3359\n",
      "Epoch [122/300], Step [9/29], Loss: 1.2135\n",
      "Epoch [122/300], Step [10/29], Loss: 1.3308\n",
      "Epoch [122/300], Step [11/29], Loss: 1.2949\n",
      "Epoch [122/300], Step [12/29], Loss: 1.1575\n",
      "Epoch [122/300], Step [13/29], Loss: 1.4519\n",
      "Epoch [122/300], Step [14/29], Loss: 1.1748\n",
      "Epoch [122/300], Step [15/29], Loss: 1.2949\n",
      "Epoch [122/300], Step [16/29], Loss: 1.1563\n",
      "Epoch [122/300], Step [17/29], Loss: 1.3746\n",
      "Epoch [122/300], Step [18/29], Loss: 1.5034\n",
      "Epoch [122/300], Step [19/29], Loss: 1.2079\n",
      "Epoch [122/300], Step [20/29], Loss: 1.3666\n",
      "Epoch [122/300], Step [21/29], Loss: 1.3068\n",
      "Epoch [122/300], Step [22/29], Loss: 1.0162\n",
      "Epoch [122/300], Step [23/29], Loss: 1.7601\n",
      "Epoch [122/300], Step [24/29], Loss: 1.3200\n",
      "Epoch [122/300], Step [25/29], Loss: 1.1105\n",
      "Epoch [122/300], Step [26/29], Loss: 1.2064\n",
      "Epoch [122/300], Step [27/29], Loss: 1.3273\n",
      "Epoch [122/300], Step [28/29], Loss: 1.3908\n",
      "Epoch [122/300], Step [29/29], Loss: 0.9919\n",
      "Epoch [123/300], Step [1/29], Loss: 1.3353\n",
      "Epoch [123/300], Step [2/29], Loss: 1.0820\n",
      "Epoch [123/300], Step [3/29], Loss: 1.2290\n",
      "Epoch [123/300], Step [4/29], Loss: 1.3839\n",
      "Epoch [123/300], Step [5/29], Loss: 1.1096\n",
      "Epoch [123/300], Step [6/29], Loss: 1.1069\n",
      "Epoch [123/300], Step [7/29], Loss: 1.1416\n",
      "Epoch [123/300], Step [8/29], Loss: 1.4497\n",
      "Epoch [123/300], Step [9/29], Loss: 1.5505\n",
      "Epoch [123/300], Step [10/29], Loss: 1.1438\n",
      "Epoch [123/300], Step [11/29], Loss: 1.2840\n",
      "Epoch [123/300], Step [12/29], Loss: 1.3860\n",
      "Epoch [123/300], Step [13/29], Loss: 1.3070\n",
      "Epoch [123/300], Step [14/29], Loss: 1.2823\n",
      "Epoch [123/300], Step [15/29], Loss: 1.5179\n",
      "Epoch [123/300], Step [16/29], Loss: 1.3919\n",
      "Epoch [123/300], Step [17/29], Loss: 1.1212\n",
      "Epoch [123/300], Step [18/29], Loss: 1.4114\n",
      "Epoch [123/300], Step [19/29], Loss: 1.2072\n",
      "Epoch [123/300], Step [20/29], Loss: 1.3077\n",
      "Epoch [123/300], Step [21/29], Loss: 1.2012\n",
      "Epoch [123/300], Step [22/29], Loss: 1.5043\n",
      "Epoch [123/300], Step [23/29], Loss: 1.3018\n",
      "Epoch [123/300], Step [24/29], Loss: 1.2226\n",
      "Epoch [123/300], Step [25/29], Loss: 1.3207\n",
      "Epoch [123/300], Step [26/29], Loss: 1.4480\n",
      "Epoch [123/300], Step [27/29], Loss: 1.3174\n",
      "Epoch [123/300], Step [28/29], Loss: 1.0742\n",
      "Epoch [123/300], Step [29/29], Loss: 1.9131\n",
      "Epoch [124/300], Step [1/29], Loss: 1.3375\n",
      "Epoch [124/300], Step [2/29], Loss: 0.9194\n",
      "Epoch [124/300], Step [3/29], Loss: 1.2172\n",
      "Epoch [124/300], Step [4/29], Loss: 1.0378\n",
      "Epoch [124/300], Step [5/29], Loss: 1.1795\n",
      "Epoch [124/300], Step [6/29], Loss: 1.1798\n",
      "Epoch [124/300], Step [7/29], Loss: 1.4812\n",
      "Epoch [124/300], Step [8/29], Loss: 1.2842\n",
      "Epoch [124/300], Step [9/29], Loss: 1.3106\n",
      "Epoch [124/300], Step [10/29], Loss: 1.4085\n",
      "Epoch [124/300], Step [11/29], Loss: 1.0590\n",
      "Epoch [124/300], Step [12/29], Loss: 1.5126\n",
      "Epoch [124/300], Step [13/29], Loss: 1.2911\n",
      "Epoch [124/300], Step [14/29], Loss: 1.3338\n",
      "Epoch [124/300], Step [15/29], Loss: 1.3868\n",
      "Epoch [124/300], Step [16/29], Loss: 1.3981\n",
      "Epoch [124/300], Step [17/29], Loss: 1.3093\n",
      "Epoch [124/300], Step [18/29], Loss: 1.2267\n",
      "Epoch [124/300], Step [19/29], Loss: 1.1557\n",
      "Epoch [124/300], Step [20/29], Loss: 1.3347\n",
      "Epoch [124/300], Step [21/29], Loss: 1.4213\n",
      "Epoch [124/300], Step [22/29], Loss: 1.2898\n",
      "Epoch [124/300], Step [23/29], Loss: 1.4615\n",
      "Epoch [124/300], Step [24/29], Loss: 1.3979\n",
      "Epoch [124/300], Step [25/29], Loss: 1.1559\n",
      "Epoch [124/300], Step [26/29], Loss: 1.7210\n",
      "Epoch [124/300], Step [27/29], Loss: 1.0817\n",
      "Epoch [124/300], Step [28/29], Loss: 1.3409\n",
      "Epoch [124/300], Step [29/29], Loss: 1.3174\n",
      "Epoch [125/300], Step [1/29], Loss: 1.1874\n",
      "Epoch [125/300], Step [2/29], Loss: 1.2991\n",
      "Epoch [125/300], Step [3/29], Loss: 1.2686\n",
      "Epoch [125/300], Step [4/29], Loss: 1.2632\n",
      "Epoch [125/300], Step [5/29], Loss: 1.4819\n",
      "Epoch [125/300], Step [6/29], Loss: 1.0381\n",
      "Epoch [125/300], Step [7/29], Loss: 1.2799\n",
      "Epoch [125/300], Step [8/29], Loss: 1.0798\n",
      "Epoch [125/300], Step [9/29], Loss: 1.3929\n",
      "Epoch [125/300], Step [10/29], Loss: 1.4299\n",
      "Epoch [125/300], Step [11/29], Loss: 1.3233\n",
      "Epoch [125/300], Step [12/29], Loss: 1.4424\n",
      "Epoch [125/300], Step [13/29], Loss: 1.1948\n",
      "Epoch [125/300], Step [14/29], Loss: 1.5024\n",
      "Epoch [125/300], Step [15/29], Loss: 1.2572\n",
      "Epoch [125/300], Step [16/29], Loss: 1.3818\n",
      "Epoch [125/300], Step [17/29], Loss: 1.1193\n",
      "Epoch [125/300], Step [18/29], Loss: 1.3015\n",
      "Epoch [125/300], Step [19/29], Loss: 1.3867\n",
      "Epoch [125/300], Step [20/29], Loss: 1.3359\n",
      "Epoch [125/300], Step [21/29], Loss: 1.2914\n",
      "Epoch [125/300], Step [22/29], Loss: 1.3133\n",
      "Epoch [125/300], Step [23/29], Loss: 1.2105\n",
      "Epoch [125/300], Step [24/29], Loss: 1.2753\n",
      "Epoch [125/300], Step [25/29], Loss: 1.3889\n",
      "Epoch [125/300], Step [26/29], Loss: 1.3668\n",
      "Epoch [125/300], Step [27/29], Loss: 1.2896\n",
      "Epoch [125/300], Step [28/29], Loss: 1.2337\n",
      "Epoch [125/300], Step [29/29], Loss: 2.2938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/300], Step [1/29], Loss: 1.4272\n",
      "Epoch [126/300], Step [2/29], Loss: 1.5844\n",
      "Epoch [126/300], Step [3/29], Loss: 1.0878\n",
      "Epoch [126/300], Step [4/29], Loss: 1.4866\n",
      "Epoch [126/300], Step [5/29], Loss: 1.2230\n",
      "Epoch [126/300], Step [6/29], Loss: 1.6854\n",
      "Epoch [126/300], Step [7/29], Loss: 1.2625\n",
      "Epoch [126/300], Step [8/29], Loss: 1.3799\n",
      "Epoch [126/300], Step [9/29], Loss: 1.1737\n",
      "Epoch [126/300], Step [10/29], Loss: 1.4410\n",
      "Epoch [126/300], Step [11/29], Loss: 1.3379\n",
      "Epoch [126/300], Step [12/29], Loss: 1.2178\n",
      "Epoch [126/300], Step [13/29], Loss: 1.2205\n",
      "Epoch [126/300], Step [14/29], Loss: 1.3530\n",
      "Epoch [126/300], Step [15/29], Loss: 1.4928\n",
      "Epoch [126/300], Step [16/29], Loss: 1.3061\n",
      "Epoch [126/300], Step [17/29], Loss: 1.2658\n",
      "Epoch [126/300], Step [18/29], Loss: 1.0551\n",
      "Epoch [126/300], Step [19/29], Loss: 1.1567\n",
      "Epoch [126/300], Step [20/29], Loss: 1.3988\n",
      "Epoch [126/300], Step [21/29], Loss: 1.2026\n",
      "Epoch [126/300], Step [22/29], Loss: 1.2330\n",
      "Epoch [126/300], Step [23/29], Loss: 1.2949\n",
      "Epoch [126/300], Step [24/29], Loss: 1.1417\n",
      "Epoch [126/300], Step [25/29], Loss: 1.5049\n",
      "Epoch [126/300], Step [26/29], Loss: 0.9289\n",
      "Epoch [126/300], Step [27/29], Loss: 1.1410\n",
      "Epoch [126/300], Step [28/29], Loss: 1.4117\n",
      "Epoch [126/300], Step [29/29], Loss: 2.4017\n",
      "Epoch [127/300], Step [1/29], Loss: 1.3342\n",
      "Epoch [127/300], Step [2/29], Loss: 1.2921\n",
      "Epoch [127/300], Step [3/29], Loss: 1.1881\n",
      "Epoch [127/300], Step [4/29], Loss: 1.3053\n",
      "Epoch [127/300], Step [5/29], Loss: 1.2572\n",
      "Epoch [127/300], Step [6/29], Loss: 1.3129\n",
      "Epoch [127/300], Step [7/29], Loss: 1.1897\n",
      "Epoch [127/300], Step [8/29], Loss: 1.3868\n",
      "Epoch [127/300], Step [9/29], Loss: 1.2710\n",
      "Epoch [127/300], Step [10/29], Loss: 1.5211\n",
      "Epoch [127/300], Step [11/29], Loss: 1.4462\n",
      "Epoch [127/300], Step [12/29], Loss: 1.0662\n",
      "Epoch [127/300], Step [13/29], Loss: 1.1631\n",
      "Epoch [127/300], Step [14/29], Loss: 1.1200\n",
      "Epoch [127/300], Step [15/29], Loss: 1.1713\n",
      "Epoch [127/300], Step [16/29], Loss: 1.3358\n",
      "Epoch [127/300], Step [17/29], Loss: 1.6073\n",
      "Epoch [127/300], Step [18/29], Loss: 1.6827\n",
      "Epoch [127/300], Step [19/29], Loss: 1.5115\n",
      "Epoch [127/300], Step [20/29], Loss: 1.3770\n",
      "Epoch [127/300], Step [21/29], Loss: 1.4190\n",
      "Epoch [127/300], Step [22/29], Loss: 1.3286\n",
      "Epoch [127/300], Step [23/29], Loss: 1.1783\n",
      "Epoch [127/300], Step [24/29], Loss: 1.2041\n",
      "Epoch [127/300], Step [25/29], Loss: 1.4170\n",
      "Epoch [127/300], Step [26/29], Loss: 1.2403\n",
      "Epoch [127/300], Step [27/29], Loss: 1.0131\n",
      "Epoch [127/300], Step [28/29], Loss: 1.1647\n",
      "Epoch [127/300], Step [29/29], Loss: 1.9525\n",
      "Epoch [128/300], Step [1/29], Loss: 1.1245\n",
      "Epoch [128/300], Step [2/29], Loss: 1.3382\n",
      "Epoch [128/300], Step [3/29], Loss: 1.3575\n",
      "Epoch [128/300], Step [4/29], Loss: 1.0706\n",
      "Epoch [128/300], Step [5/29], Loss: 1.0612\n",
      "Epoch [128/300], Step [6/29], Loss: 1.2678\n",
      "Epoch [128/300], Step [7/29], Loss: 1.2105\n",
      "Epoch [128/300], Step [8/29], Loss: 1.2338\n",
      "Epoch [128/300], Step [9/29], Loss: 1.3956\n",
      "Epoch [128/300], Step [10/29], Loss: 1.3816\n",
      "Epoch [128/300], Step [11/29], Loss: 1.1543\n",
      "Epoch [128/300], Step [12/29], Loss: 0.8615\n",
      "Epoch [128/300], Step [13/29], Loss: 1.4475\n",
      "Epoch [128/300], Step [14/29], Loss: 1.5868\n",
      "Epoch [128/300], Step [15/29], Loss: 1.3134\n",
      "Epoch [128/300], Step [16/29], Loss: 1.3862\n",
      "Epoch [128/300], Step [17/29], Loss: 1.4422\n",
      "Epoch [128/300], Step [18/29], Loss: 1.4102\n",
      "Epoch [128/300], Step [19/29], Loss: 1.3389\n",
      "Epoch [128/300], Step [20/29], Loss: 1.2755\n",
      "Epoch [128/300], Step [21/29], Loss: 1.6201\n",
      "Epoch [128/300], Step [22/29], Loss: 1.5976\n",
      "Epoch [128/300], Step [23/29], Loss: 0.9183\n",
      "Epoch [128/300], Step [24/29], Loss: 1.0904\n",
      "Epoch [128/300], Step [25/29], Loss: 1.4075\n",
      "Epoch [128/300], Step [26/29], Loss: 1.2812\n",
      "Epoch [128/300], Step [27/29], Loss: 1.3205\n",
      "Epoch [128/300], Step [28/29], Loss: 1.4002\n",
      "Epoch [128/300], Step [29/29], Loss: 2.0156\n",
      "Epoch [129/300], Step [1/29], Loss: 1.3399\n",
      "Epoch [129/300], Step [2/29], Loss: 1.3669\n",
      "Epoch [129/300], Step [3/29], Loss: 1.1594\n",
      "Epoch [129/300], Step [4/29], Loss: 1.2986\n",
      "Epoch [129/300], Step [5/29], Loss: 1.0585\n",
      "Epoch [129/300], Step [6/29], Loss: 1.0254\n",
      "Epoch [129/300], Step [7/29], Loss: 1.3443\n",
      "Epoch [129/300], Step [8/29], Loss: 1.4185\n",
      "Epoch [129/300], Step [9/29], Loss: 1.3064\n",
      "Epoch [129/300], Step [10/29], Loss: 1.0776\n",
      "Epoch [129/300], Step [11/29], Loss: 1.2357\n",
      "Epoch [129/300], Step [12/29], Loss: 1.3644\n",
      "Epoch [129/300], Step [13/29], Loss: 1.3089\n",
      "Epoch [129/300], Step [14/29], Loss: 1.1962\n",
      "Epoch [129/300], Step [15/29], Loss: 1.3176\n",
      "Epoch [129/300], Step [16/29], Loss: 1.2940\n",
      "Epoch [129/300], Step [17/29], Loss: 1.4159\n",
      "Epoch [129/300], Step [18/29], Loss: 1.5156\n",
      "Epoch [129/300], Step [19/29], Loss: 1.3190\n",
      "Epoch [129/300], Step [20/29], Loss: 1.4989\n",
      "Epoch [129/300], Step [21/29], Loss: 1.2195\n",
      "Epoch [129/300], Step [22/29], Loss: 1.4394\n",
      "Epoch [129/300], Step [23/29], Loss: 1.4141\n",
      "Epoch [129/300], Step [24/29], Loss: 1.3857\n",
      "Epoch [129/300], Step [25/29], Loss: 1.4722\n",
      "Epoch [129/300], Step [26/29], Loss: 1.3650\n",
      "Epoch [129/300], Step [27/29], Loss: 1.2059\n",
      "Epoch [129/300], Step [28/29], Loss: 1.3020\n",
      "Epoch [129/300], Step [29/29], Loss: 1.2973\n",
      "Epoch [130/300], Step [1/29], Loss: 1.1826\n",
      "Epoch [130/300], Step [2/29], Loss: 1.2340\n",
      "Epoch [130/300], Step [3/29], Loss: 1.1245\n",
      "Epoch [130/300], Step [4/29], Loss: 1.3870\n",
      "Epoch [130/300], Step [5/29], Loss: 0.9411\n",
      "Epoch [130/300], Step [6/29], Loss: 1.3420\n",
      "Epoch [130/300], Step [7/29], Loss: 1.2351\n",
      "Epoch [130/300], Step [8/29], Loss: 1.4766\n",
      "Epoch [130/300], Step [9/29], Loss: 1.3633\n",
      "Epoch [130/300], Step [10/29], Loss: 1.2729\n",
      "Epoch [130/300], Step [11/29], Loss: 1.3425\n",
      "Epoch [130/300], Step [12/29], Loss: 1.2136\n",
      "Epoch [130/300], Step [13/29], Loss: 1.4222\n",
      "Epoch [130/300], Step [14/29], Loss: 1.3071\n",
      "Epoch [130/300], Step [15/29], Loss: 1.4607\n",
      "Epoch [130/300], Step [16/29], Loss: 1.2253\n",
      "Epoch [130/300], Step [17/29], Loss: 1.5193\n",
      "Epoch [130/300], Step [18/29], Loss: 1.1376\n",
      "Epoch [130/300], Step [19/29], Loss: 0.9072\n",
      "Epoch [130/300], Step [20/29], Loss: 1.1622\n",
      "Epoch [130/300], Step [21/29], Loss: 1.2802\n",
      "Epoch [130/300], Step [22/29], Loss: 1.3544\n",
      "Epoch [130/300], Step [23/29], Loss: 1.2272\n",
      "Epoch [130/300], Step [24/29], Loss: 1.5104\n",
      "Epoch [130/300], Step [25/29], Loss: 1.2445\n",
      "Epoch [130/300], Step [26/29], Loss: 1.1607\n",
      "Epoch [130/300], Step [27/29], Loss: 1.5327\n",
      "Epoch [130/300], Step [28/29], Loss: 1.2755\n",
      "Epoch [130/300], Step [29/29], Loss: 1.8276\n",
      "Epoch [131/300], Step [1/29], Loss: 1.4129\n",
      "Epoch [131/300], Step [2/29], Loss: 1.0634\n",
      "Epoch [131/300], Step [3/29], Loss: 1.0297\n",
      "Epoch [131/300], Step [4/29], Loss: 1.3614\n",
      "Epoch [131/300], Step [5/29], Loss: 1.4837\n",
      "Epoch [131/300], Step [6/29], Loss: 1.4314\n",
      "Epoch [131/300], Step [7/29], Loss: 1.4424\n",
      "Epoch [131/300], Step [8/29], Loss: 1.4627\n",
      "Epoch [131/300], Step [9/29], Loss: 1.4393\n",
      "Epoch [131/300], Step [10/29], Loss: 1.2681\n",
      "Epoch [131/300], Step [11/29], Loss: 1.1820\n",
      "Epoch [131/300], Step [12/29], Loss: 1.1392\n",
      "Epoch [131/300], Step [13/29], Loss: 1.2007\n",
      "Epoch [131/300], Step [14/29], Loss: 1.0820\n",
      "Epoch [131/300], Step [15/29], Loss: 1.1709\n",
      "Epoch [131/300], Step [16/29], Loss: 1.3044\n",
      "Epoch [131/300], Step [17/29], Loss: 1.1858\n",
      "Epoch [131/300], Step [18/29], Loss: 1.5234\n",
      "Epoch [131/300], Step [19/29], Loss: 1.1686\n",
      "Epoch [131/300], Step [20/29], Loss: 1.2608\n",
      "Epoch [131/300], Step [21/29], Loss: 1.4141\n",
      "Epoch [131/300], Step [22/29], Loss: 1.2402\n",
      "Epoch [131/300], Step [23/29], Loss: 1.3620\n",
      "Epoch [131/300], Step [24/29], Loss: 1.3285\n",
      "Epoch [131/300], Step [25/29], Loss: 1.3805\n",
      "Epoch [131/300], Step [26/29], Loss: 1.0388\n",
      "Epoch [131/300], Step [27/29], Loss: 1.4504\n",
      "Epoch [131/300], Step [28/29], Loss: 1.4347\n",
      "Epoch [131/300], Step [29/29], Loss: 1.4549\n",
      "Epoch [132/300], Step [1/29], Loss: 1.1724\n",
      "Epoch [132/300], Step [2/29], Loss: 1.3783\n",
      "Epoch [132/300], Step [3/29], Loss: 1.1631\n",
      "Epoch [132/300], Step [4/29], Loss: 1.3068\n",
      "Epoch [132/300], Step [5/29], Loss: 1.3668\n",
      "Epoch [132/300], Step [6/29], Loss: 1.2463\n",
      "Epoch [132/300], Step [7/29], Loss: 1.2336\n",
      "Epoch [132/300], Step [8/29], Loss: 1.5019\n",
      "Epoch [132/300], Step [9/29], Loss: 1.2965\n",
      "Epoch [132/300], Step [10/29], Loss: 1.3137\n",
      "Epoch [132/300], Step [11/29], Loss: 1.4889\n",
      "Epoch [132/300], Step [12/29], Loss: 1.5218\n",
      "Epoch [132/300], Step [13/29], Loss: 1.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/300], Step [14/29], Loss: 1.0935\n",
      "Epoch [132/300], Step [15/29], Loss: 1.3367\n",
      "Epoch [132/300], Step [16/29], Loss: 1.2852\n",
      "Epoch [132/300], Step [17/29], Loss: 1.2347\n",
      "Epoch [132/300], Step [18/29], Loss: 1.3795\n",
      "Epoch [132/300], Step [19/29], Loss: 1.2808\n",
      "Epoch [132/300], Step [20/29], Loss: 1.2221\n",
      "Epoch [132/300], Step [21/29], Loss: 1.4112\n",
      "Epoch [132/300], Step [22/29], Loss: 1.2484\n",
      "Epoch [132/300], Step [23/29], Loss: 1.2915\n",
      "Epoch [132/300], Step [24/29], Loss: 1.6390\n",
      "Epoch [132/300], Step [25/29], Loss: 0.9398\n",
      "Epoch [132/300], Step [26/29], Loss: 1.1865\n",
      "Epoch [132/300], Step [27/29], Loss: 1.3697\n",
      "Epoch [132/300], Step [28/29], Loss: 1.3042\n",
      "Epoch [132/300], Step [29/29], Loss: 3.4419\n",
      "Epoch [133/300], Step [1/29], Loss: 1.3524\n",
      "Epoch [133/300], Step [2/29], Loss: 1.3231\n",
      "Epoch [133/300], Step [3/29], Loss: 1.3694\n",
      "Epoch [133/300], Step [4/29], Loss: 1.4806\n",
      "Epoch [133/300], Step [5/29], Loss: 1.1579\n",
      "Epoch [133/300], Step [6/29], Loss: 1.1924\n",
      "Epoch [133/300], Step [7/29], Loss: 1.2214\n",
      "Epoch [133/300], Step [8/29], Loss: 1.1895\n",
      "Epoch [133/300], Step [9/29], Loss: 1.3326\n",
      "Epoch [133/300], Step [10/29], Loss: 1.5709\n",
      "Epoch [133/300], Step [11/29], Loss: 1.1228\n",
      "Epoch [133/300], Step [12/29], Loss: 1.4921\n",
      "Epoch [133/300], Step [13/29], Loss: 1.3555\n",
      "Epoch [133/300], Step [14/29], Loss: 1.4486\n",
      "Epoch [133/300], Step [15/29], Loss: 1.2666\n",
      "Epoch [133/300], Step [16/29], Loss: 1.0922\n",
      "Epoch [133/300], Step [17/29], Loss: 1.2102\n",
      "Epoch [133/300], Step [18/29], Loss: 1.2562\n",
      "Epoch [133/300], Step [19/29], Loss: 1.3211\n",
      "Epoch [133/300], Step [20/29], Loss: 1.5037\n",
      "Epoch [133/300], Step [21/29], Loss: 1.0411\n",
      "Epoch [133/300], Step [22/29], Loss: 1.1443\n",
      "Epoch [133/300], Step [23/29], Loss: 1.4095\n",
      "Epoch [133/300], Step [24/29], Loss: 1.3705\n",
      "Epoch [133/300], Step [25/29], Loss: 1.3880\n",
      "Epoch [133/300], Step [26/29], Loss: 1.2339\n",
      "Epoch [133/300], Step [27/29], Loss: 1.4169\n",
      "Epoch [133/300], Step [28/29], Loss: 1.0376\n",
      "Epoch [133/300], Step [29/29], Loss: 2.3329\n",
      "Epoch [134/300], Step [1/29], Loss: 1.5937\n",
      "Epoch [134/300], Step [2/29], Loss: 1.1371\n",
      "Epoch [134/300], Step [3/29], Loss: 1.2946\n",
      "Epoch [134/300], Step [4/29], Loss: 1.1373\n",
      "Epoch [134/300], Step [5/29], Loss: 1.2758\n",
      "Epoch [134/300], Step [6/29], Loss: 1.1463\n",
      "Epoch [134/300], Step [7/29], Loss: 1.1934\n",
      "Epoch [134/300], Step [8/29], Loss: 1.3194\n",
      "Epoch [134/300], Step [9/29], Loss: 1.2867\n",
      "Epoch [134/300], Step [10/29], Loss: 1.4289\n",
      "Epoch [134/300], Step [11/29], Loss: 1.3303\n",
      "Epoch [134/300], Step [12/29], Loss: 1.3189\n",
      "Epoch [134/300], Step [13/29], Loss: 1.2573\n",
      "Epoch [134/300], Step [14/29], Loss: 1.2950\n",
      "Epoch [134/300], Step [15/29], Loss: 1.4393\n",
      "Epoch [134/300], Step [16/29], Loss: 1.0544\n",
      "Epoch [134/300], Step [17/29], Loss: 1.5038\n",
      "Epoch [134/300], Step [18/29], Loss: 1.2995\n",
      "Epoch [134/300], Step [19/29], Loss: 1.2111\n",
      "Epoch [134/300], Step [20/29], Loss: 1.2763\n",
      "Epoch [134/300], Step [21/29], Loss: 1.4306\n",
      "Epoch [134/300], Step [22/29], Loss: 1.4934\n",
      "Epoch [134/300], Step [23/29], Loss: 1.3219\n",
      "Epoch [134/300], Step [24/29], Loss: 1.1429\n",
      "Epoch [134/300], Step [25/29], Loss: 1.1780\n",
      "Epoch [134/300], Step [26/29], Loss: 1.4354\n",
      "Epoch [134/300], Step [27/29], Loss: 1.2791\n",
      "Epoch [134/300], Step [28/29], Loss: 1.2396\n",
      "Epoch [134/300], Step [29/29], Loss: 2.5034\n",
      "Epoch [135/300], Step [1/29], Loss: 1.1370\n",
      "Epoch [135/300], Step [2/29], Loss: 1.2310\n",
      "Epoch [135/300], Step [3/29], Loss: 1.0128\n",
      "Epoch [135/300], Step [4/29], Loss: 1.3548\n",
      "Epoch [135/300], Step [5/29], Loss: 1.6401\n",
      "Epoch [135/300], Step [6/29], Loss: 1.0750\n",
      "Epoch [135/300], Step [7/29], Loss: 1.5059\n",
      "Epoch [135/300], Step [8/29], Loss: 1.2431\n",
      "Epoch [135/300], Step [9/29], Loss: 1.4217\n",
      "Epoch [135/300], Step [10/29], Loss: 1.3467\n",
      "Epoch [135/300], Step [11/29], Loss: 1.0490\n",
      "Epoch [135/300], Step [12/29], Loss: 1.4487\n",
      "Epoch [135/300], Step [13/29], Loss: 1.3410\n",
      "Epoch [135/300], Step [14/29], Loss: 1.3453\n",
      "Epoch [135/300], Step [15/29], Loss: 1.0136\n",
      "Epoch [135/300], Step [16/29], Loss: 1.2694\n",
      "Epoch [135/300], Step [17/29], Loss: 1.2714\n",
      "Epoch [135/300], Step [18/29], Loss: 1.3879\n",
      "Epoch [135/300], Step [19/29], Loss: 1.4212\n",
      "Epoch [135/300], Step [20/29], Loss: 1.3399\n",
      "Epoch [135/300], Step [21/29], Loss: 1.2036\n",
      "Epoch [135/300], Step [22/29], Loss: 1.2651\n",
      "Epoch [135/300], Step [23/29], Loss: 1.3633\n",
      "Epoch [135/300], Step [24/29], Loss: 1.3487\n",
      "Epoch [135/300], Step [25/29], Loss: 1.2646\n",
      "Epoch [135/300], Step [26/29], Loss: 1.4887\n",
      "Epoch [135/300], Step [27/29], Loss: 1.3168\n",
      "Epoch [135/300], Step [28/29], Loss: 1.3845\n",
      "Epoch [135/300], Step [29/29], Loss: 0.1746\n",
      "Epoch [136/300], Step [1/29], Loss: 1.4635\n",
      "Epoch [136/300], Step [2/29], Loss: 1.5693\n",
      "Epoch [136/300], Step [3/29], Loss: 1.4438\n",
      "Epoch [136/300], Step [4/29], Loss: 1.3355\n",
      "Epoch [136/300], Step [5/29], Loss: 1.0948\n",
      "Epoch [136/300], Step [6/29], Loss: 1.5022\n",
      "Epoch [136/300], Step [7/29], Loss: 1.0020\n",
      "Epoch [136/300], Step [8/29], Loss: 1.4368\n",
      "Epoch [136/300], Step [9/29], Loss: 1.4267\n",
      "Epoch [136/300], Step [10/29], Loss: 1.2396\n",
      "Epoch [136/300], Step [11/29], Loss: 1.2420\n",
      "Epoch [136/300], Step [12/29], Loss: 1.0911\n",
      "Epoch [136/300], Step [13/29], Loss: 1.1913\n",
      "Epoch [136/300], Step [14/29], Loss: 1.1620\n",
      "Epoch [136/300], Step [15/29], Loss: 1.1940\n",
      "Epoch [136/300], Step [16/29], Loss: 1.1814\n",
      "Epoch [136/300], Step [17/29], Loss: 1.2730\n",
      "Epoch [136/300], Step [18/29], Loss: 1.1379\n",
      "Epoch [136/300], Step [19/29], Loss: 1.2088\n",
      "Epoch [136/300], Step [20/29], Loss: 1.5640\n",
      "Epoch [136/300], Step [21/29], Loss: 1.3162\n",
      "Epoch [136/300], Step [22/29], Loss: 1.1128\n",
      "Epoch [136/300], Step [23/29], Loss: 1.4929\n",
      "Epoch [136/300], Step [24/29], Loss: 1.3704\n",
      "Epoch [136/300], Step [25/29], Loss: 1.1674\n",
      "Epoch [136/300], Step [26/29], Loss: 1.1122\n",
      "Epoch [136/300], Step [27/29], Loss: 1.3189\n",
      "Epoch [136/300], Step [28/29], Loss: 1.1998\n",
      "Epoch [136/300], Step [29/29], Loss: 0.8815\n",
      "Epoch [137/300], Step [1/29], Loss: 1.0246\n",
      "Epoch [137/300], Step [2/29], Loss: 1.7131\n",
      "Epoch [137/300], Step [3/29], Loss: 1.4966\n",
      "Epoch [137/300], Step [4/29], Loss: 1.2739\n",
      "Epoch [137/300], Step [5/29], Loss: 1.1441\n",
      "Epoch [137/300], Step [6/29], Loss: 1.3658\n",
      "Epoch [137/300], Step [7/29], Loss: 1.2558\n",
      "Epoch [137/300], Step [8/29], Loss: 1.3201\n",
      "Epoch [137/300], Step [9/29], Loss: 1.0851\n",
      "Epoch [137/300], Step [10/29], Loss: 1.0345\n",
      "Epoch [137/300], Step [11/29], Loss: 1.1649\n",
      "Epoch [137/300], Step [12/29], Loss: 1.2132\n",
      "Epoch [137/300], Step [13/29], Loss: 1.1562\n",
      "Epoch [137/300], Step [14/29], Loss: 1.3426\n",
      "Epoch [137/300], Step [15/29], Loss: 1.2570\n",
      "Epoch [137/300], Step [16/29], Loss: 1.0297\n",
      "Epoch [137/300], Step [17/29], Loss: 1.3190\n",
      "Epoch [137/300], Step [18/29], Loss: 1.5076\n",
      "Epoch [137/300], Step [19/29], Loss: 1.7136\n",
      "Epoch [137/300], Step [20/29], Loss: 1.2237\n",
      "Epoch [137/300], Step [21/29], Loss: 1.2711\n",
      "Epoch [137/300], Step [22/29], Loss: 1.4592\n",
      "Epoch [137/300], Step [23/29], Loss: 1.4066\n",
      "Epoch [137/300], Step [24/29], Loss: 1.2101\n",
      "Epoch [137/300], Step [25/29], Loss: 1.4713\n",
      "Epoch [137/300], Step [26/29], Loss: 1.3292\n",
      "Epoch [137/300], Step [27/29], Loss: 1.1391\n",
      "Epoch [137/300], Step [28/29], Loss: 1.4485\n",
      "Epoch [137/300], Step [29/29], Loss: 0.6726\n",
      "Epoch [138/300], Step [1/29], Loss: 1.8447\n",
      "Epoch [138/300], Step [2/29], Loss: 1.3023\n",
      "Epoch [138/300], Step [3/29], Loss: 1.2203\n",
      "Epoch [138/300], Step [4/29], Loss: 1.4524\n",
      "Epoch [138/300], Step [5/29], Loss: 1.3051\n",
      "Epoch [138/300], Step [6/29], Loss: 1.2977\n",
      "Epoch [138/300], Step [7/29], Loss: 1.2411\n",
      "Epoch [138/300], Step [8/29], Loss: 1.1178\n",
      "Epoch [138/300], Step [9/29], Loss: 1.5352\n",
      "Epoch [138/300], Step [10/29], Loss: 1.2575\n",
      "Epoch [138/300], Step [11/29], Loss: 1.3886\n",
      "Epoch [138/300], Step [12/29], Loss: 1.3398\n",
      "Epoch [138/300], Step [13/29], Loss: 1.3747\n",
      "Epoch [138/300], Step [14/29], Loss: 1.4422\n",
      "Epoch [138/300], Step [15/29], Loss: 1.2719\n",
      "Epoch [138/300], Step [16/29], Loss: 1.1650\n",
      "Epoch [138/300], Step [17/29], Loss: 1.5148\n",
      "Epoch [138/300], Step [18/29], Loss: 1.1996\n",
      "Epoch [138/300], Step [19/29], Loss: 1.4132\n",
      "Epoch [138/300], Step [20/29], Loss: 1.1926\n",
      "Epoch [138/300], Step [21/29], Loss: 1.2367\n",
      "Epoch [138/300], Step [22/29], Loss: 1.2270\n",
      "Epoch [138/300], Step [23/29], Loss: 1.3020\n",
      "Epoch [138/300], Step [24/29], Loss: 1.1255\n",
      "Epoch [138/300], Step [25/29], Loss: 1.2717\n",
      "Epoch [138/300], Step [26/29], Loss: 1.1865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/300], Step [27/29], Loss: 1.3917\n",
      "Epoch [138/300], Step [28/29], Loss: 1.3012\n",
      "Epoch [138/300], Step [29/29], Loss: 0.6535\n",
      "Epoch [139/300], Step [1/29], Loss: 1.2292\n",
      "Epoch [139/300], Step [2/29], Loss: 1.3194\n",
      "Epoch [139/300], Step [3/29], Loss: 1.4743\n",
      "Epoch [139/300], Step [4/29], Loss: 1.5163\n",
      "Epoch [139/300], Step [5/29], Loss: 1.0933\n",
      "Epoch [139/300], Step [6/29], Loss: 1.1286\n",
      "Epoch [139/300], Step [7/29], Loss: 1.0960\n",
      "Epoch [139/300], Step [8/29], Loss: 1.4042\n",
      "Epoch [139/300], Step [9/29], Loss: 1.4651\n",
      "Epoch [139/300], Step [10/29], Loss: 1.2685\n",
      "Epoch [139/300], Step [11/29], Loss: 1.4027\n",
      "Epoch [139/300], Step [12/29], Loss: 1.2698\n",
      "Epoch [139/300], Step [13/29], Loss: 1.4514\n",
      "Epoch [139/300], Step [14/29], Loss: 1.2583\n",
      "Epoch [139/300], Step [15/29], Loss: 1.5217\n",
      "Epoch [139/300], Step [16/29], Loss: 1.3217\n",
      "Epoch [139/300], Step [17/29], Loss: 1.3368\n",
      "Epoch [139/300], Step [18/29], Loss: 1.2292\n",
      "Epoch [139/300], Step [19/29], Loss: 1.2720\n",
      "Epoch [139/300], Step [20/29], Loss: 1.3307\n",
      "Epoch [139/300], Step [21/29], Loss: 1.2529\n",
      "Epoch [139/300], Step [22/29], Loss: 1.1736\n",
      "Epoch [139/300], Step [23/29], Loss: 1.2766\n",
      "Epoch [139/300], Step [24/29], Loss: 1.0050\n",
      "Epoch [139/300], Step [25/29], Loss: 1.2051\n",
      "Epoch [139/300], Step [26/29], Loss: 1.3567\n",
      "Epoch [139/300], Step [27/29], Loss: 1.3514\n",
      "Epoch [139/300], Step [28/29], Loss: 1.2160\n",
      "Epoch [139/300], Step [29/29], Loss: 1.6623\n",
      "Epoch [140/300], Step [1/29], Loss: 1.2649\n",
      "Epoch [140/300], Step [2/29], Loss: 1.2520\n",
      "Epoch [140/300], Step [3/29], Loss: 1.2489\n",
      "Epoch [140/300], Step [4/29], Loss: 1.3684\n",
      "Epoch [140/300], Step [5/29], Loss: 1.2390\n",
      "Epoch [140/300], Step [6/29], Loss: 1.3440\n",
      "Epoch [140/300], Step [7/29], Loss: 1.3710\n",
      "Epoch [140/300], Step [8/29], Loss: 1.4192\n",
      "Epoch [140/300], Step [9/29], Loss: 1.2200\n",
      "Epoch [140/300], Step [10/29], Loss: 1.3433\n",
      "Epoch [140/300], Step [11/29], Loss: 1.3977\n",
      "Epoch [140/300], Step [12/29], Loss: 1.3242\n",
      "Epoch [140/300], Step [13/29], Loss: 1.2444\n",
      "Epoch [140/300], Step [14/29], Loss: 1.1590\n",
      "Epoch [140/300], Step [15/29], Loss: 1.1112\n",
      "Epoch [140/300], Step [16/29], Loss: 1.2544\n",
      "Epoch [140/300], Step [17/29], Loss: 1.1747\n",
      "Epoch [140/300], Step [18/29], Loss: 1.4925\n",
      "Epoch [140/300], Step [19/29], Loss: 1.2686\n",
      "Epoch [140/300], Step [20/29], Loss: 1.2221\n",
      "Epoch [140/300], Step [21/29], Loss: 1.3569\n",
      "Epoch [140/300], Step [22/29], Loss: 1.2698\n",
      "Epoch [140/300], Step [23/29], Loss: 1.4251\n",
      "Epoch [140/300], Step [24/29], Loss: 1.4247\n",
      "Epoch [140/300], Step [25/29], Loss: 1.2641\n",
      "Epoch [140/300], Step [26/29], Loss: 1.5124\n",
      "Epoch [140/300], Step [27/29], Loss: 1.2057\n",
      "Epoch [140/300], Step [28/29], Loss: 1.1679\n",
      "Epoch [140/300], Step [29/29], Loss: 1.5893\n",
      "Epoch [141/300], Step [1/29], Loss: 1.1016\n",
      "Epoch [141/300], Step [2/29], Loss: 1.3534\n",
      "Epoch [141/300], Step [3/29], Loss: 1.3033\n",
      "Epoch [141/300], Step [4/29], Loss: 1.0813\n",
      "Epoch [141/300], Step [5/29], Loss: 1.2066\n",
      "Epoch [141/300], Step [6/29], Loss: 1.2974\n",
      "Epoch [141/300], Step [7/29], Loss: 1.2616\n",
      "Epoch [141/300], Step [8/29], Loss: 1.4941\n",
      "Epoch [141/300], Step [9/29], Loss: 1.4811\n",
      "Epoch [141/300], Step [10/29], Loss: 1.3709\n",
      "Epoch [141/300], Step [11/29], Loss: 1.1305\n",
      "Epoch [141/300], Step [12/29], Loss: 1.5541\n",
      "Epoch [141/300], Step [13/29], Loss: 1.0773\n",
      "Epoch [141/300], Step [14/29], Loss: 1.2441\n",
      "Epoch [141/300], Step [15/29], Loss: 1.3037\n",
      "Epoch [141/300], Step [16/29], Loss: 1.1487\n",
      "Epoch [141/300], Step [17/29], Loss: 1.2066\n",
      "Epoch [141/300], Step [18/29], Loss: 1.3812\n",
      "Epoch [141/300], Step [19/29], Loss: 1.4595\n",
      "Epoch [141/300], Step [20/29], Loss: 1.4156\n",
      "Epoch [141/300], Step [21/29], Loss: 1.4485\n",
      "Epoch [141/300], Step [22/29], Loss: 1.2881\n",
      "Epoch [141/300], Step [23/29], Loss: 1.1571\n",
      "Epoch [141/300], Step [24/29], Loss: 1.1308\n",
      "Epoch [141/300], Step [25/29], Loss: 1.1567\n",
      "Epoch [141/300], Step [26/29], Loss: 1.4051\n",
      "Epoch [141/300], Step [27/29], Loss: 1.3360\n",
      "Epoch [141/300], Step [28/29], Loss: 1.3297\n",
      "Epoch [141/300], Step [29/29], Loss: 3.0905\n",
      "Epoch [142/300], Step [1/29], Loss: 1.2697\n",
      "Epoch [142/300], Step [2/29], Loss: 1.2463\n",
      "Epoch [142/300], Step [3/29], Loss: 1.2176\n",
      "Epoch [142/300], Step [4/29], Loss: 1.2444\n",
      "Epoch [142/300], Step [5/29], Loss: 1.5726\n",
      "Epoch [142/300], Step [6/29], Loss: 1.2701\n",
      "Epoch [142/300], Step [7/29], Loss: 1.1227\n",
      "Epoch [142/300], Step [8/29], Loss: 1.3653\n",
      "Epoch [142/300], Step [9/29], Loss: 1.1154\n",
      "Epoch [142/300], Step [10/29], Loss: 1.1994\n",
      "Epoch [142/300], Step [11/29], Loss: 1.4889\n",
      "Epoch [142/300], Step [12/29], Loss: 1.3072\n",
      "Epoch [142/300], Step [13/29], Loss: 1.1062\n",
      "Epoch [142/300], Step [14/29], Loss: 1.0470\n",
      "Epoch [142/300], Step [15/29], Loss: 1.1628\n",
      "Epoch [142/300], Step [16/29], Loss: 1.0415\n",
      "Epoch [142/300], Step [17/29], Loss: 1.4394\n",
      "Epoch [142/300], Step [18/29], Loss: 1.4895\n",
      "Epoch [142/300], Step [19/29], Loss: 1.3657\n",
      "Epoch [142/300], Step [20/29], Loss: 1.3220\n",
      "Epoch [142/300], Step [21/29], Loss: 1.0559\n",
      "Epoch [142/300], Step [22/29], Loss: 1.0324\n",
      "Epoch [142/300], Step [23/29], Loss: 1.5897\n",
      "Epoch [142/300], Step [24/29], Loss: 1.2205\n",
      "Epoch [142/300], Step [25/29], Loss: 1.3528\n",
      "Epoch [142/300], Step [26/29], Loss: 1.8011\n",
      "Epoch [142/300], Step [27/29], Loss: 1.2897\n",
      "Epoch [142/300], Step [28/29], Loss: 1.1976\n",
      "Epoch [142/300], Step [29/29], Loss: 1.5357\n",
      "Epoch [143/300], Step [1/29], Loss: 1.2011\n",
      "Epoch [143/300], Step [2/29], Loss: 1.4923\n",
      "Epoch [143/300], Step [3/29], Loss: 1.3204\n",
      "Epoch [143/300], Step [4/29], Loss: 1.4476\n",
      "Epoch [143/300], Step [5/29], Loss: 1.2733\n",
      "Epoch [143/300], Step [6/29], Loss: 1.3488\n",
      "Epoch [143/300], Step [7/29], Loss: 1.4930\n",
      "Epoch [143/300], Step [8/29], Loss: 1.2374\n",
      "Epoch [143/300], Step [9/29], Loss: 1.4630\n",
      "Epoch [143/300], Step [10/29], Loss: 1.2184\n",
      "Epoch [143/300], Step [11/29], Loss: 1.3261\n",
      "Epoch [143/300], Step [12/29], Loss: 1.1819\n",
      "Epoch [143/300], Step [13/29], Loss: 1.2446\n",
      "Epoch [143/300], Step [14/29], Loss: 1.0878\n",
      "Epoch [143/300], Step [15/29], Loss: 1.1304\n",
      "Epoch [143/300], Step [16/29], Loss: 1.3626\n",
      "Epoch [143/300], Step [17/29], Loss: 1.0582\n",
      "Epoch [143/300], Step [18/29], Loss: 1.1868\n",
      "Epoch [143/300], Step [19/29], Loss: 1.2181\n",
      "Epoch [143/300], Step [20/29], Loss: 1.0743\n",
      "Epoch [143/300], Step [21/29], Loss: 1.4825\n",
      "Epoch [143/300], Step [22/29], Loss: 1.1919\n",
      "Epoch [143/300], Step [23/29], Loss: 1.3848\n",
      "Epoch [143/300], Step [24/29], Loss: 1.1321\n",
      "Epoch [143/300], Step [25/29], Loss: 1.3466\n",
      "Epoch [143/300], Step [26/29], Loss: 1.3994\n",
      "Epoch [143/300], Step [27/29], Loss: 1.2810\n",
      "Epoch [143/300], Step [28/29], Loss: 1.4079\n",
      "Epoch [143/300], Step [29/29], Loss: 0.5080\n",
      "Epoch [144/300], Step [1/29], Loss: 1.4468\n",
      "Epoch [144/300], Step [2/29], Loss: 1.3463\n",
      "Epoch [144/300], Step [3/29], Loss: 1.2240\n",
      "Epoch [144/300], Step [4/29], Loss: 1.1694\n",
      "Epoch [144/300], Step [5/29], Loss: 1.2867\n",
      "Epoch [144/300], Step [6/29], Loss: 1.2186\n",
      "Epoch [144/300], Step [7/29], Loss: 1.4863\n",
      "Epoch [144/300], Step [8/29], Loss: 1.0942\n",
      "Epoch [144/300], Step [9/29], Loss: 1.3233\n",
      "Epoch [144/300], Step [10/29], Loss: 1.1642\n",
      "Epoch [144/300], Step [11/29], Loss: 1.2297\n",
      "Epoch [144/300], Step [12/29], Loss: 1.4675\n",
      "Epoch [144/300], Step [13/29], Loss: 1.0105\n",
      "Epoch [144/300], Step [14/29], Loss: 1.3264\n",
      "Epoch [144/300], Step [15/29], Loss: 1.2337\n",
      "Epoch [144/300], Step [16/29], Loss: 1.2709\n",
      "Epoch [144/300], Step [17/29], Loss: 1.1515\n",
      "Epoch [144/300], Step [18/29], Loss: 1.2300\n",
      "Epoch [144/300], Step [19/29], Loss: 1.2430\n",
      "Epoch [144/300], Step [20/29], Loss: 1.2929\n",
      "Epoch [144/300], Step [21/29], Loss: 1.3802\n",
      "Epoch [144/300], Step [22/29], Loss: 1.3202\n",
      "Epoch [144/300], Step [23/29], Loss: 1.2322\n",
      "Epoch [144/300], Step [24/29], Loss: 1.3391\n",
      "Epoch [144/300], Step [25/29], Loss: 1.3222\n",
      "Epoch [144/300], Step [26/29], Loss: 1.3993\n",
      "Epoch [144/300], Step [27/29], Loss: 1.3099\n",
      "Epoch [144/300], Step [28/29], Loss: 1.4080\n",
      "Epoch [144/300], Step [29/29], Loss: 2.1106\n",
      "Epoch [145/300], Step [1/29], Loss: 1.5736\n",
      "Epoch [145/300], Step [2/29], Loss: 1.3315\n",
      "Epoch [145/300], Step [3/29], Loss: 1.2223\n",
      "Epoch [145/300], Step [4/29], Loss: 1.1554\n",
      "Epoch [145/300], Step [5/29], Loss: 1.3720\n",
      "Epoch [145/300], Step [6/29], Loss: 1.2026\n",
      "Epoch [145/300], Step [7/29], Loss: 1.2127\n",
      "Epoch [145/300], Step [8/29], Loss: 1.5238\n",
      "Epoch [145/300], Step [9/29], Loss: 1.3808\n",
      "Epoch [145/300], Step [10/29], Loss: 1.2889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/300], Step [11/29], Loss: 1.5306\n",
      "Epoch [145/300], Step [12/29], Loss: 1.2993\n",
      "Epoch [145/300], Step [13/29], Loss: 1.1934\n",
      "Epoch [145/300], Step [14/29], Loss: 1.3375\n",
      "Epoch [145/300], Step [15/29], Loss: 1.2458\n",
      "Epoch [145/300], Step [16/29], Loss: 1.1553\n",
      "Epoch [145/300], Step [17/29], Loss: 1.3701\n",
      "Epoch [145/300], Step [18/29], Loss: 1.0743\n",
      "Epoch [145/300], Step [19/29], Loss: 1.2469\n",
      "Epoch [145/300], Step [20/29], Loss: 1.3603\n",
      "Epoch [145/300], Step [21/29], Loss: 1.4651\n",
      "Epoch [145/300], Step [22/29], Loss: 1.1265\n",
      "Epoch [145/300], Step [23/29], Loss: 1.1024\n",
      "Epoch [145/300], Step [24/29], Loss: 1.1605\n",
      "Epoch [145/300], Step [25/29], Loss: 1.2948\n",
      "Epoch [145/300], Step [26/29], Loss: 1.3241\n",
      "Epoch [145/300], Step [27/29], Loss: 1.3403\n",
      "Epoch [145/300], Step [28/29], Loss: 1.4149\n",
      "Epoch [145/300], Step [29/29], Loss: 1.1130\n",
      "Epoch [146/300], Step [1/29], Loss: 1.4810\n",
      "Epoch [146/300], Step [2/29], Loss: 1.2794\n",
      "Epoch [146/300], Step [3/29], Loss: 1.2364\n",
      "Epoch [146/300], Step [4/29], Loss: 1.1899\n",
      "Epoch [146/300], Step [5/29], Loss: 1.3074\n",
      "Epoch [146/300], Step [6/29], Loss: 1.1163\n",
      "Epoch [146/300], Step [7/29], Loss: 1.4339\n",
      "Epoch [146/300], Step [8/29], Loss: 1.3635\n",
      "Epoch [146/300], Step [9/29], Loss: 1.2584\n",
      "Epoch [146/300], Step [10/29], Loss: 1.3701\n",
      "Epoch [146/300], Step [11/29], Loss: 1.2894\n",
      "Epoch [146/300], Step [12/29], Loss: 1.1338\n",
      "Epoch [146/300], Step [13/29], Loss: 1.2429\n",
      "Epoch [146/300], Step [14/29], Loss: 1.4215\n",
      "Epoch [146/300], Step [15/29], Loss: 1.2688\n",
      "Epoch [146/300], Step [16/29], Loss: 1.2993\n",
      "Epoch [146/300], Step [17/29], Loss: 1.2415\n",
      "Epoch [146/300], Step [18/29], Loss: 1.2746\n",
      "Epoch [146/300], Step [19/29], Loss: 1.4717\n",
      "Epoch [146/300], Step [20/29], Loss: 1.1986\n",
      "Epoch [146/300], Step [21/29], Loss: 1.1704\n",
      "Epoch [146/300], Step [22/29], Loss: 1.4238\n",
      "Epoch [146/300], Step [23/29], Loss: 1.2353\n",
      "Epoch [146/300], Step [24/29], Loss: 1.2816\n",
      "Epoch [146/300], Step [25/29], Loss: 1.2946\n",
      "Epoch [146/300], Step [26/29], Loss: 1.3941\n",
      "Epoch [146/300], Step [27/29], Loss: 1.4159\n",
      "Epoch [146/300], Step [28/29], Loss: 1.1947\n",
      "Epoch [146/300], Step [29/29], Loss: 0.4598\n",
      "Epoch [147/300], Step [1/29], Loss: 1.2364\n",
      "Epoch [147/300], Step [2/29], Loss: 1.3212\n",
      "Epoch [147/300], Step [3/29], Loss: 1.2067\n",
      "Epoch [147/300], Step [4/29], Loss: 1.3156\n",
      "Epoch [147/300], Step [5/29], Loss: 0.9734\n",
      "Epoch [147/300], Step [6/29], Loss: 1.4879\n",
      "Epoch [147/300], Step [7/29], Loss: 1.2638\n",
      "Epoch [147/300], Step [8/29], Loss: 1.5076\n",
      "Epoch [147/300], Step [9/29], Loss: 1.3624\n",
      "Epoch [147/300], Step [10/29], Loss: 1.1900\n",
      "Epoch [147/300], Step [11/29], Loss: 1.2633\n",
      "Epoch [147/300], Step [12/29], Loss: 1.4187\n",
      "Epoch [147/300], Step [13/29], Loss: 1.5922\n",
      "Epoch [147/300], Step [14/29], Loss: 1.3759\n",
      "Epoch [147/300], Step [15/29], Loss: 1.0352\n",
      "Epoch [147/300], Step [16/29], Loss: 1.4853\n",
      "Epoch [147/300], Step [17/29], Loss: 1.5503\n",
      "Epoch [147/300], Step [18/29], Loss: 1.2251\n",
      "Epoch [147/300], Step [19/29], Loss: 1.0820\n",
      "Epoch [147/300], Step [20/29], Loss: 1.1916\n",
      "Epoch [147/300], Step [21/29], Loss: 1.1563\n",
      "Epoch [147/300], Step [22/29], Loss: 1.2385\n",
      "Epoch [147/300], Step [23/29], Loss: 1.3043\n",
      "Epoch [147/300], Step [24/29], Loss: 1.4133\n",
      "Epoch [147/300], Step [25/29], Loss: 1.4381\n",
      "Epoch [147/300], Step [26/29], Loss: 1.1217\n",
      "Epoch [147/300], Step [27/29], Loss: 1.2281\n",
      "Epoch [147/300], Step [28/29], Loss: 1.2991\n",
      "Epoch [147/300], Step [29/29], Loss: 0.8748\n",
      "Epoch [148/300], Step [1/29], Loss: 1.3045\n",
      "Epoch [148/300], Step [2/29], Loss: 1.2708\n",
      "Epoch [148/300], Step [3/29], Loss: 1.2771\n",
      "Epoch [148/300], Step [4/29], Loss: 1.2550\n",
      "Epoch [148/300], Step [5/29], Loss: 1.1617\n",
      "Epoch [148/300], Step [6/29], Loss: 1.1917\n",
      "Epoch [148/300], Step [7/29], Loss: 1.0462\n",
      "Epoch [148/300], Step [8/29], Loss: 1.2320\n",
      "Epoch [148/300], Step [9/29], Loss: 1.2853\n",
      "Epoch [148/300], Step [10/29], Loss: 1.4849\n",
      "Epoch [148/300], Step [11/29], Loss: 1.1303\n",
      "Epoch [148/300], Step [12/29], Loss: 1.4966\n",
      "Epoch [148/300], Step [13/29], Loss: 1.3692\n",
      "Epoch [148/300], Step [14/29], Loss: 1.2318\n",
      "Epoch [148/300], Step [15/29], Loss: 1.0855\n",
      "Epoch [148/300], Step [16/29], Loss: 1.3205\n",
      "Epoch [148/300], Step [17/29], Loss: 0.9707\n",
      "Epoch [148/300], Step [18/29], Loss: 1.2564\n",
      "Epoch [148/300], Step [19/29], Loss: 1.4533\n",
      "Epoch [148/300], Step [20/29], Loss: 1.2327\n",
      "Epoch [148/300], Step [21/29], Loss: 1.3848\n",
      "Epoch [148/300], Step [22/29], Loss: 1.6257\n",
      "Epoch [148/300], Step [23/29], Loss: 1.5084\n",
      "Epoch [148/300], Step [24/29], Loss: 1.2606\n",
      "Epoch [148/300], Step [25/29], Loss: 1.3579\n",
      "Epoch [148/300], Step [26/29], Loss: 1.3023\n",
      "Epoch [148/300], Step [27/29], Loss: 1.2259\n",
      "Epoch [148/300], Step [28/29], Loss: 1.3044\n",
      "Epoch [148/300], Step [29/29], Loss: 1.9240\n",
      "Epoch [149/300], Step [1/29], Loss: 1.0892\n",
      "Epoch [149/300], Step [2/29], Loss: 1.4609\n",
      "Epoch [149/300], Step [3/29], Loss: 1.4467\n",
      "Epoch [149/300], Step [4/29], Loss: 1.3070\n",
      "Epoch [149/300], Step [5/29], Loss: 1.1737\n",
      "Epoch [149/300], Step [6/29], Loss: 1.4041\n",
      "Epoch [149/300], Step [7/29], Loss: 1.5387\n",
      "Epoch [149/300], Step [8/29], Loss: 1.2859\n",
      "Epoch [149/300], Step [9/29], Loss: 1.3889\n",
      "Epoch [149/300], Step [10/29], Loss: 1.3378\n",
      "Epoch [149/300], Step [11/29], Loss: 1.2135\n",
      "Epoch [149/300], Step [12/29], Loss: 1.4768\n",
      "Epoch [149/300], Step [13/29], Loss: 0.9878\n",
      "Epoch [149/300], Step [14/29], Loss: 1.2509\n",
      "Epoch [149/300], Step [15/29], Loss: 1.2964\n",
      "Epoch [149/300], Step [16/29], Loss: 1.3447\n",
      "Epoch [149/300], Step [17/29], Loss: 1.3523\n",
      "Epoch [149/300], Step [18/29], Loss: 1.3858\n",
      "Epoch [149/300], Step [19/29], Loss: 1.1126\n",
      "Epoch [149/300], Step [20/29], Loss: 1.2952\n",
      "Epoch [149/300], Step [21/29], Loss: 1.4182\n",
      "Epoch [149/300], Step [22/29], Loss: 1.2939\n",
      "Epoch [149/300], Step [23/29], Loss: 1.0758\n",
      "Epoch [149/300], Step [24/29], Loss: 1.2414\n",
      "Epoch [149/300], Step [25/29], Loss: 1.2165\n",
      "Epoch [149/300], Step [26/29], Loss: 1.3167\n",
      "Epoch [149/300], Step [27/29], Loss: 1.2211\n",
      "Epoch [149/300], Step [28/29], Loss: 1.3560\n",
      "Epoch [149/300], Step [29/29], Loss: 0.8186\n",
      "Epoch [150/300], Step [1/29], Loss: 1.1255\n",
      "Epoch [150/300], Step [2/29], Loss: 1.5097\n",
      "Epoch [150/300], Step [3/29], Loss: 1.2957\n",
      "Epoch [150/300], Step [4/29], Loss: 1.0795\n",
      "Epoch [150/300], Step [5/29], Loss: 1.6589\n",
      "Epoch [150/300], Step [6/29], Loss: 1.3038\n",
      "Epoch [150/300], Step [7/29], Loss: 1.2739\n",
      "Epoch [150/300], Step [8/29], Loss: 1.3354\n",
      "Epoch [150/300], Step [9/29], Loss: 1.5382\n",
      "Epoch [150/300], Step [10/29], Loss: 1.3749\n",
      "Epoch [150/300], Step [11/29], Loss: 1.3827\n",
      "Epoch [150/300], Step [12/29], Loss: 1.1634\n",
      "Epoch [150/300], Step [13/29], Loss: 1.2449\n",
      "Epoch [150/300], Step [14/29], Loss: 1.1492\n",
      "Epoch [150/300], Step [15/29], Loss: 1.2995\n",
      "Epoch [150/300], Step [16/29], Loss: 1.0481\n",
      "Epoch [150/300], Step [17/29], Loss: 1.1571\n",
      "Epoch [150/300], Step [18/29], Loss: 1.2538\n",
      "Epoch [150/300], Step [19/29], Loss: 1.5200\n",
      "Epoch [150/300], Step [20/29], Loss: 1.4024\n",
      "Epoch [150/300], Step [21/29], Loss: 1.0974\n",
      "Epoch [150/300], Step [22/29], Loss: 1.1258\n",
      "Epoch [150/300], Step [23/29], Loss: 1.0699\n",
      "Epoch [150/300], Step [24/29], Loss: 1.3389\n",
      "Epoch [150/300], Step [25/29], Loss: 1.0623\n",
      "Epoch [150/300], Step [26/29], Loss: 1.4312\n",
      "Epoch [150/300], Step [27/29], Loss: 1.2441\n",
      "Epoch [150/300], Step [28/29], Loss: 1.3249\n",
      "Epoch [150/300], Step [29/29], Loss: 1.9095\n",
      "Epoch [151/300], Step [1/29], Loss: 1.1792\n",
      "Epoch [151/300], Step [2/29], Loss: 1.2402\n",
      "Epoch [151/300], Step [3/29], Loss: 1.2006\n",
      "Epoch [151/300], Step [4/29], Loss: 1.0707\n",
      "Epoch [151/300], Step [5/29], Loss: 1.4151\n",
      "Epoch [151/300], Step [6/29], Loss: 1.2600\n",
      "Epoch [151/300], Step [7/29], Loss: 1.4683\n",
      "Epoch [151/300], Step [8/29], Loss: 1.3841\n",
      "Epoch [151/300], Step [9/29], Loss: 1.5058\n",
      "Epoch [151/300], Step [10/29], Loss: 1.1940\n",
      "Epoch [151/300], Step [11/29], Loss: 1.3585\n",
      "Epoch [151/300], Step [12/29], Loss: 1.2887\n",
      "Epoch [151/300], Step [13/29], Loss: 1.2316\n",
      "Epoch [151/300], Step [14/29], Loss: 1.3897\n",
      "Epoch [151/300], Step [15/29], Loss: 1.0527\n",
      "Epoch [151/300], Step [16/29], Loss: 1.2769\n",
      "Epoch [151/300], Step [17/29], Loss: 1.3529\n",
      "Epoch [151/300], Step [18/29], Loss: 1.5452\n",
      "Epoch [151/300], Step [19/29], Loss: 1.4033\n",
      "Epoch [151/300], Step [20/29], Loss: 1.1688\n",
      "Epoch [151/300], Step [21/29], Loss: 1.3671\n",
      "Epoch [151/300], Step [22/29], Loss: 1.4203\n",
      "Epoch [151/300], Step [23/29], Loss: 1.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/300], Step [24/29], Loss: 1.6418\n",
      "Epoch [151/300], Step [25/29], Loss: 1.3535\n",
      "Epoch [151/300], Step [26/29], Loss: 1.2622\n",
      "Epoch [151/300], Step [27/29], Loss: 0.9828\n",
      "Epoch [151/300], Step [28/29], Loss: 1.1872\n",
      "Epoch [151/300], Step [29/29], Loss: 1.6389\n",
      "Epoch [152/300], Step [1/29], Loss: 1.5177\n",
      "Epoch [152/300], Step [2/29], Loss: 1.2195\n",
      "Epoch [152/300], Step [3/29], Loss: 1.5250\n",
      "Epoch [152/300], Step [4/29], Loss: 1.3921\n",
      "Epoch [152/300], Step [5/29], Loss: 1.2990\n",
      "Epoch [152/300], Step [6/29], Loss: 1.3996\n",
      "Epoch [152/300], Step [7/29], Loss: 1.2966\n",
      "Epoch [152/300], Step [8/29], Loss: 1.2367\n",
      "Epoch [152/300], Step [9/29], Loss: 1.1972\n",
      "Epoch [152/300], Step [10/29], Loss: 1.3494\n",
      "Epoch [152/300], Step [11/29], Loss: 1.3358\n",
      "Epoch [152/300], Step [12/29], Loss: 1.2237\n",
      "Epoch [152/300], Step [13/29], Loss: 1.1898\n",
      "Epoch [152/300], Step [14/29], Loss: 1.2333\n",
      "Epoch [152/300], Step [15/29], Loss: 1.4827\n",
      "Epoch [152/300], Step [16/29], Loss: 1.2543\n",
      "Epoch [152/300], Step [17/29], Loss: 0.9514\n",
      "Epoch [152/300], Step [18/29], Loss: 1.2326\n",
      "Epoch [152/300], Step [19/29], Loss: 1.0691\n",
      "Epoch [152/300], Step [20/29], Loss: 1.4447\n",
      "Epoch [152/300], Step [21/29], Loss: 1.3075\n",
      "Epoch [152/300], Step [22/29], Loss: 1.0418\n",
      "Epoch [152/300], Step [23/29], Loss: 1.2560\n",
      "Epoch [152/300], Step [24/29], Loss: 1.3253\n",
      "Epoch [152/300], Step [25/29], Loss: 1.1982\n",
      "Epoch [152/300], Step [26/29], Loss: 1.4959\n",
      "Epoch [152/300], Step [27/29], Loss: 1.4507\n",
      "Epoch [152/300], Step [28/29], Loss: 1.2671\n",
      "Epoch [152/300], Step [29/29], Loss: 0.7336\n",
      "Epoch [153/300], Step [1/29], Loss: 1.1484\n",
      "Epoch [153/300], Step [2/29], Loss: 1.2660\n",
      "Epoch [153/300], Step [3/29], Loss: 1.5972\n",
      "Epoch [153/300], Step [4/29], Loss: 1.1517\n",
      "Epoch [153/300], Step [5/29], Loss: 1.3024\n",
      "Epoch [153/300], Step [6/29], Loss: 0.9573\n",
      "Epoch [153/300], Step [7/29], Loss: 1.4681\n",
      "Epoch [153/300], Step [8/29], Loss: 1.2511\n",
      "Epoch [153/300], Step [9/29], Loss: 1.2049\n",
      "Epoch [153/300], Step [10/29], Loss: 1.3721\n",
      "Epoch [153/300], Step [11/29], Loss: 1.2572\n",
      "Epoch [153/300], Step [12/29], Loss: 1.4616\n",
      "Epoch [153/300], Step [13/29], Loss: 1.1782\n",
      "Epoch [153/300], Step [14/29], Loss: 1.3426\n",
      "Epoch [153/300], Step [15/29], Loss: 1.4522\n",
      "Epoch [153/300], Step [16/29], Loss: 1.3462\n",
      "Epoch [153/300], Step [17/29], Loss: 1.3258\n",
      "Epoch [153/300], Step [18/29], Loss: 1.2974\n",
      "Epoch [153/300], Step [19/29], Loss: 1.3050\n",
      "Epoch [153/300], Step [20/29], Loss: 1.1093\n",
      "Epoch [153/300], Step [21/29], Loss: 1.3199\n",
      "Epoch [153/300], Step [22/29], Loss: 1.2315\n",
      "Epoch [153/300], Step [23/29], Loss: 1.2813\n",
      "Epoch [153/300], Step [24/29], Loss: 1.2638\n",
      "Epoch [153/300], Step [25/29], Loss: 1.4724\n",
      "Epoch [153/300], Step [26/29], Loss: 1.3684\n",
      "Epoch [153/300], Step [27/29], Loss: 1.1144\n",
      "Epoch [153/300], Step [28/29], Loss: 1.4528\n",
      "Epoch [153/300], Step [29/29], Loss: 1.5734\n",
      "Epoch [154/300], Step [1/29], Loss: 1.2205\n",
      "Epoch [154/300], Step [2/29], Loss: 1.0719\n",
      "Epoch [154/300], Step [3/29], Loss: 1.3365\n",
      "Epoch [154/300], Step [4/29], Loss: 1.1370\n",
      "Epoch [154/300], Step [5/29], Loss: 1.1449\n",
      "Epoch [154/300], Step [6/29], Loss: 1.4237\n",
      "Epoch [154/300], Step [7/29], Loss: 1.3855\n",
      "Epoch [154/300], Step [8/29], Loss: 1.6083\n",
      "Epoch [154/300], Step [9/29], Loss: 1.1318\n",
      "Epoch [154/300], Step [10/29], Loss: 1.4474\n",
      "Epoch [154/300], Step [11/29], Loss: 1.1510\n",
      "Epoch [154/300], Step [12/29], Loss: 1.5256\n",
      "Epoch [154/300], Step [13/29], Loss: 1.3629\n",
      "Epoch [154/300], Step [14/29], Loss: 1.2054\n",
      "Epoch [154/300], Step [15/29], Loss: 1.0076\n",
      "Epoch [154/300], Step [16/29], Loss: 1.0770\n",
      "Epoch [154/300], Step [17/29], Loss: 1.5449\n",
      "Epoch [154/300], Step [18/29], Loss: 1.4556\n",
      "Epoch [154/300], Step [19/29], Loss: 1.2974\n",
      "Epoch [154/300], Step [20/29], Loss: 1.5162\n",
      "Epoch [154/300], Step [21/29], Loss: 1.3982\n",
      "Epoch [154/300], Step [22/29], Loss: 1.2958\n",
      "Epoch [154/300], Step [23/29], Loss: 1.2098\n",
      "Epoch [154/300], Step [24/29], Loss: 1.1972\n",
      "Epoch [154/300], Step [25/29], Loss: 1.3121\n",
      "Epoch [154/300], Step [26/29], Loss: 1.3536\n",
      "Epoch [154/300], Step [27/29], Loss: 1.2949\n",
      "Epoch [154/300], Step [28/29], Loss: 1.3479\n",
      "Epoch [154/300], Step [29/29], Loss: 1.3707\n",
      "Epoch [155/300], Step [1/29], Loss: 1.2494\n",
      "Epoch [155/300], Step [2/29], Loss: 1.2605\n",
      "Epoch [155/300], Step [3/29], Loss: 1.3296\n",
      "Epoch [155/300], Step [4/29], Loss: 1.0787\n",
      "Epoch [155/300], Step [5/29], Loss: 1.3203\n",
      "Epoch [155/300], Step [6/29], Loss: 1.3383\n",
      "Epoch [155/300], Step [7/29], Loss: 1.3015\n",
      "Epoch [155/300], Step [8/29], Loss: 1.2139\n",
      "Epoch [155/300], Step [9/29], Loss: 1.3917\n",
      "Epoch [155/300], Step [10/29], Loss: 1.1476\n",
      "Epoch [155/300], Step [11/29], Loss: 1.3414\n",
      "Epoch [155/300], Step [12/29], Loss: 1.3193\n",
      "Epoch [155/300], Step [13/29], Loss: 1.4066\n",
      "Epoch [155/300], Step [14/29], Loss: 1.3165\n",
      "Epoch [155/300], Step [15/29], Loss: 1.1733\n",
      "Epoch [155/300], Step [16/29], Loss: 1.5299\n",
      "Epoch [155/300], Step [17/29], Loss: 1.3674\n",
      "Epoch [155/300], Step [18/29], Loss: 1.3117\n",
      "Epoch [155/300], Step [19/29], Loss: 1.3762\n",
      "Epoch [155/300], Step [20/29], Loss: 1.1779\n",
      "Epoch [155/300], Step [21/29], Loss: 1.2226\n",
      "Epoch [155/300], Step [22/29], Loss: 1.3272\n",
      "Epoch [155/300], Step [23/29], Loss: 1.3021\n",
      "Epoch [155/300], Step [24/29], Loss: 1.1254\n",
      "Epoch [155/300], Step [25/29], Loss: 1.2729\n",
      "Epoch [155/300], Step [26/29], Loss: 1.4418\n",
      "Epoch [155/300], Step [27/29], Loss: 1.3630\n",
      "Epoch [155/300], Step [28/29], Loss: 1.1763\n",
      "Epoch [155/300], Step [29/29], Loss: 0.7038\n",
      "Epoch [156/300], Step [1/29], Loss: 1.3240\n",
      "Epoch [156/300], Step [2/29], Loss: 1.2186\n",
      "Epoch [156/300], Step [3/29], Loss: 1.1219\n",
      "Epoch [156/300], Step [4/29], Loss: 1.1362\n",
      "Epoch [156/300], Step [5/29], Loss: 1.1220\n",
      "Epoch [156/300], Step [6/29], Loss: 1.2001\n",
      "Epoch [156/300], Step [7/29], Loss: 1.2838\n",
      "Epoch [156/300], Step [8/29], Loss: 1.3822\n",
      "Epoch [156/300], Step [9/29], Loss: 1.5411\n",
      "Epoch [156/300], Step [10/29], Loss: 1.1134\n",
      "Epoch [156/300], Step [11/29], Loss: 1.6529\n",
      "Epoch [156/300], Step [12/29], Loss: 1.4399\n",
      "Epoch [156/300], Step [13/29], Loss: 1.3161\n",
      "Epoch [156/300], Step [14/29], Loss: 1.4536\n",
      "Epoch [156/300], Step [15/29], Loss: 1.0788\n",
      "Epoch [156/300], Step [16/29], Loss: 1.2395\n",
      "Epoch [156/300], Step [17/29], Loss: 1.5877\n",
      "Epoch [156/300], Step [18/29], Loss: 1.3535\n",
      "Epoch [156/300], Step [19/29], Loss: 1.0950\n",
      "Epoch [156/300], Step [20/29], Loss: 1.3040\n",
      "Epoch [156/300], Step [21/29], Loss: 1.1597\n",
      "Epoch [156/300], Step [22/29], Loss: 1.2128\n",
      "Epoch [156/300], Step [23/29], Loss: 1.4062\n",
      "Epoch [156/300], Step [24/29], Loss: 1.4898\n",
      "Epoch [156/300], Step [25/29], Loss: 1.4652\n",
      "Epoch [156/300], Step [26/29], Loss: 1.1904\n",
      "Epoch [156/300], Step [27/29], Loss: 1.3028\n",
      "Epoch [156/300], Step [28/29], Loss: 1.2444\n",
      "Epoch [156/300], Step [29/29], Loss: 2.0116\n",
      "Epoch [157/300], Step [1/29], Loss: 1.3496\n",
      "Epoch [157/300], Step [2/29], Loss: 1.3505\n",
      "Epoch [157/300], Step [3/29], Loss: 1.3079\n",
      "Epoch [157/300], Step [4/29], Loss: 1.3535\n",
      "Epoch [157/300], Step [5/29], Loss: 1.5225\n",
      "Epoch [157/300], Step [6/29], Loss: 1.2948\n",
      "Epoch [157/300], Step [7/29], Loss: 1.1838\n",
      "Epoch [157/300], Step [8/29], Loss: 1.4148\n",
      "Epoch [157/300], Step [9/29], Loss: 1.0790\n",
      "Epoch [157/300], Step [10/29], Loss: 1.4976\n",
      "Epoch [157/300], Step [11/29], Loss: 1.5289\n",
      "Epoch [157/300], Step [12/29], Loss: 1.3741\n",
      "Epoch [157/300], Step [13/29], Loss: 1.2047\n",
      "Epoch [157/300], Step [14/29], Loss: 1.4386\n",
      "Epoch [157/300], Step [15/29], Loss: 1.2653\n",
      "Epoch [157/300], Step [16/29], Loss: 1.1788\n",
      "Epoch [157/300], Step [17/29], Loss: 1.3493\n",
      "Epoch [157/300], Step [18/29], Loss: 1.4513\n",
      "Epoch [157/300], Step [19/29], Loss: 1.2490\n",
      "Epoch [157/300], Step [20/29], Loss: 0.9574\n",
      "Epoch [157/300], Step [21/29], Loss: 1.1969\n",
      "Epoch [157/300], Step [22/29], Loss: 1.0909\n",
      "Epoch [157/300], Step [23/29], Loss: 1.3596\n",
      "Epoch [157/300], Step [24/29], Loss: 1.4904\n",
      "Epoch [157/300], Step [25/29], Loss: 1.3597\n",
      "Epoch [157/300], Step [26/29], Loss: 1.4083\n",
      "Epoch [157/300], Step [27/29], Loss: 1.1043\n",
      "Epoch [157/300], Step [28/29], Loss: 1.0852\n",
      "Epoch [157/300], Step [29/29], Loss: 3.1492\n",
      "Epoch [158/300], Step [1/29], Loss: 1.1966\n",
      "Epoch [158/300], Step [2/29], Loss: 1.1776\n",
      "Epoch [158/300], Step [3/29], Loss: 1.3024\n",
      "Epoch [158/300], Step [4/29], Loss: 1.2826\n",
      "Epoch [158/300], Step [5/29], Loss: 1.3465\n",
      "Epoch [158/300], Step [6/29], Loss: 1.4242\n",
      "Epoch [158/300], Step [7/29], Loss: 1.3212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/300], Step [8/29], Loss: 1.4013\n",
      "Epoch [158/300], Step [9/29], Loss: 1.3226\n",
      "Epoch [158/300], Step [10/29], Loss: 1.1311\n",
      "Epoch [158/300], Step [11/29], Loss: 1.2741\n",
      "Epoch [158/300], Step [12/29], Loss: 1.3889\n",
      "Epoch [158/300], Step [13/29], Loss: 1.5844\n",
      "Epoch [158/300], Step [14/29], Loss: 1.1585\n",
      "Epoch [158/300], Step [15/29], Loss: 1.1541\n",
      "Epoch [158/300], Step [16/29], Loss: 1.4153\n",
      "Epoch [158/300], Step [17/29], Loss: 1.5293\n",
      "Epoch [158/300], Step [18/29], Loss: 1.4997\n",
      "Epoch [158/300], Step [19/29], Loss: 1.3449\n",
      "Epoch [158/300], Step [20/29], Loss: 1.1627\n",
      "Epoch [158/300], Step [21/29], Loss: 1.3868\n",
      "Epoch [158/300], Step [22/29], Loss: 1.0439\n",
      "Epoch [158/300], Step [23/29], Loss: 1.2676\n",
      "Epoch [158/300], Step [24/29], Loss: 1.4649\n",
      "Epoch [158/300], Step [25/29], Loss: 1.5815\n",
      "Epoch [158/300], Step [26/29], Loss: 1.1632\n",
      "Epoch [158/300], Step [27/29], Loss: 1.1023\n",
      "Epoch [158/300], Step [28/29], Loss: 1.0027\n",
      "Epoch [158/300], Step [29/29], Loss: 0.8828\n",
      "Epoch [159/300], Step [1/29], Loss: 1.1700\n",
      "Epoch [159/300], Step [2/29], Loss: 1.3292\n",
      "Epoch [159/300], Step [3/29], Loss: 1.1891\n",
      "Epoch [159/300], Step [4/29], Loss: 1.1536\n",
      "Epoch [159/300], Step [5/29], Loss: 1.3067\n",
      "Epoch [159/300], Step [6/29], Loss: 1.3021\n",
      "Epoch [159/300], Step [7/29], Loss: 1.3420\n",
      "Epoch [159/300], Step [8/29], Loss: 1.4440\n",
      "Epoch [159/300], Step [9/29], Loss: 1.2151\n",
      "Epoch [159/300], Step [10/29], Loss: 1.2606\n",
      "Epoch [159/300], Step [11/29], Loss: 1.0427\n",
      "Epoch [159/300], Step [12/29], Loss: 1.4453\n",
      "Epoch [159/300], Step [13/29], Loss: 1.3412\n",
      "Epoch [159/300], Step [14/29], Loss: 1.2551\n",
      "Epoch [159/300], Step [15/29], Loss: 1.3175\n",
      "Epoch [159/300], Step [16/29], Loss: 1.3154\n",
      "Epoch [159/300], Step [17/29], Loss: 1.1668\n",
      "Epoch [159/300], Step [18/29], Loss: 1.4576\n",
      "Epoch [159/300], Step [19/29], Loss: 1.3178\n",
      "Epoch [159/300], Step [20/29], Loss: 0.9490\n",
      "Epoch [159/300], Step [21/29], Loss: 1.2939\n",
      "Epoch [159/300], Step [22/29], Loss: 1.2919\n",
      "Epoch [159/300], Step [23/29], Loss: 1.5431\n",
      "Epoch [159/300], Step [24/29], Loss: 1.4140\n",
      "Epoch [159/300], Step [25/29], Loss: 1.3457\n",
      "Epoch [159/300], Step [26/29], Loss: 1.3072\n",
      "Epoch [159/300], Step [27/29], Loss: 1.2605\n",
      "Epoch [159/300], Step [28/29], Loss: 1.3418\n",
      "Epoch [159/300], Step [29/29], Loss: 0.7985\n",
      "Epoch [160/300], Step [1/29], Loss: 1.4141\n",
      "Epoch [160/300], Step [2/29], Loss: 1.3104\n",
      "Epoch [160/300], Step [3/29], Loss: 1.3637\n",
      "Epoch [160/300], Step [4/29], Loss: 1.3475\n",
      "Epoch [160/300], Step [5/29], Loss: 1.3700\n",
      "Epoch [160/300], Step [6/29], Loss: 1.2396\n",
      "Epoch [160/300], Step [7/29], Loss: 1.0062\n",
      "Epoch [160/300], Step [8/29], Loss: 1.3434\n",
      "Epoch [160/300], Step [9/29], Loss: 1.2744\n",
      "Epoch [160/300], Step [10/29], Loss: 1.5977\n",
      "Epoch [160/300], Step [11/29], Loss: 1.1720\n",
      "Epoch [160/300], Step [12/29], Loss: 1.3164\n",
      "Epoch [160/300], Step [13/29], Loss: 1.3891\n",
      "Epoch [160/300], Step [14/29], Loss: 1.1965\n",
      "Epoch [160/300], Step [15/29], Loss: 1.4341\n",
      "Epoch [160/300], Step [16/29], Loss: 1.5566\n",
      "Epoch [160/300], Step [17/29], Loss: 1.1795\n",
      "Epoch [160/300], Step [18/29], Loss: 1.3631\n",
      "Epoch [160/300], Step [19/29], Loss: 1.4875\n",
      "Epoch [160/300], Step [20/29], Loss: 1.1654\n",
      "Epoch [160/300], Step [21/29], Loss: 1.3327\n",
      "Epoch [160/300], Step [22/29], Loss: 1.1671\n",
      "Epoch [160/300], Step [23/29], Loss: 1.3130\n",
      "Epoch [160/300], Step [24/29], Loss: 1.2211\n",
      "Epoch [160/300], Step [25/29], Loss: 1.0082\n",
      "Epoch [160/300], Step [26/29], Loss: 1.2796\n",
      "Epoch [160/300], Step [27/29], Loss: 1.1157\n",
      "Epoch [160/300], Step [28/29], Loss: 1.2916\n",
      "Epoch [160/300], Step [29/29], Loss: 1.6665\n",
      "Epoch [161/300], Step [1/29], Loss: 1.0675\n",
      "Epoch [161/300], Step [2/29], Loss: 1.3338\n",
      "Epoch [161/300], Step [3/29], Loss: 1.2786\n",
      "Epoch [161/300], Step [4/29], Loss: 1.5216\n",
      "Epoch [161/300], Step [5/29], Loss: 1.2851\n",
      "Epoch [161/300], Step [6/29], Loss: 1.0964\n",
      "Epoch [161/300], Step [7/29], Loss: 1.4847\n",
      "Epoch [161/300], Step [8/29], Loss: 1.2877\n",
      "Epoch [161/300], Step [9/29], Loss: 1.3994\n",
      "Epoch [161/300], Step [10/29], Loss: 1.2449\n",
      "Epoch [161/300], Step [11/29], Loss: 1.4819\n",
      "Epoch [161/300], Step [12/29], Loss: 1.3375\n",
      "Epoch [161/300], Step [13/29], Loss: 1.3448\n",
      "Epoch [161/300], Step [14/29], Loss: 1.3450\n",
      "Epoch [161/300], Step [15/29], Loss: 1.3153\n",
      "Epoch [161/300], Step [16/29], Loss: 1.3262\n",
      "Epoch [161/300], Step [17/29], Loss: 1.0044\n",
      "Epoch [161/300], Step [18/29], Loss: 1.0982\n",
      "Epoch [161/300], Step [19/29], Loss: 1.2917\n",
      "Epoch [161/300], Step [20/29], Loss: 1.4349\n",
      "Epoch [161/300], Step [21/29], Loss: 1.1837\n",
      "Epoch [161/300], Step [22/29], Loss: 1.3444\n",
      "Epoch [161/300], Step [23/29], Loss: 1.2193\n",
      "Epoch [161/300], Step [24/29], Loss: 1.5916\n",
      "Epoch [161/300], Step [25/29], Loss: 1.3308\n",
      "Epoch [161/300], Step [26/29], Loss: 1.2506\n",
      "Epoch [161/300], Step [27/29], Loss: 1.2501\n",
      "Epoch [161/300], Step [28/29], Loss: 1.3801\n",
      "Epoch [161/300], Step [29/29], Loss: 1.9566\n",
      "Epoch [162/300], Step [1/29], Loss: 1.2047\n",
      "Epoch [162/300], Step [2/29], Loss: 1.1675\n",
      "Epoch [162/300], Step [3/29], Loss: 1.3853\n",
      "Epoch [162/300], Step [4/29], Loss: 1.5360\n",
      "Epoch [162/300], Step [5/29], Loss: 1.3238\n",
      "Epoch [162/300], Step [6/29], Loss: 1.2506\n",
      "Epoch [162/300], Step [7/29], Loss: 1.3940\n",
      "Epoch [162/300], Step [8/29], Loss: 1.3268\n",
      "Epoch [162/300], Step [9/29], Loss: 1.1436\n",
      "Epoch [162/300], Step [10/29], Loss: 1.1378\n",
      "Epoch [162/300], Step [11/29], Loss: 1.1218\n",
      "Epoch [162/300], Step [12/29], Loss: 1.1395\n",
      "Epoch [162/300], Step [13/29], Loss: 1.1539\n",
      "Epoch [162/300], Step [14/29], Loss: 1.3335\n",
      "Epoch [162/300], Step [15/29], Loss: 1.1685\n",
      "Epoch [162/300], Step [16/29], Loss: 1.3789\n",
      "Epoch [162/300], Step [17/29], Loss: 1.4105\n",
      "Epoch [162/300], Step [18/29], Loss: 1.2270\n",
      "Epoch [162/300], Step [19/29], Loss: 1.1150\n",
      "Epoch [162/300], Step [20/29], Loss: 1.7774\n",
      "Epoch [162/300], Step [21/29], Loss: 1.3286\n",
      "Epoch [162/300], Step [22/29], Loss: 1.5915\n",
      "Epoch [162/300], Step [23/29], Loss: 1.3723\n",
      "Epoch [162/300], Step [24/29], Loss: 1.2270\n",
      "Epoch [162/300], Step [25/29], Loss: 1.2983\n",
      "Epoch [162/300], Step [26/29], Loss: 1.5215\n",
      "Epoch [162/300], Step [27/29], Loss: 1.1065\n",
      "Epoch [162/300], Step [28/29], Loss: 1.2630\n",
      "Epoch [162/300], Step [29/29], Loss: 2.5736\n",
      "Epoch [163/300], Step [1/29], Loss: 1.4727\n",
      "Epoch [163/300], Step [2/29], Loss: 1.3900\n",
      "Epoch [163/300], Step [3/29], Loss: 1.1978\n",
      "Epoch [163/300], Step [4/29], Loss: 1.3457\n",
      "Epoch [163/300], Step [5/29], Loss: 1.2368\n",
      "Epoch [163/300], Step [6/29], Loss: 1.1339\n",
      "Epoch [163/300], Step [7/29], Loss: 1.0662\n",
      "Epoch [163/300], Step [8/29], Loss: 1.2293\n",
      "Epoch [163/300], Step [9/29], Loss: 1.2717\n",
      "Epoch [163/300], Step [10/29], Loss: 1.4127\n",
      "Epoch [163/300], Step [11/29], Loss: 1.4796\n",
      "Epoch [163/300], Step [12/29], Loss: 1.5109\n",
      "Epoch [163/300], Step [13/29], Loss: 1.1947\n",
      "Epoch [163/300], Step [14/29], Loss: 1.3408\n",
      "Epoch [163/300], Step [15/29], Loss: 1.0246\n",
      "Epoch [163/300], Step [16/29], Loss: 1.3338\n",
      "Epoch [163/300], Step [17/29], Loss: 1.1436\n",
      "Epoch [163/300], Step [18/29], Loss: 1.4094\n",
      "Epoch [163/300], Step [19/29], Loss: 0.9671\n",
      "Epoch [163/300], Step [20/29], Loss: 1.3784\n",
      "Epoch [163/300], Step [21/29], Loss: 1.5031\n",
      "Epoch [163/300], Step [22/29], Loss: 1.3593\n",
      "Epoch [163/300], Step [23/29], Loss: 1.3823\n",
      "Epoch [163/300], Step [24/29], Loss: 1.2331\n",
      "Epoch [163/300], Step [25/29], Loss: 1.2860\n",
      "Epoch [163/300], Step [26/29], Loss: 1.3414\n",
      "Epoch [163/300], Step [27/29], Loss: 1.2330\n",
      "Epoch [163/300], Step [28/29], Loss: 1.3003\n",
      "Epoch [163/300], Step [29/29], Loss: 0.8631\n",
      "Epoch [164/300], Step [1/29], Loss: 1.2676\n",
      "Epoch [164/300], Step [2/29], Loss: 1.2925\n",
      "Epoch [164/300], Step [3/29], Loss: 1.3375\n",
      "Epoch [164/300], Step [4/29], Loss: 1.1892\n",
      "Epoch [164/300], Step [5/29], Loss: 1.4149\n",
      "Epoch [164/300], Step [6/29], Loss: 1.1429\n",
      "Epoch [164/300], Step [7/29], Loss: 1.1841\n",
      "Epoch [164/300], Step [8/29], Loss: 1.4890\n",
      "Epoch [164/300], Step [9/29], Loss: 0.9393\n",
      "Epoch [164/300], Step [10/29], Loss: 1.5115\n",
      "Epoch [164/300], Step [11/29], Loss: 1.4517\n",
      "Epoch [164/300], Step [12/29], Loss: 1.2737\n",
      "Epoch [164/300], Step [13/29], Loss: 1.4762\n",
      "Epoch [164/300], Step [14/29], Loss: 1.0416\n",
      "Epoch [164/300], Step [15/29], Loss: 1.1359\n",
      "Epoch [164/300], Step [16/29], Loss: 1.3635\n",
      "Epoch [164/300], Step [17/29], Loss: 1.1374\n",
      "Epoch [164/300], Step [18/29], Loss: 1.0540\n",
      "Epoch [164/300], Step [19/29], Loss: 1.4383\n",
      "Epoch [164/300], Step [20/29], Loss: 1.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/300], Step [21/29], Loss: 1.2197\n",
      "Epoch [164/300], Step [22/29], Loss: 1.4555\n",
      "Epoch [164/300], Step [23/29], Loss: 1.2479\n",
      "Epoch [164/300], Step [24/29], Loss: 1.6210\n",
      "Epoch [164/300], Step [25/29], Loss: 1.3298\n",
      "Epoch [164/300], Step [26/29], Loss: 1.1419\n",
      "Epoch [164/300], Step [27/29], Loss: 1.4549\n",
      "Epoch [164/300], Step [28/29], Loss: 1.4239\n",
      "Epoch [164/300], Step [29/29], Loss: 2.7258\n",
      "Epoch [165/300], Step [1/29], Loss: 1.3113\n",
      "Epoch [165/300], Step [2/29], Loss: 1.4561\n",
      "Epoch [165/300], Step [3/29], Loss: 1.2808\n",
      "Epoch [165/300], Step [4/29], Loss: 1.2749\n",
      "Epoch [165/300], Step [5/29], Loss: 1.1754\n",
      "Epoch [165/300], Step [6/29], Loss: 1.3914\n",
      "Epoch [165/300], Step [7/29], Loss: 1.4894\n",
      "Epoch [165/300], Step [8/29], Loss: 1.1511\n",
      "Epoch [165/300], Step [9/29], Loss: 1.3337\n",
      "Epoch [165/300], Step [10/29], Loss: 1.3467\n",
      "Epoch [165/300], Step [11/29], Loss: 1.0770\n",
      "Epoch [165/300], Step [12/29], Loss: 1.1240\n",
      "Epoch [165/300], Step [13/29], Loss: 1.2258\n",
      "Epoch [165/300], Step [14/29], Loss: 1.1322\n",
      "Epoch [165/300], Step [15/29], Loss: 1.2983\n",
      "Epoch [165/300], Step [16/29], Loss: 1.4073\n",
      "Epoch [165/300], Step [17/29], Loss: 1.4585\n",
      "Epoch [165/300], Step [18/29], Loss: 1.1995\n",
      "Epoch [165/300], Step [19/29], Loss: 1.2737\n",
      "Epoch [165/300], Step [20/29], Loss: 1.1817\n",
      "Epoch [165/300], Step [21/29], Loss: 1.0667\n",
      "Epoch [165/300], Step [22/29], Loss: 1.4421\n",
      "Epoch [165/300], Step [23/29], Loss: 1.3777\n",
      "Epoch [165/300], Step [24/29], Loss: 1.1211\n",
      "Epoch [165/300], Step [25/29], Loss: 1.2104\n",
      "Epoch [165/300], Step [26/29], Loss: 1.3201\n",
      "Epoch [165/300], Step [27/29], Loss: 1.6217\n",
      "Epoch [165/300], Step [28/29], Loss: 1.3112\n",
      "Epoch [165/300], Step [29/29], Loss: 2.1229\n",
      "Epoch [166/300], Step [1/29], Loss: 1.1714\n",
      "Epoch [166/300], Step [2/29], Loss: 1.2246\n",
      "Epoch [166/300], Step [3/29], Loss: 1.2582\n",
      "Epoch [166/300], Step [4/29], Loss: 1.4936\n",
      "Epoch [166/300], Step [5/29], Loss: 1.5949\n",
      "Epoch [166/300], Step [6/29], Loss: 1.2925\n",
      "Epoch [166/300], Step [7/29], Loss: 1.1130\n",
      "Epoch [166/300], Step [8/29], Loss: 1.1187\n",
      "Epoch [166/300], Step [9/29], Loss: 1.1614\n",
      "Epoch [166/300], Step [10/29], Loss: 1.1496\n",
      "Epoch [166/300], Step [11/29], Loss: 1.5547\n",
      "Epoch [166/300], Step [12/29], Loss: 1.3909\n",
      "Epoch [166/300], Step [13/29], Loss: 1.3577\n",
      "Epoch [166/300], Step [14/29], Loss: 1.1972\n",
      "Epoch [166/300], Step [15/29], Loss: 1.1300\n",
      "Epoch [166/300], Step [16/29], Loss: 1.1492\n",
      "Epoch [166/300], Step [17/29], Loss: 1.5349\n",
      "Epoch [166/300], Step [18/29], Loss: 1.5953\n",
      "Epoch [166/300], Step [19/29], Loss: 1.3875\n",
      "Epoch [166/300], Step [20/29], Loss: 1.2564\n",
      "Epoch [166/300], Step [21/29], Loss: 1.2475\n",
      "Epoch [166/300], Step [22/29], Loss: 1.0989\n",
      "Epoch [166/300], Step [23/29], Loss: 1.2899\n",
      "Epoch [166/300], Step [24/29], Loss: 1.4928\n",
      "Epoch [166/300], Step [25/29], Loss: 1.2510\n",
      "Epoch [166/300], Step [26/29], Loss: 1.3429\n",
      "Epoch [166/300], Step [27/29], Loss: 1.3075\n",
      "Epoch [166/300], Step [28/29], Loss: 1.1714\n",
      "Epoch [166/300], Step [29/29], Loss: 2.3171\n",
      "Epoch [167/300], Step [1/29], Loss: 1.3185\n",
      "Epoch [167/300], Step [2/29], Loss: 1.5818\n",
      "Epoch [167/300], Step [3/29], Loss: 1.1385\n",
      "Epoch [167/300], Step [4/29], Loss: 1.2589\n",
      "Epoch [167/300], Step [5/29], Loss: 1.4030\n",
      "Epoch [167/300], Step [6/29], Loss: 1.4323\n",
      "Epoch [167/300], Step [7/29], Loss: 1.2667\n",
      "Epoch [167/300], Step [8/29], Loss: 1.1220\n",
      "Epoch [167/300], Step [9/29], Loss: 1.3928\n",
      "Epoch [167/300], Step [10/29], Loss: 1.3307\n",
      "Epoch [167/300], Step [11/29], Loss: 1.2619\n",
      "Epoch [167/300], Step [12/29], Loss: 1.0614\n",
      "Epoch [167/300], Step [13/29], Loss: 1.3419\n",
      "Epoch [167/300], Step [14/29], Loss: 1.4060\n",
      "Epoch [167/300], Step [15/29], Loss: 1.1241\n",
      "Epoch [167/300], Step [16/29], Loss: 1.2853\n",
      "Epoch [167/300], Step [17/29], Loss: 1.2713\n",
      "Epoch [167/300], Step [18/29], Loss: 1.3556\n",
      "Epoch [167/300], Step [19/29], Loss: 1.2012\n",
      "Epoch [167/300], Step [20/29], Loss: 1.0397\n",
      "Epoch [167/300], Step [21/29], Loss: 1.3272\n",
      "Epoch [167/300], Step [22/29], Loss: 1.2263\n",
      "Epoch [167/300], Step [23/29], Loss: 1.5505\n",
      "Epoch [167/300], Step [24/29], Loss: 1.3276\n",
      "Epoch [167/300], Step [25/29], Loss: 1.4668\n",
      "Epoch [167/300], Step [26/29], Loss: 1.2833\n",
      "Epoch [167/300], Step [27/29], Loss: 1.3008\n",
      "Epoch [167/300], Step [28/29], Loss: 1.2871\n",
      "Epoch [167/300], Step [29/29], Loss: 1.7970\n",
      "Epoch [168/300], Step [1/29], Loss: 1.2437\n",
      "Epoch [168/300], Step [2/29], Loss: 1.3320\n",
      "Epoch [168/300], Step [3/29], Loss: 1.3204\n",
      "Epoch [168/300], Step [4/29], Loss: 1.4513\n",
      "Epoch [168/300], Step [5/29], Loss: 1.1217\n",
      "Epoch [168/300], Step [6/29], Loss: 1.3151\n",
      "Epoch [168/300], Step [7/29], Loss: 1.4197\n",
      "Epoch [168/300], Step [8/29], Loss: 1.2127\n",
      "Epoch [168/300], Step [9/29], Loss: 1.1596\n",
      "Epoch [168/300], Step [10/29], Loss: 1.4835\n",
      "Epoch [168/300], Step [11/29], Loss: 1.2497\n",
      "Epoch [168/300], Step [12/29], Loss: 1.2908\n",
      "Epoch [168/300], Step [13/29], Loss: 1.3291\n",
      "Epoch [168/300], Step [14/29], Loss: 1.5509\n",
      "Epoch [168/300], Step [15/29], Loss: 1.3886\n",
      "Epoch [168/300], Step [16/29], Loss: 1.3561\n",
      "Epoch [168/300], Step [17/29], Loss: 1.3686\n",
      "Epoch [168/300], Step [18/29], Loss: 0.9989\n",
      "Epoch [168/300], Step [19/29], Loss: 1.4905\n",
      "Epoch [168/300], Step [20/29], Loss: 1.1398\n",
      "Epoch [168/300], Step [21/29], Loss: 1.3042\n",
      "Epoch [168/300], Step [22/29], Loss: 1.2619\n",
      "Epoch [168/300], Step [23/29], Loss: 1.1342\n",
      "Epoch [168/300], Step [24/29], Loss: 1.3944\n",
      "Epoch [168/300], Step [25/29], Loss: 1.2327\n",
      "Epoch [168/300], Step [26/29], Loss: 1.2665\n",
      "Epoch [168/300], Step [27/29], Loss: 1.2274\n",
      "Epoch [168/300], Step [28/29], Loss: 1.3994\n",
      "Epoch [168/300], Step [29/29], Loss: 2.0253\n",
      "Epoch [169/300], Step [1/29], Loss: 1.1758\n",
      "Epoch [169/300], Step [2/29], Loss: 1.0329\n",
      "Epoch [169/300], Step [3/29], Loss: 1.2579\n",
      "Epoch [169/300], Step [4/29], Loss: 1.4909\n",
      "Epoch [169/300], Step [5/29], Loss: 1.4424\n",
      "Epoch [169/300], Step [6/29], Loss: 1.2370\n",
      "Epoch [169/300], Step [7/29], Loss: 1.3586\n",
      "Epoch [169/300], Step [8/29], Loss: 1.4492\n",
      "Epoch [169/300], Step [9/29], Loss: 1.2274\n",
      "Epoch [169/300], Step [10/29], Loss: 1.2885\n",
      "Epoch [169/300], Step [11/29], Loss: 1.4955\n",
      "Epoch [169/300], Step [12/29], Loss: 1.1907\n",
      "Epoch [169/300], Step [13/29], Loss: 1.6303\n",
      "Epoch [169/300], Step [14/29], Loss: 1.2384\n",
      "Epoch [169/300], Step [15/29], Loss: 1.3383\n",
      "Epoch [169/300], Step [16/29], Loss: 1.3154\n",
      "Epoch [169/300], Step [17/29], Loss: 1.1648\n",
      "Epoch [169/300], Step [18/29], Loss: 1.4381\n",
      "Epoch [169/300], Step [19/29], Loss: 1.2167\n",
      "Epoch [169/300], Step [20/29], Loss: 1.1568\n",
      "Epoch [169/300], Step [21/29], Loss: 1.3833\n",
      "Epoch [169/300], Step [22/29], Loss: 1.2039\n",
      "Epoch [169/300], Step [23/29], Loss: 1.3280\n",
      "Epoch [169/300], Step [24/29], Loss: 1.4537\n",
      "Epoch [169/300], Step [25/29], Loss: 1.2708\n",
      "Epoch [169/300], Step [26/29], Loss: 1.2950\n",
      "Epoch [169/300], Step [27/29], Loss: 1.3692\n",
      "Epoch [169/300], Step [28/29], Loss: 1.3370\n",
      "Epoch [169/300], Step [29/29], Loss: 1.2788\n",
      "Epoch [170/300], Step [1/29], Loss: 1.2869\n",
      "Epoch [170/300], Step [2/29], Loss: 1.1450\n",
      "Epoch [170/300], Step [3/29], Loss: 1.5300\n",
      "Epoch [170/300], Step [4/29], Loss: 1.1931\n",
      "Epoch [170/300], Step [5/29], Loss: 1.2994\n",
      "Epoch [170/300], Step [6/29], Loss: 1.2118\n",
      "Epoch [170/300], Step [7/29], Loss: 1.2096\n",
      "Epoch [170/300], Step [8/29], Loss: 1.2195\n",
      "Epoch [170/300], Step [9/29], Loss: 1.1523\n",
      "Epoch [170/300], Step [10/29], Loss: 1.2568\n",
      "Epoch [170/300], Step [11/29], Loss: 1.3465\n",
      "Epoch [170/300], Step [12/29], Loss: 1.2236\n",
      "Epoch [170/300], Step [13/29], Loss: 1.2533\n",
      "Epoch [170/300], Step [14/29], Loss: 1.3905\n",
      "Epoch [170/300], Step [15/29], Loss: 1.4152\n",
      "Epoch [170/300], Step [16/29], Loss: 1.5864\n",
      "Epoch [170/300], Step [17/29], Loss: 1.2716\n",
      "Epoch [170/300], Step [18/29], Loss: 1.2476\n",
      "Epoch [170/300], Step [19/29], Loss: 1.2547\n",
      "Epoch [170/300], Step [20/29], Loss: 1.3186\n",
      "Epoch [170/300], Step [21/29], Loss: 1.5586\n",
      "Epoch [170/300], Step [22/29], Loss: 1.2715\n",
      "Epoch [170/300], Step [23/29], Loss: 1.1397\n",
      "Epoch [170/300], Step [24/29], Loss: 1.3263\n",
      "Epoch [170/300], Step [25/29], Loss: 1.3921\n",
      "Epoch [170/300], Step [26/29], Loss: 1.2808\n",
      "Epoch [170/300], Step [27/29], Loss: 1.2716\n",
      "Epoch [170/300], Step [28/29], Loss: 1.3447\n",
      "Epoch [170/300], Step [29/29], Loss: 1.4661\n",
      "Epoch [171/300], Step [1/29], Loss: 1.3512\n",
      "Epoch [171/300], Step [2/29], Loss: 1.3439\n",
      "Epoch [171/300], Step [3/29], Loss: 1.2735\n",
      "Epoch [171/300], Step [4/29], Loss: 0.8408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/300], Step [5/29], Loss: 1.7070\n",
      "Epoch [171/300], Step [6/29], Loss: 1.2560\n",
      "Epoch [171/300], Step [7/29], Loss: 1.5474\n",
      "Epoch [171/300], Step [8/29], Loss: 1.2822\n",
      "Epoch [171/300], Step [9/29], Loss: 1.0387\n",
      "Epoch [171/300], Step [10/29], Loss: 1.2829\n",
      "Epoch [171/300], Step [11/29], Loss: 1.0492\n",
      "Epoch [171/300], Step [12/29], Loss: 1.1062\n",
      "Epoch [171/300], Step [13/29], Loss: 1.0094\n",
      "Epoch [171/300], Step [14/29], Loss: 1.3356\n",
      "Epoch [171/300], Step [15/29], Loss: 1.7678\n",
      "Epoch [171/300], Step [16/29], Loss: 1.3290\n",
      "Epoch [171/300], Step [17/29], Loss: 1.1658\n",
      "Epoch [171/300], Step [18/29], Loss: 1.5704\n",
      "Epoch [171/300], Step [19/29], Loss: 1.4406\n",
      "Epoch [171/300], Step [20/29], Loss: 1.3215\n",
      "Epoch [171/300], Step [21/29], Loss: 0.9816\n",
      "Epoch [171/300], Step [22/29], Loss: 1.4609\n",
      "Epoch [171/300], Step [23/29], Loss: 1.4188\n",
      "Epoch [171/300], Step [24/29], Loss: 1.2196\n",
      "Epoch [171/300], Step [25/29], Loss: 1.3315\n",
      "Epoch [171/300], Step [26/29], Loss: 1.1831\n",
      "Epoch [171/300], Step [27/29], Loss: 1.3231\n",
      "Epoch [171/300], Step [28/29], Loss: 1.0617\n",
      "Epoch [171/300], Step [29/29], Loss: 1.2440\n",
      "Epoch [172/300], Step [1/29], Loss: 1.1074\n",
      "Epoch [172/300], Step [2/29], Loss: 1.2113\n",
      "Epoch [172/300], Step [3/29], Loss: 1.4799\n",
      "Epoch [172/300], Step [4/29], Loss: 1.1258\n",
      "Epoch [172/300], Step [5/29], Loss: 1.2562\n",
      "Epoch [172/300], Step [6/29], Loss: 1.1941\n",
      "Epoch [172/300], Step [7/29], Loss: 1.4244\n",
      "Epoch [172/300], Step [8/29], Loss: 1.6291\n",
      "Epoch [172/300], Step [9/29], Loss: 1.6009\n",
      "Epoch [172/300], Step [10/29], Loss: 1.4544\n",
      "Epoch [172/300], Step [11/29], Loss: 1.2102\n",
      "Epoch [172/300], Step [12/29], Loss: 1.0437\n",
      "Epoch [172/300], Step [13/29], Loss: 1.1320\n",
      "Epoch [172/300], Step [14/29], Loss: 1.1661\n",
      "Epoch [172/300], Step [15/29], Loss: 1.2462\n",
      "Epoch [172/300], Step [16/29], Loss: 1.2578\n",
      "Epoch [172/300], Step [17/29], Loss: 1.2209\n",
      "Epoch [172/300], Step [18/29], Loss: 1.1682\n",
      "Epoch [172/300], Step [19/29], Loss: 1.2004\n",
      "Epoch [172/300], Step [20/29], Loss: 1.4210\n",
      "Epoch [172/300], Step [21/29], Loss: 1.2547\n",
      "Epoch [172/300], Step [22/29], Loss: 1.3870\n",
      "Epoch [172/300], Step [23/29], Loss: 1.3217\n",
      "Epoch [172/300], Step [24/29], Loss: 1.2445\n",
      "Epoch [172/300], Step [25/29], Loss: 1.1911\n",
      "Epoch [172/300], Step [26/29], Loss: 1.2201\n",
      "Epoch [172/300], Step [27/29], Loss: 1.4990\n",
      "Epoch [172/300], Step [28/29], Loss: 1.3168\n",
      "Epoch [172/300], Step [29/29], Loss: 2.8085\n",
      "Epoch [173/300], Step [1/29], Loss: 1.1864\n",
      "Epoch [173/300], Step [2/29], Loss: 1.3952\n",
      "Epoch [173/300], Step [3/29], Loss: 1.0447\n",
      "Epoch [173/300], Step [4/29], Loss: 1.1622\n",
      "Epoch [173/300], Step [5/29], Loss: 1.3951\n",
      "Epoch [173/300], Step [6/29], Loss: 1.2879\n",
      "Epoch [173/300], Step [7/29], Loss: 1.3451\n",
      "Epoch [173/300], Step [8/29], Loss: 1.3626\n",
      "Epoch [173/300], Step [9/29], Loss: 1.1955\n",
      "Epoch [173/300], Step [10/29], Loss: 1.3053\n",
      "Epoch [173/300], Step [11/29], Loss: 1.0927\n",
      "Epoch [173/300], Step [12/29], Loss: 1.3010\n",
      "Epoch [173/300], Step [13/29], Loss: 1.2137\n",
      "Epoch [173/300], Step [14/29], Loss: 1.2721\n",
      "Epoch [173/300], Step [15/29], Loss: 1.1515\n",
      "Epoch [173/300], Step [16/29], Loss: 1.2970\n",
      "Epoch [173/300], Step [17/29], Loss: 1.6045\n",
      "Epoch [173/300], Step [18/29], Loss: 1.0592\n",
      "Epoch [173/300], Step [19/29], Loss: 1.5099\n",
      "Epoch [173/300], Step [20/29], Loss: 1.0071\n",
      "Epoch [173/300], Step [21/29], Loss: 1.4101\n",
      "Epoch [173/300], Step [22/29], Loss: 1.3767\n",
      "Epoch [173/300], Step [23/29], Loss: 1.3887\n",
      "Epoch [173/300], Step [24/29], Loss: 1.1950\n",
      "Epoch [173/300], Step [25/29], Loss: 1.4273\n",
      "Epoch [173/300], Step [26/29], Loss: 1.2696\n",
      "Epoch [173/300], Step [27/29], Loss: 1.3486\n",
      "Epoch [173/300], Step [28/29], Loss: 1.2651\n",
      "Epoch [173/300], Step [29/29], Loss: 1.2547\n",
      "Epoch [174/300], Step [1/29], Loss: 1.4488\n",
      "Epoch [174/300], Step [2/29], Loss: 1.0547\n",
      "Epoch [174/300], Step [3/29], Loss: 1.1526\n",
      "Epoch [174/300], Step [4/29], Loss: 1.1771\n",
      "Epoch [174/300], Step [5/29], Loss: 1.3213\n",
      "Epoch [174/300], Step [6/29], Loss: 1.2498\n",
      "Epoch [174/300], Step [7/29], Loss: 1.4460\n",
      "Epoch [174/300], Step [8/29], Loss: 1.0015\n",
      "Epoch [174/300], Step [9/29], Loss: 1.2745\n",
      "Epoch [174/300], Step [10/29], Loss: 1.2818\n",
      "Epoch [174/300], Step [11/29], Loss: 1.0932\n",
      "Epoch [174/300], Step [12/29], Loss: 1.1842\n",
      "Epoch [174/300], Step [13/29], Loss: 1.3683\n",
      "Epoch [174/300], Step [14/29], Loss: 1.3689\n",
      "Epoch [174/300], Step [15/29], Loss: 1.2060\n",
      "Epoch [174/300], Step [16/29], Loss: 1.2711\n",
      "Epoch [174/300], Step [17/29], Loss: 1.0552\n",
      "Epoch [174/300], Step [18/29], Loss: 1.4280\n",
      "Epoch [174/300], Step [19/29], Loss: 1.5118\n",
      "Epoch [174/300], Step [20/29], Loss: 1.1735\n",
      "Epoch [174/300], Step [21/29], Loss: 1.4645\n",
      "Epoch [174/300], Step [22/29], Loss: 1.3001\n",
      "Epoch [174/300], Step [23/29], Loss: 1.2479\n",
      "Epoch [174/300], Step [24/29], Loss: 1.5373\n",
      "Epoch [174/300], Step [25/29], Loss: 1.4786\n",
      "Epoch [174/300], Step [26/29], Loss: 1.4400\n",
      "Epoch [174/300], Step [27/29], Loss: 1.5894\n",
      "Epoch [174/300], Step [28/29], Loss: 1.3932\n",
      "Epoch [174/300], Step [29/29], Loss: 2.4384\n",
      "Epoch [175/300], Step [1/29], Loss: 1.1254\n",
      "Epoch [175/300], Step [2/29], Loss: 1.1449\n",
      "Epoch [175/300], Step [3/29], Loss: 1.1561\n",
      "Epoch [175/300], Step [4/29], Loss: 1.4712\n",
      "Epoch [175/300], Step [5/29], Loss: 1.0962\n",
      "Epoch [175/300], Step [6/29], Loss: 1.4119\n",
      "Epoch [175/300], Step [7/29], Loss: 1.5156\n",
      "Epoch [175/300], Step [8/29], Loss: 1.1217\n",
      "Epoch [175/300], Step [9/29], Loss: 1.3383\n",
      "Epoch [175/300], Step [10/29], Loss: 1.3675\n",
      "Epoch [175/300], Step [11/29], Loss: 1.3468\n",
      "Epoch [175/300], Step [12/29], Loss: 1.1699\n",
      "Epoch [175/300], Step [13/29], Loss: 1.4426\n",
      "Epoch [175/300], Step [14/29], Loss: 1.3017\n",
      "Epoch [175/300], Step [15/29], Loss: 1.5062\n",
      "Epoch [175/300], Step [16/29], Loss: 1.2136\n",
      "Epoch [175/300], Step [17/29], Loss: 1.2534\n",
      "Epoch [175/300], Step [18/29], Loss: 1.3378\n",
      "Epoch [175/300], Step [19/29], Loss: 1.3010\n",
      "Epoch [175/300], Step [20/29], Loss: 1.0518\n",
      "Epoch [175/300], Step [21/29], Loss: 1.2188\n",
      "Epoch [175/300], Step [22/29], Loss: 1.4814\n",
      "Epoch [175/300], Step [23/29], Loss: 0.9801\n",
      "Epoch [175/300], Step [24/29], Loss: 1.3612\n",
      "Epoch [175/300], Step [25/29], Loss: 1.4274\n",
      "Epoch [175/300], Step [26/29], Loss: 1.3712\n",
      "Epoch [175/300], Step [27/29], Loss: 1.3318\n",
      "Epoch [175/300], Step [28/29], Loss: 1.3064\n",
      "Epoch [175/300], Step [29/29], Loss: 2.0359\n",
      "Epoch [176/300], Step [1/29], Loss: 1.2227\n",
      "Epoch [176/300], Step [2/29], Loss: 1.0256\n",
      "Epoch [176/300], Step [3/29], Loss: 1.3772\n",
      "Epoch [176/300], Step [4/29], Loss: 1.1517\n",
      "Epoch [176/300], Step [5/29], Loss: 1.3112\n",
      "Epoch [176/300], Step [6/29], Loss: 1.4727\n",
      "Epoch [176/300], Step [7/29], Loss: 1.2817\n",
      "Epoch [176/300], Step [8/29], Loss: 1.4253\n",
      "Epoch [176/300], Step [9/29], Loss: 1.2237\n",
      "Epoch [176/300], Step [10/29], Loss: 1.3696\n",
      "Epoch [176/300], Step [11/29], Loss: 1.5321\n",
      "Epoch [176/300], Step [12/29], Loss: 1.4776\n",
      "Epoch [176/300], Step [13/29], Loss: 1.1905\n",
      "Epoch [176/300], Step [14/29], Loss: 1.2744\n",
      "Epoch [176/300], Step [15/29], Loss: 1.4663\n",
      "Epoch [176/300], Step [16/29], Loss: 1.3542\n",
      "Epoch [176/300], Step [17/29], Loss: 1.4076\n",
      "Epoch [176/300], Step [18/29], Loss: 1.3297\n",
      "Epoch [176/300], Step [19/29], Loss: 1.3291\n",
      "Epoch [176/300], Step [20/29], Loss: 1.3386\n",
      "Epoch [176/300], Step [21/29], Loss: 1.3416\n",
      "Epoch [176/300], Step [22/29], Loss: 1.4978\n",
      "Epoch [176/300], Step [23/29], Loss: 1.0711\n",
      "Epoch [176/300], Step [24/29], Loss: 1.1654\n",
      "Epoch [176/300], Step [25/29], Loss: 1.2566\n",
      "Epoch [176/300], Step [26/29], Loss: 1.0763\n",
      "Epoch [176/300], Step [27/29], Loss: 1.5968\n",
      "Epoch [176/300], Step [28/29], Loss: 1.1431\n",
      "Epoch [176/300], Step [29/29], Loss: 0.7000\n",
      "Epoch [177/300], Step [1/29], Loss: 1.1497\n",
      "Epoch [177/300], Step [2/29], Loss: 1.1352\n",
      "Epoch [177/300], Step [3/29], Loss: 1.2787\n",
      "Epoch [177/300], Step [4/29], Loss: 1.2552\n",
      "Epoch [177/300], Step [5/29], Loss: 1.3198\n",
      "Epoch [177/300], Step [6/29], Loss: 1.1658\n",
      "Epoch [177/300], Step [7/29], Loss: 1.0676\n",
      "Epoch [177/300], Step [8/29], Loss: 1.1346\n",
      "Epoch [177/300], Step [9/29], Loss: 1.4606\n",
      "Epoch [177/300], Step [10/29], Loss: 1.4969\n",
      "Epoch [177/300], Step [11/29], Loss: 1.0682\n",
      "Epoch [177/300], Step [12/29], Loss: 1.2735\n",
      "Epoch [177/300], Step [13/29], Loss: 1.4481\n",
      "Epoch [177/300], Step [14/29], Loss: 1.1871\n",
      "Epoch [177/300], Step [15/29], Loss: 1.3642\n",
      "Epoch [177/300], Step [16/29], Loss: 1.3991\n",
      "Epoch [177/300], Step [17/29], Loss: 1.3749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/300], Step [18/29], Loss: 1.4378\n",
      "Epoch [177/300], Step [19/29], Loss: 1.2538\n",
      "Epoch [177/300], Step [20/29], Loss: 1.3071\n",
      "Epoch [177/300], Step [21/29], Loss: 1.3636\n",
      "Epoch [177/300], Step [22/29], Loss: 1.2051\n",
      "Epoch [177/300], Step [23/29], Loss: 1.4388\n",
      "Epoch [177/300], Step [24/29], Loss: 1.4544\n",
      "Epoch [177/300], Step [25/29], Loss: 1.3843\n",
      "Epoch [177/300], Step [26/29], Loss: 1.5509\n",
      "Epoch [177/300], Step [27/29], Loss: 1.2616\n",
      "Epoch [177/300], Step [28/29], Loss: 1.1391\n",
      "Epoch [177/300], Step [29/29], Loss: 0.6180\n",
      "Epoch [178/300], Step [1/29], Loss: 1.4244\n",
      "Epoch [178/300], Step [2/29], Loss: 1.0946\n",
      "Epoch [178/300], Step [3/29], Loss: 1.3696\n",
      "Epoch [178/300], Step [4/29], Loss: 1.3318\n",
      "Epoch [178/300], Step [5/29], Loss: 1.1841\n",
      "Epoch [178/300], Step [6/29], Loss: 1.2664\n",
      "Epoch [178/300], Step [7/29], Loss: 1.3554\n",
      "Epoch [178/300], Step [8/29], Loss: 1.3421\n",
      "Epoch [178/300], Step [9/29], Loss: 1.4264\n",
      "Epoch [178/300], Step [10/29], Loss: 1.2871\n",
      "Epoch [178/300], Step [11/29], Loss: 1.2237\n",
      "Epoch [178/300], Step [12/29], Loss: 1.1543\n",
      "Epoch [178/300], Step [13/29], Loss: 1.1354\n",
      "Epoch [178/300], Step [14/29], Loss: 1.6576\n",
      "Epoch [178/300], Step [15/29], Loss: 1.6208\n",
      "Epoch [178/300], Step [16/29], Loss: 1.6017\n",
      "Epoch [178/300], Step [17/29], Loss: 1.2885\n",
      "Epoch [178/300], Step [18/29], Loss: 1.3438\n",
      "Epoch [178/300], Step [19/29], Loss: 1.2544\n",
      "Epoch [178/300], Step [20/29], Loss: 1.4997\n",
      "Epoch [178/300], Step [21/29], Loss: 1.0182\n",
      "Epoch [178/300], Step [22/29], Loss: 1.3219\n",
      "Epoch [178/300], Step [23/29], Loss: 1.2903\n",
      "Epoch [178/300], Step [24/29], Loss: 1.1684\n",
      "Epoch [178/300], Step [25/29], Loss: 1.2655\n",
      "Epoch [178/300], Step [26/29], Loss: 1.1794\n",
      "Epoch [178/300], Step [27/29], Loss: 0.9194\n",
      "Epoch [178/300], Step [28/29], Loss: 1.4080\n",
      "Epoch [178/300], Step [29/29], Loss: 0.8562\n",
      "Epoch [179/300], Step [1/29], Loss: 1.2764\n",
      "Epoch [179/300], Step [2/29], Loss: 1.4032\n",
      "Epoch [179/300], Step [3/29], Loss: 1.2570\n",
      "Epoch [179/300], Step [4/29], Loss: 1.4567\n",
      "Epoch [179/300], Step [5/29], Loss: 1.2976\n",
      "Epoch [179/300], Step [6/29], Loss: 1.2598\n",
      "Epoch [179/300], Step [7/29], Loss: 1.1804\n",
      "Epoch [179/300], Step [8/29], Loss: 1.2600\n",
      "Epoch [179/300], Step [9/29], Loss: 1.4256\n",
      "Epoch [179/300], Step [10/29], Loss: 1.4508\n",
      "Epoch [179/300], Step [11/29], Loss: 1.4104\n",
      "Epoch [179/300], Step [12/29], Loss: 1.2789\n",
      "Epoch [179/300], Step [13/29], Loss: 1.4763\n",
      "Epoch [179/300], Step [14/29], Loss: 1.1766\n",
      "Epoch [179/300], Step [15/29], Loss: 1.2793\n",
      "Epoch [179/300], Step [16/29], Loss: 1.2160\n",
      "Epoch [179/300], Step [17/29], Loss: 1.2873\n",
      "Epoch [179/300], Step [18/29], Loss: 1.2857\n",
      "Epoch [179/300], Step [19/29], Loss: 1.1672\n",
      "Epoch [179/300], Step [20/29], Loss: 1.3716\n",
      "Epoch [179/300], Step [21/29], Loss: 1.2071\n",
      "Epoch [179/300], Step [22/29], Loss: 1.5351\n",
      "Epoch [179/300], Step [23/29], Loss: 1.3022\n",
      "Epoch [179/300], Step [24/29], Loss: 1.1944\n",
      "Epoch [179/300], Step [25/29], Loss: 1.3446\n",
      "Epoch [179/300], Step [26/29], Loss: 1.3128\n",
      "Epoch [179/300], Step [27/29], Loss: 0.9925\n",
      "Epoch [179/300], Step [28/29], Loss: 1.4720\n",
      "Epoch [179/300], Step [29/29], Loss: 0.8359\n",
      "Epoch [180/300], Step [1/29], Loss: 1.3793\n",
      "Epoch [180/300], Step [2/29], Loss: 1.1016\n",
      "Epoch [180/300], Step [3/29], Loss: 1.1364\n",
      "Epoch [180/300], Step [4/29], Loss: 1.5799\n",
      "Epoch [180/300], Step [5/29], Loss: 1.2634\n",
      "Epoch [180/300], Step [6/29], Loss: 1.3549\n",
      "Epoch [180/300], Step [7/29], Loss: 1.2931\n",
      "Epoch [180/300], Step [8/29], Loss: 1.1272\n",
      "Epoch [180/300], Step [9/29], Loss: 1.3146\n",
      "Epoch [180/300], Step [10/29], Loss: 1.3748\n",
      "Epoch [180/300], Step [11/29], Loss: 1.2158\n",
      "Epoch [180/300], Step [12/29], Loss: 1.3023\n",
      "Epoch [180/300], Step [13/29], Loss: 1.2131\n",
      "Epoch [180/300], Step [14/29], Loss: 1.0879\n",
      "Epoch [180/300], Step [15/29], Loss: 1.2772\n",
      "Epoch [180/300], Step [16/29], Loss: 1.1205\n",
      "Epoch [180/300], Step [17/29], Loss: 1.3086\n",
      "Epoch [180/300], Step [18/29], Loss: 1.5186\n",
      "Epoch [180/300], Step [19/29], Loss: 0.9322\n",
      "Epoch [180/300], Step [20/29], Loss: 1.3761\n",
      "Epoch [180/300], Step [21/29], Loss: 1.2994\n",
      "Epoch [180/300], Step [22/29], Loss: 0.9884\n",
      "Epoch [180/300], Step [23/29], Loss: 1.4341\n",
      "Epoch [180/300], Step [24/29], Loss: 1.3802\n",
      "Epoch [180/300], Step [25/29], Loss: 1.3873\n",
      "Epoch [180/300], Step [26/29], Loss: 1.5920\n",
      "Epoch [180/300], Step [27/29], Loss: 1.1826\n",
      "Epoch [180/300], Step [28/29], Loss: 1.4704\n",
      "Epoch [180/300], Step [29/29], Loss: 1.3204\n",
      "Epoch [181/300], Step [1/29], Loss: 1.2781\n",
      "Epoch [181/300], Step [2/29], Loss: 1.3051\n",
      "Epoch [181/300], Step [3/29], Loss: 1.0905\n",
      "Epoch [181/300], Step [4/29], Loss: 1.3313\n",
      "Epoch [181/300], Step [5/29], Loss: 1.2934\n",
      "Epoch [181/300], Step [6/29], Loss: 1.5136\n",
      "Epoch [181/300], Step [7/29], Loss: 1.3737\n",
      "Epoch [181/300], Step [8/29], Loss: 1.1197\n",
      "Epoch [181/300], Step [9/29], Loss: 1.1435\n",
      "Epoch [181/300], Step [10/29], Loss: 1.5348\n",
      "Epoch [181/300], Step [11/29], Loss: 1.3089\n",
      "Epoch [181/300], Step [12/29], Loss: 1.2921\n",
      "Epoch [181/300], Step [13/29], Loss: 1.3187\n",
      "Epoch [181/300], Step [14/29], Loss: 1.2519\n",
      "Epoch [181/300], Step [15/29], Loss: 1.4006\n",
      "Epoch [181/300], Step [16/29], Loss: 1.3992\n",
      "Epoch [181/300], Step [17/29], Loss: 1.3338\n",
      "Epoch [181/300], Step [18/29], Loss: 1.0992\n",
      "Epoch [181/300], Step [19/29], Loss: 1.2610\n",
      "Epoch [181/300], Step [20/29], Loss: 1.1910\n",
      "Epoch [181/300], Step [21/29], Loss: 1.1548\n",
      "Epoch [181/300], Step [22/29], Loss: 1.2952\n",
      "Epoch [181/300], Step [23/29], Loss: 1.5318\n",
      "Epoch [181/300], Step [24/29], Loss: 1.1856\n",
      "Epoch [181/300], Step [25/29], Loss: 1.3675\n",
      "Epoch [181/300], Step [26/29], Loss: 1.2755\n",
      "Epoch [181/300], Step [27/29], Loss: 1.5514\n",
      "Epoch [181/300], Step [28/29], Loss: 1.1806\n",
      "Epoch [181/300], Step [29/29], Loss: 2.5206\n",
      "Epoch [182/300], Step [1/29], Loss: 1.3874\n",
      "Epoch [182/300], Step [2/29], Loss: 1.3568\n",
      "Epoch [182/300], Step [3/29], Loss: 1.4447\n",
      "Epoch [182/300], Step [4/29], Loss: 1.2476\n",
      "Epoch [182/300], Step [5/29], Loss: 1.3795\n",
      "Epoch [182/300], Step [6/29], Loss: 1.3936\n",
      "Epoch [182/300], Step [7/29], Loss: 1.2330\n",
      "Epoch [182/300], Step [8/29], Loss: 1.4613\n",
      "Epoch [182/300], Step [9/29], Loss: 1.3130\n",
      "Epoch [182/300], Step [10/29], Loss: 1.7230\n",
      "Epoch [182/300], Step [11/29], Loss: 1.3038\n",
      "Epoch [182/300], Step [12/29], Loss: 0.9902\n",
      "Epoch [182/300], Step [13/29], Loss: 1.0622\n",
      "Epoch [182/300], Step [14/29], Loss: 1.4742\n",
      "Epoch [182/300], Step [15/29], Loss: 1.5353\n",
      "Epoch [182/300], Step [16/29], Loss: 1.2650\n",
      "Epoch [182/300], Step [17/29], Loss: 1.3288\n",
      "Epoch [182/300], Step [18/29], Loss: 0.9162\n",
      "Epoch [182/300], Step [19/29], Loss: 1.3267\n",
      "Epoch [182/300], Step [20/29], Loss: 1.2547\n",
      "Epoch [182/300], Step [21/29], Loss: 1.2663\n",
      "Epoch [182/300], Step [22/29], Loss: 1.4036\n",
      "Epoch [182/300], Step [23/29], Loss: 1.0881\n",
      "Epoch [182/300], Step [24/29], Loss: 1.0655\n",
      "Epoch [182/300], Step [25/29], Loss: 1.2475\n",
      "Epoch [182/300], Step [26/29], Loss: 1.3085\n",
      "Epoch [182/300], Step [27/29], Loss: 1.4425\n",
      "Epoch [182/300], Step [28/29], Loss: 1.2900\n",
      "Epoch [182/300], Step [29/29], Loss: 1.0301\n",
      "Epoch [183/300], Step [1/29], Loss: 1.2862\n",
      "Epoch [183/300], Step [2/29], Loss: 1.3829\n",
      "Epoch [183/300], Step [3/29], Loss: 1.6069\n",
      "Epoch [183/300], Step [4/29], Loss: 1.3072\n",
      "Epoch [183/300], Step [5/29], Loss: 1.3953\n",
      "Epoch [183/300], Step [6/29], Loss: 1.2196\n",
      "Epoch [183/300], Step [7/29], Loss: 1.2110\n",
      "Epoch [183/300], Step [8/29], Loss: 1.5342\n",
      "Epoch [183/300], Step [9/29], Loss: 1.6034\n",
      "Epoch [183/300], Step [10/29], Loss: 1.4382\n",
      "Epoch [183/300], Step [11/29], Loss: 1.2099\n",
      "Epoch [183/300], Step [12/29], Loss: 1.2286\n",
      "Epoch [183/300], Step [13/29], Loss: 1.2974\n",
      "Epoch [183/300], Step [14/29], Loss: 1.2137\n",
      "Epoch [183/300], Step [15/29], Loss: 1.1941\n",
      "Epoch [183/300], Step [16/29], Loss: 1.4901\n",
      "Epoch [183/300], Step [17/29], Loss: 1.0666\n",
      "Epoch [183/300], Step [18/29], Loss: 1.0617\n",
      "Epoch [183/300], Step [19/29], Loss: 1.1955\n",
      "Epoch [183/300], Step [20/29], Loss: 1.5682\n",
      "Epoch [183/300], Step [21/29], Loss: 1.4418\n",
      "Epoch [183/300], Step [22/29], Loss: 1.1493\n",
      "Epoch [183/300], Step [23/29], Loss: 1.1649\n",
      "Epoch [183/300], Step [24/29], Loss: 1.2991\n",
      "Epoch [183/300], Step [25/29], Loss: 1.3470\n",
      "Epoch [183/300], Step [26/29], Loss: 1.4266\n",
      "Epoch [183/300], Step [27/29], Loss: 1.3580\n",
      "Epoch [183/300], Step [28/29], Loss: 1.0826\n",
      "Epoch [183/300], Step [29/29], Loss: 0.5381\n",
      "Epoch [184/300], Step [1/29], Loss: 1.1700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/300], Step [2/29], Loss: 1.3019\n",
      "Epoch [184/300], Step [3/29], Loss: 1.3688\n",
      "Epoch [184/300], Step [4/29], Loss: 1.3335\n",
      "Epoch [184/300], Step [5/29], Loss: 1.2205\n",
      "Epoch [184/300], Step [6/29], Loss: 1.3369\n",
      "Epoch [184/300], Step [7/29], Loss: 1.3893\n",
      "Epoch [184/300], Step [8/29], Loss: 1.0195\n",
      "Epoch [184/300], Step [9/29], Loss: 1.4883\n",
      "Epoch [184/300], Step [10/29], Loss: 1.4747\n",
      "Epoch [184/300], Step [11/29], Loss: 1.1048\n",
      "Epoch [184/300], Step [12/29], Loss: 1.2960\n",
      "Epoch [184/300], Step [13/29], Loss: 1.4561\n",
      "Epoch [184/300], Step [14/29], Loss: 1.3947\n",
      "Epoch [184/300], Step [15/29], Loss: 1.0548\n",
      "Epoch [184/300], Step [16/29], Loss: 1.3063\n",
      "Epoch [184/300], Step [17/29], Loss: 1.5205\n",
      "Epoch [184/300], Step [18/29], Loss: 1.0049\n",
      "Epoch [184/300], Step [19/29], Loss: 1.1370\n",
      "Epoch [184/300], Step [20/29], Loss: 1.3036\n",
      "Epoch [184/300], Step [21/29], Loss: 1.5260\n",
      "Epoch [184/300], Step [22/29], Loss: 1.4115\n",
      "Epoch [184/300], Step [23/29], Loss: 1.4100\n",
      "Epoch [184/300], Step [24/29], Loss: 1.3955\n",
      "Epoch [184/300], Step [25/29], Loss: 1.3076\n",
      "Epoch [184/300], Step [26/29], Loss: 1.1533\n",
      "Epoch [184/300], Step [27/29], Loss: 1.1044\n",
      "Epoch [184/300], Step [28/29], Loss: 1.2927\n",
      "Epoch [184/300], Step [29/29], Loss: 1.4096\n",
      "Epoch [185/300], Step [1/29], Loss: 1.1129\n",
      "Epoch [185/300], Step [2/29], Loss: 1.1711\n",
      "Epoch [185/300], Step [3/29], Loss: 1.0706\n",
      "Epoch [185/300], Step [4/29], Loss: 1.6931\n",
      "Epoch [185/300], Step [5/29], Loss: 1.4318\n",
      "Epoch [185/300], Step [6/29], Loss: 1.2647\n",
      "Epoch [185/300], Step [7/29], Loss: 1.1947\n",
      "Epoch [185/300], Step [8/29], Loss: 1.2864\n",
      "Epoch [185/300], Step [9/29], Loss: 1.0832\n",
      "Epoch [185/300], Step [10/29], Loss: 1.2429\n",
      "Epoch [185/300], Step [11/29], Loss: 1.2507\n",
      "Epoch [185/300], Step [12/29], Loss: 1.0310\n",
      "Epoch [185/300], Step [13/29], Loss: 1.1258\n",
      "Epoch [185/300], Step [14/29], Loss: 1.4338\n",
      "Epoch [185/300], Step [15/29], Loss: 1.2300\n",
      "Epoch [185/300], Step [16/29], Loss: 1.2817\n",
      "Epoch [185/300], Step [17/29], Loss: 1.5861\n",
      "Epoch [185/300], Step [18/29], Loss: 1.3531\n",
      "Epoch [185/300], Step [19/29], Loss: 1.1992\n",
      "Epoch [185/300], Step [20/29], Loss: 1.1872\n",
      "Epoch [185/300], Step [21/29], Loss: 1.0628\n",
      "Epoch [185/300], Step [22/29], Loss: 1.2602\n",
      "Epoch [185/300], Step [23/29], Loss: 1.4209\n",
      "Epoch [185/300], Step [24/29], Loss: 1.5548\n",
      "Epoch [185/300], Step [25/29], Loss: 1.4084\n",
      "Epoch [185/300], Step [26/29], Loss: 1.3702\n",
      "Epoch [185/300], Step [27/29], Loss: 1.2491\n",
      "Epoch [185/300], Step [28/29], Loss: 1.2992\n",
      "Epoch [185/300], Step [29/29], Loss: 1.2327\n",
      "Epoch [186/300], Step [1/29], Loss: 1.4013\n",
      "Epoch [186/300], Step [2/29], Loss: 1.0740\n",
      "Epoch [186/300], Step [3/29], Loss: 1.4740\n",
      "Epoch [186/300], Step [4/29], Loss: 1.3554\n",
      "Epoch [186/300], Step [5/29], Loss: 1.0962\n",
      "Epoch [186/300], Step [6/29], Loss: 1.4300\n",
      "Epoch [186/300], Step [7/29], Loss: 1.0855\n",
      "Epoch [186/300], Step [8/29], Loss: 1.3754\n",
      "Epoch [186/300], Step [9/29], Loss: 1.2551\n",
      "Epoch [186/300], Step [10/29], Loss: 1.1771\n",
      "Epoch [186/300], Step [11/29], Loss: 1.2969\n",
      "Epoch [186/300], Step [12/29], Loss: 1.1507\n",
      "Epoch [186/300], Step [13/29], Loss: 1.0689\n",
      "Epoch [186/300], Step [14/29], Loss: 1.2023\n",
      "Epoch [186/300], Step [15/29], Loss: 1.2559\n",
      "Epoch [186/300], Step [16/29], Loss: 1.5038\n",
      "Epoch [186/300], Step [17/29], Loss: 1.3952\n",
      "Epoch [186/300], Step [18/29], Loss: 1.1856\n",
      "Epoch [186/300], Step [19/29], Loss: 1.5235\n",
      "Epoch [186/300], Step [20/29], Loss: 1.4588\n",
      "Epoch [186/300], Step [21/29], Loss: 1.5700\n",
      "Epoch [186/300], Step [22/29], Loss: 1.3775\n",
      "Epoch [186/300], Step [23/29], Loss: 1.3524\n",
      "Epoch [186/300], Step [24/29], Loss: 1.1348\n",
      "Epoch [186/300], Step [25/29], Loss: 1.2748\n",
      "Epoch [186/300], Step [26/29], Loss: 1.3444\n",
      "Epoch [186/300], Step [27/29], Loss: 1.2782\n",
      "Epoch [186/300], Step [28/29], Loss: 1.1595\n",
      "Epoch [186/300], Step [29/29], Loss: 1.1816\n",
      "Epoch [187/300], Step [1/29], Loss: 1.3367\n",
      "Epoch [187/300], Step [2/29], Loss: 1.1153\n",
      "Epoch [187/300], Step [3/29], Loss: 1.3280\n",
      "Epoch [187/300], Step [4/29], Loss: 1.5961\n",
      "Epoch [187/300], Step [5/29], Loss: 1.1373\n",
      "Epoch [187/300], Step [6/29], Loss: 1.2438\n",
      "Epoch [187/300], Step [7/29], Loss: 1.4991\n",
      "Epoch [187/300], Step [8/29], Loss: 1.2011\n",
      "Epoch [187/300], Step [9/29], Loss: 1.2832\n",
      "Epoch [187/300], Step [10/29], Loss: 1.0748\n",
      "Epoch [187/300], Step [11/29], Loss: 1.2179\n",
      "Epoch [187/300], Step [12/29], Loss: 1.1928\n",
      "Epoch [187/300], Step [13/29], Loss: 1.2082\n",
      "Epoch [187/300], Step [14/29], Loss: 1.0907\n",
      "Epoch [187/300], Step [15/29], Loss: 1.3370\n",
      "Epoch [187/300], Step [16/29], Loss: 1.2797\n",
      "Epoch [187/300], Step [17/29], Loss: 1.5045\n",
      "Epoch [187/300], Step [18/29], Loss: 1.3544\n",
      "Epoch [187/300], Step [19/29], Loss: 1.1980\n",
      "Epoch [187/300], Step [20/29], Loss: 1.2936\n",
      "Epoch [187/300], Step [21/29], Loss: 1.2379\n",
      "Epoch [187/300], Step [22/29], Loss: 1.3474\n",
      "Epoch [187/300], Step [23/29], Loss: 1.2815\n",
      "Epoch [187/300], Step [24/29], Loss: 1.3822\n",
      "Epoch [187/300], Step [25/29], Loss: 1.4726\n",
      "Epoch [187/300], Step [26/29], Loss: 1.0847\n",
      "Epoch [187/300], Step [27/29], Loss: 1.3525\n",
      "Epoch [187/300], Step [28/29], Loss: 1.3761\n",
      "Epoch [187/300], Step [29/29], Loss: 2.6142\n",
      "Epoch [188/300], Step [1/29], Loss: 1.3983\n",
      "Epoch [188/300], Step [2/29], Loss: 1.2744\n",
      "Epoch [188/300], Step [3/29], Loss: 1.1977\n",
      "Epoch [188/300], Step [4/29], Loss: 1.3972\n",
      "Epoch [188/300], Step [5/29], Loss: 1.3682\n",
      "Epoch [188/300], Step [6/29], Loss: 1.3202\n",
      "Epoch [188/300], Step [7/29], Loss: 1.3306\n",
      "Epoch [188/300], Step [8/29], Loss: 1.3497\n",
      "Epoch [188/300], Step [9/29], Loss: 1.1009\n",
      "Epoch [188/300], Step [10/29], Loss: 1.1430\n",
      "Epoch [188/300], Step [11/29], Loss: 1.1535\n",
      "Epoch [188/300], Step [12/29], Loss: 1.1047\n",
      "Epoch [188/300], Step [13/29], Loss: 1.4132\n",
      "Epoch [188/300], Step [14/29], Loss: 1.4506\n",
      "Epoch [188/300], Step [15/29], Loss: 1.3702\n",
      "Epoch [188/300], Step [16/29], Loss: 1.4992\n",
      "Epoch [188/300], Step [17/29], Loss: 1.0434\n",
      "Epoch [188/300], Step [18/29], Loss: 1.4927\n",
      "Epoch [188/300], Step [19/29], Loss: 1.1928\n",
      "Epoch [188/300], Step [20/29], Loss: 1.1528\n",
      "Epoch [188/300], Step [21/29], Loss: 1.5724\n",
      "Epoch [188/300], Step [22/29], Loss: 1.0192\n",
      "Epoch [188/300], Step [23/29], Loss: 1.2427\n",
      "Epoch [188/300], Step [24/29], Loss: 1.4855\n",
      "Epoch [188/300], Step [25/29], Loss: 1.4210\n",
      "Epoch [188/300], Step [26/29], Loss: 1.2998\n",
      "Epoch [188/300], Step [27/29], Loss: 1.4747\n",
      "Epoch [188/300], Step [28/29], Loss: 1.0911\n",
      "Epoch [188/300], Step [29/29], Loss: 2.4161\n",
      "Epoch [189/300], Step [1/29], Loss: 1.2836\n",
      "Epoch [189/300], Step [2/29], Loss: 1.3978\n",
      "Epoch [189/300], Step [3/29], Loss: 1.3576\n",
      "Epoch [189/300], Step [4/29], Loss: 1.2113\n",
      "Epoch [189/300], Step [5/29], Loss: 1.2928\n",
      "Epoch [189/300], Step [6/29], Loss: 1.2616\n",
      "Epoch [189/300], Step [7/29], Loss: 1.2552\n",
      "Epoch [189/300], Step [8/29], Loss: 1.1877\n",
      "Epoch [189/300], Step [9/29], Loss: 1.5275\n",
      "Epoch [189/300], Step [10/29], Loss: 1.2722\n",
      "Epoch [189/300], Step [11/29], Loss: 1.2170\n",
      "Epoch [189/300], Step [12/29], Loss: 1.4256\n",
      "Epoch [189/300], Step [13/29], Loss: 1.1124\n",
      "Epoch [189/300], Step [14/29], Loss: 1.4383\n",
      "Epoch [189/300], Step [15/29], Loss: 1.2777\n",
      "Epoch [189/300], Step [16/29], Loss: 1.3792\n",
      "Epoch [189/300], Step [17/29], Loss: 1.2442\n",
      "Epoch [189/300], Step [18/29], Loss: 1.2567\n",
      "Epoch [189/300], Step [19/29], Loss: 1.3372\n",
      "Epoch [189/300], Step [20/29], Loss: 1.4630\n",
      "Epoch [189/300], Step [21/29], Loss: 1.2354\n",
      "Epoch [189/300], Step [22/29], Loss: 1.2352\n",
      "Epoch [189/300], Step [23/29], Loss: 1.2922\n",
      "Epoch [189/300], Step [24/29], Loss: 1.4346\n",
      "Epoch [189/300], Step [25/29], Loss: 1.1210\n",
      "Epoch [189/300], Step [26/29], Loss: 1.2756\n",
      "Epoch [189/300], Step [27/29], Loss: 1.4371\n",
      "Epoch [189/300], Step [28/29], Loss: 1.0792\n",
      "Epoch [189/300], Step [29/29], Loss: 1.3586\n",
      "Epoch [190/300], Step [1/29], Loss: 1.2947\n",
      "Epoch [190/300], Step [2/29], Loss: 1.3043\n",
      "Epoch [190/300], Step [3/29], Loss: 1.3413\n",
      "Epoch [190/300], Step [4/29], Loss: 1.3904\n",
      "Epoch [190/300], Step [5/29], Loss: 1.2822\n",
      "Epoch [190/300], Step [6/29], Loss: 1.2374\n",
      "Epoch [190/300], Step [7/29], Loss: 1.4986\n",
      "Epoch [190/300], Step [8/29], Loss: 1.3457\n",
      "Epoch [190/300], Step [9/29], Loss: 1.1501\n",
      "Epoch [190/300], Step [10/29], Loss: 1.2919\n",
      "Epoch [190/300], Step [11/29], Loss: 1.3074\n",
      "Epoch [190/300], Step [12/29], Loss: 1.2349\n",
      "Epoch [190/300], Step [13/29], Loss: 1.4238\n",
      "Epoch [190/300], Step [14/29], Loss: 1.3253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/300], Step [15/29], Loss: 1.3232\n",
      "Epoch [190/300], Step [16/29], Loss: 1.1408\n",
      "Epoch [190/300], Step [17/29], Loss: 1.2326\n",
      "Epoch [190/300], Step [18/29], Loss: 1.2176\n",
      "Epoch [190/300], Step [19/29], Loss: 1.3901\n",
      "Epoch [190/300], Step [20/29], Loss: 1.3397\n",
      "Epoch [190/300], Step [21/29], Loss: 1.4177\n",
      "Epoch [190/300], Step [22/29], Loss: 1.2649\n",
      "Epoch [190/300], Step [23/29], Loss: 1.2981\n",
      "Epoch [190/300], Step [24/29], Loss: 1.4624\n",
      "Epoch [190/300], Step [25/29], Loss: 1.3885\n",
      "Epoch [190/300], Step [26/29], Loss: 1.2293\n",
      "Epoch [190/300], Step [27/29], Loss: 1.2114\n",
      "Epoch [190/300], Step [28/29], Loss: 1.2170\n",
      "Epoch [190/300], Step [29/29], Loss: 1.6669\n",
      "Epoch [191/300], Step [1/29], Loss: 1.3368\n",
      "Epoch [191/300], Step [2/29], Loss: 1.1109\n",
      "Epoch [191/300], Step [3/29], Loss: 1.2996\n",
      "Epoch [191/300], Step [4/29], Loss: 1.2241\n",
      "Epoch [191/300], Step [5/29], Loss: 1.5379\n",
      "Epoch [191/300], Step [6/29], Loss: 1.3731\n",
      "Epoch [191/300], Step [7/29], Loss: 1.2538\n",
      "Epoch [191/300], Step [8/29], Loss: 1.2834\n",
      "Epoch [191/300], Step [9/29], Loss: 1.2481\n",
      "Epoch [191/300], Step [10/29], Loss: 1.2288\n",
      "Epoch [191/300], Step [11/29], Loss: 1.3552\n",
      "Epoch [191/300], Step [12/29], Loss: 1.3263\n",
      "Epoch [191/300], Step [13/29], Loss: 1.3990\n",
      "Epoch [191/300], Step [14/29], Loss: 1.4001\n",
      "Epoch [191/300], Step [15/29], Loss: 1.4535\n",
      "Epoch [191/300], Step [16/29], Loss: 1.1607\n",
      "Epoch [191/300], Step [17/29], Loss: 1.0827\n",
      "Epoch [191/300], Step [18/29], Loss: 1.3967\n",
      "Epoch [191/300], Step [19/29], Loss: 1.3963\n",
      "Epoch [191/300], Step [20/29], Loss: 1.3448\n",
      "Epoch [191/300], Step [21/29], Loss: 1.3943\n",
      "Epoch [191/300], Step [22/29], Loss: 1.1927\n",
      "Epoch [191/300], Step [23/29], Loss: 1.2729\n",
      "Epoch [191/300], Step [24/29], Loss: 1.4041\n",
      "Epoch [191/300], Step [25/29], Loss: 1.3669\n",
      "Epoch [191/300], Step [26/29], Loss: 1.3451\n",
      "Epoch [191/300], Step [27/29], Loss: 1.3544\n",
      "Epoch [191/300], Step [28/29], Loss: 1.2627\n",
      "Epoch [191/300], Step [29/29], Loss: 3.2479\n",
      "Epoch [192/300], Step [1/29], Loss: 1.5060\n",
      "Epoch [192/300], Step [2/29], Loss: 1.1545\n",
      "Epoch [192/300], Step [3/29], Loss: 1.2331\n",
      "Epoch [192/300], Step [4/29], Loss: 1.1017\n",
      "Epoch [192/300], Step [5/29], Loss: 1.1554\n",
      "Epoch [192/300], Step [6/29], Loss: 1.4382\n",
      "Epoch [192/300], Step [7/29], Loss: 1.2021\n",
      "Epoch [192/300], Step [8/29], Loss: 1.4678\n",
      "Epoch [192/300], Step [9/29], Loss: 1.5918\n",
      "Epoch [192/300], Step [10/29], Loss: 1.3426\n",
      "Epoch [192/300], Step [11/29], Loss: 1.1111\n",
      "Epoch [192/300], Step [12/29], Loss: 1.2008\n",
      "Epoch [192/300], Step [13/29], Loss: 1.3209\n",
      "Epoch [192/300], Step [14/29], Loss: 1.1233\n",
      "Epoch [192/300], Step [15/29], Loss: 1.3690\n",
      "Epoch [192/300], Step [16/29], Loss: 1.3054\n",
      "Epoch [192/300], Step [17/29], Loss: 1.1008\n",
      "Epoch [192/300], Step [18/29], Loss: 1.5149\n",
      "Epoch [192/300], Step [19/29], Loss: 1.2403\n",
      "Epoch [192/300], Step [20/29], Loss: 1.4193\n",
      "Epoch [192/300], Step [21/29], Loss: 1.1563\n",
      "Epoch [192/300], Step [22/29], Loss: 1.3144\n",
      "Epoch [192/300], Step [23/29], Loss: 1.3970\n",
      "Epoch [192/300], Step [24/29], Loss: 1.1850\n",
      "Epoch [192/300], Step [25/29], Loss: 1.2196\n",
      "Epoch [192/300], Step [26/29], Loss: 1.4282\n",
      "Epoch [192/300], Step [27/29], Loss: 1.4810\n",
      "Epoch [192/300], Step [28/29], Loss: 1.3975\n",
      "Epoch [192/300], Step [29/29], Loss: 0.7675\n",
      "Epoch [193/300], Step [1/29], Loss: 1.2699\n",
      "Epoch [193/300], Step [2/29], Loss: 1.3486\n",
      "Epoch [193/300], Step [3/29], Loss: 1.2134\n",
      "Epoch [193/300], Step [4/29], Loss: 1.5553\n",
      "Epoch [193/300], Step [5/29], Loss: 1.4933\n",
      "Epoch [193/300], Step [6/29], Loss: 1.3805\n",
      "Epoch [193/300], Step [7/29], Loss: 1.2217\n",
      "Epoch [193/300], Step [8/29], Loss: 1.2523\n",
      "Epoch [193/300], Step [9/29], Loss: 1.1492\n",
      "Epoch [193/300], Step [10/29], Loss: 1.1404\n",
      "Epoch [193/300], Step [11/29], Loss: 1.4560\n",
      "Epoch [193/300], Step [12/29], Loss: 1.3855\n",
      "Epoch [193/300], Step [13/29], Loss: 1.5833\n",
      "Epoch [193/300], Step [14/29], Loss: 1.5166\n",
      "Epoch [193/300], Step [15/29], Loss: 1.3104\n",
      "Epoch [193/300], Step [16/29], Loss: 1.1605\n",
      "Epoch [193/300], Step [17/29], Loss: 1.1570\n",
      "Epoch [193/300], Step [18/29], Loss: 1.1951\n",
      "Epoch [193/300], Step [19/29], Loss: 1.2347\n",
      "Epoch [193/300], Step [20/29], Loss: 1.2634\n",
      "Epoch [193/300], Step [21/29], Loss: 1.1279\n",
      "Epoch [193/300], Step [22/29], Loss: 1.1365\n",
      "Epoch [193/300], Step [23/29], Loss: 1.2269\n",
      "Epoch [193/300], Step [24/29], Loss: 1.3805\n",
      "Epoch [193/300], Step [25/29], Loss: 1.4520\n",
      "Epoch [193/300], Step [26/29], Loss: 1.0685\n",
      "Epoch [193/300], Step [27/29], Loss: 1.3565\n",
      "Epoch [193/300], Step [28/29], Loss: 1.0675\n",
      "Epoch [193/300], Step [29/29], Loss: 1.8589\n",
      "Epoch [194/300], Step [1/29], Loss: 1.2246\n",
      "Epoch [194/300], Step [2/29], Loss: 1.2968\n",
      "Epoch [194/300], Step [3/29], Loss: 1.1853\n",
      "Epoch [194/300], Step [4/29], Loss: 1.3554\n",
      "Epoch [194/300], Step [5/29], Loss: 1.4014\n",
      "Epoch [194/300], Step [6/29], Loss: 1.6002\n",
      "Epoch [194/300], Step [7/29], Loss: 1.4140\n",
      "Epoch [194/300], Step [8/29], Loss: 1.3773\n",
      "Epoch [194/300], Step [9/29], Loss: 1.2483\n",
      "Epoch [194/300], Step [10/29], Loss: 1.2779\n",
      "Epoch [194/300], Step [11/29], Loss: 1.1365\n",
      "Epoch [194/300], Step [12/29], Loss: 1.3918\n",
      "Epoch [194/300], Step [13/29], Loss: 1.2350\n",
      "Epoch [194/300], Step [14/29], Loss: 1.3392\n",
      "Epoch [194/300], Step [15/29], Loss: 1.0124\n",
      "Epoch [194/300], Step [16/29], Loss: 1.3025\n",
      "Epoch [194/300], Step [17/29], Loss: 1.1586\n",
      "Epoch [194/300], Step [18/29], Loss: 1.1654\n",
      "Epoch [194/300], Step [19/29], Loss: 1.3433\n",
      "Epoch [194/300], Step [20/29], Loss: 1.4108\n",
      "Epoch [194/300], Step [21/29], Loss: 1.2722\n",
      "Epoch [194/300], Step [22/29], Loss: 1.1622\n",
      "Epoch [194/300], Step [23/29], Loss: 1.4823\n",
      "Epoch [194/300], Step [24/29], Loss: 1.4153\n",
      "Epoch [194/300], Step [25/29], Loss: 1.2314\n",
      "Epoch [194/300], Step [26/29], Loss: 1.2311\n",
      "Epoch [194/300], Step [27/29], Loss: 1.2561\n",
      "Epoch [194/300], Step [28/29], Loss: 1.2000\n",
      "Epoch [194/300], Step [29/29], Loss: 1.3183\n",
      "Epoch [195/300], Step [1/29], Loss: 1.1785\n",
      "Epoch [195/300], Step [2/29], Loss: 1.6002\n",
      "Epoch [195/300], Step [3/29], Loss: 1.3211\n",
      "Epoch [195/300], Step [4/29], Loss: 1.2404\n",
      "Epoch [195/300], Step [5/29], Loss: 1.2958\n",
      "Epoch [195/300], Step [6/29], Loss: 1.5615\n",
      "Epoch [195/300], Step [7/29], Loss: 1.0935\n",
      "Epoch [195/300], Step [8/29], Loss: 1.3850\n",
      "Epoch [195/300], Step [9/29], Loss: 1.2741\n",
      "Epoch [195/300], Step [10/29], Loss: 1.4375\n",
      "Epoch [195/300], Step [11/29], Loss: 1.4096\n",
      "Epoch [195/300], Step [12/29], Loss: 0.9563\n",
      "Epoch [195/300], Step [13/29], Loss: 1.0970\n",
      "Epoch [195/300], Step [14/29], Loss: 1.1342\n",
      "Epoch [195/300], Step [15/29], Loss: 1.3787\n",
      "Epoch [195/300], Step [16/29], Loss: 1.3542\n",
      "Epoch [195/300], Step [17/29], Loss: 1.2272\n",
      "Epoch [195/300], Step [18/29], Loss: 1.4046\n",
      "Epoch [195/300], Step [19/29], Loss: 1.3815\n",
      "Epoch [195/300], Step [20/29], Loss: 1.0953\n",
      "Epoch [195/300], Step [21/29], Loss: 1.5495\n",
      "Epoch [195/300], Step [22/29], Loss: 1.2239\n",
      "Epoch [195/300], Step [23/29], Loss: 1.0424\n",
      "Epoch [195/300], Step [24/29], Loss: 1.3641\n",
      "Epoch [195/300], Step [25/29], Loss: 1.5941\n",
      "Epoch [195/300], Step [26/29], Loss: 1.3910\n",
      "Epoch [195/300], Step [27/29], Loss: 1.3879\n",
      "Epoch [195/300], Step [28/29], Loss: 1.3391\n",
      "Epoch [195/300], Step [29/29], Loss: 1.0502\n",
      "Epoch [196/300], Step [1/29], Loss: 1.0776\n",
      "Epoch [196/300], Step [2/29], Loss: 1.2793\n",
      "Epoch [196/300], Step [3/29], Loss: 1.3769\n",
      "Epoch [196/300], Step [4/29], Loss: 1.2628\n",
      "Epoch [196/300], Step [5/29], Loss: 1.2879\n",
      "Epoch [196/300], Step [6/29], Loss: 1.0539\n",
      "Epoch [196/300], Step [7/29], Loss: 1.4126\n",
      "Epoch [196/300], Step [8/29], Loss: 1.2226\n",
      "Epoch [196/300], Step [9/29], Loss: 1.1527\n",
      "Epoch [196/300], Step [10/29], Loss: 1.2873\n",
      "Epoch [196/300], Step [11/29], Loss: 1.4893\n",
      "Epoch [196/300], Step [12/29], Loss: 1.3135\n",
      "Epoch [196/300], Step [13/29], Loss: 1.4675\n",
      "Epoch [196/300], Step [14/29], Loss: 1.1023\n",
      "Epoch [196/300], Step [15/29], Loss: 1.1264\n",
      "Epoch [196/300], Step [16/29], Loss: 1.3881\n",
      "Epoch [196/300], Step [17/29], Loss: 1.5803\n",
      "Epoch [196/300], Step [18/29], Loss: 1.3017\n",
      "Epoch [196/300], Step [19/29], Loss: 1.3769\n",
      "Epoch [196/300], Step [20/29], Loss: 1.2650\n",
      "Epoch [196/300], Step [21/29], Loss: 1.2481\n",
      "Epoch [196/300], Step [22/29], Loss: 1.4625\n",
      "Epoch [196/300], Step [23/29], Loss: 1.3949\n",
      "Epoch [196/300], Step [24/29], Loss: 1.3761\n",
      "Epoch [196/300], Step [25/29], Loss: 1.3786\n",
      "Epoch [196/300], Step [26/29], Loss: 1.0169\n",
      "Epoch [196/300], Step [27/29], Loss: 1.2369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/300], Step [28/29], Loss: 1.1661\n",
      "Epoch [196/300], Step [29/29], Loss: 2.8289\n",
      "Epoch [197/300], Step [1/29], Loss: 1.3347\n",
      "Epoch [197/300], Step [2/29], Loss: 1.3500\n",
      "Epoch [197/300], Step [3/29], Loss: 1.2583\n",
      "Epoch [197/300], Step [4/29], Loss: 1.5453\n",
      "Epoch [197/300], Step [5/29], Loss: 1.4993\n",
      "Epoch [197/300], Step [6/29], Loss: 1.7501\n",
      "Epoch [197/300], Step [7/29], Loss: 1.4425\n",
      "Epoch [197/300], Step [8/29], Loss: 1.2990\n",
      "Epoch [197/300], Step [9/29], Loss: 1.0035\n",
      "Epoch [197/300], Step [10/29], Loss: 1.3918\n",
      "Epoch [197/300], Step [11/29], Loss: 1.2192\n",
      "Epoch [197/300], Step [12/29], Loss: 1.2030\n",
      "Epoch [197/300], Step [13/29], Loss: 1.2553\n",
      "Epoch [197/300], Step [14/29], Loss: 1.1801\n",
      "Epoch [197/300], Step [15/29], Loss: 1.2125\n",
      "Epoch [197/300], Step [16/29], Loss: 1.1531\n",
      "Epoch [197/300], Step [17/29], Loss: 1.1714\n",
      "Epoch [197/300], Step [18/29], Loss: 1.0720\n",
      "Epoch [197/300], Step [19/29], Loss: 1.3455\n",
      "Epoch [197/300], Step [20/29], Loss: 0.9052\n",
      "Epoch [197/300], Step [21/29], Loss: 1.1088\n",
      "Epoch [197/300], Step [22/29], Loss: 1.0715\n",
      "Epoch [197/300], Step [23/29], Loss: 1.2378\n",
      "Epoch [197/300], Step [24/29], Loss: 1.6673\n",
      "Epoch [197/300], Step [25/29], Loss: 1.7742\n",
      "Epoch [197/300], Step [26/29], Loss: 1.4608\n",
      "Epoch [197/300], Step [27/29], Loss: 1.2255\n",
      "Epoch [197/300], Step [28/29], Loss: 1.2214\n",
      "Epoch [197/300], Step [29/29], Loss: 1.2629\n",
      "Epoch [198/300], Step [1/29], Loss: 1.6920\n",
      "Epoch [198/300], Step [2/29], Loss: 1.4853\n",
      "Epoch [198/300], Step [3/29], Loss: 1.3045\n",
      "Epoch [198/300], Step [4/29], Loss: 1.4652\n",
      "Epoch [198/300], Step [5/29], Loss: 1.5045\n",
      "Epoch [198/300], Step [6/29], Loss: 1.1171\n",
      "Epoch [198/300], Step [7/29], Loss: 1.2697\n",
      "Epoch [198/300], Step [8/29], Loss: 1.2802\n",
      "Epoch [198/300], Step [9/29], Loss: 1.1434\n",
      "Epoch [198/300], Step [10/29], Loss: 1.1963\n",
      "Epoch [198/300], Step [11/29], Loss: 1.3629\n",
      "Epoch [198/300], Step [12/29], Loss: 1.2426\n",
      "Epoch [198/300], Step [13/29], Loss: 1.4063\n",
      "Epoch [198/300], Step [14/29], Loss: 1.1458\n",
      "Epoch [198/300], Step [15/29], Loss: 1.4631\n",
      "Epoch [198/300], Step [16/29], Loss: 1.3142\n",
      "Epoch [198/300], Step [17/29], Loss: 1.2795\n",
      "Epoch [198/300], Step [18/29], Loss: 1.1160\n",
      "Epoch [198/300], Step [19/29], Loss: 1.3524\n",
      "Epoch [198/300], Step [20/29], Loss: 1.4077\n",
      "Epoch [198/300], Step [21/29], Loss: 1.0844\n",
      "Epoch [198/300], Step [22/29], Loss: 1.1134\n",
      "Epoch [198/300], Step [23/29], Loss: 1.2679\n",
      "Epoch [198/300], Step [24/29], Loss: 1.5578\n",
      "Epoch [198/300], Step [25/29], Loss: 1.0266\n",
      "Epoch [198/300], Step [26/29], Loss: 1.1333\n",
      "Epoch [198/300], Step [27/29], Loss: 1.3370\n",
      "Epoch [198/300], Step [28/29], Loss: 1.3081\n",
      "Epoch [198/300], Step [29/29], Loss: 1.4359\n",
      "Epoch [199/300], Step [1/29], Loss: 1.2298\n",
      "Epoch [199/300], Step [2/29], Loss: 1.3974\n",
      "Epoch [199/300], Step [3/29], Loss: 1.2551\n",
      "Epoch [199/300], Step [4/29], Loss: 1.2200\n",
      "Epoch [199/300], Step [5/29], Loss: 1.2769\n",
      "Epoch [199/300], Step [6/29], Loss: 1.4618\n",
      "Epoch [199/300], Step [7/29], Loss: 1.1413\n",
      "Epoch [199/300], Step [8/29], Loss: 1.0167\n",
      "Epoch [199/300], Step [9/29], Loss: 1.2177\n",
      "Epoch [199/300], Step [10/29], Loss: 1.3790\n",
      "Epoch [199/300], Step [11/29], Loss: 1.2920\n",
      "Epoch [199/300], Step [12/29], Loss: 1.4362\n",
      "Epoch [199/300], Step [13/29], Loss: 1.4470\n",
      "Epoch [199/300], Step [14/29], Loss: 1.5786\n",
      "Epoch [199/300], Step [15/29], Loss: 1.2858\n",
      "Epoch [199/300], Step [16/29], Loss: 1.2437\n",
      "Epoch [199/300], Step [17/29], Loss: 1.1983\n",
      "Epoch [199/300], Step [18/29], Loss: 1.2908\n",
      "Epoch [199/300], Step [19/29], Loss: 1.5311\n",
      "Epoch [199/300], Step [20/29], Loss: 1.0694\n",
      "Epoch [199/300], Step [21/29], Loss: 1.3020\n",
      "Epoch [199/300], Step [22/29], Loss: 1.1453\n",
      "Epoch [199/300], Step [23/29], Loss: 1.3319\n",
      "Epoch [199/300], Step [24/29], Loss: 1.2904\n",
      "Epoch [199/300], Step [25/29], Loss: 1.2392\n",
      "Epoch [199/300], Step [26/29], Loss: 1.3663\n",
      "Epoch [199/300], Step [27/29], Loss: 1.3160\n",
      "Epoch [199/300], Step [28/29], Loss: 1.4748\n",
      "Epoch [199/300], Step [29/29], Loss: 1.4101\n",
      "Epoch [200/300], Step [1/29], Loss: 0.9611\n",
      "Epoch [200/300], Step [2/29], Loss: 1.4008\n",
      "Epoch [200/300], Step [3/29], Loss: 1.2844\n",
      "Epoch [200/300], Step [4/29], Loss: 1.3837\n",
      "Epoch [200/300], Step [5/29], Loss: 1.2880\n",
      "Epoch [200/300], Step [6/29], Loss: 1.3299\n",
      "Epoch [200/300], Step [7/29], Loss: 1.1918\n",
      "Epoch [200/300], Step [8/29], Loss: 1.2918\n",
      "Epoch [200/300], Step [9/29], Loss: 1.2031\n",
      "Epoch [200/300], Step [10/29], Loss: 1.2338\n",
      "Epoch [200/300], Step [11/29], Loss: 1.4341\n",
      "Epoch [200/300], Step [12/29], Loss: 1.3195\n",
      "Epoch [200/300], Step [13/29], Loss: 1.3073\n",
      "Epoch [200/300], Step [14/29], Loss: 1.1334\n",
      "Epoch [200/300], Step [15/29], Loss: 1.5346\n",
      "Epoch [200/300], Step [16/29], Loss: 1.3230\n",
      "Epoch [200/300], Step [17/29], Loss: 1.1699\n",
      "Epoch [200/300], Step [18/29], Loss: 1.3360\n",
      "Epoch [200/300], Step [19/29], Loss: 1.3267\n",
      "Epoch [200/300], Step [20/29], Loss: 1.2253\n",
      "Epoch [200/300], Step [21/29], Loss: 1.1884\n",
      "Epoch [200/300], Step [22/29], Loss: 1.2667\n",
      "Epoch [200/300], Step [23/29], Loss: 1.5760\n",
      "Epoch [200/300], Step [24/29], Loss: 1.1696\n",
      "Epoch [200/300], Step [25/29], Loss: 1.5772\n",
      "Epoch [200/300], Step [26/29], Loss: 1.3505\n",
      "Epoch [200/300], Step [27/29], Loss: 1.0965\n",
      "Epoch [200/300], Step [28/29], Loss: 1.5041\n",
      "Epoch [200/300], Step [29/29], Loss: 0.8133\n",
      "Epoch [201/300], Step [1/29], Loss: 1.4290\n",
      "Epoch [201/300], Step [2/29], Loss: 1.4190\n",
      "Epoch [201/300], Step [3/29], Loss: 1.1576\n",
      "Epoch [201/300], Step [4/29], Loss: 1.2256\n",
      "Epoch [201/300], Step [5/29], Loss: 1.1193\n",
      "Epoch [201/300], Step [6/29], Loss: 1.2676\n",
      "Epoch [201/300], Step [7/29], Loss: 1.2136\n",
      "Epoch [201/300], Step [8/29], Loss: 1.4270\n",
      "Epoch [201/300], Step [9/29], Loss: 1.1598\n",
      "Epoch [201/300], Step [10/29], Loss: 1.2632\n",
      "Epoch [201/300], Step [11/29], Loss: 1.2849\n",
      "Epoch [201/300], Step [12/29], Loss: 1.2525\n",
      "Epoch [201/300], Step [13/29], Loss: 0.9411\n",
      "Epoch [201/300], Step [14/29], Loss: 1.1590\n",
      "Epoch [201/300], Step [15/29], Loss: 1.4810\n",
      "Epoch [201/300], Step [16/29], Loss: 1.3581\n",
      "Epoch [201/300], Step [17/29], Loss: 1.2676\n",
      "Epoch [201/300], Step [18/29], Loss: 1.2591\n",
      "Epoch [201/300], Step [19/29], Loss: 1.4365\n",
      "Epoch [201/300], Step [20/29], Loss: 1.3546\n",
      "Epoch [201/300], Step [21/29], Loss: 1.3767\n",
      "Epoch [201/300], Step [22/29], Loss: 1.2808\n",
      "Epoch [201/300], Step [23/29], Loss: 1.0691\n",
      "Epoch [201/300], Step [24/29], Loss: 1.4444\n",
      "Epoch [201/300], Step [25/29], Loss: 1.3164\n",
      "Epoch [201/300], Step [26/29], Loss: 1.3481\n",
      "Epoch [201/300], Step [27/29], Loss: 1.3867\n",
      "Epoch [201/300], Step [28/29], Loss: 1.2988\n",
      "Epoch [201/300], Step [29/29], Loss: 2.0728\n",
      "Epoch [202/300], Step [1/29], Loss: 1.3652\n",
      "Epoch [202/300], Step [2/29], Loss: 1.4938\n",
      "Epoch [202/300], Step [3/29], Loss: 1.1705\n",
      "Epoch [202/300], Step [4/29], Loss: 1.3886\n",
      "Epoch [202/300], Step [5/29], Loss: 1.2472\n",
      "Epoch [202/300], Step [6/29], Loss: 1.1712\n",
      "Epoch [202/300], Step [7/29], Loss: 1.2736\n",
      "Epoch [202/300], Step [8/29], Loss: 1.4077\n",
      "Epoch [202/300], Step [9/29], Loss: 1.1184\n",
      "Epoch [202/300], Step [10/29], Loss: 1.2121\n",
      "Epoch [202/300], Step [11/29], Loss: 1.4260\n",
      "Epoch [202/300], Step [12/29], Loss: 1.4108\n",
      "Epoch [202/300], Step [13/29], Loss: 1.3793\n",
      "Epoch [202/300], Step [14/29], Loss: 0.9730\n",
      "Epoch [202/300], Step [15/29], Loss: 1.2013\n",
      "Epoch [202/300], Step [16/29], Loss: 1.2499\n",
      "Epoch [202/300], Step [17/29], Loss: 1.4427\n",
      "Epoch [202/300], Step [18/29], Loss: 1.2710\n",
      "Epoch [202/300], Step [19/29], Loss: 1.1168\n",
      "Epoch [202/300], Step [20/29], Loss: 1.3431\n",
      "Epoch [202/300], Step [21/29], Loss: 1.2682\n",
      "Epoch [202/300], Step [22/29], Loss: 1.3498\n",
      "Epoch [202/300], Step [23/29], Loss: 1.4666\n",
      "Epoch [202/300], Step [24/29], Loss: 1.2729\n",
      "Epoch [202/300], Step [25/29], Loss: 1.3150\n",
      "Epoch [202/300], Step [26/29], Loss: 1.4553\n",
      "Epoch [202/300], Step [27/29], Loss: 1.3886\n",
      "Epoch [202/300], Step [28/29], Loss: 1.4417\n",
      "Epoch [202/300], Step [29/29], Loss: 0.6816\n",
      "Epoch [203/300], Step [1/29], Loss: 1.1688\n",
      "Epoch [203/300], Step [2/29], Loss: 1.3575\n",
      "Epoch [203/300], Step [3/29], Loss: 1.1819\n",
      "Epoch [203/300], Step [4/29], Loss: 1.3511\n",
      "Epoch [203/300], Step [5/29], Loss: 1.3281\n",
      "Epoch [203/300], Step [6/29], Loss: 1.1505\n",
      "Epoch [203/300], Step [7/29], Loss: 1.3282\n",
      "Epoch [203/300], Step [8/29], Loss: 1.3361\n",
      "Epoch [203/300], Step [9/29], Loss: 1.3089\n",
      "Epoch [203/300], Step [10/29], Loss: 1.4444\n",
      "Epoch [203/300], Step [11/29], Loss: 1.2368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [203/300], Step [12/29], Loss: 1.2168\n",
      "Epoch [203/300], Step [13/29], Loss: 1.3868\n",
      "Epoch [203/300], Step [14/29], Loss: 1.1998\n",
      "Epoch [203/300], Step [15/29], Loss: 1.2261\n",
      "Epoch [203/300], Step [16/29], Loss: 1.4899\n",
      "Epoch [203/300], Step [17/29], Loss: 1.1644\n",
      "Epoch [203/300], Step [18/29], Loss: 1.1530\n",
      "Epoch [203/300], Step [19/29], Loss: 1.2454\n",
      "Epoch [203/300], Step [20/29], Loss: 1.2459\n",
      "Epoch [203/300], Step [21/29], Loss: 1.1518\n",
      "Epoch [203/300], Step [22/29], Loss: 1.4815\n",
      "Epoch [203/300], Step [23/29], Loss: 1.3910\n",
      "Epoch [203/300], Step [24/29], Loss: 1.1799\n",
      "Epoch [203/300], Step [25/29], Loss: 1.5168\n",
      "Epoch [203/300], Step [26/29], Loss: 1.0834\n",
      "Epoch [203/300], Step [27/29], Loss: 1.3958\n",
      "Epoch [203/300], Step [28/29], Loss: 1.7182\n",
      "Epoch [203/300], Step [29/29], Loss: 1.2911\n",
      "Epoch [204/300], Step [1/29], Loss: 1.2604\n",
      "Epoch [204/300], Step [2/29], Loss: 1.2410\n",
      "Epoch [204/300], Step [3/29], Loss: 1.5018\n",
      "Epoch [204/300], Step [4/29], Loss: 1.1522\n",
      "Epoch [204/300], Step [5/29], Loss: 1.2061\n",
      "Epoch [204/300], Step [6/29], Loss: 1.3243\n",
      "Epoch [204/300], Step [7/29], Loss: 1.1765\n",
      "Epoch [204/300], Step [8/29], Loss: 1.2013\n",
      "Epoch [204/300], Step [9/29], Loss: 1.2522\n",
      "Epoch [204/300], Step [10/29], Loss: 0.9185\n",
      "Epoch [204/300], Step [11/29], Loss: 1.4080\n",
      "Epoch [204/300], Step [12/29], Loss: 1.3066\n",
      "Epoch [204/300], Step [13/29], Loss: 1.3414\n",
      "Epoch [204/300], Step [14/29], Loss: 1.3171\n",
      "Epoch [204/300], Step [15/29], Loss: 1.3057\n",
      "Epoch [204/300], Step [16/29], Loss: 1.2674\n",
      "Epoch [204/300], Step [17/29], Loss: 1.4664\n",
      "Epoch [204/300], Step [18/29], Loss: 1.2854\n",
      "Epoch [204/300], Step [19/29], Loss: 1.1356\n",
      "Epoch [204/300], Step [20/29], Loss: 1.0596\n",
      "Epoch [204/300], Step [21/29], Loss: 1.6376\n",
      "Epoch [204/300], Step [22/29], Loss: 1.5329\n",
      "Epoch [204/300], Step [23/29], Loss: 1.3883\n",
      "Epoch [204/300], Step [24/29], Loss: 1.2552\n",
      "Epoch [204/300], Step [25/29], Loss: 1.5100\n",
      "Epoch [204/300], Step [26/29], Loss: 1.2371\n",
      "Epoch [204/300], Step [27/29], Loss: 1.1092\n",
      "Epoch [204/300], Step [28/29], Loss: 1.2628\n",
      "Epoch [204/300], Step [29/29], Loss: 1.3452\n",
      "Epoch [205/300], Step [1/29], Loss: 1.4678\n",
      "Epoch [205/300], Step [2/29], Loss: 1.1774\n",
      "Epoch [205/300], Step [3/29], Loss: 1.4258\n",
      "Epoch [205/300], Step [4/29], Loss: 1.3933\n",
      "Epoch [205/300], Step [5/29], Loss: 1.4291\n",
      "Epoch [205/300], Step [6/29], Loss: 1.4142\n",
      "Epoch [205/300], Step [7/29], Loss: 1.1613\n",
      "Epoch [205/300], Step [8/29], Loss: 1.0737\n",
      "Epoch [205/300], Step [9/29], Loss: 1.4918\n",
      "Epoch [205/300], Step [10/29], Loss: 1.0980\n",
      "Epoch [205/300], Step [11/29], Loss: 1.2456\n",
      "Epoch [205/300], Step [12/29], Loss: 0.8709\n",
      "Epoch [205/300], Step [13/29], Loss: 1.3193\n",
      "Epoch [205/300], Step [14/29], Loss: 1.3506\n",
      "Epoch [205/300], Step [15/29], Loss: 1.5321\n",
      "Epoch [205/300], Step [16/29], Loss: 1.3603\n",
      "Epoch [205/300], Step [17/29], Loss: 1.4377\n",
      "Epoch [205/300], Step [18/29], Loss: 1.3533\n",
      "Epoch [205/300], Step [19/29], Loss: 1.2289\n",
      "Epoch [205/300], Step [20/29], Loss: 1.4541\n",
      "Epoch [205/300], Step [21/29], Loss: 1.5057\n",
      "Epoch [205/300], Step [22/29], Loss: 1.2367\n",
      "Epoch [205/300], Step [23/29], Loss: 1.2672\n",
      "Epoch [205/300], Step [24/29], Loss: 1.3419\n",
      "Epoch [205/300], Step [25/29], Loss: 1.0843\n",
      "Epoch [205/300], Step [26/29], Loss: 1.2935\n",
      "Epoch [205/300], Step [27/29], Loss: 1.2870\n",
      "Epoch [205/300], Step [28/29], Loss: 1.2939\n",
      "Epoch [205/300], Step [29/29], Loss: 0.3695\n",
      "Epoch [206/300], Step [1/29], Loss: 1.3224\n",
      "Epoch [206/300], Step [2/29], Loss: 1.2534\n",
      "Epoch [206/300], Step [3/29], Loss: 1.1689\n",
      "Epoch [206/300], Step [4/29], Loss: 1.3231\n",
      "Epoch [206/300], Step [5/29], Loss: 1.5418\n",
      "Epoch [206/300], Step [6/29], Loss: 1.3524\n",
      "Epoch [206/300], Step [7/29], Loss: 1.2962\n",
      "Epoch [206/300], Step [8/29], Loss: 1.4066\n",
      "Epoch [206/300], Step [9/29], Loss: 1.4638\n",
      "Epoch [206/300], Step [10/29], Loss: 1.3028\n",
      "Epoch [206/300], Step [11/29], Loss: 1.1536\n",
      "Epoch [206/300], Step [12/29], Loss: 1.3499\n",
      "Epoch [206/300], Step [13/29], Loss: 1.3274\n",
      "Epoch [206/300], Step [14/29], Loss: 1.1525\n",
      "Epoch [206/300], Step [15/29], Loss: 1.3781\n",
      "Epoch [206/300], Step [16/29], Loss: 1.1127\n",
      "Epoch [206/300], Step [17/29], Loss: 1.2511\n",
      "Epoch [206/300], Step [18/29], Loss: 1.3553\n",
      "Epoch [206/300], Step [19/29], Loss: 1.3982\n",
      "Epoch [206/300], Step [20/29], Loss: 1.3355\n",
      "Epoch [206/300], Step [21/29], Loss: 1.3097\n",
      "Epoch [206/300], Step [22/29], Loss: 1.4470\n",
      "Epoch [206/300], Step [23/29], Loss: 1.2229\n",
      "Epoch [206/300], Step [24/29], Loss: 1.2785\n",
      "Epoch [206/300], Step [25/29], Loss: 1.2219\n",
      "Epoch [206/300], Step [26/29], Loss: 1.3574\n",
      "Epoch [206/300], Step [27/29], Loss: 1.1704\n",
      "Epoch [206/300], Step [28/29], Loss: 1.2584\n",
      "Epoch [206/300], Step [29/29], Loss: 1.2225\n",
      "Epoch [207/300], Step [1/29], Loss: 1.4072\n",
      "Epoch [207/300], Step [2/29], Loss: 1.4215\n",
      "Epoch [207/300], Step [3/29], Loss: 1.3802\n",
      "Epoch [207/300], Step [4/29], Loss: 1.6780\n",
      "Epoch [207/300], Step [5/29], Loss: 1.4358\n",
      "Epoch [207/300], Step [6/29], Loss: 1.3058\n",
      "Epoch [207/300], Step [7/29], Loss: 1.2147\n",
      "Epoch [207/300], Step [8/29], Loss: 1.3028\n",
      "Epoch [207/300], Step [9/29], Loss: 1.0227\n",
      "Epoch [207/300], Step [10/29], Loss: 1.0463\n",
      "Epoch [207/300], Step [11/29], Loss: 1.4582\n",
      "Epoch [207/300], Step [12/29], Loss: 1.3453\n",
      "Epoch [207/300], Step [13/29], Loss: 1.1782\n",
      "Epoch [207/300], Step [14/29], Loss: 1.3084\n",
      "Epoch [207/300], Step [15/29], Loss: 1.2649\n",
      "Epoch [207/300], Step [16/29], Loss: 1.1350\n",
      "Epoch [207/300], Step [17/29], Loss: 1.3132\n",
      "Epoch [207/300], Step [18/29], Loss: 1.2379\n",
      "Epoch [207/300], Step [19/29], Loss: 1.2280\n",
      "Epoch [207/300], Step [20/29], Loss: 1.4450\n",
      "Epoch [207/300], Step [21/29], Loss: 1.2069\n",
      "Epoch [207/300], Step [22/29], Loss: 1.3775\n",
      "Epoch [207/300], Step [23/29], Loss: 1.1765\n",
      "Epoch [207/300], Step [24/29], Loss: 1.1643\n",
      "Epoch [207/300], Step [25/29], Loss: 1.2089\n",
      "Epoch [207/300], Step [26/29], Loss: 1.3058\n",
      "Epoch [207/300], Step [27/29], Loss: 1.3499\n",
      "Epoch [207/300], Step [28/29], Loss: 1.2902\n",
      "Epoch [207/300], Step [29/29], Loss: 1.6910\n",
      "Epoch [208/300], Step [1/29], Loss: 1.3538\n",
      "Epoch [208/300], Step [2/29], Loss: 1.3954\n",
      "Epoch [208/300], Step [3/29], Loss: 1.1312\n",
      "Epoch [208/300], Step [4/29], Loss: 1.4265\n",
      "Epoch [208/300], Step [5/29], Loss: 1.3957\n",
      "Epoch [208/300], Step [6/29], Loss: 1.1884\n",
      "Epoch [208/300], Step [7/29], Loss: 1.3280\n",
      "Epoch [208/300], Step [8/29], Loss: 1.0749\n",
      "Epoch [208/300], Step [9/29], Loss: 1.5155\n",
      "Epoch [208/300], Step [10/29], Loss: 1.3871\n",
      "Epoch [208/300], Step [11/29], Loss: 1.1965\n",
      "Epoch [208/300], Step [12/29], Loss: 1.2639\n",
      "Epoch [208/300], Step [13/29], Loss: 1.3042\n",
      "Epoch [208/300], Step [14/29], Loss: 1.5198\n",
      "Epoch [208/300], Step [15/29], Loss: 1.1435\n",
      "Epoch [208/300], Step [16/29], Loss: 1.2261\n",
      "Epoch [208/300], Step [17/29], Loss: 1.3793\n",
      "Epoch [208/300], Step [18/29], Loss: 1.3402\n",
      "Epoch [208/300], Step [19/29], Loss: 1.5297\n",
      "Epoch [208/300], Step [20/29], Loss: 1.2321\n",
      "Epoch [208/300], Step [21/29], Loss: 1.3885\n",
      "Epoch [208/300], Step [22/29], Loss: 1.2323\n",
      "Epoch [208/300], Step [23/29], Loss: 1.3865\n",
      "Epoch [208/300], Step [24/29], Loss: 1.0839\n",
      "Epoch [208/300], Step [25/29], Loss: 1.0907\n",
      "Epoch [208/300], Step [26/29], Loss: 1.5520\n",
      "Epoch [208/300], Step [27/29], Loss: 1.1391\n",
      "Epoch [208/300], Step [28/29], Loss: 1.4468\n",
      "Epoch [208/300], Step [29/29], Loss: 1.3893\n",
      "Epoch [209/300], Step [1/29], Loss: 1.0301\n",
      "Epoch [209/300], Step [2/29], Loss: 1.5387\n",
      "Epoch [209/300], Step [3/29], Loss: 1.4845\n",
      "Epoch [209/300], Step [4/29], Loss: 1.3003\n",
      "Epoch [209/300], Step [5/29], Loss: 1.1840\n",
      "Epoch [209/300], Step [6/29], Loss: 1.3015\n",
      "Epoch [209/300], Step [7/29], Loss: 1.3340\n",
      "Epoch [209/300], Step [8/29], Loss: 1.0411\n",
      "Epoch [209/300], Step [9/29], Loss: 1.3236\n",
      "Epoch [209/300], Step [10/29], Loss: 1.3348\n",
      "Epoch [209/300], Step [11/29], Loss: 1.2507\n",
      "Epoch [209/300], Step [12/29], Loss: 1.0661\n",
      "Epoch [209/300], Step [13/29], Loss: 1.0403\n",
      "Epoch [209/300], Step [14/29], Loss: 1.4218\n",
      "Epoch [209/300], Step [15/29], Loss: 1.1907\n",
      "Epoch [209/300], Step [16/29], Loss: 1.3135\n",
      "Epoch [209/300], Step [17/29], Loss: 1.2785\n",
      "Epoch [209/300], Step [18/29], Loss: 1.2609\n",
      "Epoch [209/300], Step [19/29], Loss: 1.2104\n",
      "Epoch [209/300], Step [20/29], Loss: 1.2091\n",
      "Epoch [209/300], Step [21/29], Loss: 1.3884\n",
      "Epoch [209/300], Step [22/29], Loss: 1.1967\n",
      "Epoch [209/300], Step [23/29], Loss: 1.3157\n",
      "Epoch [209/300], Step [24/29], Loss: 1.5477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [209/300], Step [25/29], Loss: 1.2894\n",
      "Epoch [209/300], Step [26/29], Loss: 1.5056\n",
      "Epoch [209/300], Step [27/29], Loss: 1.2588\n",
      "Epoch [209/300], Step [28/29], Loss: 1.3749\n",
      "Epoch [209/300], Step [29/29], Loss: 0.8097\n",
      "Epoch [210/300], Step [1/29], Loss: 1.3186\n",
      "Epoch [210/300], Step [2/29], Loss: 1.0595\n",
      "Epoch [210/300], Step [3/29], Loss: 1.2139\n",
      "Epoch [210/300], Step [4/29], Loss: 1.3740\n",
      "Epoch [210/300], Step [5/29], Loss: 1.3476\n",
      "Epoch [210/300], Step [6/29], Loss: 1.1563\n",
      "Epoch [210/300], Step [7/29], Loss: 1.1623\n",
      "Epoch [210/300], Step [8/29], Loss: 1.0742\n",
      "Epoch [210/300], Step [9/29], Loss: 1.1476\n",
      "Epoch [210/300], Step [10/29], Loss: 1.4068\n",
      "Epoch [210/300], Step [11/29], Loss: 1.4347\n",
      "Epoch [210/300], Step [12/29], Loss: 1.3624\n",
      "Epoch [210/300], Step [13/29], Loss: 1.3649\n",
      "Epoch [210/300], Step [14/29], Loss: 1.4246\n",
      "Epoch [210/300], Step [15/29], Loss: 1.4145\n",
      "Epoch [210/300], Step [16/29], Loss: 1.5276\n",
      "Epoch [210/300], Step [17/29], Loss: 1.4536\n",
      "Epoch [210/300], Step [18/29], Loss: 1.3132\n",
      "Epoch [210/300], Step [19/29], Loss: 1.3629\n",
      "Epoch [210/300], Step [20/29], Loss: 1.2314\n",
      "Epoch [210/300], Step [21/29], Loss: 1.1825\n",
      "Epoch [210/300], Step [22/29], Loss: 1.3824\n",
      "Epoch [210/300], Step [23/29], Loss: 1.1053\n",
      "Epoch [210/300], Step [24/29], Loss: 1.4744\n",
      "Epoch [210/300], Step [25/29], Loss: 1.4451\n",
      "Epoch [210/300], Step [26/29], Loss: 1.1056\n",
      "Epoch [210/300], Step [27/29], Loss: 1.1366\n",
      "Epoch [210/300], Step [28/29], Loss: 1.2974\n",
      "Epoch [210/300], Step [29/29], Loss: 1.7157\n",
      "Epoch [211/300], Step [1/29], Loss: 1.3867\n",
      "Epoch [211/300], Step [2/29], Loss: 1.0494\n",
      "Epoch [211/300], Step [3/29], Loss: 1.3232\n",
      "Epoch [211/300], Step [4/29], Loss: 1.2975\n",
      "Epoch [211/300], Step [5/29], Loss: 1.4075\n",
      "Epoch [211/300], Step [6/29], Loss: 1.2590\n",
      "Epoch [211/300], Step [7/29], Loss: 1.3188\n",
      "Epoch [211/300], Step [8/29], Loss: 1.2555\n",
      "Epoch [211/300], Step [9/29], Loss: 1.5107\n",
      "Epoch [211/300], Step [10/29], Loss: 1.3750\n",
      "Epoch [211/300], Step [11/29], Loss: 1.3042\n",
      "Epoch [211/300], Step [12/29], Loss: 1.2193\n",
      "Epoch [211/300], Step [13/29], Loss: 1.3059\n",
      "Epoch [211/300], Step [14/29], Loss: 1.4791\n",
      "Epoch [211/300], Step [15/29], Loss: 1.3349\n",
      "Epoch [211/300], Step [16/29], Loss: 1.2850\n",
      "Epoch [211/300], Step [17/29], Loss: 1.3968\n",
      "Epoch [211/300], Step [18/29], Loss: 1.1356\n",
      "Epoch [211/300], Step [19/29], Loss: 1.2968\n",
      "Epoch [211/300], Step [20/29], Loss: 1.2727\n",
      "Epoch [211/300], Step [21/29], Loss: 1.3828\n",
      "Epoch [211/300], Step [22/29], Loss: 1.3394\n",
      "Epoch [211/300], Step [23/29], Loss: 1.4175\n",
      "Epoch [211/300], Step [24/29], Loss: 0.9969\n",
      "Epoch [211/300], Step [25/29], Loss: 1.1755\n",
      "Epoch [211/300], Step [26/29], Loss: 1.3549\n",
      "Epoch [211/300], Step [27/29], Loss: 1.1723\n",
      "Epoch [211/300], Step [28/29], Loss: 1.1478\n",
      "Epoch [211/300], Step [29/29], Loss: 0.6632\n",
      "Epoch [212/300], Step [1/29], Loss: 1.2689\n",
      "Epoch [212/300], Step [2/29], Loss: 1.4360\n",
      "Epoch [212/300], Step [3/29], Loss: 1.3445\n",
      "Epoch [212/300], Step [4/29], Loss: 1.2434\n",
      "Epoch [212/300], Step [5/29], Loss: 1.0881\n",
      "Epoch [212/300], Step [6/29], Loss: 1.2752\n",
      "Epoch [212/300], Step [7/29], Loss: 1.3104\n",
      "Epoch [212/300], Step [8/29], Loss: 1.2307\n",
      "Epoch [212/300], Step [9/29], Loss: 1.4881\n",
      "Epoch [212/300], Step [10/29], Loss: 1.3539\n",
      "Epoch [212/300], Step [11/29], Loss: 1.1771\n",
      "Epoch [212/300], Step [12/29], Loss: 1.2105\n",
      "Epoch [212/300], Step [13/29], Loss: 1.4952\n",
      "Epoch [212/300], Step [14/29], Loss: 1.5428\n",
      "Epoch [212/300], Step [15/29], Loss: 1.1541\n",
      "Epoch [212/300], Step [16/29], Loss: 1.4247\n",
      "Epoch [212/300], Step [17/29], Loss: 1.0358\n",
      "Epoch [212/300], Step [18/29], Loss: 1.3085\n",
      "Epoch [212/300], Step [19/29], Loss: 1.3413\n",
      "Epoch [212/300], Step [20/29], Loss: 1.1847\n",
      "Epoch [212/300], Step [21/29], Loss: 1.4755\n",
      "Epoch [212/300], Step [22/29], Loss: 1.2187\n",
      "Epoch [212/300], Step [23/29], Loss: 1.3093\n",
      "Epoch [212/300], Step [24/29], Loss: 1.3016\n",
      "Epoch [212/300], Step [25/29], Loss: 1.0501\n",
      "Epoch [212/300], Step [26/29], Loss: 1.1673\n",
      "Epoch [212/300], Step [27/29], Loss: 1.3716\n",
      "Epoch [212/300], Step [28/29], Loss: 1.3268\n",
      "Epoch [212/300], Step [29/29], Loss: 1.9073\n",
      "Epoch [213/300], Step [1/29], Loss: 1.4715\n",
      "Epoch [213/300], Step [2/29], Loss: 1.2851\n",
      "Epoch [213/300], Step [3/29], Loss: 1.2901\n",
      "Epoch [213/300], Step [4/29], Loss: 1.3466\n",
      "Epoch [213/300], Step [5/29], Loss: 1.4515\n",
      "Epoch [213/300], Step [6/29], Loss: 1.5432\n",
      "Epoch [213/300], Step [7/29], Loss: 1.3917\n",
      "Epoch [213/300], Step [8/29], Loss: 1.1424\n",
      "Epoch [213/300], Step [9/29], Loss: 1.2874\n",
      "Epoch [213/300], Step [10/29], Loss: 1.2053\n",
      "Epoch [213/300], Step [11/29], Loss: 1.3642\n",
      "Epoch [213/300], Step [12/29], Loss: 1.2512\n",
      "Epoch [213/300], Step [13/29], Loss: 1.3777\n",
      "Epoch [213/300], Step [14/29], Loss: 1.5602\n",
      "Epoch [213/300], Step [15/29], Loss: 1.4336\n",
      "Epoch [213/300], Step [16/29], Loss: 1.0340\n",
      "Epoch [213/300], Step [17/29], Loss: 1.1251\n",
      "Epoch [213/300], Step [18/29], Loss: 1.3113\n",
      "Epoch [213/300], Step [19/29], Loss: 1.4385\n",
      "Epoch [213/300], Step [20/29], Loss: 1.2987\n",
      "Epoch [213/300], Step [21/29], Loss: 1.1411\n",
      "Epoch [213/300], Step [22/29], Loss: 1.2412\n",
      "Epoch [213/300], Step [23/29], Loss: 1.1639\n",
      "Epoch [213/300], Step [24/29], Loss: 1.2818\n",
      "Epoch [213/300], Step [25/29], Loss: 1.2761\n",
      "Epoch [213/300], Step [26/29], Loss: 1.0706\n",
      "Epoch [213/300], Step [27/29], Loss: 1.4312\n",
      "Epoch [213/300], Step [28/29], Loss: 1.4627\n",
      "Epoch [213/300], Step [29/29], Loss: 0.5430\n",
      "Epoch [214/300], Step [1/29], Loss: 1.4268\n",
      "Epoch [214/300], Step [2/29], Loss: 1.2096\n",
      "Epoch [214/300], Step [3/29], Loss: 1.1483\n",
      "Epoch [214/300], Step [4/29], Loss: 1.3251\n",
      "Epoch [214/300], Step [5/29], Loss: 1.2443\n",
      "Epoch [214/300], Step [6/29], Loss: 1.4825\n",
      "Epoch [214/300], Step [7/29], Loss: 1.1673\n",
      "Epoch [214/300], Step [8/29], Loss: 1.0888\n",
      "Epoch [214/300], Step [9/29], Loss: 1.3678\n",
      "Epoch [214/300], Step [10/29], Loss: 1.1040\n",
      "Epoch [214/300], Step [11/29], Loss: 1.1085\n",
      "Epoch [214/300], Step [12/29], Loss: 1.2071\n",
      "Epoch [214/300], Step [13/29], Loss: 1.4131\n",
      "Epoch [214/300], Step [14/29], Loss: 1.2676\n",
      "Epoch [214/300], Step [15/29], Loss: 1.4938\n",
      "Epoch [214/300], Step [16/29], Loss: 1.3209\n",
      "Epoch [214/300], Step [17/29], Loss: 1.3606\n",
      "Epoch [214/300], Step [18/29], Loss: 1.2052\n",
      "Epoch [214/300], Step [19/29], Loss: 1.1464\n",
      "Epoch [214/300], Step [20/29], Loss: 1.0920\n",
      "Epoch [214/300], Step [21/29], Loss: 1.6679\n",
      "Epoch [214/300], Step [22/29], Loss: 1.1471\n",
      "Epoch [214/300], Step [23/29], Loss: 1.1525\n",
      "Epoch [214/300], Step [24/29], Loss: 1.6787\n",
      "Epoch [214/300], Step [25/29], Loss: 1.5420\n",
      "Epoch [214/300], Step [26/29], Loss: 1.0869\n",
      "Epoch [214/300], Step [27/29], Loss: 1.2793\n",
      "Epoch [214/300], Step [28/29], Loss: 1.0984\n",
      "Epoch [214/300], Step [29/29], Loss: 3.0660\n",
      "Epoch [215/300], Step [1/29], Loss: 1.3008\n",
      "Epoch [215/300], Step [2/29], Loss: 1.0703\n",
      "Epoch [215/300], Step [3/29], Loss: 1.2217\n",
      "Epoch [215/300], Step [4/29], Loss: 1.0486\n",
      "Epoch [215/300], Step [5/29], Loss: 1.1431\n",
      "Epoch [215/300], Step [6/29], Loss: 0.9411\n",
      "Epoch [215/300], Step [7/29], Loss: 1.3318\n",
      "Epoch [215/300], Step [8/29], Loss: 1.2361\n",
      "Epoch [215/300], Step [9/29], Loss: 1.4431\n",
      "Epoch [215/300], Step [10/29], Loss: 1.2501\n",
      "Epoch [215/300], Step [11/29], Loss: 1.5820\n",
      "Epoch [215/300], Step [12/29], Loss: 1.1206\n",
      "Epoch [215/300], Step [13/29], Loss: 1.5133\n",
      "Epoch [215/300], Step [14/29], Loss: 1.2035\n",
      "Epoch [215/300], Step [15/29], Loss: 1.2097\n",
      "Epoch [215/300], Step [16/29], Loss: 1.6437\n",
      "Epoch [215/300], Step [17/29], Loss: 1.2182\n",
      "Epoch [215/300], Step [18/29], Loss: 1.3874\n",
      "Epoch [215/300], Step [19/29], Loss: 1.3134\n",
      "Epoch [215/300], Step [20/29], Loss: 1.3172\n",
      "Epoch [215/300], Step [21/29], Loss: 1.5200\n",
      "Epoch [215/300], Step [22/29], Loss: 1.2527\n",
      "Epoch [215/300], Step [23/29], Loss: 1.3363\n",
      "Epoch [215/300], Step [24/29], Loss: 1.4447\n",
      "Epoch [215/300], Step [25/29], Loss: 1.2723\n",
      "Epoch [215/300], Step [26/29], Loss: 1.0462\n",
      "Epoch [215/300], Step [27/29], Loss: 1.3872\n",
      "Epoch [215/300], Step [28/29], Loss: 1.5195\n",
      "Epoch [215/300], Step [29/29], Loss: 0.8485\n",
      "Epoch [216/300], Step [1/29], Loss: 1.4494\n",
      "Epoch [216/300], Step [2/29], Loss: 1.3465\n",
      "Epoch [216/300], Step [3/29], Loss: 1.5604\n",
      "Epoch [216/300], Step [4/29], Loss: 1.0738\n",
      "Epoch [216/300], Step [5/29], Loss: 1.4894\n",
      "Epoch [216/300], Step [6/29], Loss: 1.3118\n",
      "Epoch [216/300], Step [7/29], Loss: 1.3099\n",
      "Epoch [216/300], Step [8/29], Loss: 1.3999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [216/300], Step [9/29], Loss: 1.1838\n",
      "Epoch [216/300], Step [10/29], Loss: 1.3670\n",
      "Epoch [216/300], Step [11/29], Loss: 1.2311\n",
      "Epoch [216/300], Step [12/29], Loss: 1.1641\n",
      "Epoch [216/300], Step [13/29], Loss: 1.2886\n",
      "Epoch [216/300], Step [14/29], Loss: 1.1935\n",
      "Epoch [216/300], Step [15/29], Loss: 1.0566\n",
      "Epoch [216/300], Step [16/29], Loss: 1.1998\n",
      "Epoch [216/300], Step [17/29], Loss: 1.2052\n",
      "Epoch [216/300], Step [18/29], Loss: 1.1667\n",
      "Epoch [216/300], Step [19/29], Loss: 1.2746\n",
      "Epoch [216/300], Step [20/29], Loss: 1.2124\n",
      "Epoch [216/300], Step [21/29], Loss: 1.3275\n",
      "Epoch [216/300], Step [22/29], Loss: 1.2964\n",
      "Epoch [216/300], Step [23/29], Loss: 1.5802\n",
      "Epoch [216/300], Step [24/29], Loss: 1.2192\n",
      "Epoch [216/300], Step [25/29], Loss: 1.1686\n",
      "Epoch [216/300], Step [26/29], Loss: 1.5297\n",
      "Epoch [216/300], Step [27/29], Loss: 1.3799\n",
      "Epoch [216/300], Step [28/29], Loss: 1.3105\n",
      "Epoch [216/300], Step [29/29], Loss: 1.5365\n",
      "Epoch [217/300], Step [1/29], Loss: 1.3106\n",
      "Epoch [217/300], Step [2/29], Loss: 1.6307\n",
      "Epoch [217/300], Step [3/29], Loss: 1.4807\n",
      "Epoch [217/300], Step [4/29], Loss: 1.6019\n",
      "Epoch [217/300], Step [5/29], Loss: 1.4389\n",
      "Epoch [217/300], Step [6/29], Loss: 1.0215\n",
      "Epoch [217/300], Step [7/29], Loss: 1.2688\n",
      "Epoch [217/300], Step [8/29], Loss: 1.1308\n",
      "Epoch [217/300], Step [9/29], Loss: 1.0137\n",
      "Epoch [217/300], Step [10/29], Loss: 1.4467\n",
      "Epoch [217/300], Step [11/29], Loss: 1.2014\n",
      "Epoch [217/300], Step [12/29], Loss: 1.1866\n",
      "Epoch [217/300], Step [13/29], Loss: 1.4739\n",
      "Epoch [217/300], Step [14/29], Loss: 1.3070\n",
      "Epoch [217/300], Step [15/29], Loss: 1.2515\n",
      "Epoch [217/300], Step [16/29], Loss: 1.4672\n",
      "Epoch [217/300], Step [17/29], Loss: 1.5065\n",
      "Epoch [217/300], Step [18/29], Loss: 1.1024\n",
      "Epoch [217/300], Step [19/29], Loss: 1.1817\n",
      "Epoch [217/300], Step [20/29], Loss: 1.5839\n",
      "Epoch [217/300], Step [21/29], Loss: 1.2954\n",
      "Epoch [217/300], Step [22/29], Loss: 1.1979\n",
      "Epoch [217/300], Step [23/29], Loss: 1.2421\n",
      "Epoch [217/300], Step [24/29], Loss: 1.1964\n",
      "Epoch [217/300], Step [25/29], Loss: 1.4172\n",
      "Epoch [217/300], Step [26/29], Loss: 1.1955\n",
      "Epoch [217/300], Step [27/29], Loss: 1.0772\n",
      "Epoch [217/300], Step [28/29], Loss: 1.1160\n",
      "Epoch [217/300], Step [29/29], Loss: 1.8694\n",
      "Epoch [218/300], Step [1/29], Loss: 1.1657\n",
      "Epoch [218/300], Step [2/29], Loss: 1.2954\n",
      "Epoch [218/300], Step [3/29], Loss: 1.2165\n",
      "Epoch [218/300], Step [4/29], Loss: 1.2171\n",
      "Epoch [218/300], Step [5/29], Loss: 1.1391\n",
      "Epoch [218/300], Step [6/29], Loss: 1.3038\n",
      "Epoch [218/300], Step [7/29], Loss: 1.2439\n",
      "Epoch [218/300], Step [8/29], Loss: 1.1980\n",
      "Epoch [218/300], Step [9/29], Loss: 1.3534\n",
      "Epoch [218/300], Step [10/29], Loss: 1.1773\n",
      "Epoch [218/300], Step [11/29], Loss: 1.2669\n",
      "Epoch [218/300], Step [12/29], Loss: 1.5712\n",
      "Epoch [218/300], Step [13/29], Loss: 1.0938\n",
      "Epoch [218/300], Step [14/29], Loss: 1.2769\n",
      "Epoch [218/300], Step [15/29], Loss: 1.2715\n",
      "Epoch [218/300], Step [16/29], Loss: 1.5913\n",
      "Epoch [218/300], Step [17/29], Loss: 1.3141\n",
      "Epoch [218/300], Step [18/29], Loss: 1.0159\n",
      "Epoch [218/300], Step [19/29], Loss: 1.4608\n",
      "Epoch [218/300], Step [20/29], Loss: 1.0368\n",
      "Epoch [218/300], Step [21/29], Loss: 1.2834\n",
      "Epoch [218/300], Step [22/29], Loss: 1.4305\n",
      "Epoch [218/300], Step [23/29], Loss: 1.4352\n",
      "Epoch [218/300], Step [24/29], Loss: 1.5334\n",
      "Epoch [218/300], Step [25/29], Loss: 1.4322\n",
      "Epoch [218/300], Step [26/29], Loss: 1.5015\n",
      "Epoch [218/300], Step [27/29], Loss: 1.4367\n",
      "Epoch [218/300], Step [28/29], Loss: 1.1043\n",
      "Epoch [218/300], Step [29/29], Loss: 1.0816\n",
      "Epoch [219/300], Step [1/29], Loss: 1.2255\n",
      "Epoch [219/300], Step [2/29], Loss: 1.3537\n",
      "Epoch [219/300], Step [3/29], Loss: 1.0489\n",
      "Epoch [219/300], Step [4/29], Loss: 1.3679\n",
      "Epoch [219/300], Step [5/29], Loss: 1.3383\n",
      "Epoch [219/300], Step [6/29], Loss: 1.4395\n",
      "Epoch [219/300], Step [7/29], Loss: 1.1630\n",
      "Epoch [219/300], Step [8/29], Loss: 1.3370\n",
      "Epoch [219/300], Step [9/29], Loss: 1.3920\n",
      "Epoch [219/300], Step [10/29], Loss: 1.2342\n",
      "Epoch [219/300], Step [11/29], Loss: 1.5023\n",
      "Epoch [219/300], Step [12/29], Loss: 1.2525\n",
      "Epoch [219/300], Step [13/29], Loss: 1.3870\n",
      "Epoch [219/300], Step [14/29], Loss: 1.1454\n",
      "Epoch [219/300], Step [15/29], Loss: 1.2573\n",
      "Epoch [219/300], Step [16/29], Loss: 1.3547\n",
      "Epoch [219/300], Step [17/29], Loss: 1.1017\n",
      "Epoch [219/300], Step [18/29], Loss: 1.3972\n",
      "Epoch [219/300], Step [19/29], Loss: 0.9997\n",
      "Epoch [219/300], Step [20/29], Loss: 1.1645\n",
      "Epoch [219/300], Step [21/29], Loss: 1.4087\n",
      "Epoch [219/300], Step [22/29], Loss: 1.1061\n",
      "Epoch [219/300], Step [23/29], Loss: 1.2171\n",
      "Epoch [219/300], Step [24/29], Loss: 1.5647\n",
      "Epoch [219/300], Step [25/29], Loss: 1.1671\n",
      "Epoch [219/300], Step [26/29], Loss: 1.6763\n",
      "Epoch [219/300], Step [27/29], Loss: 1.1608\n",
      "Epoch [219/300], Step [28/29], Loss: 1.4290\n",
      "Epoch [219/300], Step [29/29], Loss: 1.3865\n",
      "Epoch [220/300], Step [1/29], Loss: 1.4011\n",
      "Epoch [220/300], Step [2/29], Loss: 1.1615\n",
      "Epoch [220/300], Step [3/29], Loss: 1.6348\n",
      "Epoch [220/300], Step [4/29], Loss: 1.3064\n",
      "Epoch [220/300], Step [5/29], Loss: 1.2483\n",
      "Epoch [220/300], Step [6/29], Loss: 1.0915\n",
      "Epoch [220/300], Step [7/29], Loss: 1.4054\n",
      "Epoch [220/300], Step [8/29], Loss: 1.2291\n",
      "Epoch [220/300], Step [9/29], Loss: 1.3760\n",
      "Epoch [220/300], Step [10/29], Loss: 1.6128\n",
      "Epoch [220/300], Step [11/29], Loss: 1.3249\n",
      "Epoch [220/300], Step [12/29], Loss: 1.2201\n",
      "Epoch [220/300], Step [13/29], Loss: 1.4227\n",
      "Epoch [220/300], Step [14/29], Loss: 1.2692\n",
      "Epoch [220/300], Step [15/29], Loss: 1.4584\n",
      "Epoch [220/300], Step [16/29], Loss: 1.3486\n",
      "Epoch [220/300], Step [17/29], Loss: 1.2216\n",
      "Epoch [220/300], Step [18/29], Loss: 1.3052\n",
      "Epoch [220/300], Step [19/29], Loss: 1.3666\n",
      "Epoch [220/300], Step [20/29], Loss: 1.1874\n",
      "Epoch [220/300], Step [21/29], Loss: 1.3099\n",
      "Epoch [220/300], Step [22/29], Loss: 1.0235\n",
      "Epoch [220/300], Step [23/29], Loss: 1.3646\n",
      "Epoch [220/300], Step [24/29], Loss: 1.0895\n",
      "Epoch [220/300], Step [25/29], Loss: 1.1758\n",
      "Epoch [220/300], Step [26/29], Loss: 1.2166\n",
      "Epoch [220/300], Step [27/29], Loss: 1.2623\n",
      "Epoch [220/300], Step [28/29], Loss: 1.2901\n",
      "Epoch [220/300], Step [29/29], Loss: 2.3455\n",
      "Epoch [221/300], Step [1/29], Loss: 1.4163\n",
      "Epoch [221/300], Step [2/29], Loss: 1.4754\n",
      "Epoch [221/300], Step [3/29], Loss: 1.1529\n",
      "Epoch [221/300], Step [4/29], Loss: 1.1409\n",
      "Epoch [221/300], Step [5/29], Loss: 1.3508\n",
      "Epoch [221/300], Step [6/29], Loss: 1.5513\n",
      "Epoch [221/300], Step [7/29], Loss: 1.4581\n",
      "Epoch [221/300], Step [8/29], Loss: 1.0977\n",
      "Epoch [221/300], Step [9/29], Loss: 1.4030\n",
      "Epoch [221/300], Step [10/29], Loss: 1.1661\n",
      "Epoch [221/300], Step [11/29], Loss: 1.2935\n",
      "Epoch [221/300], Step [12/29], Loss: 1.2751\n",
      "Epoch [221/300], Step [13/29], Loss: 1.0729\n",
      "Epoch [221/300], Step [14/29], Loss: 1.4041\n",
      "Epoch [221/300], Step [15/29], Loss: 1.3884\n",
      "Epoch [221/300], Step [16/29], Loss: 1.2105\n",
      "Epoch [221/300], Step [17/29], Loss: 1.1432\n",
      "Epoch [221/300], Step [18/29], Loss: 1.0865\n",
      "Epoch [221/300], Step [19/29], Loss: 1.3796\n",
      "Epoch [221/300], Step [20/29], Loss: 1.4638\n",
      "Epoch [221/300], Step [21/29], Loss: 1.3271\n",
      "Epoch [221/300], Step [22/29], Loss: 1.4783\n",
      "Epoch [221/300], Step [23/29], Loss: 1.2252\n",
      "Epoch [221/300], Step [24/29], Loss: 1.2111\n",
      "Epoch [221/300], Step [25/29], Loss: 1.3821\n",
      "Epoch [221/300], Step [26/29], Loss: 1.4386\n",
      "Epoch [221/300], Step [27/29], Loss: 1.2568\n",
      "Epoch [221/300], Step [28/29], Loss: 1.1272\n",
      "Epoch [221/300], Step [29/29], Loss: 1.1746\n",
      "Epoch [222/300], Step [1/29], Loss: 1.4420\n",
      "Epoch [222/300], Step [2/29], Loss: 1.1528\n",
      "Epoch [222/300], Step [3/29], Loss: 1.1707\n",
      "Epoch [222/300], Step [4/29], Loss: 1.3048\n",
      "Epoch [222/300], Step [5/29], Loss: 1.2927\n",
      "Epoch [222/300], Step [6/29], Loss: 1.2988\n",
      "Epoch [222/300], Step [7/29], Loss: 1.6268\n",
      "Epoch [222/300], Step [8/29], Loss: 1.2839\n",
      "Epoch [222/300], Step [9/29], Loss: 1.2195\n",
      "Epoch [222/300], Step [10/29], Loss: 1.4103\n",
      "Epoch [222/300], Step [11/29], Loss: 1.4063\n",
      "Epoch [222/300], Step [12/29], Loss: 1.6483\n",
      "Epoch [222/300], Step [13/29], Loss: 1.1472\n",
      "Epoch [222/300], Step [14/29], Loss: 1.1021\n",
      "Epoch [222/300], Step [15/29], Loss: 1.2677\n",
      "Epoch [222/300], Step [16/29], Loss: 1.3798\n",
      "Epoch [222/300], Step [17/29], Loss: 1.5076\n",
      "Epoch [222/300], Step [18/29], Loss: 1.0888\n",
      "Epoch [222/300], Step [19/29], Loss: 1.3636\n",
      "Epoch [222/300], Step [20/29], Loss: 1.3952\n",
      "Epoch [222/300], Step [21/29], Loss: 1.2569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [222/300], Step [22/29], Loss: 1.2581\n",
      "Epoch [222/300], Step [23/29], Loss: 1.1747\n",
      "Epoch [222/300], Step [24/29], Loss: 1.3432\n",
      "Epoch [222/300], Step [25/29], Loss: 1.0700\n",
      "Epoch [222/300], Step [26/29], Loss: 1.2552\n",
      "Epoch [222/300], Step [27/29], Loss: 1.3686\n",
      "Epoch [222/300], Step [28/29], Loss: 1.1828\n",
      "Epoch [222/300], Step [29/29], Loss: 0.4590\n",
      "Epoch [223/300], Step [1/29], Loss: 1.5392\n",
      "Epoch [223/300], Step [2/29], Loss: 1.1786\n",
      "Epoch [223/300], Step [3/29], Loss: 1.1199\n",
      "Epoch [223/300], Step [4/29], Loss: 1.1817\n",
      "Epoch [223/300], Step [5/29], Loss: 1.2532\n",
      "Epoch [223/300], Step [6/29], Loss: 1.1711\n",
      "Epoch [223/300], Step [7/29], Loss: 1.2500\n",
      "Epoch [223/300], Step [8/29], Loss: 1.5665\n",
      "Epoch [223/300], Step [9/29], Loss: 1.0636\n",
      "Epoch [223/300], Step [10/29], Loss: 1.0087\n",
      "Epoch [223/300], Step [11/29], Loss: 1.2252\n",
      "Epoch [223/300], Step [12/29], Loss: 1.3336\n",
      "Epoch [223/300], Step [13/29], Loss: 1.3779\n",
      "Epoch [223/300], Step [14/29], Loss: 1.3351\n",
      "Epoch [223/300], Step [15/29], Loss: 1.6410\n",
      "Epoch [223/300], Step [16/29], Loss: 1.2310\n",
      "Epoch [223/300], Step [17/29], Loss: 1.0376\n",
      "Epoch [223/300], Step [18/29], Loss: 1.4699\n",
      "Epoch [223/300], Step [19/29], Loss: 1.3902\n",
      "Epoch [223/300], Step [20/29], Loss: 1.0318\n",
      "Epoch [223/300], Step [21/29], Loss: 1.2232\n",
      "Epoch [223/300], Step [22/29], Loss: 1.2878\n",
      "Epoch [223/300], Step [23/29], Loss: 1.4547\n",
      "Epoch [223/300], Step [24/29], Loss: 1.5078\n",
      "Epoch [223/300], Step [25/29], Loss: 1.1716\n",
      "Epoch [223/300], Step [26/29], Loss: 1.2544\n",
      "Epoch [223/300], Step [27/29], Loss: 1.3084\n",
      "Epoch [223/300], Step [28/29], Loss: 1.2982\n",
      "Epoch [223/300], Step [29/29], Loss: 1.3036\n",
      "Epoch [224/300], Step [1/29], Loss: 1.2305\n",
      "Epoch [224/300], Step [2/29], Loss: 1.5686\n",
      "Epoch [224/300], Step [3/29], Loss: 1.3444\n",
      "Epoch [224/300], Step [4/29], Loss: 1.2500\n",
      "Epoch [224/300], Step [5/29], Loss: 1.2560\n",
      "Epoch [224/300], Step [6/29], Loss: 1.5352\n",
      "Epoch [224/300], Step [7/29], Loss: 1.1985\n",
      "Epoch [224/300], Step [8/29], Loss: 1.4052\n",
      "Epoch [224/300], Step [9/29], Loss: 1.4082\n",
      "Epoch [224/300], Step [10/29], Loss: 1.1972\n",
      "Epoch [224/300], Step [11/29], Loss: 1.5450\n",
      "Epoch [224/300], Step [12/29], Loss: 1.3975\n",
      "Epoch [224/300], Step [13/29], Loss: 1.1250\n",
      "Epoch [224/300], Step [14/29], Loss: 1.0924\n",
      "Epoch [224/300], Step [15/29], Loss: 1.3341\n",
      "Epoch [224/300], Step [16/29], Loss: 1.2180\n",
      "Epoch [224/300], Step [17/29], Loss: 1.2132\n",
      "Epoch [224/300], Step [18/29], Loss: 1.2414\n",
      "Epoch [224/300], Step [19/29], Loss: 1.3119\n",
      "Epoch [224/300], Step [20/29], Loss: 1.3298\n",
      "Epoch [224/300], Step [21/29], Loss: 1.1617\n",
      "Epoch [224/300], Step [22/29], Loss: 1.2388\n",
      "Epoch [224/300], Step [23/29], Loss: 1.2734\n",
      "Epoch [224/300], Step [24/29], Loss: 1.2329\n",
      "Epoch [224/300], Step [25/29], Loss: 1.1185\n",
      "Epoch [224/300], Step [26/29], Loss: 1.3449\n",
      "Epoch [224/300], Step [27/29], Loss: 1.1379\n",
      "Epoch [224/300], Step [28/29], Loss: 1.1326\n",
      "Epoch [224/300], Step [29/29], Loss: 1.3665\n",
      "Epoch [225/300], Step [1/29], Loss: 1.1810\n",
      "Epoch [225/300], Step [2/29], Loss: 0.9971\n",
      "Epoch [225/300], Step [3/29], Loss: 1.6344\n",
      "Epoch [225/300], Step [4/29], Loss: 1.5271\n",
      "Epoch [225/300], Step [5/29], Loss: 1.5392\n",
      "Epoch [225/300], Step [6/29], Loss: 1.2685\n",
      "Epoch [225/300], Step [7/29], Loss: 0.9733\n",
      "Epoch [225/300], Step [8/29], Loss: 1.5609\n",
      "Epoch [225/300], Step [9/29], Loss: 1.4773\n",
      "Epoch [225/300], Step [10/29], Loss: 1.3341\n",
      "Epoch [225/300], Step [11/29], Loss: 1.1372\n",
      "Epoch [225/300], Step [12/29], Loss: 1.2669\n",
      "Epoch [225/300], Step [13/29], Loss: 1.4577\n",
      "Epoch [225/300], Step [14/29], Loss: 1.2245\n",
      "Epoch [225/300], Step [15/29], Loss: 1.1657\n",
      "Epoch [225/300], Step [16/29], Loss: 1.2772\n",
      "Epoch [225/300], Step [17/29], Loss: 0.9889\n",
      "Epoch [225/300], Step [18/29], Loss: 1.0744\n",
      "Epoch [225/300], Step [19/29], Loss: 1.3832\n",
      "Epoch [225/300], Step [20/29], Loss: 1.4919\n",
      "Epoch [225/300], Step [21/29], Loss: 1.5394\n",
      "Epoch [225/300], Step [22/29], Loss: 1.3479\n",
      "Epoch [225/300], Step [23/29], Loss: 1.1960\n",
      "Epoch [225/300], Step [24/29], Loss: 1.3080\n",
      "Epoch [225/300], Step [25/29], Loss: 1.2093\n",
      "Epoch [225/300], Step [26/29], Loss: 1.3324\n",
      "Epoch [225/300], Step [27/29], Loss: 1.4959\n",
      "Epoch [225/300], Step [28/29], Loss: 1.2087\n",
      "Epoch [225/300], Step [29/29], Loss: 1.2083\n",
      "Epoch [226/300], Step [1/29], Loss: 1.3488\n",
      "Epoch [226/300], Step [2/29], Loss: 1.4903\n",
      "Epoch [226/300], Step [3/29], Loss: 1.1769\n",
      "Epoch [226/300], Step [4/29], Loss: 1.0512\n",
      "Epoch [226/300], Step [5/29], Loss: 1.0771\n",
      "Epoch [226/300], Step [6/29], Loss: 1.1476\n",
      "Epoch [226/300], Step [7/29], Loss: 1.3757\n",
      "Epoch [226/300], Step [8/29], Loss: 1.3816\n",
      "Epoch [226/300], Step [9/29], Loss: 1.5464\n",
      "Epoch [226/300], Step [10/29], Loss: 1.2529\n",
      "Epoch [226/300], Step [11/29], Loss: 1.0857\n",
      "Epoch [226/300], Step [12/29], Loss: 1.1511\n",
      "Epoch [226/300], Step [13/29], Loss: 1.2958\n",
      "Epoch [226/300], Step [14/29], Loss: 1.3147\n",
      "Epoch [226/300], Step [15/29], Loss: 1.2432\n",
      "Epoch [226/300], Step [16/29], Loss: 1.3351\n",
      "Epoch [226/300], Step [17/29], Loss: 1.3302\n",
      "Epoch [226/300], Step [18/29], Loss: 1.1588\n",
      "Epoch [226/300], Step [19/29], Loss: 1.5487\n",
      "Epoch [226/300], Step [20/29], Loss: 1.2341\n",
      "Epoch [226/300], Step [21/29], Loss: 1.5239\n",
      "Epoch [226/300], Step [22/29], Loss: 1.2122\n",
      "Epoch [226/300], Step [23/29], Loss: 1.1872\n",
      "Epoch [226/300], Step [24/29], Loss: 1.2502\n",
      "Epoch [226/300], Step [25/29], Loss: 1.1716\n",
      "Epoch [226/300], Step [26/29], Loss: 1.2584\n",
      "Epoch [226/300], Step [27/29], Loss: 1.3142\n",
      "Epoch [226/300], Step [28/29], Loss: 1.4172\n",
      "Epoch [226/300], Step [29/29], Loss: 1.6741\n",
      "Epoch [227/300], Step [1/29], Loss: 1.5123\n",
      "Epoch [227/300], Step [2/29], Loss: 1.1369\n",
      "Epoch [227/300], Step [3/29], Loss: 1.5651\n",
      "Epoch [227/300], Step [4/29], Loss: 1.3571\n",
      "Epoch [227/300], Step [5/29], Loss: 1.2913\n",
      "Epoch [227/300], Step [6/29], Loss: 1.3576\n",
      "Epoch [227/300], Step [7/29], Loss: 1.2487\n",
      "Epoch [227/300], Step [8/29], Loss: 1.5053\n",
      "Epoch [227/300], Step [9/29], Loss: 1.2698\n",
      "Epoch [227/300], Step [10/29], Loss: 1.1332\n",
      "Epoch [227/300], Step [11/29], Loss: 1.2459\n",
      "Epoch [227/300], Step [12/29], Loss: 1.2513\n",
      "Epoch [227/300], Step [13/29], Loss: 1.2811\n",
      "Epoch [227/300], Step [14/29], Loss: 1.3747\n",
      "Epoch [227/300], Step [15/29], Loss: 1.5067\n",
      "Epoch [227/300], Step [16/29], Loss: 1.4920\n",
      "Epoch [227/300], Step [17/29], Loss: 0.9994\n",
      "Epoch [227/300], Step [18/29], Loss: 1.4259\n",
      "Epoch [227/300], Step [19/29], Loss: 1.4157\n",
      "Epoch [227/300], Step [20/29], Loss: 1.1268\n",
      "Epoch [227/300], Step [21/29], Loss: 0.9966\n",
      "Epoch [227/300], Step [22/29], Loss: 1.0737\n",
      "Epoch [227/300], Step [23/29], Loss: 1.4797\n",
      "Epoch [227/300], Step [24/29], Loss: 1.2727\n",
      "Epoch [227/300], Step [25/29], Loss: 1.2817\n",
      "Epoch [227/300], Step [26/29], Loss: 1.3190\n",
      "Epoch [227/300], Step [27/29], Loss: 1.3577\n",
      "Epoch [227/300], Step [28/29], Loss: 0.9047\n",
      "Epoch [227/300], Step [29/29], Loss: 0.9963\n",
      "Epoch [228/300], Step [1/29], Loss: 1.4833\n",
      "Epoch [228/300], Step [2/29], Loss: 1.2753\n",
      "Epoch [228/300], Step [3/29], Loss: 1.2518\n",
      "Epoch [228/300], Step [4/29], Loss: 1.0741\n",
      "Epoch [228/300], Step [5/29], Loss: 1.2956\n",
      "Epoch [228/300], Step [6/29], Loss: 1.3134\n",
      "Epoch [228/300], Step [7/29], Loss: 1.1926\n",
      "Epoch [228/300], Step [8/29], Loss: 1.2720\n",
      "Epoch [228/300], Step [9/29], Loss: 1.3761\n",
      "Epoch [228/300], Step [10/29], Loss: 1.2173\n",
      "Epoch [228/300], Step [11/29], Loss: 1.3521\n",
      "Epoch [228/300], Step [12/29], Loss: 1.3425\n",
      "Epoch [228/300], Step [13/29], Loss: 1.3658\n",
      "Epoch [228/300], Step [14/29], Loss: 1.5264\n",
      "Epoch [228/300], Step [15/29], Loss: 1.2166\n",
      "Epoch [228/300], Step [16/29], Loss: 1.4010\n",
      "Epoch [228/300], Step [17/29], Loss: 1.2485\n",
      "Epoch [228/300], Step [18/29], Loss: 1.3013\n",
      "Epoch [228/300], Step [19/29], Loss: 1.4518\n",
      "Epoch [228/300], Step [20/29], Loss: 1.4303\n",
      "Epoch [228/300], Step [21/29], Loss: 1.4822\n",
      "Epoch [228/300], Step [22/29], Loss: 1.2338\n",
      "Epoch [228/300], Step [23/29], Loss: 1.1382\n",
      "Epoch [228/300], Step [24/29], Loss: 1.0255\n",
      "Epoch [228/300], Step [25/29], Loss: 1.0999\n",
      "Epoch [228/300], Step [26/29], Loss: 1.2893\n",
      "Epoch [228/300], Step [27/29], Loss: 1.3080\n",
      "Epoch [228/300], Step [28/29], Loss: 1.4921\n",
      "Epoch [228/300], Step [29/29], Loss: 1.5279\n",
      "Epoch [229/300], Step [1/29], Loss: 1.4752\n",
      "Epoch [229/300], Step [2/29], Loss: 1.1931\n",
      "Epoch [229/300], Step [3/29], Loss: 1.2297\n",
      "Epoch [229/300], Step [4/29], Loss: 1.3456\n",
      "Epoch [229/300], Step [5/29], Loss: 1.5336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [229/300], Step [6/29], Loss: 1.0940\n",
      "Epoch [229/300], Step [7/29], Loss: 1.2653\n",
      "Epoch [229/300], Step [8/29], Loss: 1.4643\n",
      "Epoch [229/300], Step [9/29], Loss: 1.4295\n",
      "Epoch [229/300], Step [10/29], Loss: 1.2774\n",
      "Epoch [229/300], Step [11/29], Loss: 1.3506\n",
      "Epoch [229/300], Step [12/29], Loss: 1.4138\n",
      "Epoch [229/300], Step [13/29], Loss: 1.4861\n",
      "Epoch [229/300], Step [14/29], Loss: 1.0229\n",
      "Epoch [229/300], Step [15/29], Loss: 1.2208\n",
      "Epoch [229/300], Step [16/29], Loss: 1.1004\n",
      "Epoch [229/300], Step [17/29], Loss: 1.1139\n",
      "Epoch [229/300], Step [18/29], Loss: 1.2877\n",
      "Epoch [229/300], Step [19/29], Loss: 1.2914\n",
      "Epoch [229/300], Step [20/29], Loss: 1.4703\n",
      "Epoch [229/300], Step [21/29], Loss: 1.6511\n",
      "Epoch [229/300], Step [22/29], Loss: 1.2466\n",
      "Epoch [229/300], Step [23/29], Loss: 1.2128\n",
      "Epoch [229/300], Step [24/29], Loss: 1.3681\n",
      "Epoch [229/300], Step [25/29], Loss: 1.3292\n",
      "Epoch [229/300], Step [26/29], Loss: 1.1774\n",
      "Epoch [229/300], Step [27/29], Loss: 1.2425\n",
      "Epoch [229/300], Step [28/29], Loss: 1.1632\n",
      "Epoch [229/300], Step [29/29], Loss: 1.9008\n",
      "Epoch [230/300], Step [1/29], Loss: 1.1157\n",
      "Epoch [230/300], Step [2/29], Loss: 1.4521\n",
      "Epoch [230/300], Step [3/29], Loss: 1.5074\n",
      "Epoch [230/300], Step [4/29], Loss: 1.2171\n",
      "Epoch [230/300], Step [5/29], Loss: 1.3688\n",
      "Epoch [230/300], Step [6/29], Loss: 1.4601\n",
      "Epoch [230/300], Step [7/29], Loss: 1.3961\n",
      "Epoch [230/300], Step [8/29], Loss: 1.3800\n",
      "Epoch [230/300], Step [9/29], Loss: 1.3107\n",
      "Epoch [230/300], Step [10/29], Loss: 1.2231\n",
      "Epoch [230/300], Step [11/29], Loss: 1.2035\n",
      "Epoch [230/300], Step [12/29], Loss: 1.0552\n",
      "Epoch [230/300], Step [13/29], Loss: 1.5884\n",
      "Epoch [230/300], Step [14/29], Loss: 1.4810\n",
      "Epoch [230/300], Step [15/29], Loss: 1.4133\n",
      "Epoch [230/300], Step [16/29], Loss: 1.1493\n",
      "Epoch [230/300], Step [17/29], Loss: 0.9910\n",
      "Epoch [230/300], Step [18/29], Loss: 1.2391\n",
      "Epoch [230/300], Step [19/29], Loss: 0.9081\n",
      "Epoch [230/300], Step [20/29], Loss: 1.3849\n",
      "Epoch [230/300], Step [21/29], Loss: 1.2336\n",
      "Epoch [230/300], Step [22/29], Loss: 1.1801\n",
      "Epoch [230/300], Step [23/29], Loss: 1.3993\n",
      "Epoch [230/300], Step [24/29], Loss: 1.2380\n",
      "Epoch [230/300], Step [25/29], Loss: 1.1958\n",
      "Epoch [230/300], Step [26/29], Loss: 1.2569\n",
      "Epoch [230/300], Step [27/29], Loss: 1.3695\n",
      "Epoch [230/300], Step [28/29], Loss: 1.4623\n",
      "Epoch [230/300], Step [29/29], Loss: 1.7548\n",
      "Epoch [231/300], Step [1/29], Loss: 1.3403\n",
      "Epoch [231/300], Step [2/29], Loss: 1.3833\n",
      "Epoch [231/300], Step [3/29], Loss: 1.4748\n",
      "Epoch [231/300], Step [4/29], Loss: 1.5584\n",
      "Epoch [231/300], Step [5/29], Loss: 1.0417\n",
      "Epoch [231/300], Step [6/29], Loss: 1.5084\n",
      "Epoch [231/300], Step [7/29], Loss: 1.1143\n",
      "Epoch [231/300], Step [8/29], Loss: 1.4673\n",
      "Epoch [231/300], Step [9/29], Loss: 1.2699\n",
      "Epoch [231/300], Step [10/29], Loss: 1.2682\n",
      "Epoch [231/300], Step [11/29], Loss: 1.6227\n",
      "Epoch [231/300], Step [12/29], Loss: 1.4005\n",
      "Epoch [231/300], Step [13/29], Loss: 1.2849\n",
      "Epoch [231/300], Step [14/29], Loss: 1.4943\n",
      "Epoch [231/300], Step [15/29], Loss: 1.1118\n",
      "Epoch [231/300], Step [16/29], Loss: 1.2638\n",
      "Epoch [231/300], Step [17/29], Loss: 1.0499\n",
      "Epoch [231/300], Step [18/29], Loss: 1.2066\n",
      "Epoch [231/300], Step [19/29], Loss: 1.1620\n",
      "Epoch [231/300], Step [20/29], Loss: 1.2932\n",
      "Epoch [231/300], Step [21/29], Loss: 1.5829\n",
      "Epoch [231/300], Step [22/29], Loss: 1.3368\n",
      "Epoch [231/300], Step [23/29], Loss: 1.2295\n",
      "Epoch [231/300], Step [24/29], Loss: 1.3264\n",
      "Epoch [231/300], Step [25/29], Loss: 1.2452\n",
      "Epoch [231/300], Step [26/29], Loss: 1.2496\n",
      "Epoch [231/300], Step [27/29], Loss: 1.4077\n",
      "Epoch [231/300], Step [28/29], Loss: 1.1422\n",
      "Epoch [231/300], Step [29/29], Loss: 0.4474\n",
      "Epoch [232/300], Step [1/29], Loss: 1.2856\n",
      "Epoch [232/300], Step [2/29], Loss: 1.3903\n",
      "Epoch [232/300], Step [3/29], Loss: 1.4570\n",
      "Epoch [232/300], Step [4/29], Loss: 1.3741\n",
      "Epoch [232/300], Step [5/29], Loss: 1.2103\n",
      "Epoch [232/300], Step [6/29], Loss: 1.4253\n",
      "Epoch [232/300], Step [7/29], Loss: 1.2662\n",
      "Epoch [232/300], Step [8/29], Loss: 1.3520\n",
      "Epoch [232/300], Step [9/29], Loss: 1.2724\n",
      "Epoch [232/300], Step [10/29], Loss: 1.2985\n",
      "Epoch [232/300], Step [11/29], Loss: 1.3131\n",
      "Epoch [232/300], Step [12/29], Loss: 1.2033\n",
      "Epoch [232/300], Step [13/29], Loss: 1.3361\n",
      "Epoch [232/300], Step [14/29], Loss: 1.0417\n",
      "Epoch [232/300], Step [15/29], Loss: 1.3375\n",
      "Epoch [232/300], Step [16/29], Loss: 1.2532\n",
      "Epoch [232/300], Step [17/29], Loss: 1.2819\n",
      "Epoch [232/300], Step [18/29], Loss: 1.3729\n",
      "Epoch [232/300], Step [19/29], Loss: 1.3238\n",
      "Epoch [232/300], Step [20/29], Loss: 1.2997\n",
      "Epoch [232/300], Step [21/29], Loss: 1.3120\n",
      "Epoch [232/300], Step [22/29], Loss: 1.1922\n",
      "Epoch [232/300], Step [23/29], Loss: 1.1117\n",
      "Epoch [232/300], Step [24/29], Loss: 1.4796\n",
      "Epoch [232/300], Step [25/29], Loss: 1.3410\n",
      "Epoch [232/300], Step [26/29], Loss: 1.4033\n",
      "Epoch [232/300], Step [27/29], Loss: 1.1664\n",
      "Epoch [232/300], Step [28/29], Loss: 1.4499\n",
      "Epoch [232/300], Step [29/29], Loss: 1.1294\n",
      "Epoch [233/300], Step [1/29], Loss: 1.2085\n",
      "Epoch [233/300], Step [2/29], Loss: 1.2163\n",
      "Epoch [233/300], Step [3/29], Loss: 1.3417\n",
      "Epoch [233/300], Step [4/29], Loss: 1.4213\n",
      "Epoch [233/300], Step [5/29], Loss: 1.3480\n",
      "Epoch [233/300], Step [6/29], Loss: 1.1647\n",
      "Epoch [233/300], Step [7/29], Loss: 1.3095\n",
      "Epoch [233/300], Step [8/29], Loss: 1.2086\n",
      "Epoch [233/300], Step [9/29], Loss: 1.2279\n",
      "Epoch [233/300], Step [10/29], Loss: 1.5167\n",
      "Epoch [233/300], Step [11/29], Loss: 0.9688\n",
      "Epoch [233/300], Step [12/29], Loss: 1.4085\n",
      "Epoch [233/300], Step [13/29], Loss: 1.2201\n",
      "Epoch [233/300], Step [14/29], Loss: 1.1911\n",
      "Epoch [233/300], Step [15/29], Loss: 1.4268\n",
      "Epoch [233/300], Step [16/29], Loss: 1.4141\n",
      "Epoch [233/300], Step [17/29], Loss: 1.2005\n",
      "Epoch [233/300], Step [18/29], Loss: 1.0426\n",
      "Epoch [233/300], Step [19/29], Loss: 1.1977\n",
      "Epoch [233/300], Step [20/29], Loss: 1.2805\n",
      "Epoch [233/300], Step [21/29], Loss: 1.1373\n",
      "Epoch [233/300], Step [22/29], Loss: 1.4591\n",
      "Epoch [233/300], Step [23/29], Loss: 1.4774\n",
      "Epoch [233/300], Step [24/29], Loss: 1.2557\n",
      "Epoch [233/300], Step [25/29], Loss: 1.3223\n",
      "Epoch [233/300], Step [26/29], Loss: 1.3337\n",
      "Epoch [233/300], Step [27/29], Loss: 1.3791\n",
      "Epoch [233/300], Step [28/29], Loss: 1.3017\n",
      "Epoch [233/300], Step [29/29], Loss: 2.1669\n",
      "Epoch [234/300], Step [1/29], Loss: 1.2677\n",
      "Epoch [234/300], Step [2/29], Loss: 1.4366\n",
      "Epoch [234/300], Step [3/29], Loss: 1.3122\n",
      "Epoch [234/300], Step [4/29], Loss: 1.3478\n",
      "Epoch [234/300], Step [5/29], Loss: 1.2169\n",
      "Epoch [234/300], Step [6/29], Loss: 1.3477\n",
      "Epoch [234/300], Step [7/29], Loss: 1.3887\n",
      "Epoch [234/300], Step [8/29], Loss: 1.2868\n",
      "Epoch [234/300], Step [9/29], Loss: 1.2919\n",
      "Epoch [234/300], Step [10/29], Loss: 1.2789\n",
      "Epoch [234/300], Step [11/29], Loss: 1.2832\n",
      "Epoch [234/300], Step [12/29], Loss: 1.3260\n",
      "Epoch [234/300], Step [13/29], Loss: 1.1893\n",
      "Epoch [234/300], Step [14/29], Loss: 1.3794\n",
      "Epoch [234/300], Step [15/29], Loss: 1.4021\n",
      "Epoch [234/300], Step [16/29], Loss: 1.0929\n",
      "Epoch [234/300], Step [17/29], Loss: 1.1906\n",
      "Epoch [234/300], Step [18/29], Loss: 1.1876\n",
      "Epoch [234/300], Step [19/29], Loss: 1.0110\n",
      "Epoch [234/300], Step [20/29], Loss: 1.1837\n",
      "Epoch [234/300], Step [21/29], Loss: 1.5652\n",
      "Epoch [234/300], Step [22/29], Loss: 1.2040\n",
      "Epoch [234/300], Step [23/29], Loss: 1.4972\n",
      "Epoch [234/300], Step [24/29], Loss: 1.3754\n",
      "Epoch [234/300], Step [25/29], Loss: 1.3857\n",
      "Epoch [234/300], Step [26/29], Loss: 1.3334\n",
      "Epoch [234/300], Step [27/29], Loss: 1.3924\n",
      "Epoch [234/300], Step [28/29], Loss: 1.1545\n",
      "Epoch [234/300], Step [29/29], Loss: 0.8238\n",
      "Epoch [235/300], Step [1/29], Loss: 1.1872\n",
      "Epoch [235/300], Step [2/29], Loss: 1.5041\n",
      "Epoch [235/300], Step [3/29], Loss: 1.3975\n",
      "Epoch [235/300], Step [4/29], Loss: 1.4735\n",
      "Epoch [235/300], Step [5/29], Loss: 1.2764\n",
      "Epoch [235/300], Step [6/29], Loss: 1.2177\n",
      "Epoch [235/300], Step [7/29], Loss: 1.3827\n",
      "Epoch [235/300], Step [8/29], Loss: 1.3621\n",
      "Epoch [235/300], Step [9/29], Loss: 1.4298\n",
      "Epoch [235/300], Step [10/29], Loss: 1.5894\n",
      "Epoch [235/300], Step [11/29], Loss: 1.1311\n",
      "Epoch [235/300], Step [12/29], Loss: 1.1813\n",
      "Epoch [235/300], Step [13/29], Loss: 1.2407\n",
      "Epoch [235/300], Step [14/29], Loss: 1.1560\n",
      "Epoch [235/300], Step [15/29], Loss: 1.3296\n",
      "Epoch [235/300], Step [16/29], Loss: 1.2859\n",
      "Epoch [235/300], Step [17/29], Loss: 1.0432\n",
      "Epoch [235/300], Step [18/29], Loss: 1.5750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [235/300], Step [19/29], Loss: 1.2613\n",
      "Epoch [235/300], Step [20/29], Loss: 1.3667\n",
      "Epoch [235/300], Step [21/29], Loss: 1.4742\n",
      "Epoch [235/300], Step [22/29], Loss: 1.1259\n",
      "Epoch [235/300], Step [23/29], Loss: 1.2815\n",
      "Epoch [235/300], Step [24/29], Loss: 1.3643\n",
      "Epoch [235/300], Step [25/29], Loss: 1.2243\n",
      "Epoch [235/300], Step [26/29], Loss: 1.0213\n",
      "Epoch [235/300], Step [27/29], Loss: 1.1225\n",
      "Epoch [235/300], Step [28/29], Loss: 1.0960\n",
      "Epoch [235/300], Step [29/29], Loss: 3.3988\n",
      "Epoch [236/300], Step [1/29], Loss: 1.2645\n",
      "Epoch [236/300], Step [2/29], Loss: 0.9422\n",
      "Epoch [236/300], Step [3/29], Loss: 1.5384\n",
      "Epoch [236/300], Step [4/29], Loss: 1.4745\n",
      "Epoch [236/300], Step [5/29], Loss: 1.4195\n",
      "Epoch [236/300], Step [6/29], Loss: 1.5169\n",
      "Epoch [236/300], Step [7/29], Loss: 1.2121\n",
      "Epoch [236/300], Step [8/29], Loss: 1.1550\n",
      "Epoch [236/300], Step [9/29], Loss: 1.3383\n",
      "Epoch [236/300], Step [10/29], Loss: 1.2096\n",
      "Epoch [236/300], Step [11/29], Loss: 1.3707\n",
      "Epoch [236/300], Step [12/29], Loss: 1.1633\n",
      "Epoch [236/300], Step [13/29], Loss: 1.1916\n",
      "Epoch [236/300], Step [14/29], Loss: 1.3223\n",
      "Epoch [236/300], Step [15/29], Loss: 1.3095\n",
      "Epoch [236/300], Step [16/29], Loss: 0.9318\n",
      "Epoch [236/300], Step [17/29], Loss: 1.4195\n",
      "Epoch [236/300], Step [18/29], Loss: 1.2255\n",
      "Epoch [236/300], Step [19/29], Loss: 1.5490\n",
      "Epoch [236/300], Step [20/29], Loss: 1.2810\n",
      "Epoch [236/300], Step [21/29], Loss: 1.3361\n",
      "Epoch [236/300], Step [22/29], Loss: 1.2557\n",
      "Epoch [236/300], Step [23/29], Loss: 1.2398\n",
      "Epoch [236/300], Step [24/29], Loss: 1.2585\n",
      "Epoch [236/300], Step [25/29], Loss: 1.5605\n",
      "Epoch [236/300], Step [26/29], Loss: 1.1476\n",
      "Epoch [236/300], Step [27/29], Loss: 1.1895\n",
      "Epoch [236/300], Step [28/29], Loss: 1.1443\n",
      "Epoch [236/300], Step [29/29], Loss: 2.4697\n",
      "Epoch [237/300], Step [1/29], Loss: 1.3578\n",
      "Epoch [237/300], Step [2/29], Loss: 1.1935\n",
      "Epoch [237/300], Step [3/29], Loss: 1.2849\n",
      "Epoch [237/300], Step [4/29], Loss: 1.3182\n",
      "Epoch [237/300], Step [5/29], Loss: 1.2365\n",
      "Epoch [237/300], Step [6/29], Loss: 1.3411\n",
      "Epoch [237/300], Step [7/29], Loss: 1.3616\n",
      "Epoch [237/300], Step [8/29], Loss: 1.2450\n",
      "Epoch [237/300], Step [9/29], Loss: 1.0692\n",
      "Epoch [237/300], Step [10/29], Loss: 1.4167\n",
      "Epoch [237/300], Step [11/29], Loss: 1.3765\n",
      "Epoch [237/300], Step [12/29], Loss: 1.2690\n",
      "Epoch [237/300], Step [13/29], Loss: 1.3154\n",
      "Epoch [237/300], Step [14/29], Loss: 1.2030\n",
      "Epoch [237/300], Step [15/29], Loss: 1.2719\n",
      "Epoch [237/300], Step [16/29], Loss: 1.1969\n",
      "Epoch [237/300], Step [17/29], Loss: 0.8479\n",
      "Epoch [237/300], Step [18/29], Loss: 1.3326\n",
      "Epoch [237/300], Step [19/29], Loss: 1.1449\n",
      "Epoch [237/300], Step [20/29], Loss: 1.1620\n",
      "Epoch [237/300], Step [21/29], Loss: 1.1874\n",
      "Epoch [237/300], Step [22/29], Loss: 1.4662\n",
      "Epoch [237/300], Step [23/29], Loss: 1.3487\n",
      "Epoch [237/300], Step [24/29], Loss: 1.6779\n",
      "Epoch [237/300], Step [25/29], Loss: 0.9482\n",
      "Epoch [237/300], Step [26/29], Loss: 1.4421\n",
      "Epoch [237/300], Step [27/29], Loss: 1.4946\n",
      "Epoch [237/300], Step [28/29], Loss: 1.4238\n",
      "Epoch [237/300], Step [29/29], Loss: 0.8764\n",
      "Epoch [238/300], Step [1/29], Loss: 1.3668\n",
      "Epoch [238/300], Step [2/29], Loss: 1.2082\n",
      "Epoch [238/300], Step [3/29], Loss: 1.1764\n",
      "Epoch [238/300], Step [4/29], Loss: 1.2836\n",
      "Epoch [238/300], Step [5/29], Loss: 1.2487\n",
      "Epoch [238/300], Step [6/29], Loss: 1.3460\n",
      "Epoch [238/300], Step [7/29], Loss: 1.2508\n",
      "Epoch [238/300], Step [8/29], Loss: 1.2869\n",
      "Epoch [238/300], Step [9/29], Loss: 1.2998\n",
      "Epoch [238/300], Step [10/29], Loss: 1.3164\n",
      "Epoch [238/300], Step [11/29], Loss: 1.5125\n",
      "Epoch [238/300], Step [12/29], Loss: 1.3343\n",
      "Epoch [238/300], Step [13/29], Loss: 1.5728\n",
      "Epoch [238/300], Step [14/29], Loss: 1.0065\n",
      "Epoch [238/300], Step [15/29], Loss: 1.6963\n",
      "Epoch [238/300], Step [16/29], Loss: 1.2719\n",
      "Epoch [238/300], Step [17/29], Loss: 1.3641\n",
      "Epoch [238/300], Step [18/29], Loss: 1.2609\n",
      "Epoch [238/300], Step [19/29], Loss: 1.1503\n",
      "Epoch [238/300], Step [20/29], Loss: 1.3051\n",
      "Epoch [238/300], Step [21/29], Loss: 1.2776\n",
      "Epoch [238/300], Step [22/29], Loss: 1.4775\n",
      "Epoch [238/300], Step [23/29], Loss: 1.2186\n",
      "Epoch [238/300], Step [24/29], Loss: 1.3715\n",
      "Epoch [238/300], Step [25/29], Loss: 1.2272\n",
      "Epoch [238/300], Step [26/29], Loss: 1.3461\n",
      "Epoch [238/300], Step [27/29], Loss: 1.2162\n",
      "Epoch [238/300], Step [28/29], Loss: 1.0651\n",
      "Epoch [238/300], Step [29/29], Loss: 1.4459\n",
      "Epoch [239/300], Step [1/29], Loss: 1.5708\n",
      "Epoch [239/300], Step [2/29], Loss: 1.2011\n",
      "Epoch [239/300], Step [3/29], Loss: 1.3205\n",
      "Epoch [239/300], Step [4/29], Loss: 1.0040\n",
      "Epoch [239/300], Step [5/29], Loss: 0.9777\n",
      "Epoch [239/300], Step [6/29], Loss: 1.5622\n",
      "Epoch [239/300], Step [7/29], Loss: 1.1403\n",
      "Epoch [239/300], Step [8/29], Loss: 1.4890\n",
      "Epoch [239/300], Step [9/29], Loss: 1.0363\n",
      "Epoch [239/300], Step [10/29], Loss: 1.3067\n",
      "Epoch [239/300], Step [11/29], Loss: 1.5177\n",
      "Epoch [239/300], Step [12/29], Loss: 1.2328\n",
      "Epoch [239/300], Step [13/29], Loss: 1.3513\n",
      "Epoch [239/300], Step [14/29], Loss: 1.1849\n",
      "Epoch [239/300], Step [15/29], Loss: 1.0535\n",
      "Epoch [239/300], Step [16/29], Loss: 1.3246\n",
      "Epoch [239/300], Step [17/29], Loss: 1.2895\n",
      "Epoch [239/300], Step [18/29], Loss: 1.5131\n",
      "Epoch [239/300], Step [19/29], Loss: 1.3273\n",
      "Epoch [239/300], Step [20/29], Loss: 1.0520\n",
      "Epoch [239/300], Step [21/29], Loss: 1.5375\n",
      "Epoch [239/300], Step [22/29], Loss: 1.0765\n",
      "Epoch [239/300], Step [23/29], Loss: 1.3023\n",
      "Epoch [239/300], Step [24/29], Loss: 1.4804\n",
      "Epoch [239/300], Step [25/29], Loss: 1.4747\n",
      "Epoch [239/300], Step [26/29], Loss: 1.3743\n",
      "Epoch [239/300], Step [27/29], Loss: 1.2073\n",
      "Epoch [239/300], Step [28/29], Loss: 1.3481\n",
      "Epoch [239/300], Step [29/29], Loss: 1.9600\n",
      "Epoch [240/300], Step [1/29], Loss: 1.2443\n",
      "Epoch [240/300], Step [2/29], Loss: 1.4316\n",
      "Epoch [240/300], Step [3/29], Loss: 1.3219\n",
      "Epoch [240/300], Step [4/29], Loss: 1.3215\n",
      "Epoch [240/300], Step [5/29], Loss: 1.2893\n",
      "Epoch [240/300], Step [6/29], Loss: 1.0912\n",
      "Epoch [240/300], Step [7/29], Loss: 1.0633\n",
      "Epoch [240/300], Step [8/29], Loss: 1.2361\n",
      "Epoch [240/300], Step [9/29], Loss: 1.3332\n",
      "Epoch [240/300], Step [10/29], Loss: 1.1841\n",
      "Epoch [240/300], Step [11/29], Loss: 1.2720\n",
      "Epoch [240/300], Step [12/29], Loss: 1.2002\n",
      "Epoch [240/300], Step [13/29], Loss: 1.2596\n",
      "Epoch [240/300], Step [14/29], Loss: 1.3129\n",
      "Epoch [240/300], Step [15/29], Loss: 1.4928\n",
      "Epoch [240/300], Step [16/29], Loss: 1.2139\n",
      "Epoch [240/300], Step [17/29], Loss: 1.1496\n",
      "Epoch [240/300], Step [18/29], Loss: 1.2604\n",
      "Epoch [240/300], Step [19/29], Loss: 1.2462\n",
      "Epoch [240/300], Step [20/29], Loss: 1.2990\n",
      "Epoch [240/300], Step [21/29], Loss: 1.2089\n",
      "Epoch [240/300], Step [22/29], Loss: 1.2473\n",
      "Epoch [240/300], Step [23/29], Loss: 1.0744\n",
      "Epoch [240/300], Step [24/29], Loss: 1.2491\n",
      "Epoch [240/300], Step [25/29], Loss: 1.3735\n",
      "Epoch [240/300], Step [26/29], Loss: 1.3529\n",
      "Epoch [240/300], Step [27/29], Loss: 1.4701\n",
      "Epoch [240/300], Step [28/29], Loss: 1.4684\n",
      "Epoch [240/300], Step [29/29], Loss: 1.2915\n",
      "Epoch [241/300], Step [1/29], Loss: 1.5121\n",
      "Epoch [241/300], Step [2/29], Loss: 1.0360\n",
      "Epoch [241/300], Step [3/29], Loss: 1.5268\n",
      "Epoch [241/300], Step [4/29], Loss: 1.2416\n",
      "Epoch [241/300], Step [5/29], Loss: 1.2460\n",
      "Epoch [241/300], Step [6/29], Loss: 1.3217\n",
      "Epoch [241/300], Step [7/29], Loss: 1.2182\n",
      "Epoch [241/300], Step [8/29], Loss: 1.2552\n",
      "Epoch [241/300], Step [9/29], Loss: 1.4430\n",
      "Epoch [241/300], Step [10/29], Loss: 1.2442\n",
      "Epoch [241/300], Step [11/29], Loss: 1.2962\n",
      "Epoch [241/300], Step [12/29], Loss: 1.3831\n",
      "Epoch [241/300], Step [13/29], Loss: 1.2817\n",
      "Epoch [241/300], Step [14/29], Loss: 1.4681\n",
      "Epoch [241/300], Step [15/29], Loss: 1.3251\n",
      "Epoch [241/300], Step [16/29], Loss: 1.0997\n",
      "Epoch [241/300], Step [17/29], Loss: 1.2333\n",
      "Epoch [241/300], Step [18/29], Loss: 1.5325\n",
      "Epoch [241/300], Step [19/29], Loss: 1.3286\n",
      "Epoch [241/300], Step [20/29], Loss: 1.4246\n",
      "Epoch [241/300], Step [21/29], Loss: 1.4285\n",
      "Epoch [241/300], Step [22/29], Loss: 1.2864\n",
      "Epoch [241/300], Step [23/29], Loss: 1.3809\n",
      "Epoch [241/300], Step [24/29], Loss: 1.0580\n",
      "Epoch [241/300], Step [25/29], Loss: 1.0708\n",
      "Epoch [241/300], Step [26/29], Loss: 1.0477\n",
      "Epoch [241/300], Step [27/29], Loss: 1.3770\n",
      "Epoch [241/300], Step [28/29], Loss: 1.1540\n",
      "Epoch [241/300], Step [29/29], Loss: 2.2653\n",
      "Epoch [242/300], Step [1/29], Loss: 1.2234\n",
      "Epoch [242/300], Step [2/29], Loss: 1.1730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [242/300], Step [3/29], Loss: 1.1060\n",
      "Epoch [242/300], Step [4/29], Loss: 1.4452\n",
      "Epoch [242/300], Step [5/29], Loss: 1.3152\n",
      "Epoch [242/300], Step [6/29], Loss: 1.4629\n",
      "Epoch [242/300], Step [7/29], Loss: 1.1381\n",
      "Epoch [242/300], Step [8/29], Loss: 1.1754\n",
      "Epoch [242/300], Step [9/29], Loss: 1.1812\n",
      "Epoch [242/300], Step [10/29], Loss: 1.2453\n",
      "Epoch [242/300], Step [11/29], Loss: 1.2238\n",
      "Epoch [242/300], Step [12/29], Loss: 1.2295\n",
      "Epoch [242/300], Step [13/29], Loss: 1.8007\n",
      "Epoch [242/300], Step [14/29], Loss: 1.4257\n",
      "Epoch [242/300], Step [15/29], Loss: 1.4943\n",
      "Epoch [242/300], Step [16/29], Loss: 1.1825\n",
      "Epoch [242/300], Step [17/29], Loss: 1.0493\n",
      "Epoch [242/300], Step [18/29], Loss: 1.2064\n",
      "Epoch [242/300], Step [19/29], Loss: 1.3102\n",
      "Epoch [242/300], Step [20/29], Loss: 1.1805\n",
      "Epoch [242/300], Step [21/29], Loss: 1.5915\n",
      "Epoch [242/300], Step [22/29], Loss: 1.2576\n",
      "Epoch [242/300], Step [23/29], Loss: 1.2927\n",
      "Epoch [242/300], Step [24/29], Loss: 1.3693\n",
      "Epoch [242/300], Step [25/29], Loss: 1.3365\n",
      "Epoch [242/300], Step [26/29], Loss: 1.2333\n",
      "Epoch [242/300], Step [27/29], Loss: 1.3087\n",
      "Epoch [242/300], Step [28/29], Loss: 1.1317\n",
      "Epoch [242/300], Step [29/29], Loss: 2.5741\n",
      "Epoch [243/300], Step [1/29], Loss: 1.1301\n",
      "Epoch [243/300], Step [2/29], Loss: 1.2535\n",
      "Epoch [243/300], Step [3/29], Loss: 1.2418\n",
      "Epoch [243/300], Step [4/29], Loss: 1.1687\n",
      "Epoch [243/300], Step [5/29], Loss: 1.2659\n",
      "Epoch [243/300], Step [6/29], Loss: 1.2448\n",
      "Epoch [243/300], Step [7/29], Loss: 0.9928\n",
      "Epoch [243/300], Step [8/29], Loss: 1.1015\n",
      "Epoch [243/300], Step [9/29], Loss: 1.3628\n",
      "Epoch [243/300], Step [10/29], Loss: 1.3705\n",
      "Epoch [243/300], Step [11/29], Loss: 1.4376\n",
      "Epoch [243/300], Step [12/29], Loss: 1.2649\n",
      "Epoch [243/300], Step [13/29], Loss: 1.0750\n",
      "Epoch [243/300], Step [14/29], Loss: 1.1722\n",
      "Epoch [243/300], Step [15/29], Loss: 1.3710\n",
      "Epoch [243/300], Step [16/29], Loss: 1.2353\n",
      "Epoch [243/300], Step [17/29], Loss: 1.3895\n",
      "Epoch [243/300], Step [18/29], Loss: 1.4791\n",
      "Epoch [243/300], Step [19/29], Loss: 1.2771\n",
      "Epoch [243/300], Step [20/29], Loss: 1.1759\n",
      "Epoch [243/300], Step [21/29], Loss: 1.2465\n",
      "Epoch [243/300], Step [22/29], Loss: 1.2339\n",
      "Epoch [243/300], Step [23/29], Loss: 1.3858\n",
      "Epoch [243/300], Step [24/29], Loss: 1.3850\n",
      "Epoch [243/300], Step [25/29], Loss: 1.2357\n",
      "Epoch [243/300], Step [26/29], Loss: 1.4544\n",
      "Epoch [243/300], Step [27/29], Loss: 1.5503\n",
      "Epoch [243/300], Step [28/29], Loss: 1.2970\n",
      "Epoch [243/300], Step [29/29], Loss: 2.8434\n",
      "Epoch [244/300], Step [1/29], Loss: 1.4040\n",
      "Epoch [244/300], Step [2/29], Loss: 1.2414\n",
      "Epoch [244/300], Step [3/29], Loss: 1.0134\n",
      "Epoch [244/300], Step [4/29], Loss: 1.2112\n",
      "Epoch [244/300], Step [5/29], Loss: 1.0918\n",
      "Epoch [244/300], Step [6/29], Loss: 0.9679\n",
      "Epoch [244/300], Step [7/29], Loss: 1.1522\n",
      "Epoch [244/300], Step [8/29], Loss: 1.3426\n",
      "Epoch [244/300], Step [9/29], Loss: 1.3771\n",
      "Epoch [244/300], Step [10/29], Loss: 1.1169\n",
      "Epoch [244/300], Step [11/29], Loss: 1.5713\n",
      "Epoch [244/300], Step [12/29], Loss: 1.3386\n",
      "Epoch [244/300], Step [13/29], Loss: 1.3050\n",
      "Epoch [244/300], Step [14/29], Loss: 1.0431\n",
      "Epoch [244/300], Step [15/29], Loss: 1.2151\n",
      "Epoch [244/300], Step [16/29], Loss: 1.2387\n",
      "Epoch [244/300], Step [17/29], Loss: 1.4145\n",
      "Epoch [244/300], Step [18/29], Loss: 1.4060\n",
      "Epoch [244/300], Step [19/29], Loss: 1.3794\n",
      "Epoch [244/300], Step [20/29], Loss: 1.6473\n",
      "Epoch [244/300], Step [21/29], Loss: 1.4625\n",
      "Epoch [244/300], Step [22/29], Loss: 1.1911\n",
      "Epoch [244/300], Step [23/29], Loss: 1.4191\n",
      "Epoch [244/300], Step [24/29], Loss: 1.2369\n",
      "Epoch [244/300], Step [25/29], Loss: 1.4565\n",
      "Epoch [244/300], Step [26/29], Loss: 1.2167\n",
      "Epoch [244/300], Step [27/29], Loss: 1.3796\n",
      "Epoch [244/300], Step [28/29], Loss: 1.4217\n",
      "Epoch [244/300], Step [29/29], Loss: 1.7227\n",
      "Epoch [245/300], Step [1/29], Loss: 1.2584\n",
      "Epoch [245/300], Step [2/29], Loss: 1.3397\n",
      "Epoch [245/300], Step [3/29], Loss: 1.3354\n",
      "Epoch [245/300], Step [4/29], Loss: 1.0950\n",
      "Epoch [245/300], Step [5/29], Loss: 1.4951\n",
      "Epoch [245/300], Step [6/29], Loss: 1.5490\n",
      "Epoch [245/300], Step [7/29], Loss: 1.2540\n",
      "Epoch [245/300], Step [8/29], Loss: 1.5290\n",
      "Epoch [245/300], Step [9/29], Loss: 1.2839\n",
      "Epoch [245/300], Step [10/29], Loss: 1.2430\n",
      "Epoch [245/300], Step [11/29], Loss: 1.2076\n",
      "Epoch [245/300], Step [12/29], Loss: 1.2903\n",
      "Epoch [245/300], Step [13/29], Loss: 1.2516\n",
      "Epoch [245/300], Step [14/29], Loss: 1.3535\n",
      "Epoch [245/300], Step [15/29], Loss: 1.1143\n",
      "Epoch [245/300], Step [16/29], Loss: 1.2481\n",
      "Epoch [245/300], Step [17/29], Loss: 1.2466\n",
      "Epoch [245/300], Step [18/29], Loss: 1.1936\n",
      "Epoch [245/300], Step [19/29], Loss: 1.2189\n",
      "Epoch [245/300], Step [20/29], Loss: 1.3725\n",
      "Epoch [245/300], Step [21/29], Loss: 1.1722\n",
      "Epoch [245/300], Step [22/29], Loss: 1.4809\n",
      "Epoch [245/300], Step [23/29], Loss: 1.0505\n",
      "Epoch [245/300], Step [24/29], Loss: 1.2971\n",
      "Epoch [245/300], Step [25/29], Loss: 1.4911\n",
      "Epoch [245/300], Step [26/29], Loss: 1.3869\n",
      "Epoch [245/300], Step [27/29], Loss: 1.3620\n",
      "Epoch [245/300], Step [28/29], Loss: 1.2074\n",
      "Epoch [245/300], Step [29/29], Loss: 1.2276\n",
      "Epoch [246/300], Step [1/29], Loss: 1.3805\n",
      "Epoch [246/300], Step [2/29], Loss: 1.4617\n",
      "Epoch [246/300], Step [3/29], Loss: 1.1285\n",
      "Epoch [246/300], Step [4/29], Loss: 1.3806\n",
      "Epoch [246/300], Step [5/29], Loss: 1.3257\n",
      "Epoch [246/300], Step [6/29], Loss: 1.3995\n",
      "Epoch [246/300], Step [7/29], Loss: 1.3807\n",
      "Epoch [246/300], Step [8/29], Loss: 1.2296\n",
      "Epoch [246/300], Step [9/29], Loss: 1.5347\n",
      "Epoch [246/300], Step [10/29], Loss: 1.2986\n",
      "Epoch [246/300], Step [11/29], Loss: 1.3162\n",
      "Epoch [246/300], Step [12/29], Loss: 1.2269\n",
      "Epoch [246/300], Step [13/29], Loss: 1.2614\n",
      "Epoch [246/300], Step [14/29], Loss: 1.4561\n",
      "Epoch [246/300], Step [15/29], Loss: 1.0958\n",
      "Epoch [246/300], Step [16/29], Loss: 1.2921\n",
      "Epoch [246/300], Step [17/29], Loss: 1.3483\n",
      "Epoch [246/300], Step [18/29], Loss: 1.2275\n",
      "Epoch [246/300], Step [19/29], Loss: 1.1302\n",
      "Epoch [246/300], Step [20/29], Loss: 1.2566\n",
      "Epoch [246/300], Step [21/29], Loss: 1.2328\n",
      "Epoch [246/300], Step [22/29], Loss: 1.4946\n",
      "Epoch [246/300], Step [23/29], Loss: 1.1524\n",
      "Epoch [246/300], Step [24/29], Loss: 1.3545\n",
      "Epoch [246/300], Step [25/29], Loss: 1.4341\n",
      "Epoch [246/300], Step [26/29], Loss: 1.2906\n",
      "Epoch [246/300], Step [27/29], Loss: 1.3884\n",
      "Epoch [246/300], Step [28/29], Loss: 1.2799\n",
      "Epoch [246/300], Step [29/29], Loss: 1.5698\n",
      "Epoch [247/300], Step [1/29], Loss: 1.4886\n",
      "Epoch [247/300], Step [2/29], Loss: 1.2887\n",
      "Epoch [247/300], Step [3/29], Loss: 1.0872\n",
      "Epoch [247/300], Step [4/29], Loss: 1.3091\n",
      "Epoch [247/300], Step [5/29], Loss: 1.3666\n",
      "Epoch [247/300], Step [6/29], Loss: 1.3123\n",
      "Epoch [247/300], Step [7/29], Loss: 1.1201\n",
      "Epoch [247/300], Step [8/29], Loss: 1.1599\n",
      "Epoch [247/300], Step [9/29], Loss: 1.3335\n",
      "Epoch [247/300], Step [10/29], Loss: 1.5574\n",
      "Epoch [247/300], Step [11/29], Loss: 1.0570\n",
      "Epoch [247/300], Step [12/29], Loss: 1.1084\n",
      "Epoch [247/300], Step [13/29], Loss: 1.5097\n",
      "Epoch [247/300], Step [14/29], Loss: 1.1802\n",
      "Epoch [247/300], Step [15/29], Loss: 1.4202\n",
      "Epoch [247/300], Step [16/29], Loss: 1.1360\n",
      "Epoch [247/300], Step [17/29], Loss: 1.3638\n",
      "Epoch [247/300], Step [18/29], Loss: 1.2265\n",
      "Epoch [247/300], Step [19/29], Loss: 1.2100\n",
      "Epoch [247/300], Step [20/29], Loss: 1.3040\n",
      "Epoch [247/300], Step [21/29], Loss: 1.3086\n",
      "Epoch [247/300], Step [22/29], Loss: 1.4368\n",
      "Epoch [247/300], Step [23/29], Loss: 1.3609\n",
      "Epoch [247/300], Step [24/29], Loss: 1.1400\n",
      "Epoch [247/300], Step [25/29], Loss: 1.3861\n",
      "Epoch [247/300], Step [26/29], Loss: 1.1419\n",
      "Epoch [247/300], Step [27/29], Loss: 1.3513\n",
      "Epoch [247/300], Step [28/29], Loss: 1.2030\n",
      "Epoch [247/300], Step [29/29], Loss: 1.6329\n",
      "Epoch [248/300], Step [1/29], Loss: 1.0176\n",
      "Epoch [248/300], Step [2/29], Loss: 1.7334\n",
      "Epoch [248/300], Step [3/29], Loss: 1.4510\n",
      "Epoch [248/300], Step [4/29], Loss: 1.0986\n",
      "Epoch [248/300], Step [5/29], Loss: 1.3138\n",
      "Epoch [248/300], Step [6/29], Loss: 1.3014\n",
      "Epoch [248/300], Step [7/29], Loss: 1.2262\n",
      "Epoch [248/300], Step [8/29], Loss: 1.4313\n",
      "Epoch [248/300], Step [9/29], Loss: 1.1694\n",
      "Epoch [248/300], Step [10/29], Loss: 1.2893\n",
      "Epoch [248/300], Step [11/29], Loss: 1.0212\n",
      "Epoch [248/300], Step [12/29], Loss: 1.4978\n",
      "Epoch [248/300], Step [13/29], Loss: 1.1775\n",
      "Epoch [248/300], Step [14/29], Loss: 1.1257\n",
      "Epoch [248/300], Step [15/29], Loss: 1.3539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [248/300], Step [16/29], Loss: 1.2472\n",
      "Epoch [248/300], Step [17/29], Loss: 1.5651\n",
      "Epoch [248/300], Step [18/29], Loss: 1.2754\n",
      "Epoch [248/300], Step [19/29], Loss: 1.0766\n",
      "Epoch [248/300], Step [20/29], Loss: 1.3979\n",
      "Epoch [248/300], Step [21/29], Loss: 1.3148\n",
      "Epoch [248/300], Step [22/29], Loss: 1.3404\n",
      "Epoch [248/300], Step [23/29], Loss: 1.2121\n",
      "Epoch [248/300], Step [24/29], Loss: 1.3642\n",
      "Epoch [248/300], Step [25/29], Loss: 1.2188\n",
      "Epoch [248/300], Step [26/29], Loss: 1.2741\n",
      "Epoch [248/300], Step [27/29], Loss: 1.1128\n",
      "Epoch [248/300], Step [28/29], Loss: 1.3715\n",
      "Epoch [248/300], Step [29/29], Loss: 1.9472\n",
      "Epoch [249/300], Step [1/29], Loss: 1.6157\n",
      "Epoch [249/300], Step [2/29], Loss: 1.2411\n",
      "Epoch [249/300], Step [3/29], Loss: 1.1613\n",
      "Epoch [249/300], Step [4/29], Loss: 1.2749\n",
      "Epoch [249/300], Step [5/29], Loss: 1.0154\n",
      "Epoch [249/300], Step [6/29], Loss: 1.2397\n",
      "Epoch [249/300], Step [7/29], Loss: 1.3744\n",
      "Epoch [249/300], Step [8/29], Loss: 1.4989\n",
      "Epoch [249/300], Step [9/29], Loss: 1.2980\n",
      "Epoch [249/300], Step [10/29], Loss: 1.4444\n",
      "Epoch [249/300], Step [11/29], Loss: 1.2515\n",
      "Epoch [249/300], Step [12/29], Loss: 1.2804\n",
      "Epoch [249/300], Step [13/29], Loss: 1.4780\n",
      "Epoch [249/300], Step [14/29], Loss: 1.0649\n",
      "Epoch [249/300], Step [15/29], Loss: 1.2136\n",
      "Epoch [249/300], Step [16/29], Loss: 1.2070\n",
      "Epoch [249/300], Step [17/29], Loss: 1.3926\n",
      "Epoch [249/300], Step [18/29], Loss: 1.6643\n",
      "Epoch [249/300], Step [19/29], Loss: 1.4363\n",
      "Epoch [249/300], Step [20/29], Loss: 1.2373\n",
      "Epoch [249/300], Step [21/29], Loss: 1.3001\n",
      "Epoch [249/300], Step [22/29], Loss: 1.1173\n",
      "Epoch [249/300], Step [23/29], Loss: 1.3062\n",
      "Epoch [249/300], Step [24/29], Loss: 1.1797\n",
      "Epoch [249/300], Step [25/29], Loss: 1.3281\n",
      "Epoch [249/300], Step [26/29], Loss: 1.1379\n",
      "Epoch [249/300], Step [27/29], Loss: 1.1180\n",
      "Epoch [249/300], Step [28/29], Loss: 1.2174\n",
      "Epoch [249/300], Step [29/29], Loss: 1.9929\n",
      "Epoch [250/300], Step [1/29], Loss: 1.4750\n",
      "Epoch [250/300], Step [2/29], Loss: 1.2583\n",
      "Epoch [250/300], Step [3/29], Loss: 1.2805\n",
      "Epoch [250/300], Step [4/29], Loss: 1.5088\n",
      "Epoch [250/300], Step [5/29], Loss: 1.0132\n",
      "Epoch [250/300], Step [6/29], Loss: 1.1468\n",
      "Epoch [250/300], Step [7/29], Loss: 1.3602\n",
      "Epoch [250/300], Step [8/29], Loss: 1.5641\n",
      "Epoch [250/300], Step [9/29], Loss: 1.2379\n",
      "Epoch [250/300], Step [10/29], Loss: 1.1459\n",
      "Epoch [250/300], Step [11/29], Loss: 1.4255\n",
      "Epoch [250/300], Step [12/29], Loss: 1.1900\n",
      "Epoch [250/300], Step [13/29], Loss: 1.4555\n",
      "Epoch [250/300], Step [14/29], Loss: 1.3965\n",
      "Epoch [250/300], Step [15/29], Loss: 1.4402\n",
      "Epoch [250/300], Step [16/29], Loss: 1.1817\n",
      "Epoch [250/300], Step [17/29], Loss: 1.2434\n",
      "Epoch [250/300], Step [18/29], Loss: 1.2842\n",
      "Epoch [250/300], Step [19/29], Loss: 1.2262\n",
      "Epoch [250/300], Step [20/29], Loss: 1.3361\n",
      "Epoch [250/300], Step [21/29], Loss: 1.3326\n",
      "Epoch [250/300], Step [22/29], Loss: 1.4390\n",
      "Epoch [250/300], Step [23/29], Loss: 1.3988\n",
      "Epoch [250/300], Step [24/29], Loss: 1.2022\n",
      "Epoch [250/300], Step [25/29], Loss: 1.4117\n",
      "Epoch [250/300], Step [26/29], Loss: 1.5390\n",
      "Epoch [250/300], Step [27/29], Loss: 1.1889\n",
      "Epoch [250/300], Step [28/29], Loss: 1.1633\n",
      "Epoch [250/300], Step [29/29], Loss: 1.3212\n",
      "Epoch [251/300], Step [1/29], Loss: 1.0267\n",
      "Epoch [251/300], Step [2/29], Loss: 1.2284\n",
      "Epoch [251/300], Step [3/29], Loss: 1.2375\n",
      "Epoch [251/300], Step [4/29], Loss: 1.5423\n",
      "Epoch [251/300], Step [5/29], Loss: 1.1015\n",
      "Epoch [251/300], Step [6/29], Loss: 1.2434\n",
      "Epoch [251/300], Step [7/29], Loss: 1.0424\n",
      "Epoch [251/300], Step [8/29], Loss: 1.3962\n",
      "Epoch [251/300], Step [9/29], Loss: 1.2642\n",
      "Epoch [251/300], Step [10/29], Loss: 1.2151\n",
      "Epoch [251/300], Step [11/29], Loss: 1.2662\n",
      "Epoch [251/300], Step [12/29], Loss: 1.2366\n",
      "Epoch [251/300], Step [13/29], Loss: 1.5096\n",
      "Epoch [251/300], Step [14/29], Loss: 1.4744\n",
      "Epoch [251/300], Step [15/29], Loss: 1.5863\n",
      "Epoch [251/300], Step [16/29], Loss: 1.3390\n",
      "Epoch [251/300], Step [17/29], Loss: 1.1057\n",
      "Epoch [251/300], Step [18/29], Loss: 1.2009\n",
      "Epoch [251/300], Step [19/29], Loss: 1.4032\n",
      "Epoch [251/300], Step [20/29], Loss: 1.2274\n",
      "Epoch [251/300], Step [21/29], Loss: 1.1737\n",
      "Epoch [251/300], Step [22/29], Loss: 1.3970\n",
      "Epoch [251/300], Step [23/29], Loss: 1.5383\n",
      "Epoch [251/300], Step [24/29], Loss: 1.2541\n",
      "Epoch [251/300], Step [25/29], Loss: 1.3688\n",
      "Epoch [251/300], Step [26/29], Loss: 1.2577\n",
      "Epoch [251/300], Step [27/29], Loss: 1.2412\n",
      "Epoch [251/300], Step [28/29], Loss: 1.4382\n",
      "Epoch [251/300], Step [29/29], Loss: 1.5170\n",
      "Epoch [252/300], Step [1/29], Loss: 1.3420\n",
      "Epoch [252/300], Step [2/29], Loss: 1.3077\n",
      "Epoch [252/300], Step [3/29], Loss: 1.1009\n",
      "Epoch [252/300], Step [4/29], Loss: 1.3139\n",
      "Epoch [252/300], Step [5/29], Loss: 1.2180\n",
      "Epoch [252/300], Step [6/29], Loss: 1.1838\n",
      "Epoch [252/300], Step [7/29], Loss: 1.3522\n",
      "Epoch [252/300], Step [8/29], Loss: 1.6943\n",
      "Epoch [252/300], Step [9/29], Loss: 1.2789\n",
      "Epoch [252/300], Step [10/29], Loss: 1.4696\n",
      "Epoch [252/300], Step [11/29], Loss: 1.3451\n",
      "Epoch [252/300], Step [12/29], Loss: 1.3038\n",
      "Epoch [252/300], Step [13/29], Loss: 1.4181\n",
      "Epoch [252/300], Step [14/29], Loss: 1.2713\n",
      "Epoch [252/300], Step [15/29], Loss: 1.1181\n",
      "Epoch [252/300], Step [16/29], Loss: 1.2921\n",
      "Epoch [252/300], Step [17/29], Loss: 1.2077\n",
      "Epoch [252/300], Step [18/29], Loss: 1.0302\n",
      "Epoch [252/300], Step [19/29], Loss: 1.2723\n",
      "Epoch [252/300], Step [20/29], Loss: 1.2191\n",
      "Epoch [252/300], Step [21/29], Loss: 1.0173\n",
      "Epoch [252/300], Step [22/29], Loss: 1.1889\n",
      "Epoch [252/300], Step [23/29], Loss: 1.2699\n",
      "Epoch [252/300], Step [24/29], Loss: 1.3431\n",
      "Epoch [252/300], Step [25/29], Loss: 1.2616\n",
      "Epoch [252/300], Step [26/29], Loss: 1.4001\n",
      "Epoch [252/300], Step [27/29], Loss: 1.2339\n",
      "Epoch [252/300], Step [28/29], Loss: 1.2962\n",
      "Epoch [252/300], Step [29/29], Loss: 1.4838\n",
      "Epoch [253/300], Step [1/29], Loss: 1.3114\n",
      "Epoch [253/300], Step [2/29], Loss: 1.2631\n",
      "Epoch [253/300], Step [3/29], Loss: 1.5742\n",
      "Epoch [253/300], Step [4/29], Loss: 1.4911\n",
      "Epoch [253/300], Step [5/29], Loss: 1.3655\n",
      "Epoch [253/300], Step [6/29], Loss: 1.4606\n",
      "Epoch [253/300], Step [7/29], Loss: 1.2098\n",
      "Epoch [253/300], Step [8/29], Loss: 1.3879\n",
      "Epoch [253/300], Step [9/29], Loss: 1.3533\n",
      "Epoch [253/300], Step [10/29], Loss: 1.4520\n",
      "Epoch [253/300], Step [11/29], Loss: 1.2468\n",
      "Epoch [253/300], Step [12/29], Loss: 1.3449\n",
      "Epoch [253/300], Step [13/29], Loss: 1.2188\n",
      "Epoch [253/300], Step [14/29], Loss: 0.9537\n",
      "Epoch [253/300], Step [15/29], Loss: 1.2541\n",
      "Epoch [253/300], Step [16/29], Loss: 1.2076\n",
      "Epoch [253/300], Step [17/29], Loss: 1.4202\n",
      "Epoch [253/300], Step [18/29], Loss: 1.1943\n",
      "Epoch [253/300], Step [19/29], Loss: 1.3119\n",
      "Epoch [253/300], Step [20/29], Loss: 1.0669\n",
      "Epoch [253/300], Step [21/29], Loss: 1.0601\n",
      "Epoch [253/300], Step [22/29], Loss: 1.1707\n",
      "Epoch [253/300], Step [23/29], Loss: 1.5133\n",
      "Epoch [253/300], Step [24/29], Loss: 1.4048\n",
      "Epoch [253/300], Step [25/29], Loss: 1.3195\n",
      "Epoch [253/300], Step [26/29], Loss: 1.1408\n",
      "Epoch [253/300], Step [27/29], Loss: 1.2205\n",
      "Epoch [253/300], Step [28/29], Loss: 1.3936\n",
      "Epoch [253/300], Step [29/29], Loss: 2.2049\n",
      "Epoch [254/300], Step [1/29], Loss: 1.2633\n",
      "Epoch [254/300], Step [2/29], Loss: 1.1601\n",
      "Epoch [254/300], Step [3/29], Loss: 1.3980\n",
      "Epoch [254/300], Step [4/29], Loss: 1.5016\n",
      "Epoch [254/300], Step [5/29], Loss: 1.3211\n",
      "Epoch [254/300], Step [6/29], Loss: 1.3334\n",
      "Epoch [254/300], Step [7/29], Loss: 1.1394\n",
      "Epoch [254/300], Step [8/29], Loss: 1.0870\n",
      "Epoch [254/300], Step [9/29], Loss: 1.3980\n",
      "Epoch [254/300], Step [10/29], Loss: 1.1826\n",
      "Epoch [254/300], Step [11/29], Loss: 1.1635\n",
      "Epoch [254/300], Step [12/29], Loss: 1.0951\n",
      "Epoch [254/300], Step [13/29], Loss: 1.3700\n",
      "Epoch [254/300], Step [14/29], Loss: 1.1980\n",
      "Epoch [254/300], Step [15/29], Loss: 1.3096\n",
      "Epoch [254/300], Step [16/29], Loss: 1.5672\n",
      "Epoch [254/300], Step [17/29], Loss: 1.3092\n",
      "Epoch [254/300], Step [18/29], Loss: 1.5230\n",
      "Epoch [254/300], Step [19/29], Loss: 1.2113\n",
      "Epoch [254/300], Step [20/29], Loss: 1.3948\n",
      "Epoch [254/300], Step [21/29], Loss: 1.3819\n",
      "Epoch [254/300], Step [22/29], Loss: 1.1567\n",
      "Epoch [254/300], Step [23/29], Loss: 1.2190\n",
      "Epoch [254/300], Step [24/29], Loss: 1.4487\n",
      "Epoch [254/300], Step [25/29], Loss: 1.2343\n",
      "Epoch [254/300], Step [26/29], Loss: 1.3729\n",
      "Epoch [254/300], Step [27/29], Loss: 1.0477\n",
      "Epoch [254/300], Step [28/29], Loss: 1.6412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [254/300], Step [29/29], Loss: 1.2287\n",
      "Epoch [255/300], Step [1/29], Loss: 1.3358\n",
      "Epoch [255/300], Step [2/29], Loss: 1.2941\n",
      "Epoch [255/300], Step [3/29], Loss: 1.1170\n",
      "Epoch [255/300], Step [4/29], Loss: 1.4285\n",
      "Epoch [255/300], Step [5/29], Loss: 1.0960\n",
      "Epoch [255/300], Step [6/29], Loss: 1.5621\n",
      "Epoch [255/300], Step [7/29], Loss: 1.2440\n",
      "Epoch [255/300], Step [8/29], Loss: 1.3461\n",
      "Epoch [255/300], Step [9/29], Loss: 1.1292\n",
      "Epoch [255/300], Step [10/29], Loss: 1.4125\n",
      "Epoch [255/300], Step [11/29], Loss: 1.1289\n",
      "Epoch [255/300], Step [12/29], Loss: 1.2366\n",
      "Epoch [255/300], Step [13/29], Loss: 1.5547\n",
      "Epoch [255/300], Step [14/29], Loss: 1.3875\n",
      "Epoch [255/300], Step [15/29], Loss: 1.3764\n",
      "Epoch [255/300], Step [16/29], Loss: 1.1604\n",
      "Epoch [255/300], Step [17/29], Loss: 1.4573\n",
      "Epoch [255/300], Step [18/29], Loss: 1.4269\n",
      "Epoch [255/300], Step [19/29], Loss: 1.2209\n",
      "Epoch [255/300], Step [20/29], Loss: 1.3297\n",
      "Epoch [255/300], Step [21/29], Loss: 1.4901\n",
      "Epoch [255/300], Step [22/29], Loss: 1.3806\n",
      "Epoch [255/300], Step [23/29], Loss: 1.4180\n",
      "Epoch [255/300], Step [24/29], Loss: 1.3688\n",
      "Epoch [255/300], Step [25/29], Loss: 1.2358\n",
      "Epoch [255/300], Step [26/29], Loss: 1.3447\n",
      "Epoch [255/300], Step [27/29], Loss: 1.1244\n",
      "Epoch [255/300], Step [28/29], Loss: 1.0865\n",
      "Epoch [255/300], Step [29/29], Loss: 0.6413\n",
      "Epoch [256/300], Step [1/29], Loss: 0.9046\n",
      "Epoch [256/300], Step [2/29], Loss: 1.1421\n",
      "Epoch [256/300], Step [3/29], Loss: 1.0052\n",
      "Epoch [256/300], Step [4/29], Loss: 1.4468\n",
      "Epoch [256/300], Step [5/29], Loss: 1.1777\n",
      "Epoch [256/300], Step [6/29], Loss: 1.2687\n",
      "Epoch [256/300], Step [7/29], Loss: 1.3624\n",
      "Epoch [256/300], Step [8/29], Loss: 1.3468\n",
      "Epoch [256/300], Step [9/29], Loss: 1.1424\n",
      "Epoch [256/300], Step [10/29], Loss: 1.2057\n",
      "Epoch [256/300], Step [11/29], Loss: 1.4848\n",
      "Epoch [256/300], Step [12/29], Loss: 1.4362\n",
      "Epoch [256/300], Step [13/29], Loss: 1.3542\n",
      "Epoch [256/300], Step [14/29], Loss: 1.2603\n",
      "Epoch [256/300], Step [15/29], Loss: 1.4803\n",
      "Epoch [256/300], Step [16/29], Loss: 1.0299\n",
      "Epoch [256/300], Step [17/29], Loss: 1.2415\n",
      "Epoch [256/300], Step [18/29], Loss: 1.3898\n",
      "Epoch [256/300], Step [19/29], Loss: 1.1770\n",
      "Epoch [256/300], Step [20/29], Loss: 1.3370\n",
      "Epoch [256/300], Step [21/29], Loss: 1.0908\n",
      "Epoch [256/300], Step [22/29], Loss: 1.2998\n",
      "Epoch [256/300], Step [23/29], Loss: 1.7093\n",
      "Epoch [256/300], Step [24/29], Loss: 1.4553\n",
      "Epoch [256/300], Step [25/29], Loss: 1.3525\n",
      "Epoch [256/300], Step [26/29], Loss: 1.2406\n",
      "Epoch [256/300], Step [27/29], Loss: 1.2845\n",
      "Epoch [256/300], Step [28/29], Loss: 1.4641\n",
      "Epoch [256/300], Step [29/29], Loss: 2.6521\n",
      "Epoch [257/300], Step [1/29], Loss: 1.4045\n",
      "Epoch [257/300], Step [2/29], Loss: 1.2652\n",
      "Epoch [257/300], Step [3/29], Loss: 1.1744\n",
      "Epoch [257/300], Step [4/29], Loss: 1.4034\n",
      "Epoch [257/300], Step [5/29], Loss: 1.2017\n",
      "Epoch [257/300], Step [6/29], Loss: 1.7183\n",
      "Epoch [257/300], Step [7/29], Loss: 1.1191\n",
      "Epoch [257/300], Step [8/29], Loss: 1.3022\n",
      "Epoch [257/300], Step [9/29], Loss: 1.2826\n",
      "Epoch [257/300], Step [10/29], Loss: 1.2398\n",
      "Epoch [257/300], Step [11/29], Loss: 1.2415\n",
      "Epoch [257/300], Step [12/29], Loss: 1.0297\n",
      "Epoch [257/300], Step [13/29], Loss: 1.4856\n",
      "Epoch [257/300], Step [14/29], Loss: 1.1917\n",
      "Epoch [257/300], Step [15/29], Loss: 0.9326\n",
      "Epoch [257/300], Step [16/29], Loss: 1.1866\n",
      "Epoch [257/300], Step [17/29], Loss: 1.2256\n",
      "Epoch [257/300], Step [18/29], Loss: 1.3101\n",
      "Epoch [257/300], Step [19/29], Loss: 1.3794\n",
      "Epoch [257/300], Step [20/29], Loss: 1.3389\n",
      "Epoch [257/300], Step [21/29], Loss: 1.3675\n",
      "Epoch [257/300], Step [22/29], Loss: 1.2287\n",
      "Epoch [257/300], Step [23/29], Loss: 1.1666\n",
      "Epoch [257/300], Step [24/29], Loss: 1.3317\n",
      "Epoch [257/300], Step [25/29], Loss: 1.3368\n",
      "Epoch [257/300], Step [26/29], Loss: 1.4228\n",
      "Epoch [257/300], Step [27/29], Loss: 1.3383\n",
      "Epoch [257/300], Step [28/29], Loss: 1.6873\n",
      "Epoch [257/300], Step [29/29], Loss: 1.7448\n",
      "Epoch [258/300], Step [1/29], Loss: 1.3391\n",
      "Epoch [258/300], Step [2/29], Loss: 1.1300\n",
      "Epoch [258/300], Step [3/29], Loss: 1.1729\n",
      "Epoch [258/300], Step [4/29], Loss: 1.3093\n",
      "Epoch [258/300], Step [5/29], Loss: 1.4641\n",
      "Epoch [258/300], Step [6/29], Loss: 1.2024\n",
      "Epoch [258/300], Step [7/29], Loss: 1.2661\n",
      "Epoch [258/300], Step [8/29], Loss: 1.3850\n",
      "Epoch [258/300], Step [9/29], Loss: 1.1927\n",
      "Epoch [258/300], Step [10/29], Loss: 1.4492\n",
      "Epoch [258/300], Step [11/29], Loss: 1.1106\n",
      "Epoch [258/300], Step [12/29], Loss: 1.6025\n",
      "Epoch [258/300], Step [13/29], Loss: 1.2551\n",
      "Epoch [258/300], Step [14/29], Loss: 1.2655\n",
      "Epoch [258/300], Step [15/29], Loss: 1.3327\n",
      "Epoch [258/300], Step [16/29], Loss: 1.2926\n",
      "Epoch [258/300], Step [17/29], Loss: 1.2117\n",
      "Epoch [258/300], Step [18/29], Loss: 1.2344\n",
      "Epoch [258/300], Step [19/29], Loss: 1.2887\n",
      "Epoch [258/300], Step [20/29], Loss: 1.4558\n",
      "Epoch [258/300], Step [21/29], Loss: 1.4970\n",
      "Epoch [258/300], Step [22/29], Loss: 1.3139\n",
      "Epoch [258/300], Step [23/29], Loss: 1.3236\n",
      "Epoch [258/300], Step [24/29], Loss: 1.2060\n",
      "Epoch [258/300], Step [25/29], Loss: 1.4533\n",
      "Epoch [258/300], Step [26/29], Loss: 1.2444\n",
      "Epoch [258/300], Step [27/29], Loss: 1.4902\n",
      "Epoch [258/300], Step [28/29], Loss: 1.1620\n",
      "Epoch [258/300], Step [29/29], Loss: 0.9761\n",
      "Epoch [259/300], Step [1/29], Loss: 1.3079\n",
      "Epoch [259/300], Step [2/29], Loss: 1.1562\n",
      "Epoch [259/300], Step [3/29], Loss: 1.2758\n",
      "Epoch [259/300], Step [4/29], Loss: 1.2696\n",
      "Epoch [259/300], Step [5/29], Loss: 1.1937\n",
      "Epoch [259/300], Step [6/29], Loss: 1.2717\n",
      "Epoch [259/300], Step [7/29], Loss: 1.0857\n",
      "Epoch [259/300], Step [8/29], Loss: 1.2652\n",
      "Epoch [259/300], Step [9/29], Loss: 1.8009\n",
      "Epoch [259/300], Step [10/29], Loss: 1.3674\n",
      "Epoch [259/300], Step [11/29], Loss: 1.5293\n",
      "Epoch [259/300], Step [12/29], Loss: 1.2905\n",
      "Epoch [259/300], Step [13/29], Loss: 1.3408\n",
      "Epoch [259/300], Step [14/29], Loss: 1.2382\n",
      "Epoch [259/300], Step [15/29], Loss: 1.4081\n",
      "Epoch [259/300], Step [16/29], Loss: 1.2614\n",
      "Epoch [259/300], Step [17/29], Loss: 1.0425\n",
      "Epoch [259/300], Step [18/29], Loss: 1.2887\n",
      "Epoch [259/300], Step [19/29], Loss: 1.2959\n",
      "Epoch [259/300], Step [20/29], Loss: 1.1924\n",
      "Epoch [259/300], Step [21/29], Loss: 1.2234\n",
      "Epoch [259/300], Step [22/29], Loss: 1.5479\n",
      "Epoch [259/300], Step [23/29], Loss: 1.2497\n",
      "Epoch [259/300], Step [24/29], Loss: 1.2345\n",
      "Epoch [259/300], Step [25/29], Loss: 1.3480\n",
      "Epoch [259/300], Step [26/29], Loss: 1.1866\n",
      "Epoch [259/300], Step [27/29], Loss: 1.0728\n",
      "Epoch [259/300], Step [28/29], Loss: 1.2924\n",
      "Epoch [259/300], Step [29/29], Loss: 1.4652\n",
      "Epoch [260/300], Step [1/29], Loss: 1.3316\n",
      "Epoch [260/300], Step [2/29], Loss: 1.2993\n",
      "Epoch [260/300], Step [3/29], Loss: 1.3125\n",
      "Epoch [260/300], Step [4/29], Loss: 1.1379\n",
      "Epoch [260/300], Step [5/29], Loss: 1.4415\n",
      "Epoch [260/300], Step [6/29], Loss: 1.2831\n",
      "Epoch [260/300], Step [7/29], Loss: 1.6019\n",
      "Epoch [260/300], Step [8/29], Loss: 1.3725\n",
      "Epoch [260/300], Step [9/29], Loss: 1.1218\n",
      "Epoch [260/300], Step [10/29], Loss: 1.1150\n",
      "Epoch [260/300], Step [11/29], Loss: 1.4311\n",
      "Epoch [260/300], Step [12/29], Loss: 1.0803\n",
      "Epoch [260/300], Step [13/29], Loss: 1.2491\n",
      "Epoch [260/300], Step [14/29], Loss: 1.4605\n",
      "Epoch [260/300], Step [15/29], Loss: 1.2310\n",
      "Epoch [260/300], Step [16/29], Loss: 1.1921\n",
      "Epoch [260/300], Step [17/29], Loss: 1.4708\n",
      "Epoch [260/300], Step [18/29], Loss: 1.0670\n",
      "Epoch [260/300], Step [19/29], Loss: 1.4939\n",
      "Epoch [260/300], Step [20/29], Loss: 1.2838\n",
      "Epoch [260/300], Step [21/29], Loss: 1.4166\n",
      "Epoch [260/300], Step [22/29], Loss: 1.2020\n",
      "Epoch [260/300], Step [23/29], Loss: 1.1395\n",
      "Epoch [260/300], Step [24/29], Loss: 1.4610\n",
      "Epoch [260/300], Step [25/29], Loss: 1.0376\n",
      "Epoch [260/300], Step [26/29], Loss: 1.4248\n",
      "Epoch [260/300], Step [27/29], Loss: 1.3150\n",
      "Epoch [260/300], Step [28/29], Loss: 1.4819\n",
      "Epoch [260/300], Step [29/29], Loss: 1.5007\n",
      "Epoch [261/300], Step [1/29], Loss: 1.2688\n",
      "Epoch [261/300], Step [2/29], Loss: 1.0180\n",
      "Epoch [261/300], Step [3/29], Loss: 1.3043\n",
      "Epoch [261/300], Step [4/29], Loss: 1.3519\n",
      "Epoch [261/300], Step [5/29], Loss: 1.3613\n",
      "Epoch [261/300], Step [6/29], Loss: 1.2746\n",
      "Epoch [261/300], Step [7/29], Loss: 1.2193\n",
      "Epoch [261/300], Step [8/29], Loss: 1.2993\n",
      "Epoch [261/300], Step [9/29], Loss: 1.3267\n",
      "Epoch [261/300], Step [10/29], Loss: 1.4298\n",
      "Epoch [261/300], Step [11/29], Loss: 1.2555\n",
      "Epoch [261/300], Step [12/29], Loss: 1.3335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/300], Step [13/29], Loss: 1.2307\n",
      "Epoch [261/300], Step [14/29], Loss: 1.2115\n",
      "Epoch [261/300], Step [15/29], Loss: 1.3127\n",
      "Epoch [261/300], Step [16/29], Loss: 1.4575\n",
      "Epoch [261/300], Step [17/29], Loss: 1.3452\n",
      "Epoch [261/300], Step [18/29], Loss: 1.2238\n",
      "Epoch [261/300], Step [19/29], Loss: 1.2470\n",
      "Epoch [261/300], Step [20/29], Loss: 1.2837\n",
      "Epoch [261/300], Step [21/29], Loss: 1.2969\n",
      "Epoch [261/300], Step [22/29], Loss: 1.2615\n",
      "Epoch [261/300], Step [23/29], Loss: 1.5833\n",
      "Epoch [261/300], Step [24/29], Loss: 1.1079\n",
      "Epoch [261/300], Step [25/29], Loss: 1.1908\n",
      "Epoch [261/300], Step [26/29], Loss: 1.4221\n",
      "Epoch [261/300], Step [27/29], Loss: 1.0731\n",
      "Epoch [261/300], Step [28/29], Loss: 1.1280\n",
      "Epoch [261/300], Step [29/29], Loss: 2.1629\n",
      "Epoch [262/300], Step [1/29], Loss: 1.2935\n",
      "Epoch [262/300], Step [2/29], Loss: 1.2922\n",
      "Epoch [262/300], Step [3/29], Loss: 1.4277\n",
      "Epoch [262/300], Step [4/29], Loss: 1.3843\n",
      "Epoch [262/300], Step [5/29], Loss: 1.6001\n",
      "Epoch [262/300], Step [6/29], Loss: 1.3200\n",
      "Epoch [262/300], Step [7/29], Loss: 1.3489\n",
      "Epoch [262/300], Step [8/29], Loss: 1.3766\n",
      "Epoch [262/300], Step [9/29], Loss: 1.1339\n",
      "Epoch [262/300], Step [10/29], Loss: 1.3482\n",
      "Epoch [262/300], Step [11/29], Loss: 1.4367\n",
      "Epoch [262/300], Step [12/29], Loss: 1.3996\n",
      "Epoch [262/300], Step [13/29], Loss: 1.1063\n",
      "Epoch [262/300], Step [14/29], Loss: 1.2617\n",
      "Epoch [262/300], Step [15/29], Loss: 1.2489\n",
      "Epoch [262/300], Step [16/29], Loss: 1.4407\n",
      "Epoch [262/300], Step [17/29], Loss: 1.4269\n",
      "Epoch [262/300], Step [18/29], Loss: 1.0010\n",
      "Epoch [262/300], Step [19/29], Loss: 1.1061\n",
      "Epoch [262/300], Step [20/29], Loss: 1.0310\n",
      "Epoch [262/300], Step [21/29], Loss: 1.4200\n",
      "Epoch [262/300], Step [22/29], Loss: 1.0972\n",
      "Epoch [262/300], Step [23/29], Loss: 1.3024\n",
      "Epoch [262/300], Step [24/29], Loss: 1.1000\n",
      "Epoch [262/300], Step [25/29], Loss: 1.3706\n",
      "Epoch [262/300], Step [26/29], Loss: 1.2103\n",
      "Epoch [262/300], Step [27/29], Loss: 1.5001\n",
      "Epoch [262/300], Step [28/29], Loss: 1.4309\n",
      "Epoch [262/300], Step [29/29], Loss: 1.3719\n",
      "Epoch [263/300], Step [1/29], Loss: 1.2485\n",
      "Epoch [263/300], Step [2/29], Loss: 1.3703\n",
      "Epoch [263/300], Step [3/29], Loss: 1.4188\n",
      "Epoch [263/300], Step [4/29], Loss: 1.1898\n",
      "Epoch [263/300], Step [5/29], Loss: 1.1160\n",
      "Epoch [263/300], Step [6/29], Loss: 1.2532\n",
      "Epoch [263/300], Step [7/29], Loss: 1.2627\n",
      "Epoch [263/300], Step [8/29], Loss: 1.2861\n",
      "Epoch [263/300], Step [9/29], Loss: 1.3979\n",
      "Epoch [263/300], Step [10/29], Loss: 1.4233\n",
      "Epoch [263/300], Step [11/29], Loss: 1.3608\n",
      "Epoch [263/300], Step [12/29], Loss: 1.3542\n",
      "Epoch [263/300], Step [13/29], Loss: 1.2356\n",
      "Epoch [263/300], Step [14/29], Loss: 1.0418\n",
      "Epoch [263/300], Step [15/29], Loss: 1.3572\n",
      "Epoch [263/300], Step [16/29], Loss: 1.2196\n",
      "Epoch [263/300], Step [17/29], Loss: 1.1782\n",
      "Epoch [263/300], Step [18/29], Loss: 1.3287\n",
      "Epoch [263/300], Step [19/29], Loss: 1.1883\n",
      "Epoch [263/300], Step [20/29], Loss: 1.2860\n",
      "Epoch [263/300], Step [21/29], Loss: 1.2454\n",
      "Epoch [263/300], Step [22/29], Loss: 1.3948\n",
      "Epoch [263/300], Step [23/29], Loss: 1.3298\n",
      "Epoch [263/300], Step [24/29], Loss: 1.4793\n",
      "Epoch [263/300], Step [25/29], Loss: 1.5377\n",
      "Epoch [263/300], Step [26/29], Loss: 1.5398\n",
      "Epoch [263/300], Step [27/29], Loss: 1.2069\n",
      "Epoch [263/300], Step [28/29], Loss: 1.0755\n",
      "Epoch [263/300], Step [29/29], Loss: 3.1892\n",
      "Epoch [264/300], Step [1/29], Loss: 1.2906\n",
      "Epoch [264/300], Step [2/29], Loss: 1.2359\n",
      "Epoch [264/300], Step [3/29], Loss: 1.2693\n",
      "Epoch [264/300], Step [4/29], Loss: 1.2663\n",
      "Epoch [264/300], Step [5/29], Loss: 1.3016\n",
      "Epoch [264/300], Step [6/29], Loss: 1.1785\n",
      "Epoch [264/300], Step [7/29], Loss: 1.2355\n",
      "Epoch [264/300], Step [8/29], Loss: 1.1708\n",
      "Epoch [264/300], Step [9/29], Loss: 1.1509\n",
      "Epoch [264/300], Step [10/29], Loss: 1.1021\n",
      "Epoch [264/300], Step [11/29], Loss: 1.0932\n",
      "Epoch [264/300], Step [12/29], Loss: 1.3627\n",
      "Epoch [264/300], Step [13/29], Loss: 1.4458\n",
      "Epoch [264/300], Step [14/29], Loss: 1.5473\n",
      "Epoch [264/300], Step [15/29], Loss: 1.3473\n",
      "Epoch [264/300], Step [16/29], Loss: 1.2736\n",
      "Epoch [264/300], Step [17/29], Loss: 1.0202\n",
      "Epoch [264/300], Step [18/29], Loss: 1.1104\n",
      "Epoch [264/300], Step [19/29], Loss: 1.2560\n",
      "Epoch [264/300], Step [20/29], Loss: 1.2007\n",
      "Epoch [264/300], Step [21/29], Loss: 1.5468\n",
      "Epoch [264/300], Step [22/29], Loss: 1.2047\n",
      "Epoch [264/300], Step [23/29], Loss: 1.3757\n",
      "Epoch [264/300], Step [24/29], Loss: 1.7129\n",
      "Epoch [264/300], Step [25/29], Loss: 1.5129\n",
      "Epoch [264/300], Step [26/29], Loss: 1.2898\n",
      "Epoch [264/300], Step [27/29], Loss: 1.3491\n",
      "Epoch [264/300], Step [28/29], Loss: 1.2634\n",
      "Epoch [264/300], Step [29/29], Loss: 1.7686\n",
      "Epoch [265/300], Step [1/29], Loss: 1.1626\n",
      "Epoch [265/300], Step [2/29], Loss: 1.2017\n",
      "Epoch [265/300], Step [3/29], Loss: 1.2690\n",
      "Epoch [265/300], Step [4/29], Loss: 1.2069\n",
      "Epoch [265/300], Step [5/29], Loss: 1.3906\n",
      "Epoch [265/300], Step [6/29], Loss: 1.3088\n",
      "Epoch [265/300], Step [7/29], Loss: 1.3170\n",
      "Epoch [265/300], Step [8/29], Loss: 1.1839\n",
      "Epoch [265/300], Step [9/29], Loss: 1.4613\n",
      "Epoch [265/300], Step [10/29], Loss: 1.2153\n",
      "Epoch [265/300], Step [11/29], Loss: 1.1205\n",
      "Epoch [265/300], Step [12/29], Loss: 1.0526\n",
      "Epoch [265/300], Step [13/29], Loss: 1.3683\n",
      "Epoch [265/300], Step [14/29], Loss: 1.5610\n",
      "Epoch [265/300], Step [15/29], Loss: 1.3488\n",
      "Epoch [265/300], Step [16/29], Loss: 1.1286\n",
      "Epoch [265/300], Step [17/29], Loss: 1.4680\n",
      "Epoch [265/300], Step [18/29], Loss: 1.3586\n",
      "Epoch [265/300], Step [19/29], Loss: 1.2008\n",
      "Epoch [265/300], Step [20/29], Loss: 1.2974\n",
      "Epoch [265/300], Step [21/29], Loss: 1.1005\n",
      "Epoch [265/300], Step [22/29], Loss: 1.1258\n",
      "Epoch [265/300], Step [23/29], Loss: 1.2923\n",
      "Epoch [265/300], Step [24/29], Loss: 1.2320\n",
      "Epoch [265/300], Step [25/29], Loss: 1.3578\n",
      "Epoch [265/300], Step [26/29], Loss: 1.3082\n",
      "Epoch [265/300], Step [27/29], Loss: 1.4894\n",
      "Epoch [265/300], Step [28/29], Loss: 1.3755\n",
      "Epoch [265/300], Step [29/29], Loss: 2.2155\n",
      "Epoch [266/300], Step [1/29], Loss: 1.1875\n",
      "Epoch [266/300], Step [2/29], Loss: 1.3592\n",
      "Epoch [266/300], Step [3/29], Loss: 1.2268\n",
      "Epoch [266/300], Step [4/29], Loss: 1.5096\n",
      "Epoch [266/300], Step [5/29], Loss: 1.3101\n",
      "Epoch [266/300], Step [6/29], Loss: 1.2722\n",
      "Epoch [266/300], Step [7/29], Loss: 1.0923\n",
      "Epoch [266/300], Step [8/29], Loss: 1.4321\n",
      "Epoch [266/300], Step [9/29], Loss: 1.2805\n",
      "Epoch [266/300], Step [10/29], Loss: 1.2250\n",
      "Epoch [266/300], Step [11/29], Loss: 1.2432\n",
      "Epoch [266/300], Step [12/29], Loss: 1.1630\n",
      "Epoch [266/300], Step [13/29], Loss: 1.4888\n",
      "Epoch [266/300], Step [14/29], Loss: 1.3310\n",
      "Epoch [266/300], Step [15/29], Loss: 1.2138\n",
      "Epoch [266/300], Step [16/29], Loss: 1.1249\n",
      "Epoch [266/300], Step [17/29], Loss: 1.1545\n",
      "Epoch [266/300], Step [18/29], Loss: 1.2827\n",
      "Epoch [266/300], Step [19/29], Loss: 1.2492\n",
      "Epoch [266/300], Step [20/29], Loss: 1.1307\n",
      "Epoch [266/300], Step [21/29], Loss: 1.5081\n",
      "Epoch [266/300], Step [22/29], Loss: 1.5142\n",
      "Epoch [266/300], Step [23/29], Loss: 1.4306\n",
      "Epoch [266/300], Step [24/29], Loss: 1.3997\n",
      "Epoch [266/300], Step [25/29], Loss: 1.3177\n",
      "Epoch [266/300], Step [26/29], Loss: 1.2165\n",
      "Epoch [266/300], Step [27/29], Loss: 1.0456\n",
      "Epoch [266/300], Step [28/29], Loss: 1.3835\n",
      "Epoch [266/300], Step [29/29], Loss: 3.7463\n",
      "Epoch [267/300], Step [1/29], Loss: 1.0889\n",
      "Epoch [267/300], Step [2/29], Loss: 1.3722\n",
      "Epoch [267/300], Step [3/29], Loss: 1.5986\n",
      "Epoch [267/300], Step [4/29], Loss: 1.4248\n",
      "Epoch [267/300], Step [5/29], Loss: 1.4912\n",
      "Epoch [267/300], Step [6/29], Loss: 1.0765\n",
      "Epoch [267/300], Step [7/29], Loss: 1.1294\n",
      "Epoch [267/300], Step [8/29], Loss: 1.5045\n",
      "Epoch [267/300], Step [9/29], Loss: 1.0743\n",
      "Epoch [267/300], Step [10/29], Loss: 1.1070\n",
      "Epoch [267/300], Step [11/29], Loss: 1.2513\n",
      "Epoch [267/300], Step [12/29], Loss: 1.1598\n",
      "Epoch [267/300], Step [13/29], Loss: 1.3363\n",
      "Epoch [267/300], Step [14/29], Loss: 1.2174\n",
      "Epoch [267/300], Step [15/29], Loss: 1.2631\n",
      "Epoch [267/300], Step [16/29], Loss: 1.2722\n",
      "Epoch [267/300], Step [17/29], Loss: 1.1278\n",
      "Epoch [267/300], Step [18/29], Loss: 1.5472\n",
      "Epoch [267/300], Step [19/29], Loss: 1.2001\n",
      "Epoch [267/300], Step [20/29], Loss: 1.0526\n",
      "Epoch [267/300], Step [21/29], Loss: 1.4105\n",
      "Epoch [267/300], Step [22/29], Loss: 1.3620\n",
      "Epoch [267/300], Step [23/29], Loss: 1.2046\n",
      "Epoch [267/300], Step [24/29], Loss: 1.4733\n",
      "Epoch [267/300], Step [25/29], Loss: 1.3846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [267/300], Step [26/29], Loss: 1.2908\n",
      "Epoch [267/300], Step [27/29], Loss: 1.3878\n",
      "Epoch [267/300], Step [28/29], Loss: 1.4952\n",
      "Epoch [267/300], Step [29/29], Loss: 1.7284\n",
      "Epoch [268/300], Step [1/29], Loss: 1.0335\n",
      "Epoch [268/300], Step [2/29], Loss: 1.5918\n",
      "Epoch [268/300], Step [3/29], Loss: 1.2519\n",
      "Epoch [268/300], Step [4/29], Loss: 1.5091\n",
      "Epoch [268/300], Step [5/29], Loss: 1.1763\n",
      "Epoch [268/300], Step [6/29], Loss: 1.2019\n",
      "Epoch [268/300], Step [7/29], Loss: 1.3996\n",
      "Epoch [268/300], Step [8/29], Loss: 1.2828\n",
      "Epoch [268/300], Step [9/29], Loss: 1.3718\n",
      "Epoch [268/300], Step [10/29], Loss: 0.8653\n",
      "Epoch [268/300], Step [11/29], Loss: 1.0471\n",
      "Epoch [268/300], Step [12/29], Loss: 1.1733\n",
      "Epoch [268/300], Step [13/29], Loss: 1.5576\n",
      "Epoch [268/300], Step [14/29], Loss: 1.2821\n",
      "Epoch [268/300], Step [15/29], Loss: 1.0863\n",
      "Epoch [268/300], Step [16/29], Loss: 1.0524\n",
      "Epoch [268/300], Step [17/29], Loss: 1.1915\n",
      "Epoch [268/300], Step [18/29], Loss: 1.5510\n",
      "Epoch [268/300], Step [19/29], Loss: 1.3441\n",
      "Epoch [268/300], Step [20/29], Loss: 1.1768\n",
      "Epoch [268/300], Step [21/29], Loss: 1.3427\n",
      "Epoch [268/300], Step [22/29], Loss: 1.5105\n",
      "Epoch [268/300], Step [23/29], Loss: 1.0611\n",
      "Epoch [268/300], Step [24/29], Loss: 1.4862\n",
      "Epoch [268/300], Step [25/29], Loss: 1.2516\n",
      "Epoch [268/300], Step [26/29], Loss: 1.4015\n",
      "Epoch [268/300], Step [27/29], Loss: 1.5826\n",
      "Epoch [268/300], Step [28/29], Loss: 1.3815\n",
      "Epoch [268/300], Step [29/29], Loss: 1.7065\n",
      "Epoch [269/300], Step [1/29], Loss: 1.2856\n",
      "Epoch [269/300], Step [2/29], Loss: 1.3831\n",
      "Epoch [269/300], Step [3/29], Loss: 1.4998\n",
      "Epoch [269/300], Step [4/29], Loss: 1.1448\n",
      "Epoch [269/300], Step [5/29], Loss: 1.3667\n",
      "Epoch [269/300], Step [6/29], Loss: 1.4116\n",
      "Epoch [269/300], Step [7/29], Loss: 1.3860\n",
      "Epoch [269/300], Step [8/29], Loss: 1.0578\n",
      "Epoch [269/300], Step [9/29], Loss: 1.2357\n",
      "Epoch [269/300], Step [10/29], Loss: 1.3608\n",
      "Epoch [269/300], Step [11/29], Loss: 1.4011\n",
      "Epoch [269/300], Step [12/29], Loss: 1.3283\n",
      "Epoch [269/300], Step [13/29], Loss: 1.3772\n",
      "Epoch [269/300], Step [14/29], Loss: 1.1920\n",
      "Epoch [269/300], Step [15/29], Loss: 1.5719\n",
      "Epoch [269/300], Step [16/29], Loss: 1.0586\n",
      "Epoch [269/300], Step [17/29], Loss: 1.3394\n",
      "Epoch [269/300], Step [18/29], Loss: 1.1439\n",
      "Epoch [269/300], Step [19/29], Loss: 1.3563\n",
      "Epoch [269/300], Step [20/29], Loss: 1.4550\n",
      "Epoch [269/300], Step [21/29], Loss: 1.4615\n",
      "Epoch [269/300], Step [22/29], Loss: 1.2759\n",
      "Epoch [269/300], Step [23/29], Loss: 1.2845\n",
      "Epoch [269/300], Step [24/29], Loss: 1.2508\n",
      "Epoch [269/300], Step [25/29], Loss: 1.2739\n",
      "Epoch [269/300], Step [26/29], Loss: 1.0586\n",
      "Epoch [269/300], Step [27/29], Loss: 1.2814\n",
      "Epoch [269/300], Step [28/29], Loss: 1.2215\n",
      "Epoch [269/300], Step [29/29], Loss: 1.0199\n",
      "Epoch [270/300], Step [1/29], Loss: 1.6355\n",
      "Epoch [270/300], Step [2/29], Loss: 1.1932\n",
      "Epoch [270/300], Step [3/29], Loss: 1.3814\n",
      "Epoch [270/300], Step [4/29], Loss: 1.0101\n",
      "Epoch [270/300], Step [5/29], Loss: 1.3080\n",
      "Epoch [270/300], Step [6/29], Loss: 1.4513\n",
      "Epoch [270/300], Step [7/29], Loss: 1.3564\n",
      "Epoch [270/300], Step [8/29], Loss: 1.5685\n",
      "Epoch [270/300], Step [9/29], Loss: 1.3228\n",
      "Epoch [270/300], Step [10/29], Loss: 1.2367\n",
      "Epoch [270/300], Step [11/29], Loss: 1.4513\n",
      "Epoch [270/300], Step [12/29], Loss: 1.3643\n",
      "Epoch [270/300], Step [13/29], Loss: 1.6054\n",
      "Epoch [270/300], Step [14/29], Loss: 1.0610\n",
      "Epoch [270/300], Step [15/29], Loss: 1.2742\n",
      "Epoch [270/300], Step [16/29], Loss: 1.3006\n",
      "Epoch [270/300], Step [17/29], Loss: 1.3079\n",
      "Epoch [270/300], Step [18/29], Loss: 1.1123\n",
      "Epoch [270/300], Step [19/29], Loss: 1.2094\n",
      "Epoch [270/300], Step [20/29], Loss: 1.4645\n",
      "Epoch [270/300], Step [21/29], Loss: 1.3944\n",
      "Epoch [270/300], Step [22/29], Loss: 1.0214\n",
      "Epoch [270/300], Step [23/29], Loss: 1.4247\n",
      "Epoch [270/300], Step [24/29], Loss: 1.1998\n",
      "Epoch [270/300], Step [25/29], Loss: 1.1833\n",
      "Epoch [270/300], Step [26/29], Loss: 1.1636\n",
      "Epoch [270/300], Step [27/29], Loss: 1.1105\n",
      "Epoch [270/300], Step [28/29], Loss: 1.2491\n",
      "Epoch [270/300], Step [29/29], Loss: 1.5820\n",
      "Epoch [271/300], Step [1/29], Loss: 1.2453\n",
      "Epoch [271/300], Step [2/29], Loss: 1.4415\n",
      "Epoch [271/300], Step [3/29], Loss: 1.2205\n",
      "Epoch [271/300], Step [4/29], Loss: 1.1700\n",
      "Epoch [271/300], Step [5/29], Loss: 1.1619\n",
      "Epoch [271/300], Step [6/29], Loss: 1.3229\n",
      "Epoch [271/300], Step [7/29], Loss: 1.6010\n",
      "Epoch [271/300], Step [8/29], Loss: 1.2025\n",
      "Epoch [271/300], Step [9/29], Loss: 1.2517\n",
      "Epoch [271/300], Step [10/29], Loss: 1.2416\n",
      "Epoch [271/300], Step [11/29], Loss: 1.4858\n",
      "Epoch [271/300], Step [12/29], Loss: 1.3162\n",
      "Epoch [271/300], Step [13/29], Loss: 1.4032\n",
      "Epoch [271/300], Step [14/29], Loss: 1.4582\n",
      "Epoch [271/300], Step [15/29], Loss: 1.3717\n",
      "Epoch [271/300], Step [16/29], Loss: 1.3876\n",
      "Epoch [271/300], Step [17/29], Loss: 1.0796\n",
      "Epoch [271/300], Step [18/29], Loss: 1.3309\n",
      "Epoch [271/300], Step [19/29], Loss: 1.2990\n",
      "Epoch [271/300], Step [20/29], Loss: 1.2983\n",
      "Epoch [271/300], Step [21/29], Loss: 1.2156\n",
      "Epoch [271/300], Step [22/29], Loss: 1.1676\n",
      "Epoch [271/300], Step [23/29], Loss: 1.4091\n",
      "Epoch [271/300], Step [24/29], Loss: 1.2844\n",
      "Epoch [271/300], Step [25/29], Loss: 1.2843\n",
      "Epoch [271/300], Step [26/29], Loss: 1.0188\n",
      "Epoch [271/300], Step [27/29], Loss: 1.1714\n",
      "Epoch [271/300], Step [28/29], Loss: 1.4188\n",
      "Epoch [271/300], Step [29/29], Loss: 1.2630\n",
      "Epoch [272/300], Step [1/29], Loss: 1.2986\n",
      "Epoch [272/300], Step [2/29], Loss: 1.3661\n",
      "Epoch [272/300], Step [3/29], Loss: 1.4530\n",
      "Epoch [272/300], Step [4/29], Loss: 1.3146\n",
      "Epoch [272/300], Step [5/29], Loss: 1.2937\n",
      "Epoch [272/300], Step [6/29], Loss: 1.4013\n",
      "Epoch [272/300], Step [7/29], Loss: 1.2332\n",
      "Epoch [272/300], Step [8/29], Loss: 1.3314\n",
      "Epoch [272/300], Step [9/29], Loss: 1.3394\n",
      "Epoch [272/300], Step [10/29], Loss: 1.1244\n",
      "Epoch [272/300], Step [11/29], Loss: 1.1690\n",
      "Epoch [272/300], Step [12/29], Loss: 1.2512\n",
      "Epoch [272/300], Step [13/29], Loss: 1.3586\n",
      "Epoch [272/300], Step [14/29], Loss: 1.1466\n",
      "Epoch [272/300], Step [15/29], Loss: 1.5435\n",
      "Epoch [272/300], Step [16/29], Loss: 1.3956\n",
      "Epoch [272/300], Step [17/29], Loss: 1.3452\n",
      "Epoch [272/300], Step [18/29], Loss: 1.1858\n",
      "Epoch [272/300], Step [19/29], Loss: 1.2313\n",
      "Epoch [272/300], Step [20/29], Loss: 1.0916\n",
      "Epoch [272/300], Step [21/29], Loss: 1.2648\n",
      "Epoch [272/300], Step [22/29], Loss: 1.4503\n",
      "Epoch [272/300], Step [23/29], Loss: 1.1179\n",
      "Epoch [272/300], Step [24/29], Loss: 1.2897\n",
      "Epoch [272/300], Step [25/29], Loss: 1.2864\n",
      "Epoch [272/300], Step [26/29], Loss: 1.4852\n",
      "Epoch [272/300], Step [27/29], Loss: 1.1657\n",
      "Epoch [272/300], Step [28/29], Loss: 1.4244\n",
      "Epoch [272/300], Step [29/29], Loss: 1.2610\n",
      "Epoch [273/300], Step [1/29], Loss: 1.3273\n",
      "Epoch [273/300], Step [2/29], Loss: 1.2438\n",
      "Epoch [273/300], Step [3/29], Loss: 1.1056\n",
      "Epoch [273/300], Step [4/29], Loss: 1.3040\n",
      "Epoch [273/300], Step [5/29], Loss: 1.2759\n",
      "Epoch [273/300], Step [6/29], Loss: 1.3731\n",
      "Epoch [273/300], Step [7/29], Loss: 1.5552\n",
      "Epoch [273/300], Step [8/29], Loss: 1.0514\n",
      "Epoch [273/300], Step [9/29], Loss: 1.1384\n",
      "Epoch [273/300], Step [10/29], Loss: 1.5094\n",
      "Epoch [273/300], Step [11/29], Loss: 1.3651\n",
      "Epoch [273/300], Step [12/29], Loss: 1.3272\n",
      "Epoch [273/300], Step [13/29], Loss: 1.2580\n",
      "Epoch [273/300], Step [14/29], Loss: 1.2593\n",
      "Epoch [273/300], Step [15/29], Loss: 1.4605\n",
      "Epoch [273/300], Step [16/29], Loss: 1.3676\n",
      "Epoch [273/300], Step [17/29], Loss: 1.2582\n",
      "Epoch [273/300], Step [18/29], Loss: 1.1903\n",
      "Epoch [273/300], Step [19/29], Loss: 1.2723\n",
      "Epoch [273/300], Step [20/29], Loss: 1.0844\n",
      "Epoch [273/300], Step [21/29], Loss: 1.5168\n",
      "Epoch [273/300], Step [22/29], Loss: 0.9399\n",
      "Epoch [273/300], Step [23/29], Loss: 1.2975\n",
      "Epoch [273/300], Step [24/29], Loss: 1.2438\n",
      "Epoch [273/300], Step [25/29], Loss: 1.5350\n",
      "Epoch [273/300], Step [26/29], Loss: 1.0400\n",
      "Epoch [273/300], Step [27/29], Loss: 1.4510\n",
      "Epoch [273/300], Step [28/29], Loss: 1.4696\n",
      "Epoch [273/300], Step [29/29], Loss: 1.4103\n",
      "Epoch [274/300], Step [1/29], Loss: 1.2155\n",
      "Epoch [274/300], Step [2/29], Loss: 1.7109\n",
      "Epoch [274/300], Step [3/29], Loss: 1.3585\n",
      "Epoch [274/300], Step [4/29], Loss: 1.1209\n",
      "Epoch [274/300], Step [5/29], Loss: 1.1023\n",
      "Epoch [274/300], Step [6/29], Loss: 1.0759\n",
      "Epoch [274/300], Step [7/29], Loss: 1.4150\n",
      "Epoch [274/300], Step [8/29], Loss: 1.4395\n",
      "Epoch [274/300], Step [9/29], Loss: 1.2972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [274/300], Step [10/29], Loss: 1.1867\n",
      "Epoch [274/300], Step [11/29], Loss: 1.2111\n",
      "Epoch [274/300], Step [12/29], Loss: 1.0893\n",
      "Epoch [274/300], Step [13/29], Loss: 0.9776\n",
      "Epoch [274/300], Step [14/29], Loss: 1.1443\n",
      "Epoch [274/300], Step [15/29], Loss: 1.3010\n",
      "Epoch [274/300], Step [16/29], Loss: 1.2759\n",
      "Epoch [274/300], Step [17/29], Loss: 1.3035\n",
      "Epoch [274/300], Step [18/29], Loss: 1.2295\n",
      "Epoch [274/300], Step [19/29], Loss: 1.2904\n",
      "Epoch [274/300], Step [20/29], Loss: 1.2363\n",
      "Epoch [274/300], Step [21/29], Loss: 1.3001\n",
      "Epoch [274/300], Step [22/29], Loss: 1.5627\n",
      "Epoch [274/300], Step [23/29], Loss: 1.3769\n",
      "Epoch [274/300], Step [24/29], Loss: 1.3392\n",
      "Epoch [274/300], Step [25/29], Loss: 1.2851\n",
      "Epoch [274/300], Step [26/29], Loss: 1.5104\n",
      "Epoch [274/300], Step [27/29], Loss: 1.2667\n",
      "Epoch [274/300], Step [28/29], Loss: 1.2639\n",
      "Epoch [274/300], Step [29/29], Loss: 1.9600\n",
      "Epoch [275/300], Step [1/29], Loss: 1.2331\n",
      "Epoch [275/300], Step [2/29], Loss: 1.4857\n",
      "Epoch [275/300], Step [3/29], Loss: 1.1852\n",
      "Epoch [275/300], Step [4/29], Loss: 1.1222\n",
      "Epoch [275/300], Step [5/29], Loss: 1.3454\n",
      "Epoch [275/300], Step [6/29], Loss: 1.2989\n",
      "Epoch [275/300], Step [7/29], Loss: 1.0718\n",
      "Epoch [275/300], Step [8/29], Loss: 1.2394\n",
      "Epoch [275/300], Step [9/29], Loss: 1.3018\n",
      "Epoch [275/300], Step [10/29], Loss: 1.0846\n",
      "Epoch [275/300], Step [11/29], Loss: 1.2122\n",
      "Epoch [275/300], Step [12/29], Loss: 1.3239\n",
      "Epoch [275/300], Step [13/29], Loss: 1.4569\n",
      "Epoch [275/300], Step [14/29], Loss: 1.4382\n",
      "Epoch [275/300], Step [15/29], Loss: 1.3228\n",
      "Epoch [275/300], Step [16/29], Loss: 1.1180\n",
      "Epoch [275/300], Step [17/29], Loss: 1.4983\n",
      "Epoch [275/300], Step [18/29], Loss: 1.2900\n",
      "Epoch [275/300], Step [19/29], Loss: 1.2338\n",
      "Epoch [275/300], Step [20/29], Loss: 1.0575\n",
      "Epoch [275/300], Step [21/29], Loss: 1.1176\n",
      "Epoch [275/300], Step [22/29], Loss: 1.2809\n",
      "Epoch [275/300], Step [23/29], Loss: 1.3540\n",
      "Epoch [275/300], Step [24/29], Loss: 1.4342\n",
      "Epoch [275/300], Step [25/29], Loss: 1.4134\n",
      "Epoch [275/300], Step [26/29], Loss: 1.3498\n",
      "Epoch [275/300], Step [27/29], Loss: 1.3562\n",
      "Epoch [275/300], Step [28/29], Loss: 1.3203\n",
      "Epoch [275/300], Step [29/29], Loss: 1.4246\n",
      "Epoch [276/300], Step [1/29], Loss: 1.0065\n",
      "Epoch [276/300], Step [2/29], Loss: 1.3994\n",
      "Epoch [276/300], Step [3/29], Loss: 1.2104\n",
      "Epoch [276/300], Step [4/29], Loss: 1.0723\n",
      "Epoch [276/300], Step [5/29], Loss: 1.3939\n",
      "Epoch [276/300], Step [6/29], Loss: 1.3150\n",
      "Epoch [276/300], Step [7/29], Loss: 1.2496\n",
      "Epoch [276/300], Step [8/29], Loss: 1.2577\n",
      "Epoch [276/300], Step [9/29], Loss: 1.6818\n",
      "Epoch [276/300], Step [10/29], Loss: 1.3693\n",
      "Epoch [276/300], Step [11/29], Loss: 1.2821\n",
      "Epoch [276/300], Step [12/29], Loss: 1.2972\n",
      "Epoch [276/300], Step [13/29], Loss: 1.2543\n",
      "Epoch [276/300], Step [14/29], Loss: 0.9769\n",
      "Epoch [276/300], Step [15/29], Loss: 1.2481\n",
      "Epoch [276/300], Step [16/29], Loss: 1.7291\n",
      "Epoch [276/300], Step [17/29], Loss: 1.5156\n",
      "Epoch [276/300], Step [18/29], Loss: 1.1999\n",
      "Epoch [276/300], Step [19/29], Loss: 1.1933\n",
      "Epoch [276/300], Step [20/29], Loss: 1.1456\n",
      "Epoch [276/300], Step [21/29], Loss: 1.6273\n",
      "Epoch [276/300], Step [22/29], Loss: 1.2266\n",
      "Epoch [276/300], Step [23/29], Loss: 1.4307\n",
      "Epoch [276/300], Step [24/29], Loss: 1.3517\n",
      "Epoch [276/300], Step [25/29], Loss: 1.5304\n",
      "Epoch [276/300], Step [26/29], Loss: 1.1882\n",
      "Epoch [276/300], Step [27/29], Loss: 1.1908\n",
      "Epoch [276/300], Step [28/29], Loss: 0.9680\n",
      "Epoch [276/300], Step [29/29], Loss: 1.3035\n",
      "Epoch [277/300], Step [1/29], Loss: 1.3386\n",
      "Epoch [277/300], Step [2/29], Loss: 1.4576\n",
      "Epoch [277/300], Step [3/29], Loss: 0.9762\n",
      "Epoch [277/300], Step [4/29], Loss: 1.2216\n",
      "Epoch [277/300], Step [5/29], Loss: 1.3913\n",
      "Epoch [277/300], Step [6/29], Loss: 1.4086\n",
      "Epoch [277/300], Step [7/29], Loss: 1.2548\n",
      "Epoch [277/300], Step [8/29], Loss: 1.6283\n",
      "Epoch [277/300], Step [9/29], Loss: 1.2655\n",
      "Epoch [277/300], Step [10/29], Loss: 1.2116\n",
      "Epoch [277/300], Step [11/29], Loss: 1.1731\n",
      "Epoch [277/300], Step [12/29], Loss: 1.5301\n",
      "Epoch [277/300], Step [13/29], Loss: 1.1981\n",
      "Epoch [277/300], Step [14/29], Loss: 1.5109\n",
      "Epoch [277/300], Step [15/29], Loss: 1.1969\n",
      "Epoch [277/300], Step [16/29], Loss: 1.0378\n",
      "Epoch [277/300], Step [17/29], Loss: 1.3941\n",
      "Epoch [277/300], Step [18/29], Loss: 1.3519\n",
      "Epoch [277/300], Step [19/29], Loss: 1.1985\n",
      "Epoch [277/300], Step [20/29], Loss: 1.2551\n",
      "Epoch [277/300], Step [21/29], Loss: 1.2826\n",
      "Epoch [277/300], Step [22/29], Loss: 1.3972\n",
      "Epoch [277/300], Step [23/29], Loss: 1.4109\n",
      "Epoch [277/300], Step [24/29], Loss: 1.3592\n",
      "Epoch [277/300], Step [25/29], Loss: 1.0130\n",
      "Epoch [277/300], Step [26/29], Loss: 1.4701\n",
      "Epoch [277/300], Step [27/29], Loss: 1.2808\n",
      "Epoch [277/300], Step [28/29], Loss: 1.1910\n",
      "Epoch [277/300], Step [29/29], Loss: 2.4860\n",
      "Epoch [278/300], Step [1/29], Loss: 1.2457\n",
      "Epoch [278/300], Step [2/29], Loss: 1.4529\n",
      "Epoch [278/300], Step [3/29], Loss: 1.1822\n",
      "Epoch [278/300], Step [4/29], Loss: 1.3977\n",
      "Epoch [278/300], Step [5/29], Loss: 1.3127\n",
      "Epoch [278/300], Step [6/29], Loss: 1.3228\n",
      "Epoch [278/300], Step [7/29], Loss: 1.0067\n",
      "Epoch [278/300], Step [8/29], Loss: 1.0894\n",
      "Epoch [278/300], Step [9/29], Loss: 1.1388\n",
      "Epoch [278/300], Step [10/29], Loss: 1.5385\n",
      "Epoch [278/300], Step [11/29], Loss: 1.1655\n",
      "Epoch [278/300], Step [12/29], Loss: 1.3156\n",
      "Epoch [278/300], Step [13/29], Loss: 1.2100\n",
      "Epoch [278/300], Step [14/29], Loss: 1.3209\n",
      "Epoch [278/300], Step [15/29], Loss: 1.2815\n",
      "Epoch [278/300], Step [16/29], Loss: 1.1738\n",
      "Epoch [278/300], Step [17/29], Loss: 1.2753\n",
      "Epoch [278/300], Step [18/29], Loss: 1.0973\n",
      "Epoch [278/300], Step [19/29], Loss: 1.3114\n",
      "Epoch [278/300], Step [20/29], Loss: 1.6233\n",
      "Epoch [278/300], Step [21/29], Loss: 0.9572\n",
      "Epoch [278/300], Step [22/29], Loss: 1.3627\n",
      "Epoch [278/300], Step [23/29], Loss: 1.3090\n",
      "Epoch [278/300], Step [24/29], Loss: 1.4183\n",
      "Epoch [278/300], Step [25/29], Loss: 1.1289\n",
      "Epoch [278/300], Step [26/29], Loss: 1.3521\n",
      "Epoch [278/300], Step [27/29], Loss: 1.3242\n",
      "Epoch [278/300], Step [28/29], Loss: 1.5286\n",
      "Epoch [278/300], Step [29/29], Loss: 2.5801\n",
      "Epoch [279/300], Step [1/29], Loss: 1.2980\n",
      "Epoch [279/300], Step [2/29], Loss: 1.3939\n",
      "Epoch [279/300], Step [3/29], Loss: 1.4165\n",
      "Epoch [279/300], Step [4/29], Loss: 1.3490\n",
      "Epoch [279/300], Step [5/29], Loss: 1.6264\n",
      "Epoch [279/300], Step [6/29], Loss: 1.1960\n",
      "Epoch [279/300], Step [7/29], Loss: 1.1445\n",
      "Epoch [279/300], Step [8/29], Loss: 1.3211\n",
      "Epoch [279/300], Step [9/29], Loss: 1.4501\n",
      "Epoch [279/300], Step [10/29], Loss: 1.0154\n",
      "Epoch [279/300], Step [11/29], Loss: 1.2134\n",
      "Epoch [279/300], Step [12/29], Loss: 1.3815\n",
      "Epoch [279/300], Step [13/29], Loss: 1.2737\n",
      "Epoch [279/300], Step [14/29], Loss: 1.2710\n",
      "Epoch [279/300], Step [15/29], Loss: 1.6177\n",
      "Epoch [279/300], Step [16/29], Loss: 1.5267\n",
      "Epoch [279/300], Step [17/29], Loss: 1.1052\n",
      "Epoch [279/300], Step [18/29], Loss: 1.2144\n",
      "Epoch [279/300], Step [19/29], Loss: 1.1892\n",
      "Epoch [279/300], Step [20/29], Loss: 1.4070\n",
      "Epoch [279/300], Step [21/29], Loss: 1.2764\n",
      "Epoch [279/300], Step [22/29], Loss: 1.2642\n",
      "Epoch [279/300], Step [23/29], Loss: 1.2151\n",
      "Epoch [279/300], Step [24/29], Loss: 1.2302\n",
      "Epoch [279/300], Step [25/29], Loss: 1.2449\n",
      "Epoch [279/300], Step [26/29], Loss: 1.2743\n",
      "Epoch [279/300], Step [27/29], Loss: 1.3691\n",
      "Epoch [279/300], Step [28/29], Loss: 1.4981\n",
      "Epoch [279/300], Step [29/29], Loss: 1.7017\n",
      "Epoch [280/300], Step [1/29], Loss: 1.2954\n",
      "Epoch [280/300], Step [2/29], Loss: 1.2485\n",
      "Epoch [280/300], Step [3/29], Loss: 1.3729\n",
      "Epoch [280/300], Step [4/29], Loss: 1.6185\n",
      "Epoch [280/300], Step [5/29], Loss: 1.2457\n",
      "Epoch [280/300], Step [6/29], Loss: 1.1464\n",
      "Epoch [280/300], Step [7/29], Loss: 1.1098\n",
      "Epoch [280/300], Step [8/29], Loss: 1.3630\n",
      "Epoch [280/300], Step [9/29], Loss: 1.0964\n",
      "Epoch [280/300], Step [10/29], Loss: 1.0489\n",
      "Epoch [280/300], Step [11/29], Loss: 1.3171\n",
      "Epoch [280/300], Step [12/29], Loss: 1.3888\n",
      "Epoch [280/300], Step [13/29], Loss: 1.0592\n",
      "Epoch [280/300], Step [14/29], Loss: 1.2929\n",
      "Epoch [280/300], Step [15/29], Loss: 1.5831\n",
      "Epoch [280/300], Step [16/29], Loss: 1.1036\n",
      "Epoch [280/300], Step [17/29], Loss: 1.5168\n",
      "Epoch [280/300], Step [18/29], Loss: 1.0837\n",
      "Epoch [280/300], Step [19/29], Loss: 1.3473\n",
      "Epoch [280/300], Step [20/29], Loss: 1.1279\n",
      "Epoch [280/300], Step [21/29], Loss: 1.4937\n",
      "Epoch [280/300], Step [22/29], Loss: 1.3911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/300], Step [23/29], Loss: 1.2160\n",
      "Epoch [280/300], Step [24/29], Loss: 1.6295\n",
      "Epoch [280/300], Step [25/29], Loss: 1.2502\n",
      "Epoch [280/300], Step [26/29], Loss: 1.2699\n",
      "Epoch [280/300], Step [27/29], Loss: 1.3207\n",
      "Epoch [280/300], Step [28/29], Loss: 1.3529\n",
      "Epoch [280/300], Step [29/29], Loss: 4.9819\n",
      "Epoch [281/300], Step [1/29], Loss: 1.0843\n",
      "Epoch [281/300], Step [2/29], Loss: 1.3226\n",
      "Epoch [281/300], Step [3/29], Loss: 1.3252\n",
      "Epoch [281/300], Step [4/29], Loss: 1.1315\n",
      "Epoch [281/300], Step [5/29], Loss: 1.6215\n",
      "Epoch [281/300], Step [6/29], Loss: 1.3245\n",
      "Epoch [281/300], Step [7/29], Loss: 1.3034\n",
      "Epoch [281/300], Step [8/29], Loss: 1.1328\n",
      "Epoch [281/300], Step [9/29], Loss: 1.3884\n",
      "Epoch [281/300], Step [10/29], Loss: 1.3184\n",
      "Epoch [281/300], Step [11/29], Loss: 1.6239\n",
      "Epoch [281/300], Step [12/29], Loss: 1.1679\n",
      "Epoch [281/300], Step [13/29], Loss: 1.3000\n",
      "Epoch [281/300], Step [14/29], Loss: 1.3367\n",
      "Epoch [281/300], Step [15/29], Loss: 1.1689\n",
      "Epoch [281/300], Step [16/29], Loss: 1.4934\n",
      "Epoch [281/300], Step [17/29], Loss: 1.1666\n",
      "Epoch [281/300], Step [18/29], Loss: 1.4985\n",
      "Epoch [281/300], Step [19/29], Loss: 1.3950\n",
      "Epoch [281/300], Step [20/29], Loss: 1.2958\n",
      "Epoch [281/300], Step [21/29], Loss: 1.0877\n",
      "Epoch [281/300], Step [22/29], Loss: 1.1579\n",
      "Epoch [281/300], Step [23/29], Loss: 1.1089\n",
      "Epoch [281/300], Step [24/29], Loss: 1.1328\n",
      "Epoch [281/300], Step [25/29], Loss: 1.1368\n",
      "Epoch [281/300], Step [26/29], Loss: 1.1339\n",
      "Epoch [281/300], Step [27/29], Loss: 1.1247\n",
      "Epoch [281/300], Step [28/29], Loss: 1.4748\n",
      "Epoch [281/300], Step [29/29], Loss: 0.9283\n",
      "Epoch [282/300], Step [1/29], Loss: 1.2976\n",
      "Epoch [282/300], Step [2/29], Loss: 1.2151\n",
      "Epoch [282/300], Step [3/29], Loss: 1.3510\n",
      "Epoch [282/300], Step [4/29], Loss: 1.5070\n",
      "Epoch [282/300], Step [5/29], Loss: 1.4741\n",
      "Epoch [282/300], Step [6/29], Loss: 1.3841\n",
      "Epoch [282/300], Step [7/29], Loss: 1.4056\n",
      "Epoch [282/300], Step [8/29], Loss: 1.5087\n",
      "Epoch [282/300], Step [9/29], Loss: 1.1109\n",
      "Epoch [282/300], Step [10/29], Loss: 1.1560\n",
      "Epoch [282/300], Step [11/29], Loss: 1.1964\n",
      "Epoch [282/300], Step [12/29], Loss: 1.3025\n",
      "Epoch [282/300], Step [13/29], Loss: 1.3800\n",
      "Epoch [282/300], Step [14/29], Loss: 1.1069\n",
      "Epoch [282/300], Step [15/29], Loss: 1.2150\n",
      "Epoch [282/300], Step [16/29], Loss: 1.2434\n",
      "Epoch [282/300], Step [17/29], Loss: 1.2989\n",
      "Epoch [282/300], Step [18/29], Loss: 1.2202\n",
      "Epoch [282/300], Step [19/29], Loss: 1.0669\n",
      "Epoch [282/300], Step [20/29], Loss: 1.5096\n",
      "Epoch [282/300], Step [21/29], Loss: 1.2450\n",
      "Epoch [282/300], Step [22/29], Loss: 1.5679\n",
      "Epoch [282/300], Step [23/29], Loss: 1.4509\n",
      "Epoch [282/300], Step [24/29], Loss: 1.2036\n",
      "Epoch [282/300], Step [25/29], Loss: 1.2817\n",
      "Epoch [282/300], Step [26/29], Loss: 1.0835\n",
      "Epoch [282/300], Step [27/29], Loss: 1.3019\n",
      "Epoch [282/300], Step [28/29], Loss: 1.4405\n",
      "Epoch [282/300], Step [29/29], Loss: 1.5731\n",
      "Epoch [283/300], Step [1/29], Loss: 1.3292\n",
      "Epoch [283/300], Step [2/29], Loss: 1.1437\n",
      "Epoch [283/300], Step [3/29], Loss: 1.2681\n",
      "Epoch [283/300], Step [4/29], Loss: 1.0036\n",
      "Epoch [283/300], Step [5/29], Loss: 1.3659\n",
      "Epoch [283/300], Step [6/29], Loss: 1.2294\n",
      "Epoch [283/300], Step [7/29], Loss: 1.2774\n",
      "Epoch [283/300], Step [8/29], Loss: 1.4605\n",
      "Epoch [283/300], Step [9/29], Loss: 1.3546\n",
      "Epoch [283/300], Step [10/29], Loss: 0.8995\n",
      "Epoch [283/300], Step [11/29], Loss: 1.8273\n",
      "Epoch [283/300], Step [12/29], Loss: 1.1783\n",
      "Epoch [283/300], Step [13/29], Loss: 1.2345\n",
      "Epoch [283/300], Step [14/29], Loss: 1.3277\n",
      "Epoch [283/300], Step [15/29], Loss: 1.2604\n",
      "Epoch [283/300], Step [16/29], Loss: 1.2899\n",
      "Epoch [283/300], Step [17/29], Loss: 1.3172\n",
      "Epoch [283/300], Step [18/29], Loss: 1.5951\n",
      "Epoch [283/300], Step [19/29], Loss: 1.2219\n",
      "Epoch [283/300], Step [20/29], Loss: 1.5655\n",
      "Epoch [283/300], Step [21/29], Loss: 1.1412\n",
      "Epoch [283/300], Step [22/29], Loss: 1.3123\n",
      "Epoch [283/300], Step [23/29], Loss: 1.2122\n",
      "Epoch [283/300], Step [24/29], Loss: 1.4886\n",
      "Epoch [283/300], Step [25/29], Loss: 1.0609\n",
      "Epoch [283/300], Step [26/29], Loss: 1.2153\n",
      "Epoch [283/300], Step [27/29], Loss: 1.5715\n",
      "Epoch [283/300], Step [28/29], Loss: 1.4401\n",
      "Epoch [283/300], Step [29/29], Loss: 1.3680\n",
      "Epoch [284/300], Step [1/29], Loss: 1.2517\n",
      "Epoch [284/300], Step [2/29], Loss: 1.4861\n",
      "Epoch [284/300], Step [3/29], Loss: 1.5945\n",
      "Epoch [284/300], Step [4/29], Loss: 1.1275\n",
      "Epoch [284/300], Step [5/29], Loss: 1.1783\n",
      "Epoch [284/300], Step [6/29], Loss: 1.0408\n",
      "Epoch [284/300], Step [7/29], Loss: 1.3442\n",
      "Epoch [284/300], Step [8/29], Loss: 1.5131\n",
      "Epoch [284/300], Step [9/29], Loss: 1.1208\n",
      "Epoch [284/300], Step [10/29], Loss: 1.2370\n",
      "Epoch [284/300], Step [11/29], Loss: 1.6386\n",
      "Epoch [284/300], Step [12/29], Loss: 1.2694\n",
      "Epoch [284/300], Step [13/29], Loss: 1.2509\n",
      "Epoch [284/300], Step [14/29], Loss: 1.4813\n",
      "Epoch [284/300], Step [15/29], Loss: 1.2463\n",
      "Epoch [284/300], Step [16/29], Loss: 1.3024\n",
      "Epoch [284/300], Step [17/29], Loss: 1.1934\n",
      "Epoch [284/300], Step [18/29], Loss: 1.2712\n",
      "Epoch [284/300], Step [19/29], Loss: 1.2533\n",
      "Epoch [284/300], Step [20/29], Loss: 1.2411\n",
      "Epoch [284/300], Step [21/29], Loss: 1.2826\n",
      "Epoch [284/300], Step [22/29], Loss: 1.3730\n",
      "Epoch [284/300], Step [23/29], Loss: 1.2620\n",
      "Epoch [284/300], Step [24/29], Loss: 1.1194\n",
      "Epoch [284/300], Step [25/29], Loss: 1.3825\n",
      "Epoch [284/300], Step [26/29], Loss: 1.3931\n",
      "Epoch [284/300], Step [27/29], Loss: 1.2796\n",
      "Epoch [284/300], Step [28/29], Loss: 1.1006\n",
      "Epoch [284/300], Step [29/29], Loss: 0.0847\n",
      "Epoch [285/300], Step [1/29], Loss: 1.3385\n",
      "Epoch [285/300], Step [2/29], Loss: 1.4308\n",
      "Epoch [285/300], Step [3/29], Loss: 1.3502\n",
      "Epoch [285/300], Step [4/29], Loss: 1.2908\n",
      "Epoch [285/300], Step [5/29], Loss: 1.4535\n",
      "Epoch [285/300], Step [6/29], Loss: 1.2363\n",
      "Epoch [285/300], Step [7/29], Loss: 1.4164\n",
      "Epoch [285/300], Step [8/29], Loss: 1.1537\n",
      "Epoch [285/300], Step [9/29], Loss: 1.4330\n",
      "Epoch [285/300], Step [10/29], Loss: 1.0718\n",
      "Epoch [285/300], Step [11/29], Loss: 1.2068\n",
      "Epoch [285/300], Step [12/29], Loss: 1.2438\n",
      "Epoch [285/300], Step [13/29], Loss: 1.2224\n",
      "Epoch [285/300], Step [14/29], Loss: 1.2014\n",
      "Epoch [285/300], Step [15/29], Loss: 1.2690\n",
      "Epoch [285/300], Step [16/29], Loss: 1.2335\n",
      "Epoch [285/300], Step [17/29], Loss: 1.3352\n",
      "Epoch [285/300], Step [18/29], Loss: 1.4332\n",
      "Epoch [285/300], Step [19/29], Loss: 1.4042\n",
      "Epoch [285/300], Step [20/29], Loss: 1.3383\n",
      "Epoch [285/300], Step [21/29], Loss: 1.1141\n",
      "Epoch [285/300], Step [22/29], Loss: 1.3398\n",
      "Epoch [285/300], Step [23/29], Loss: 1.3869\n",
      "Epoch [285/300], Step [24/29], Loss: 1.0590\n",
      "Epoch [285/300], Step [25/29], Loss: 1.5773\n",
      "Epoch [285/300], Step [26/29], Loss: 1.4668\n",
      "Epoch [285/300], Step [27/29], Loss: 1.1858\n",
      "Epoch [285/300], Step [28/29], Loss: 1.3630\n",
      "Epoch [285/300], Step [29/29], Loss: 0.9517\n",
      "Epoch [286/300], Step [1/29], Loss: 1.3832\n",
      "Epoch [286/300], Step [2/29], Loss: 1.2092\n",
      "Epoch [286/300], Step [3/29], Loss: 1.3047\n",
      "Epoch [286/300], Step [4/29], Loss: 1.2883\n",
      "Epoch [286/300], Step [5/29], Loss: 1.2600\n",
      "Epoch [286/300], Step [6/29], Loss: 1.3777\n",
      "Epoch [286/300], Step [7/29], Loss: 1.3804\n",
      "Epoch [286/300], Step [8/29], Loss: 1.1640\n",
      "Epoch [286/300], Step [9/29], Loss: 1.2673\n",
      "Epoch [286/300], Step [10/29], Loss: 1.3871\n",
      "Epoch [286/300], Step [11/29], Loss: 1.1675\n",
      "Epoch [286/300], Step [12/29], Loss: 1.2818\n",
      "Epoch [286/300], Step [13/29], Loss: 1.2721\n",
      "Epoch [286/300], Step [14/29], Loss: 1.3758\n",
      "Epoch [286/300], Step [15/29], Loss: 1.2147\n",
      "Epoch [286/300], Step [16/29], Loss: 1.3736\n",
      "Epoch [286/300], Step [17/29], Loss: 1.2201\n",
      "Epoch [286/300], Step [18/29], Loss: 1.1747\n",
      "Epoch [286/300], Step [19/29], Loss: 1.2092\n",
      "Epoch [286/300], Step [20/29], Loss: 1.1954\n",
      "Epoch [286/300], Step [21/29], Loss: 1.4269\n",
      "Epoch [286/300], Step [22/29], Loss: 1.3664\n",
      "Epoch [286/300], Step [23/29], Loss: 1.4202\n",
      "Epoch [286/300], Step [24/29], Loss: 1.3023\n",
      "Epoch [286/300], Step [25/29], Loss: 1.1039\n",
      "Epoch [286/300], Step [26/29], Loss: 1.3328\n",
      "Epoch [286/300], Step [27/29], Loss: 1.3803\n",
      "Epoch [286/300], Step [28/29], Loss: 1.1235\n",
      "Epoch [286/300], Step [29/29], Loss: 0.5957\n",
      "Epoch [287/300], Step [1/29], Loss: 1.2399\n",
      "Epoch [287/300], Step [2/29], Loss: 1.3498\n",
      "Epoch [287/300], Step [3/29], Loss: 1.1692\n",
      "Epoch [287/300], Step [4/29], Loss: 1.3777\n",
      "Epoch [287/300], Step [5/29], Loss: 1.2996\n",
      "Epoch [287/300], Step [6/29], Loss: 1.2886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [287/300], Step [7/29], Loss: 1.3087\n",
      "Epoch [287/300], Step [8/29], Loss: 1.3990\n",
      "Epoch [287/300], Step [9/29], Loss: 1.3778\n",
      "Epoch [287/300], Step [10/29], Loss: 1.2053\n",
      "Epoch [287/300], Step [11/29], Loss: 1.4440\n",
      "Epoch [287/300], Step [12/29], Loss: 1.3067\n",
      "Epoch [287/300], Step [13/29], Loss: 1.2221\n",
      "Epoch [287/300], Step [14/29], Loss: 1.2095\n",
      "Epoch [287/300], Step [15/29], Loss: 1.1615\n",
      "Epoch [287/300], Step [16/29], Loss: 1.2873\n",
      "Epoch [287/300], Step [17/29], Loss: 1.1981\n",
      "Epoch [287/300], Step [18/29], Loss: 1.3899\n",
      "Epoch [287/300], Step [19/29], Loss: 1.1906\n",
      "Epoch [287/300], Step [20/29], Loss: 1.4562\n",
      "Epoch [287/300], Step [21/29], Loss: 1.4034\n",
      "Epoch [287/300], Step [22/29], Loss: 1.2195\n",
      "Epoch [287/300], Step [23/29], Loss: 1.3981\n",
      "Epoch [287/300], Step [24/29], Loss: 1.0810\n",
      "Epoch [287/300], Step [25/29], Loss: 1.1952\n",
      "Epoch [287/300], Step [26/29], Loss: 1.7114\n",
      "Epoch [287/300], Step [27/29], Loss: 1.4114\n",
      "Epoch [287/300], Step [28/29], Loss: 1.4012\n",
      "Epoch [287/300], Step [29/29], Loss: 1.8242\n",
      "Epoch [288/300], Step [1/29], Loss: 1.2712\n",
      "Epoch [288/300], Step [2/29], Loss: 1.4294\n",
      "Epoch [288/300], Step [3/29], Loss: 1.3535\n",
      "Epoch [288/300], Step [4/29], Loss: 1.3233\n",
      "Epoch [288/300], Step [5/29], Loss: 1.2954\n",
      "Epoch [288/300], Step [6/29], Loss: 1.0375\n",
      "Epoch [288/300], Step [7/29], Loss: 1.2895\n",
      "Epoch [288/300], Step [8/29], Loss: 1.2437\n",
      "Epoch [288/300], Step [9/29], Loss: 1.3490\n",
      "Epoch [288/300], Step [10/29], Loss: 1.0760\n",
      "Epoch [288/300], Step [11/29], Loss: 1.0657\n",
      "Epoch [288/300], Step [12/29], Loss: 1.2676\n",
      "Epoch [288/300], Step [13/29], Loss: 1.4116\n",
      "Epoch [288/300], Step [14/29], Loss: 1.2640\n",
      "Epoch [288/300], Step [15/29], Loss: 1.3283\n",
      "Epoch [288/300], Step [16/29], Loss: 1.1194\n",
      "Epoch [288/300], Step [17/29], Loss: 1.4382\n",
      "Epoch [288/300], Step [18/29], Loss: 1.3973\n",
      "Epoch [288/300], Step [19/29], Loss: 1.6157\n",
      "Epoch [288/300], Step [20/29], Loss: 1.3990\n",
      "Epoch [288/300], Step [21/29], Loss: 1.2013\n",
      "Epoch [288/300], Step [22/29], Loss: 1.5138\n",
      "Epoch [288/300], Step [23/29], Loss: 1.4440\n",
      "Epoch [288/300], Step [24/29], Loss: 1.2126\n",
      "Epoch [288/300], Step [25/29], Loss: 1.3346\n",
      "Epoch [288/300], Step [26/29], Loss: 1.3985\n",
      "Epoch [288/300], Step [27/29], Loss: 1.2883\n",
      "Epoch [288/300], Step [28/29], Loss: 1.3277\n",
      "Epoch [288/300], Step [29/29], Loss: 1.6099\n",
      "Epoch [289/300], Step [1/29], Loss: 1.3199\n",
      "Epoch [289/300], Step [2/29], Loss: 1.3759\n",
      "Epoch [289/300], Step [3/29], Loss: 1.1239\n",
      "Epoch [289/300], Step [4/29], Loss: 1.4125\n",
      "Epoch [289/300], Step [5/29], Loss: 1.4127\n",
      "Epoch [289/300], Step [6/29], Loss: 1.5257\n",
      "Epoch [289/300], Step [7/29], Loss: 1.4161\n",
      "Epoch [289/300], Step [8/29], Loss: 1.2450\n",
      "Epoch [289/300], Step [9/29], Loss: 1.0903\n",
      "Epoch [289/300], Step [10/29], Loss: 1.4651\n",
      "Epoch [289/300], Step [11/29], Loss: 1.2273\n",
      "Epoch [289/300], Step [12/29], Loss: 1.2675\n",
      "Epoch [289/300], Step [13/29], Loss: 1.1856\n",
      "Epoch [289/300], Step [14/29], Loss: 1.2133\n",
      "Epoch [289/300], Step [15/29], Loss: 1.2458\n",
      "Epoch [289/300], Step [16/29], Loss: 1.2651\n",
      "Epoch [289/300], Step [17/29], Loss: 1.1694\n",
      "Epoch [289/300], Step [18/29], Loss: 1.4112\n",
      "Epoch [289/300], Step [19/29], Loss: 1.5015\n",
      "Epoch [289/300], Step [20/29], Loss: 1.1196\n",
      "Epoch [289/300], Step [21/29], Loss: 1.1654\n",
      "Epoch [289/300], Step [22/29], Loss: 1.2287\n",
      "Epoch [289/300], Step [23/29], Loss: 1.2187\n",
      "Epoch [289/300], Step [24/29], Loss: 1.3341\n",
      "Epoch [289/300], Step [25/29], Loss: 1.1757\n",
      "Epoch [289/300], Step [26/29], Loss: 1.2011\n",
      "Epoch [289/300], Step [27/29], Loss: 1.3410\n",
      "Epoch [289/300], Step [28/29], Loss: 1.3801\n",
      "Epoch [289/300], Step [29/29], Loss: 1.0333\n",
      "Epoch [290/300], Step [1/29], Loss: 1.4714\n",
      "Epoch [290/300], Step [2/29], Loss: 1.5702\n",
      "Epoch [290/300], Step [3/29], Loss: 1.4171\n",
      "Epoch [290/300], Step [4/29], Loss: 1.2567\n",
      "Epoch [290/300], Step [5/29], Loss: 1.0660\n",
      "Epoch [290/300], Step [6/29], Loss: 1.3301\n",
      "Epoch [290/300], Step [7/29], Loss: 1.2031\n",
      "Epoch [290/300], Step [8/29], Loss: 1.1952\n",
      "Epoch [290/300], Step [9/29], Loss: 1.1534\n",
      "Epoch [290/300], Step [10/29], Loss: 1.2557\n",
      "Epoch [290/300], Step [11/29], Loss: 1.2924\n",
      "Epoch [290/300], Step [12/29], Loss: 1.2324\n",
      "Epoch [290/300], Step [13/29], Loss: 1.4261\n",
      "Epoch [290/300], Step [14/29], Loss: 1.4123\n",
      "Epoch [290/300], Step [15/29], Loss: 1.3330\n",
      "Epoch [290/300], Step [16/29], Loss: 1.1497\n",
      "Epoch [290/300], Step [17/29], Loss: 1.3399\n",
      "Epoch [290/300], Step [18/29], Loss: 1.2874\n",
      "Epoch [290/300], Step [19/29], Loss: 1.3147\n",
      "Epoch [290/300], Step [20/29], Loss: 1.1294\n",
      "Epoch [290/300], Step [21/29], Loss: 1.1853\n",
      "Epoch [290/300], Step [22/29], Loss: 1.2738\n",
      "Epoch [290/300], Step [23/29], Loss: 1.2568\n",
      "Epoch [290/300], Step [24/29], Loss: 1.5584\n",
      "Epoch [290/300], Step [25/29], Loss: 1.3043\n",
      "Epoch [290/300], Step [26/29], Loss: 1.4937\n",
      "Epoch [290/300], Step [27/29], Loss: 1.3182\n",
      "Epoch [290/300], Step [28/29], Loss: 1.2691\n",
      "Epoch [290/300], Step [29/29], Loss: 0.9755\n",
      "Epoch [291/300], Step [1/29], Loss: 1.4982\n",
      "Epoch [291/300], Step [2/29], Loss: 1.1086\n",
      "Epoch [291/300], Step [3/29], Loss: 1.3409\n",
      "Epoch [291/300], Step [4/29], Loss: 1.2036\n",
      "Epoch [291/300], Step [5/29], Loss: 1.2000\n",
      "Epoch [291/300], Step [6/29], Loss: 1.2966\n",
      "Epoch [291/300], Step [7/29], Loss: 1.2081\n",
      "Epoch [291/300], Step [8/29], Loss: 1.4234\n",
      "Epoch [291/300], Step [9/29], Loss: 1.5345\n",
      "Epoch [291/300], Step [10/29], Loss: 1.5103\n",
      "Epoch [291/300], Step [11/29], Loss: 1.1890\n",
      "Epoch [291/300], Step [12/29], Loss: 1.2053\n",
      "Epoch [291/300], Step [13/29], Loss: 1.4226\n",
      "Epoch [291/300], Step [14/29], Loss: 1.3737\n",
      "Epoch [291/300], Step [15/29], Loss: 1.2566\n",
      "Epoch [291/300], Step [16/29], Loss: 1.1895\n",
      "Epoch [291/300], Step [17/29], Loss: 1.2520\n",
      "Epoch [291/300], Step [18/29], Loss: 1.4287\n",
      "Epoch [291/300], Step [19/29], Loss: 1.1055\n",
      "Epoch [291/300], Step [20/29], Loss: 1.3905\n",
      "Epoch [291/300], Step [21/29], Loss: 1.2720\n",
      "Epoch [291/300], Step [22/29], Loss: 1.0564\n",
      "Epoch [291/300], Step [23/29], Loss: 1.1936\n",
      "Epoch [291/300], Step [24/29], Loss: 1.2234\n",
      "Epoch [291/300], Step [25/29], Loss: 1.3446\n",
      "Epoch [291/300], Step [26/29], Loss: 1.0928\n",
      "Epoch [291/300], Step [27/29], Loss: 1.0682\n",
      "Epoch [291/300], Step [28/29], Loss: 1.2519\n",
      "Epoch [291/300], Step [29/29], Loss: 2.1780\n",
      "Epoch [292/300], Step [1/29], Loss: 1.2689\n",
      "Epoch [292/300], Step [2/29], Loss: 1.4251\n",
      "Epoch [292/300], Step [3/29], Loss: 1.2683\n",
      "Epoch [292/300], Step [4/29], Loss: 1.4502\n",
      "Epoch [292/300], Step [5/29], Loss: 1.4774\n",
      "Epoch [292/300], Step [6/29], Loss: 1.0037\n",
      "Epoch [292/300], Step [7/29], Loss: 1.1839\n",
      "Epoch [292/300], Step [8/29], Loss: 1.2959\n",
      "Epoch [292/300], Step [9/29], Loss: 1.2218\n",
      "Epoch [292/300], Step [10/29], Loss: 1.5510\n",
      "Epoch [292/300], Step [11/29], Loss: 1.3292\n",
      "Epoch [292/300], Step [12/29], Loss: 1.6120\n",
      "Epoch [292/300], Step [13/29], Loss: 1.2897\n",
      "Epoch [292/300], Step [14/29], Loss: 1.4536\n",
      "Epoch [292/300], Step [15/29], Loss: 1.2967\n",
      "Epoch [292/300], Step [16/29], Loss: 1.5305\n",
      "Epoch [292/300], Step [17/29], Loss: 1.1402\n",
      "Epoch [292/300], Step [18/29], Loss: 1.2520\n",
      "Epoch [292/300], Step [19/29], Loss: 1.0466\n",
      "Epoch [292/300], Step [20/29], Loss: 1.2633\n",
      "Epoch [292/300], Step [21/29], Loss: 1.5951\n",
      "Epoch [292/300], Step [22/29], Loss: 1.0226\n",
      "Epoch [292/300], Step [23/29], Loss: 1.2901\n",
      "Epoch [292/300], Step [24/29], Loss: 0.9697\n",
      "Epoch [292/300], Step [25/29], Loss: 1.0768\n",
      "Epoch [292/300], Step [26/29], Loss: 1.3022\n",
      "Epoch [292/300], Step [27/29], Loss: 1.2306\n",
      "Epoch [292/300], Step [28/29], Loss: 1.3283\n",
      "Epoch [292/300], Step [29/29], Loss: 0.5963\n",
      "Epoch [293/300], Step [1/29], Loss: 1.3493\n",
      "Epoch [293/300], Step [2/29], Loss: 1.3787\n",
      "Epoch [293/300], Step [3/29], Loss: 1.4807\n",
      "Epoch [293/300], Step [4/29], Loss: 1.2753\n",
      "Epoch [293/300], Step [5/29], Loss: 1.2534\n",
      "Epoch [293/300], Step [6/29], Loss: 1.4277\n",
      "Epoch [293/300], Step [7/29], Loss: 1.2227\n",
      "Epoch [293/300], Step [8/29], Loss: 1.2192\n",
      "Epoch [293/300], Step [9/29], Loss: 1.3353\n",
      "Epoch [293/300], Step [10/29], Loss: 1.3358\n",
      "Epoch [293/300], Step [11/29], Loss: 1.3669\n",
      "Epoch [293/300], Step [12/29], Loss: 1.1436\n",
      "Epoch [293/300], Step [13/29], Loss: 1.2298\n",
      "Epoch [293/300], Step [14/29], Loss: 1.4013\n",
      "Epoch [293/300], Step [15/29], Loss: 1.3753\n",
      "Epoch [293/300], Step [16/29], Loss: 1.1567\n",
      "Epoch [293/300], Step [17/29], Loss: 1.3439\n",
      "Epoch [293/300], Step [18/29], Loss: 1.1613\n",
      "Epoch [293/300], Step [19/29], Loss: 1.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [293/300], Step [20/29], Loss: 1.4147\n",
      "Epoch [293/300], Step [21/29], Loss: 1.3431\n",
      "Epoch [293/300], Step [22/29], Loss: 1.2972\n",
      "Epoch [293/300], Step [23/29], Loss: 1.4810\n",
      "Epoch [293/300], Step [24/29], Loss: 1.3821\n",
      "Epoch [293/300], Step [25/29], Loss: 1.0656\n",
      "Epoch [293/300], Step [26/29], Loss: 1.5648\n",
      "Epoch [293/300], Step [27/29], Loss: 1.4566\n",
      "Epoch [293/300], Step [28/29], Loss: 1.2244\n",
      "Epoch [293/300], Step [29/29], Loss: 0.3161\n",
      "Epoch [294/300], Step [1/29], Loss: 0.9440\n",
      "Epoch [294/300], Step [2/29], Loss: 1.3533\n",
      "Epoch [294/300], Step [3/29], Loss: 1.5551\n",
      "Epoch [294/300], Step [4/29], Loss: 1.4555\n",
      "Epoch [294/300], Step [5/29], Loss: 1.2528\n",
      "Epoch [294/300], Step [6/29], Loss: 1.3502\n",
      "Epoch [294/300], Step [7/29], Loss: 1.1772\n",
      "Epoch [294/300], Step [8/29], Loss: 1.2742\n",
      "Epoch [294/300], Step [9/29], Loss: 1.2560\n",
      "Epoch [294/300], Step [10/29], Loss: 1.2139\n",
      "Epoch [294/300], Step [11/29], Loss: 1.3287\n",
      "Epoch [294/300], Step [12/29], Loss: 1.2674\n",
      "Epoch [294/300], Step [13/29], Loss: 1.4073\n",
      "Epoch [294/300], Step [14/29], Loss: 1.2184\n",
      "Epoch [294/300], Step [15/29], Loss: 1.4646\n",
      "Epoch [294/300], Step [16/29], Loss: 1.1637\n",
      "Epoch [294/300], Step [17/29], Loss: 1.2814\n",
      "Epoch [294/300], Step [18/29], Loss: 1.1342\n",
      "Epoch [294/300], Step [19/29], Loss: 1.6126\n",
      "Epoch [294/300], Step [20/29], Loss: 1.0584\n",
      "Epoch [294/300], Step [21/29], Loss: 1.4115\n",
      "Epoch [294/300], Step [22/29], Loss: 1.1750\n",
      "Epoch [294/300], Step [23/29], Loss: 1.4055\n",
      "Epoch [294/300], Step [24/29], Loss: 1.2372\n",
      "Epoch [294/300], Step [25/29], Loss: 1.3821\n",
      "Epoch [294/300], Step [26/29], Loss: 1.2712\n",
      "Epoch [294/300], Step [27/29], Loss: 1.2296\n",
      "Epoch [294/300], Step [28/29], Loss: 1.2960\n",
      "Epoch [294/300], Step [29/29], Loss: 2.3990\n",
      "Epoch [295/300], Step [1/29], Loss: 1.3970\n",
      "Epoch [295/300], Step [2/29], Loss: 1.2472\n",
      "Epoch [295/300], Step [3/29], Loss: 1.3830\n",
      "Epoch [295/300], Step [4/29], Loss: 1.2630\n",
      "Epoch [295/300], Step [5/29], Loss: 1.0877\n",
      "Epoch [295/300], Step [6/29], Loss: 1.5449\n",
      "Epoch [295/300], Step [7/29], Loss: 1.2929\n",
      "Epoch [295/300], Step [8/29], Loss: 1.1183\n",
      "Epoch [295/300], Step [9/29], Loss: 1.1033\n",
      "Epoch [295/300], Step [10/29], Loss: 1.1248\n",
      "Epoch [295/300], Step [11/29], Loss: 1.4261\n",
      "Epoch [295/300], Step [12/29], Loss: 1.2592\n",
      "Epoch [295/300], Step [13/29], Loss: 1.2265\n",
      "Epoch [295/300], Step [14/29], Loss: 1.1877\n",
      "Epoch [295/300], Step [15/29], Loss: 1.4447\n",
      "Epoch [295/300], Step [16/29], Loss: 1.3002\n",
      "Epoch [295/300], Step [17/29], Loss: 1.1126\n",
      "Epoch [295/300], Step [18/29], Loss: 1.4071\n",
      "Epoch [295/300], Step [19/29], Loss: 1.2282\n",
      "Epoch [295/300], Step [20/29], Loss: 1.2975\n",
      "Epoch [295/300], Step [21/29], Loss: 1.5646\n",
      "Epoch [295/300], Step [22/29], Loss: 1.3648\n",
      "Epoch [295/300], Step [23/29], Loss: 1.3166\n",
      "Epoch [295/300], Step [24/29], Loss: 1.2217\n",
      "Epoch [295/300], Step [25/29], Loss: 1.3900\n",
      "Epoch [295/300], Step [26/29], Loss: 1.1922\n",
      "Epoch [295/300], Step [27/29], Loss: 1.2429\n",
      "Epoch [295/300], Step [28/29], Loss: 1.2164\n",
      "Epoch [295/300], Step [29/29], Loss: 2.3418\n",
      "Epoch [296/300], Step [1/29], Loss: 1.5464\n",
      "Epoch [296/300], Step [2/29], Loss: 1.2954\n",
      "Epoch [296/300], Step [3/29], Loss: 1.4337\n",
      "Epoch [296/300], Step [4/29], Loss: 1.2653\n",
      "Epoch [296/300], Step [5/29], Loss: 1.4158\n",
      "Epoch [296/300], Step [6/29], Loss: 1.3724\n",
      "Epoch [296/300], Step [7/29], Loss: 1.0973\n",
      "Epoch [296/300], Step [8/29], Loss: 1.1197\n",
      "Epoch [296/300], Step [9/29], Loss: 1.3017\n",
      "Epoch [296/300], Step [10/29], Loss: 0.9861\n",
      "Epoch [296/300], Step [11/29], Loss: 1.0983\n",
      "Epoch [296/300], Step [12/29], Loss: 1.2587\n",
      "Epoch [296/300], Step [13/29], Loss: 1.2755\n",
      "Epoch [296/300], Step [14/29], Loss: 1.3776\n",
      "Epoch [296/300], Step [15/29], Loss: 1.4527\n",
      "Epoch [296/300], Step [16/29], Loss: 1.4203\n",
      "Epoch [296/300], Step [17/29], Loss: 1.5870\n",
      "Epoch [296/300], Step [18/29], Loss: 1.3998\n",
      "Epoch [296/300], Step [19/29], Loss: 0.9770\n",
      "Epoch [296/300], Step [20/29], Loss: 1.1770\n",
      "Epoch [296/300], Step [21/29], Loss: 1.3506\n",
      "Epoch [296/300], Step [22/29], Loss: 1.3217\n",
      "Epoch [296/300], Step [23/29], Loss: 1.4366\n",
      "Epoch [296/300], Step [24/29], Loss: 1.1877\n",
      "Epoch [296/300], Step [25/29], Loss: 1.4251\n",
      "Epoch [296/300], Step [26/29], Loss: 1.1938\n",
      "Epoch [296/300], Step [27/29], Loss: 1.4162\n",
      "Epoch [296/300], Step [28/29], Loss: 1.5232\n",
      "Epoch [296/300], Step [29/29], Loss: 1.2326\n",
      "Epoch [297/300], Step [1/29], Loss: 1.2434\n",
      "Epoch [297/300], Step [2/29], Loss: 1.1521\n",
      "Epoch [297/300], Step [3/29], Loss: 1.3101\n",
      "Epoch [297/300], Step [4/29], Loss: 1.3662\n",
      "Epoch [297/300], Step [5/29], Loss: 1.2693\n",
      "Epoch [297/300], Step [6/29], Loss: 1.1092\n",
      "Epoch [297/300], Step [7/29], Loss: 1.3382\n",
      "Epoch [297/300], Step [8/29], Loss: 1.3395\n",
      "Epoch [297/300], Step [9/29], Loss: 1.2438\n",
      "Epoch [297/300], Step [10/29], Loss: 1.1840\n",
      "Epoch [297/300], Step [11/29], Loss: 1.3714\n",
      "Epoch [297/300], Step [12/29], Loss: 1.4790\n",
      "Epoch [297/300], Step [13/29], Loss: 1.1552\n",
      "Epoch [297/300], Step [14/29], Loss: 1.1020\n",
      "Epoch [297/300], Step [15/29], Loss: 1.5197\n",
      "Epoch [297/300], Step [16/29], Loss: 1.4188\n",
      "Epoch [297/300], Step [17/29], Loss: 1.5768\n",
      "Epoch [297/300], Step [18/29], Loss: 1.6548\n",
      "Epoch [297/300], Step [19/29], Loss: 1.3575\n",
      "Epoch [297/300], Step [20/29], Loss: 1.2032\n",
      "Epoch [297/300], Step [21/29], Loss: 1.1845\n",
      "Epoch [297/300], Step [22/29], Loss: 1.0713\n",
      "Epoch [297/300], Step [23/29], Loss: 1.2929\n",
      "Epoch [297/300], Step [24/29], Loss: 1.4267\n",
      "Epoch [297/300], Step [25/29], Loss: 1.2977\n",
      "Epoch [297/300], Step [26/29], Loss: 0.9210\n",
      "Epoch [297/300], Step [27/29], Loss: 1.1919\n",
      "Epoch [297/300], Step [28/29], Loss: 1.5027\n",
      "Epoch [297/300], Step [29/29], Loss: 1.1438\n",
      "Epoch [298/300], Step [1/29], Loss: 1.1344\n",
      "Epoch [298/300], Step [2/29], Loss: 1.3637\n",
      "Epoch [298/300], Step [3/29], Loss: 1.1991\n",
      "Epoch [298/300], Step [4/29], Loss: 1.3128\n",
      "Epoch [298/300], Step [5/29], Loss: 1.4493\n",
      "Epoch [298/300], Step [6/29], Loss: 1.2059\n",
      "Epoch [298/300], Step [7/29], Loss: 1.4523\n",
      "Epoch [298/300], Step [8/29], Loss: 1.4750\n",
      "Epoch [298/300], Step [9/29], Loss: 1.1964\n",
      "Epoch [298/300], Step [10/29], Loss: 1.3517\n",
      "Epoch [298/300], Step [11/29], Loss: 1.3092\n",
      "Epoch [298/300], Step [12/29], Loss: 1.4282\n",
      "Epoch [298/300], Step [13/29], Loss: 1.0957\n",
      "Epoch [298/300], Step [14/29], Loss: 1.3526\n",
      "Epoch [298/300], Step [15/29], Loss: 1.1200\n",
      "Epoch [298/300], Step [16/29], Loss: 1.1295\n",
      "Epoch [298/300], Step [17/29], Loss: 1.3635\n",
      "Epoch [298/300], Step [18/29], Loss: 1.3029\n",
      "Epoch [298/300], Step [19/29], Loss: 1.0806\n",
      "Epoch [298/300], Step [20/29], Loss: 1.3215\n",
      "Epoch [298/300], Step [21/29], Loss: 1.1871\n",
      "Epoch [298/300], Step [22/29], Loss: 1.3628\n",
      "Epoch [298/300], Step [23/29], Loss: 1.3097\n",
      "Epoch [298/300], Step [24/29], Loss: 0.9809\n",
      "Epoch [298/300], Step [25/29], Loss: 1.7485\n",
      "Epoch [298/300], Step [26/29], Loss: 1.3549\n",
      "Epoch [298/300], Step [27/29], Loss: 1.2071\n",
      "Epoch [298/300], Step [28/29], Loss: 1.5916\n",
      "Epoch [298/300], Step [29/29], Loss: 1.7307\n",
      "Epoch [299/300], Step [1/29], Loss: 1.3606\n",
      "Epoch [299/300], Step [2/29], Loss: 1.2490\n",
      "Epoch [299/300], Step [3/29], Loss: 1.3015\n",
      "Epoch [299/300], Step [4/29], Loss: 1.1576\n",
      "Epoch [299/300], Step [5/29], Loss: 1.3378\n",
      "Epoch [299/300], Step [6/29], Loss: 1.3736\n",
      "Epoch [299/300], Step [7/29], Loss: 1.0757\n",
      "Epoch [299/300], Step [8/29], Loss: 1.2499\n",
      "Epoch [299/300], Step [9/29], Loss: 1.3146\n",
      "Epoch [299/300], Step [10/29], Loss: 1.3203\n",
      "Epoch [299/300], Step [11/29], Loss: 1.3808\n",
      "Epoch [299/300], Step [12/29], Loss: 1.3730\n",
      "Epoch [299/300], Step [13/29], Loss: 1.3359\n",
      "Epoch [299/300], Step [14/29], Loss: 1.3545\n",
      "Epoch [299/300], Step [15/29], Loss: 1.2609\n",
      "Epoch [299/300], Step [16/29], Loss: 1.2401\n",
      "Epoch [299/300], Step [17/29], Loss: 1.6071\n",
      "Epoch [299/300], Step [18/29], Loss: 1.1600\n",
      "Epoch [299/300], Step [19/29], Loss: 1.5347\n",
      "Epoch [299/300], Step [20/29], Loss: 1.1641\n",
      "Epoch [299/300], Step [21/29], Loss: 1.1896\n",
      "Epoch [299/300], Step [22/29], Loss: 1.4290\n",
      "Epoch [299/300], Step [23/29], Loss: 1.2638\n",
      "Epoch [299/300], Step [24/29], Loss: 1.2682\n",
      "Epoch [299/300], Step [25/29], Loss: 1.3530\n",
      "Epoch [299/300], Step [26/29], Loss: 1.0279\n",
      "Epoch [299/300], Step [27/29], Loss: 1.3550\n",
      "Epoch [299/300], Step [28/29], Loss: 1.4437\n",
      "Epoch [299/300], Step [29/29], Loss: 0.8113\n",
      "Epoch [300/300], Step [1/29], Loss: 1.5205\n",
      "Epoch [300/300], Step [2/29], Loss: 1.3408\n",
      "Epoch [300/300], Step [3/29], Loss: 1.2752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/300], Step [4/29], Loss: 1.3485\n",
      "Epoch [300/300], Step [5/29], Loss: 1.3684\n",
      "Epoch [300/300], Step [6/29], Loss: 1.1974\n",
      "Epoch [300/300], Step [7/29], Loss: 1.3383\n",
      "Epoch [300/300], Step [8/29], Loss: 1.4543\n",
      "Epoch [300/300], Step [9/29], Loss: 1.0958\n",
      "Epoch [300/300], Step [10/29], Loss: 1.2853\n",
      "Epoch [300/300], Step [11/29], Loss: 1.5974\n",
      "Epoch [300/300], Step [12/29], Loss: 1.2751\n",
      "Epoch [300/300], Step [13/29], Loss: 1.2881\n",
      "Epoch [300/300], Step [14/29], Loss: 1.1604\n",
      "Epoch [300/300], Step [15/29], Loss: 1.1988\n",
      "Epoch [300/300], Step [16/29], Loss: 1.1849\n",
      "Epoch [300/300], Step [17/29], Loss: 1.3092\n",
      "Epoch [300/300], Step [18/29], Loss: 1.0169\n",
      "Epoch [300/300], Step [19/29], Loss: 1.2670\n",
      "Epoch [300/300], Step [20/29], Loss: 1.0592\n",
      "Epoch [300/300], Step [21/29], Loss: 1.3509\n",
      "Epoch [300/300], Step [22/29], Loss: 1.1880\n",
      "Epoch [300/300], Step [23/29], Loss: 1.2673\n",
      "Epoch [300/300], Step [24/29], Loss: 1.0572\n",
      "Epoch [300/300], Step [25/29], Loss: 1.0525\n",
      "Epoch [300/300], Step [26/29], Loss: 1.6759\n",
      "Epoch [300/300], Step [27/29], Loss: 1.3547\n",
      "Epoch [300/300], Step [28/29], Loss: 1.4321\n",
      "Epoch [300/300], Step [29/29], Loss: 1.8205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Model(drop_rate=0.5).cuda()\n",
    "model.load_state_dict(torch.load(\"model_training.ckpt\"))\n",
    "\n",
    "# validation model\n",
    "x=[]\n",
    "y=[]\n",
    "total_step = len(validate_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels,_,hog_features) in enumerate(validate_loader):\n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "        hog_features=hog_features.cuda()\n",
    "\n",
    "        outputs = model(images,hog_features,len(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)       \n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "               .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        # Decay learning rate\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            curr_lr /= 2\n",
    "            update_lr(optimizer, curr_lr)\n",
    "            torch.save(model.state_dict(), 'model_validation.ckpt')\n",
    "    x.append(epoch)\n",
    "    y.append(loss.item())\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "    \n",
    "torch.save(model.state_dict(), 'model_validation.ckpt')\n",
    "del model, labels, hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 59.34800780161605 %\n"
     ]
    }
   ],
   "source": [
    "model=Model(drop_rate=1.0).cuda()\n",
    "model.load_state_dict(torch.load(\"model_validation.ckpt\"))\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels,_,hog_features in test_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        hog_features=hog_features.cuda()\n",
    "        outputs = model(images,hog_features,len(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#         print(labels.size(0))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "#         print(correct)    \n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "del model, images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
