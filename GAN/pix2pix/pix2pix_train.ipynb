{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import *\n",
    "from Pix2pix_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folders not created!\n",
      "folders not created!\n"
     ]
    }
   ],
   "source": [
    "saved_dir=\"../saved_data/pix2pix_facades/\"\n",
    "sample_dir=\"../samples/pix2pix_facades/\"\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    print(\"folders created!\")\n",
    "else:\n",
    "    print(\"folders not created!\")\n",
    "if not os.path.exists(saved_dir):\n",
    "    os.makedirs(saved_dir)\n",
    "    print(\"folders created!\")\n",
    "else:\n",
    "    print(\"folders not created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "n_epochs=201\n",
    "image_width=256\n",
    "learning_rate=2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "train_data=ImageDataset(root='D:/pix2pix_dataset/facades/train/',\n",
    "                        transform=transforms.ToTensor())\n",
    "train_loader=torch.utils.data.DataLoader(train_data,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator_model=Generator().cuda()\n",
    "discriminator_model=Discriminator().cuda()\n",
    "\n",
    "optimizer_G=torch.optim.Adam(generator_model.parameters(),lr=learning_rate)\n",
    "optimizer_D=torch.optim.Adam(discriminator_model.parameters(),lr=learning_rate)\n",
    "gen_loss=nn.MSELoss().cuda()\n",
    "l1_loss=nn.L1Loss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhs\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/201] [D loss: 0.065930] [G loss: 19.880947]\n",
      "[Epoch 1/201] [D loss: 0.022466] [G loss: 18.433662]\n",
      "[Epoch 2/201] [D loss: 0.009712] [G loss: 17.936781]\n",
      "[Epoch 3/201] [D loss: 0.008439] [G loss: 18.879578]\n",
      "[Epoch 4/201] [D loss: 0.005083] [G loss: 18.339052]\n",
      "[Epoch 5/201] [D loss: 0.004214] [G loss: 15.622816]\n",
      "[Epoch 6/201] [D loss: 0.004549] [G loss: 16.037148]\n",
      "[Epoch 7/201] [D loss: 0.004531] [G loss: 15.426266]\n",
      "[Epoch 8/201] [D loss: 0.007108] [G loss: 16.150074]\n",
      "[Epoch 9/201] [D loss: 0.002883] [G loss: 15.287408]\n",
      "[Epoch 10/201] [D loss: 0.004550] [G loss: 15.545678]\n",
      "[Epoch 11/201] [D loss: 0.003084] [G loss: 15.085279]\n",
      "[Epoch 12/201] [D loss: 0.002941] [G loss: 15.747424]\n",
      "[Epoch 13/201] [D loss: 0.003193] [G loss: 14.556160]\n",
      "[Epoch 14/201] [D loss: 0.002834] [G loss: 13.119689]\n",
      "[Epoch 15/201] [D loss: 0.002105] [G loss: 14.099004]\n",
      "[Epoch 16/201] [D loss: 0.003271] [G loss: 13.743205]\n",
      "[Epoch 17/201] [D loss: 0.001659] [G loss: 13.009998]\n",
      "[Epoch 18/201] [D loss: 0.001450] [G loss: 12.469189]\n",
      "[Epoch 19/201] [D loss: 0.001993] [G loss: 12.777672]\n",
      "[Epoch 20/201] [D loss: 0.003186] [G loss: 12.038877]\n",
      "[Epoch 21/201] [D loss: 0.001699] [G loss: 11.680230]\n",
      "[Epoch 22/201] [D loss: 0.001912] [G loss: 12.433329]\n",
      "[Epoch 23/201] [D loss: 0.001244] [G loss: 11.016227]\n",
      "[Epoch 24/201] [D loss: 0.001454] [G loss: 11.740814]\n",
      "[Epoch 25/201] [D loss: 0.001009] [G loss: 11.316932]\n",
      "[Epoch 26/201] [D loss: 0.001517] [G loss: 11.134878]\n",
      "[Epoch 27/201] [D loss: 0.001526] [G loss: 10.709995]\n",
      "[Epoch 28/201] [D loss: 0.000936] [G loss: 10.186511]\n",
      "[Epoch 29/201] [D loss: 0.000801] [G loss: 10.252049]\n",
      "[Epoch 30/201] [D loss: 0.001173] [G loss: 10.901339]\n",
      "[Epoch 31/201] [D loss: 0.002191] [G loss: 10.812521]\n",
      "[Epoch 32/201] [D loss: 0.000903] [G loss: 11.057935]\n",
      "[Epoch 33/201] [D loss: 0.001775] [G loss: 10.228935]\n",
      "[Epoch 34/201] [D loss: 0.001461] [G loss: 9.815533]\n",
      "[Epoch 35/201] [D loss: 0.001316] [G loss: 9.825583]\n",
      "[Epoch 36/201] [D loss: 0.000960] [G loss: 9.575697]\n",
      "[Epoch 37/201] [D loss: 0.001055] [G loss: 9.308843]\n",
      "[Epoch 38/201] [D loss: 0.000663] [G loss: 10.076736]\n",
      "[Epoch 39/201] [D loss: 0.001247] [G loss: 9.688008]\n",
      "[Epoch 40/201] [D loss: 0.000739] [G loss: 9.623336]\n",
      "[Epoch 41/201] [D loss: 0.000531] [G loss: 9.569277]\n",
      "[Epoch 42/201] [D loss: 0.000865] [G loss: 9.162870]\n",
      "[Epoch 43/201] [D loss: 0.001427] [G loss: 8.770449]\n",
      "[Epoch 44/201] [D loss: 0.001043] [G loss: 9.319142]\n",
      "[Epoch 45/201] [D loss: 0.000647] [G loss: 8.665302]\n",
      "[Epoch 46/201] [D loss: 0.001468] [G loss: 9.191182]\n",
      "[Epoch 47/201] [D loss: 0.000656] [G loss: 8.562408]\n",
      "[Epoch 48/201] [D loss: 0.000913] [G loss: 8.800003]\n",
      "[Epoch 49/201] [D loss: 0.000450] [G loss: 8.453851]\n",
      "[Epoch 50/201] [D loss: 0.001066] [G loss: 8.763428]\n",
      "[Epoch 51/201] [D loss: 0.000632] [G loss: 8.450058]\n",
      "[Epoch 52/201] [D loss: 0.000775] [G loss: 8.347015]\n",
      "[Epoch 53/201] [D loss: 0.000525] [G loss: 8.170414]\n",
      "[Epoch 54/201] [D loss: 0.000488] [G loss: 7.941939]\n",
      "[Epoch 55/201] [D loss: 0.000669] [G loss: 7.978124]\n",
      "[Epoch 56/201] [D loss: 0.000520] [G loss: 7.954578]\n",
      "[Epoch 57/201] [D loss: 0.000559] [G loss: 7.903499]\n",
      "[Epoch 58/201] [D loss: 0.000449] [G loss: 7.601370]\n",
      "[Epoch 59/201] [D loss: 0.000993] [G loss: 7.647092]\n",
      "[Epoch 60/201] [D loss: 0.000821] [G loss: 7.062118]\n",
      "[Epoch 61/201] [D loss: 0.000575] [G loss: 7.734131]\n",
      "[Epoch 62/201] [D loss: 0.002433] [G loss: 7.560827]\n",
      "[Epoch 63/201] [D loss: 0.000839] [G loss: 7.724440]\n",
      "[Epoch 64/201] [D loss: 0.000518] [G loss: 7.240267]\n",
      "[Epoch 65/201] [D loss: 0.000874] [G loss: 7.327235]\n",
      "[Epoch 66/201] [D loss: 0.001268] [G loss: 7.596858]\n",
      "[Epoch 67/201] [D loss: 0.000621] [G loss: 7.066314]\n",
      "[Epoch 68/201] [D loss: 0.000390] [G loss: 7.195707]\n",
      "[Epoch 69/201] [D loss: 0.000643] [G loss: 6.635018]\n",
      "[Epoch 70/201] [D loss: 0.000570] [G loss: 7.390999]\n",
      "[Epoch 71/201] [D loss: 0.000272] [G loss: 7.105937]\n",
      "[Epoch 72/201] [D loss: 0.000359] [G loss: 6.843580]\n",
      "[Epoch 73/201] [D loss: 0.000563] [G loss: 6.860757]\n",
      "[Epoch 74/201] [D loss: 0.000507] [G loss: 7.200741]\n",
      "[Epoch 75/201] [D loss: 0.000572] [G loss: 6.809988]\n",
      "[Epoch 76/201] [D loss: 0.000284] [G loss: 6.757213]\n",
      "[Epoch 77/201] [D loss: 0.000613] [G loss: 6.396735]\n",
      "[Epoch 78/201] [D loss: 0.000839] [G loss: 6.764327]\n",
      "[Epoch 79/201] [D loss: 0.000531] [G loss: 7.505856]\n",
      "[Epoch 80/201] [D loss: 0.000692] [G loss: 6.332222]\n",
      "[Epoch 81/201] [D loss: 0.000239] [G loss: 6.507266]\n",
      "[Epoch 82/201] [D loss: 0.000406] [G loss: 6.817733]\n",
      "[Epoch 83/201] [D loss: 0.000273] [G loss: 6.844282]\n",
      "[Epoch 84/201] [D loss: 0.000340] [G loss: 6.456994]\n",
      "[Epoch 85/201] [D loss: 0.000417] [G loss: 6.563886]\n",
      "[Epoch 86/201] [D loss: 0.000938] [G loss: 6.598155]\n",
      "[Epoch 87/201] [D loss: 0.000426] [G loss: 6.517503]\n",
      "[Epoch 88/201] [D loss: 0.000574] [G loss: 6.956014]\n",
      "[Epoch 89/201] [D loss: 0.000490] [G loss: 6.202933]\n",
      "[Epoch 90/201] [D loss: 0.000588] [G loss: 6.615933]\n",
      "[Epoch 91/201] [D loss: 0.000274] [G loss: 6.381052]\n",
      "[Epoch 92/201] [D loss: 0.000578] [G loss: 7.248441]\n",
      "[Epoch 93/201] [D loss: 0.000384] [G loss: 6.575170]\n",
      "[Epoch 94/201] [D loss: 0.000424] [G loss: 6.405967]\n",
      "[Epoch 95/201] [D loss: 0.000857] [G loss: 6.543790]\n",
      "[Epoch 96/201] [D loss: 0.000307] [G loss: 6.427364]\n",
      "[Epoch 97/201] [D loss: 0.000771] [G loss: 6.576163]\n",
      "[Epoch 98/201] [D loss: 0.001247] [G loss: 6.560974]\n",
      "[Epoch 99/201] [D loss: 0.000629] [G loss: 6.262272]\n",
      "[Epoch 100/201] [D loss: 0.000506] [G loss: 6.068647]\n",
      "[Epoch 101/201] [D loss: 0.000281] [G loss: 5.563966]\n",
      "[Epoch 102/201] [D loss: 0.000375] [G loss: 6.165087]\n",
      "[Epoch 103/201] [D loss: 0.000932] [G loss: 6.248281]\n",
      "[Epoch 104/201] [D loss: 0.000308] [G loss: 5.838785]\n",
      "[Epoch 105/201] [D loss: 0.000882] [G loss: 6.495760]\n",
      "[Epoch 106/201] [D loss: 0.000330] [G loss: 5.760276]\n",
      "[Epoch 107/201] [D loss: 0.000365] [G loss: 5.740797]\n",
      "[Epoch 108/201] [D loss: 0.000338] [G loss: 6.136786]\n",
      "[Epoch 109/201] [D loss: 0.000215] [G loss: 6.059631]\n",
      "[Epoch 110/201] [D loss: 0.000327] [G loss: 6.083556]\n",
      "[Epoch 111/201] [D loss: 0.000164] [G loss: 5.707136]\n",
      "[Epoch 112/201] [D loss: 0.000864] [G loss: 6.498015]\n",
      "[Epoch 113/201] [D loss: 0.000497] [G loss: 5.701000]\n",
      "[Epoch 114/201] [D loss: 0.000380] [G loss: 6.026125]\n",
      "[Epoch 115/201] [D loss: 0.000656] [G loss: 5.915854]\n",
      "[Epoch 116/201] [D loss: 0.000218] [G loss: 5.841714]\n",
      "[Epoch 117/201] [D loss: 0.000392] [G loss: 6.118240]\n",
      "[Epoch 118/201] [D loss: 0.000435] [G loss: 5.508264]\n",
      "[Epoch 119/201] [D loss: 0.000360] [G loss: 5.688624]\n",
      "[Epoch 120/201] [D loss: 0.000340] [G loss: 5.635560]\n",
      "[Epoch 121/201] [D loss: 0.000190] [G loss: 5.936173]\n",
      "[Epoch 122/201] [D loss: 0.000257] [G loss: 6.089544]\n",
      "[Epoch 123/201] [D loss: 0.000516] [G loss: 5.692883]\n",
      "[Epoch 124/201] [D loss: 0.000491] [G loss: 5.993321]\n",
      "[Epoch 125/201] [D loss: 0.000624] [G loss: 5.537354]\n",
      "[Epoch 126/201] [D loss: 0.000226] [G loss: 5.540372]\n",
      "[Epoch 127/201] [D loss: 0.000293] [G loss: 5.559420]\n",
      "[Epoch 128/201] [D loss: 0.000907] [G loss: 5.206552]\n",
      "[Epoch 129/201] [D loss: 0.000163] [G loss: 5.448972]\n",
      "[Epoch 130/201] [D loss: 0.000381] [G loss: 5.311358]\n",
      "[Epoch 131/201] [D loss: 0.000223] [G loss: 5.407107]\n",
      "[Epoch 132/201] [D loss: 0.000459] [G loss: 5.349039]\n",
      "[Epoch 133/201] [D loss: 0.001304] [G loss: 5.388079]\n",
      "[Epoch 134/201] [D loss: 0.000257] [G loss: 5.687726]\n",
      "[Epoch 135/201] [D loss: 0.000452] [G loss: 5.232913]\n",
      "[Epoch 136/201] [D loss: 0.000401] [G loss: 5.590343]\n",
      "[Epoch 137/201] [D loss: 0.000279] [G loss: 5.687937]\n",
      "[Epoch 138/201] [D loss: 0.000135] [G loss: 5.586742]\n",
      "[Epoch 139/201] [D loss: 0.000154] [G loss: 5.275062]\n",
      "[Epoch 140/201] [D loss: 0.000439] [G loss: 5.506485]\n",
      "[Epoch 141/201] [D loss: 0.000182] [G loss: 5.108348]\n",
      "[Epoch 142/201] [D loss: 0.000236] [G loss: 4.921002]\n",
      "[Epoch 143/201] [D loss: 0.000164] [G loss: 5.083545]\n",
      "[Epoch 144/201] [D loss: 0.000284] [G loss: 5.322840]\n",
      "[Epoch 145/201] [D loss: 0.000793] [G loss: 5.225549]\n",
      "[Epoch 146/201] [D loss: 0.000227] [G loss: 4.919372]\n",
      "[Epoch 147/201] [D loss: 0.000273] [G loss: 5.210726]\n",
      "[Epoch 148/201] [D loss: 0.000217] [G loss: 5.262940]\n",
      "[Epoch 149/201] [D loss: 0.000199] [G loss: 5.198798]\n",
      "[Epoch 150/201] [D loss: 0.000265] [G loss: 5.157972]\n",
      "[Epoch 151/201] [D loss: 0.000360] [G loss: 5.371055]\n",
      "[Epoch 152/201] [D loss: 0.000110] [G loss: 5.452378]\n",
      "[Epoch 153/201] [D loss: 0.000283] [G loss: 5.601316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 154/201] [D loss: 0.000222] [G loss: 5.541589]\n",
      "[Epoch 155/201] [D loss: 0.000234] [G loss: 5.336924]\n",
      "[Epoch 156/201] [D loss: 0.000474] [G loss: 5.303771]\n",
      "[Epoch 157/201] [D loss: 0.000242] [G loss: 5.004519]\n",
      "[Epoch 158/201] [D loss: 0.000373] [G loss: 4.624597]\n",
      "[Epoch 159/201] [D loss: 0.000212] [G loss: 4.851966]\n",
      "[Epoch 160/201] [D loss: 0.000231] [G loss: 5.176715]\n",
      "[Epoch 161/201] [D loss: 0.000151] [G loss: 5.004280]\n",
      "[Epoch 162/201] [D loss: 0.000154] [G loss: 4.925781]\n",
      "[Epoch 163/201] [D loss: 0.000207] [G loss: 4.784417]\n",
      "[Epoch 164/201] [D loss: 0.000549] [G loss: 4.627234]\n",
      "[Epoch 165/201] [D loss: 0.000265] [G loss: 4.967001]\n",
      "[Epoch 166/201] [D loss: 0.000342] [G loss: 5.037655]\n",
      "[Epoch 167/201] [D loss: 0.000302] [G loss: 5.007478]\n",
      "[Epoch 168/201] [D loss: 0.000212] [G loss: 4.960209]\n",
      "[Epoch 169/201] [D loss: 0.000220] [G loss: 4.936253]\n",
      "[Epoch 170/201] [D loss: 0.000570] [G loss: 5.171854]\n",
      "[Epoch 171/201] [D loss: 0.000208] [G loss: 4.821294]\n",
      "[Epoch 172/201] [D loss: 0.000163] [G loss: 5.018471]\n",
      "[Epoch 173/201] [D loss: 0.000160] [G loss: 4.568255]\n",
      "[Epoch 174/201] [D loss: 0.000495] [G loss: 5.151310]\n",
      "[Epoch 175/201] [D loss: 0.000143] [G loss: 4.731598]\n",
      "[Epoch 176/201] [D loss: 0.000734] [G loss: 5.212299]\n",
      "[Epoch 177/201] [D loss: 0.000862] [G loss: 5.106959]\n",
      "[Epoch 178/201] [D loss: 0.000946] [G loss: 5.446062]\n",
      "[Epoch 179/201] [D loss: 0.000219] [G loss: 4.943772]\n",
      "[Epoch 180/201] [D loss: 0.000354] [G loss: 4.752460]\n",
      "[Epoch 181/201] [D loss: 0.000117] [G loss: 5.247169]\n",
      "[Epoch 182/201] [D loss: 0.000153] [G loss: 5.073172]\n",
      "[Epoch 183/201] [D loss: 0.000276] [G loss: 4.605974]\n",
      "[Epoch 184/201] [D loss: 0.000159] [G loss: 4.731230]\n",
      "[Epoch 185/201] [D loss: 0.000226] [G loss: 4.975894]\n",
      "[Epoch 186/201] [D loss: 0.000224] [G loss: 4.978247]\n",
      "[Epoch 187/201] [D loss: 0.000215] [G loss: 4.760839]\n",
      "[Epoch 188/201] [D loss: 0.000291] [G loss: 4.449748]\n",
      "[Epoch 189/201] [D loss: 0.000294] [G loss: 4.985250]\n",
      "[Epoch 190/201] [D loss: 0.000121] [G loss: 4.478764]\n",
      "[Epoch 191/201] [D loss: 0.000084] [G loss: 4.568032]\n",
      "[Epoch 192/201] [D loss: 0.000221] [G loss: 4.426779]\n",
      "[Epoch 193/201] [D loss: 0.000185] [G loss: 4.456645]\n",
      "[Epoch 194/201] [D loss: 0.000373] [G loss: 4.859940]\n",
      "[Epoch 195/201] [D loss: 0.000111] [G loss: 4.523263]\n",
      "[Epoch 196/201] [D loss: 0.000307] [G loss: 4.682518]\n",
      "[Epoch 197/201] [D loss: 0.000153] [G loss: 4.915833]\n",
      "[Epoch 198/201] [D loss: 0.000153] [G loss: 4.448455]\n",
      "[Epoch 199/201] [D loss: 0.000118] [G loss: 4.699314]\n",
      "[Epoch 200/201] [D loss: 0.000527] [G loss: 4.646033]\n",
      "training finished! 1942 minutes\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "total_step=len(train_loader)\n",
    "for epochs in range(n_epochs):\n",
    "    for i ,image in enumerate(train_loader):\n",
    "        image_num=int(image['A'].shape[0])\n",
    "        y_image=image['A']\n",
    "        x_image=image['B']\n",
    "        \n",
    "        \n",
    "        true_label=torch.ones(image_num,1,8,8).cuda() \n",
    "        false_label=torch.zeros(image_num,1,8,8).cuda()\n",
    "\n",
    "\n",
    "        x_image=Variable(x_image).cuda()\n",
    "        y_image=Variable(y_image).cuda()\n",
    "        #------------------\n",
    "        #Generator training\n",
    "        #------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        gen_out=generator_model.forward(x_image)\n",
    "#         print(\"gen_out.shape : \",gen_out.shape,\"reshaped_x_image.shape:\",reshaped_x_image.shape)\n",
    "        gen_dis_out=discriminator_model(gen_out,x_image)\n",
    "\n",
    "#         print(\"gen_dis_out.shape : \",gen_dis_out.shape)\n",
    "        g_loss=gen_loss(gen_dis_out,true_label)\n",
    "        g_l1=l1_loss(gen_out,y_image)\n",
    "\n",
    "        loss_G=g_loss+g_l1*100\n",
    "#         loss_G=g_loss\n",
    "        loss_G.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "        #----------------------\n",
    "        #Discriminator training\n",
    "        #----------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        #d fake loss\n",
    "        dis_fake_out=discriminator_model.forward(gen_out,y_image)\n",
    "        d_fake_loss=gen_loss(dis_fake_out,false_label)\n",
    "\n",
    "        #d real loss\n",
    "        dis_real_out=discriminator_model.forward(x_image,y_image)\n",
    "        d_real_loss=gen_loss(dis_real_out,true_label)\n",
    "\n",
    "        loss_D=(d_fake_loss+d_real_loss)*0.5\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "#     if epochs==0:\n",
    "#         x_image.cpu()\n",
    "#         y_image.cpu()\n",
    "        \n",
    "#         xx=x_image.detach()\n",
    "#         yy=y_image.detach()\n",
    "        \n",
    "#         save_image(yy,\n",
    "#                    os.path.join(sample_dir,'true_Y_images.png'))\n",
    "#         save_image(xx,\n",
    "#                    os.path.join(sample_dir,'true_X_images.png'))\n",
    "    save_image(gen_out,os.path.join(\n",
    "        sample_dir,'fake_images-{}.png'.format(epochs+1)))\n",
    "    print (\"[Epoch %d/%d] [D loss: %f] [G loss: %f]\" % (epochs, n_epochs,\n",
    "                                                        loss_D.item(), loss_G.item()))\n",
    "    if(epochs%50==0):\n",
    "        # Save the model checkpoints\n",
    "        torch.save(generator_model.state_dict(), saved_dir +\n",
    "                   '/G_pix2pix_{}.ckpt'.format(epochs+1))\n",
    "        torch.save(discriminator_model.state_dict(), saved_dir +\n",
    "                   '/D_pix2pix_{}.ckpt'.format(epochs+1))\n",
    "finished = time.time()\n",
    "hours = finished-start\n",
    "print(\"training finished! %d minutes\" % hours)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
