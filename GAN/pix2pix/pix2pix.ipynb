{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import time\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folders created!\n",
      "folders created!\n"
     ]
    }
   ],
   "source": [
    "saved_dir=\"../saved_data/pix2pix_2/\"\n",
    "sample_dir=\"../samples/pix2pix_2/\"\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    print(\"folders created!\")\n",
    "else:\n",
    "    print(\"folders not created!\")\n",
    "if not os.path.exists(saved_dir):\n",
    "    os.makedirs(saved_dir)\n",
    "    print(\"folders created!\")\n",
    "else:\n",
    "    print(\"folders not created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "n_epochs=200\n",
    "image_width=80\n",
    "learning_rate=2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load imagedataset\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = glob.glob(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.root_dir)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.root_dir[idx]\n",
    "        image = io.imread(img_name)\n",
    "        sample = image\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    \n",
    "#train data load\n",
    "train_data=ImageDataset(root_dir=\"D:/pix2pix_dataset/cityscapes/train/*.jpg\",\n",
    "                                     transform=transforms.Compose([\n",
    "                                         transforms.ToPILImage(),\n",
    "                                         transforms.Resize((image_width,image_width*2)),\n",
    "                                         transforms.ToTensor()\n",
    "                                     ]))\n",
    "train_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image = io.imread(\"D:/pix2pix_dataset/cityscapes/train/1.jpg\")\n",
    "# width=image.shape[0]\n",
    "# x_image=image[:,0:width,:] # x_data\n",
    "# y_image=image[:,width:width*2,:]# y_data\n",
    "# print(\"image.shape : \",image.shape,\"\\nx_image.shape : \",x_image.shape,\n",
    "#       \"\\ny_image.shape : \",y_image.shape)\n",
    "# #reshaped x,y data\n",
    "# reshaped_x_image=x_image\n",
    "# reshaped_x_image=np.resize(reshaped_x_image,((image_width-44),(image_width-44),3))\n",
    "# reshaped_y_image=y_image\n",
    "# reshaped_y_image=np.resize(reshaped_y_image,((image_width-44),(image_width-44),3))\n",
    "# print(\"reshaped_x_image.shape : \",reshaped_x_image.shape,\"reshaped_y_image.shape : \",\n",
    "#      reshaped_y_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 80, 160])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    sample=train_data[i]\n",
    "    print(sample.shape)\n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generator_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_model(nn.Module):\n",
    "    def __init__(self,in_channel=3):\n",
    "        super(Unet_model,self).__init__()\n",
    "        self.down1=UNetDown(in_channel,64)\n",
    "        self.down2=UNetDown(64,128)\n",
    "        self.down3=UNetDown(128,256)\n",
    "        \n",
    "        self.max_pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.up1=UNetUp(256,128)\n",
    "        self.up1_cnn=UnetUpConv(256,128)\n",
    "        \n",
    "        self.up2=UNetUp(128,64)\n",
    "        self.up2_cnn=UnetUpConv(128,64)\n",
    "        \n",
    "        self.up3=UNetUp(64,32)\n",
    "        self.up3_cnn=UnetUpConv(64,32)\n",
    "        \n",
    "        self.final=UnetUpConv(64,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        o1=self.down1(x)\n",
    "        o1_max=self.max_pool(o1)\n",
    "        o2=self.down2(o1_max)\n",
    "        o2_max=self.max_pool(o2)\n",
    "        o3=self.down3(o2_max)\n",
    "        \n",
    "        u1=self.up1(o3) # 128 특징 가지고 있다.\n",
    "        u1_concat=center_crop_concat(o2,u1)\n",
    "        u1_conv=self.up1_cnn(u1_concat)\n",
    "        \n",
    "        u2=self.up2(u1_conv)\n",
    "        u2_concat=center_crop_concat(o1,u2)\n",
    "        u2_conv=self.up2_cnn(u2_concat)\n",
    "        \n",
    "        output=self.final(u2_conv)\n",
    "        \n",
    "#         print(\"************Unet down model************\")\n",
    "#         print(\"layer1 : \",o1.shape)\n",
    "#         print(\"layer2 : \",o2.shape)\n",
    "#         print(\"layer3 : \",o3.shape)   \n",
    "#         print(\"************Unet up model************\")\n",
    "#         print(\"layer2 : \",u1_conv.shape)\n",
    "#         print(\"layer1 : \",u2_conv.shape)\n",
    "#         print(\"final : \",output.shape)\n",
    "        return output \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_size=6,out_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_size, out_size, 3, 1, 0, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(out_size),\n",
    "                                    nn.Conv2d(out_size, out_size*2,\n",
    "                                              3, 1, 0, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(out_size*2),\n",
    "                                    \n",
    "                                    nn.Conv2d(out_size*2, out_size*4,\n",
    "                                              3, 1, 0, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(out_size*4),\n",
    "                                    nn.Conv2d(out_size*4, out_size*2,\n",
    "                                              3, 1, 0, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(out_size*2),\n",
    "                                    \n",
    "                                    nn.MaxPool2d(2, 2),\n",
    "                                    nn.Conv2d(out_size*2, 1,\n",
    "                                              3, 1, 0, bias=False)\n",
    "                                    )\n",
    "\n",
    "    def forward(self, x1,x2):\n",
    "#         print(x1.shape,x2.shape)\n",
    "        x_cat=torch.cat((x1,x2),1)\n",
    "#         print(\"x1.shape : \",x1.shape,\"x2.shape : \",x2.shape,\"cat.shape : \",x_cat.shape)\n",
    "        out = self.layer1(x_cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator_model=Unet_model().cuda()\n",
    "discriminator_model=Discriminator().cuda()\n",
    "\n",
    "optimizer_G=torch.optim.Adam(generator_model.parameters(),lr=learning_rate)\n",
    "optimizer_D=torch.optim.Adam(discriminator_model.parameters(),lr=learning_rate)\n",
    "gen_loss=nn.MSELoss()\n",
    "l1_loss=nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.utils.data.dataloader.DataLoader\n"
     ]
    }
   ],
   "source": [
    "print(torch.typename(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.048125] [G loss: 26.854290]\n",
      "[Epoch 1/200] [D loss: 0.092475] [G loss: 16.437357]\n",
      "[Epoch 2/200] [D loss: 0.024986] [G loss: 14.506286]\n",
      "[Epoch 3/200] [D loss: 0.015373] [G loss: 14.663190]\n",
      "[Epoch 4/200] [D loss: 0.015067] [G loss: 13.945982]\n",
      "[Epoch 5/200] [D loss: 0.013373] [G loss: 13.362953]\n",
      "[Epoch 6/200] [D loss: 0.008679] [G loss: 15.653759]\n",
      "[Epoch 7/200] [D loss: 0.009990] [G loss: 14.416258]\n",
      "[Epoch 8/200] [D loss: 0.007615] [G loss: 15.764406]\n",
      "[Epoch 9/200] [D loss: 0.007918] [G loss: 15.834070]\n",
      "[Epoch 10/200] [D loss: 0.008239] [G loss: 13.852053]\n",
      "[Epoch 11/200] [D loss: 0.007020] [G loss: 15.781377]\n",
      "[Epoch 12/200] [D loss: 0.006337] [G loss: 14.067452]\n",
      "[Epoch 13/200] [D loss: 0.005608] [G loss: 13.370281]\n",
      "[Epoch 14/200] [D loss: 0.006897] [G loss: 13.532378]\n",
      "[Epoch 15/200] [D loss: 0.004236] [G loss: 14.590778]\n",
      "[Epoch 16/200] [D loss: 0.008143] [G loss: 14.652566]\n",
      "[Epoch 17/200] [D loss: 0.007013] [G loss: 12.903384]\n",
      "[Epoch 18/200] [D loss: 0.010851] [G loss: 14.949742]\n",
      "[Epoch 19/200] [D loss: 0.006312] [G loss: 13.144223]\n",
      "[Epoch 20/200] [D loss: 0.003265] [G loss: 13.989729]\n",
      "[Epoch 21/200] [D loss: 0.003440] [G loss: 12.746697]\n",
      "[Epoch 22/200] [D loss: 0.002868] [G loss: 14.991156]\n",
      "[Epoch 23/200] [D loss: 0.002779] [G loss: 14.332442]\n",
      "[Epoch 24/200] [D loss: 0.002547] [G loss: 12.370455]\n",
      "[Epoch 25/200] [D loss: 0.002828] [G loss: 14.347859]\n",
      "[Epoch 26/200] [D loss: 0.002371] [G loss: 13.024787]\n",
      "[Epoch 27/200] [D loss: 0.002493] [G loss: 13.807639]\n",
      "[Epoch 28/200] [D loss: 0.002124] [G loss: 15.319170]\n",
      "[Epoch 29/200] [D loss: 0.002073] [G loss: 12.782215]\n",
      "[Epoch 30/200] [D loss: 0.002937] [G loss: 12.441308]\n",
      "[Epoch 31/200] [D loss: 0.002378] [G loss: 15.664469]\n",
      "[Epoch 32/200] [D loss: 0.004144] [G loss: 11.427808]\n",
      "[Epoch 33/200] [D loss: 0.002917] [G loss: 14.698199]\n",
      "[Epoch 34/200] [D loss: 0.002220] [G loss: 15.592193]\n",
      "[Epoch 35/200] [D loss: 0.001389] [G loss: 14.098081]\n",
      "[Epoch 36/200] [D loss: 0.003082] [G loss: 15.718471]\n",
      "[Epoch 37/200] [D loss: 0.001997] [G loss: 15.891748]\n",
      "[Epoch 38/200] [D loss: 0.001557] [G loss: 13.104454]\n",
      "[Epoch 39/200] [D loss: 0.001536] [G loss: 16.073086]\n",
      "[Epoch 40/200] [D loss: 0.001456] [G loss: 13.952158]\n",
      "[Epoch 41/200] [D loss: 0.001626] [G loss: 14.333001]\n",
      "[Epoch 42/200] [D loss: 0.001755] [G loss: 12.651892]\n",
      "[Epoch 43/200] [D loss: 0.001514] [G loss: 13.127847]\n",
      "[Epoch 44/200] [D loss: 0.001644] [G loss: 15.715336]\n",
      "[Epoch 45/200] [D loss: 0.002255] [G loss: 13.695183]\n",
      "[Epoch 46/200] [D loss: 0.001475] [G loss: 16.200029]\n",
      "[Epoch 47/200] [D loss: 0.001571] [G loss: 15.184417]\n",
      "[Epoch 48/200] [D loss: 0.001669] [G loss: 16.312477]\n",
      "[Epoch 49/200] [D loss: 0.001390] [G loss: 15.250010]\n",
      "[Epoch 50/200] [D loss: 0.002854] [G loss: 12.635225]\n",
      "[Epoch 51/200] [D loss: 0.001851] [G loss: 12.872548]\n",
      "[Epoch 52/200] [D loss: 0.004537] [G loss: 15.703684]\n",
      "[Epoch 53/200] [D loss: 0.001597] [G loss: 14.798553]\n",
      "[Epoch 54/200] [D loss: 0.002482] [G loss: 12.574643]\n",
      "[Epoch 55/200] [D loss: 0.001755] [G loss: 13.144028]\n",
      "[Epoch 56/200] [D loss: 0.002134] [G loss: 15.700360]\n",
      "[Epoch 57/200] [D loss: 0.001346] [G loss: 14.511157]\n",
      "[Epoch 58/200] [D loss: 0.001292] [G loss: 16.057899]\n",
      "[Epoch 59/200] [D loss: 0.000963] [G loss: 14.026279]\n",
      "[Epoch 60/200] [D loss: 0.001422] [G loss: 13.491944]\n",
      "[Epoch 61/200] [D loss: 0.001871] [G loss: 15.308814]\n",
      "[Epoch 62/200] [D loss: 0.001031] [G loss: 13.387086]\n",
      "[Epoch 63/200] [D loss: 0.001870] [G loss: 15.593848]\n",
      "[Epoch 64/200] [D loss: 0.000967] [G loss: 15.837705]\n",
      "[Epoch 65/200] [D loss: 0.001280] [G loss: 15.865577]\n",
      "[Epoch 66/200] [D loss: 0.001135] [G loss: 15.253654]\n",
      "[Epoch 67/200] [D loss: 0.000671] [G loss: 14.639610]\n",
      "[Epoch 68/200] [D loss: 0.002226] [G loss: 12.088470]\n",
      "[Epoch 69/200] [D loss: 0.001204] [G loss: 14.121633]\n",
      "[Epoch 70/200] [D loss: 0.000753] [G loss: 14.145493]\n",
      "[Epoch 71/200] [D loss: 0.004120] [G loss: 15.095449]\n",
      "[Epoch 72/200] [D loss: 0.002584] [G loss: 15.039701]\n",
      "[Epoch 73/200] [D loss: 0.001096] [G loss: 14.657172]\n",
      "[Epoch 74/200] [D loss: 0.000778] [G loss: 14.295104]\n",
      "[Epoch 75/200] [D loss: 0.001059] [G loss: 12.849854]\n",
      "[Epoch 76/200] [D loss: 0.000817] [G loss: 13.931602]\n",
      "[Epoch 77/200] [D loss: 0.000933] [G loss: 16.087818]\n",
      "[Epoch 78/200] [D loss: 0.000949] [G loss: 14.107522]\n",
      "[Epoch 79/200] [D loss: 0.000975] [G loss: 13.696987]\n",
      "[Epoch 80/200] [D loss: 0.001371] [G loss: 14.120220]\n",
      "[Epoch 81/200] [D loss: 0.000916] [G loss: 14.481302]\n",
      "[Epoch 82/200] [D loss: 0.001301] [G loss: 15.030719]\n",
      "[Epoch 83/200] [D loss: 0.001144] [G loss: 14.552896]\n",
      "[Epoch 84/200] [D loss: 0.000678] [G loss: 15.774843]\n",
      "[Epoch 85/200] [D loss: 0.001165] [G loss: 15.356399]\n",
      "[Epoch 86/200] [D loss: 0.000803] [G loss: 13.329343]\n",
      "[Epoch 87/200] [D loss: 0.000980] [G loss: 15.016742]\n",
      "[Epoch 88/200] [D loss: 0.000979] [G loss: 14.610567]\n",
      "[Epoch 89/200] [D loss: 0.000792] [G loss: 14.945787]\n",
      "[Epoch 90/200] [D loss: 0.000773] [G loss: 13.300793]\n",
      "[Epoch 91/200] [D loss: 0.000768] [G loss: 13.809266]\n",
      "[Epoch 92/200] [D loss: 0.000924] [G loss: 17.337049]\n",
      "[Epoch 93/200] [D loss: 0.000646] [G loss: 14.628075]\n",
      "[Epoch 94/200] [D loss: 0.000701] [G loss: 15.665705]\n",
      "[Epoch 95/200] [D loss: 0.000986] [G loss: 15.954346]\n",
      "[Epoch 96/200] [D loss: 0.000802] [G loss: 14.701027]\n",
      "[Epoch 97/200] [D loss: 0.000629] [G loss: 12.300863]\n",
      "[Epoch 98/200] [D loss: 0.000745] [G loss: 12.529501]\n",
      "[Epoch 99/200] [D loss: 0.000618] [G loss: 14.594636]\n",
      "[Epoch 100/200] [D loss: 0.000545] [G loss: 15.491505]\n",
      "[Epoch 101/200] [D loss: 0.001044] [G loss: 14.862574]\n",
      "[Epoch 102/200] [D loss: 0.001012] [G loss: 15.001127]\n",
      "[Epoch 103/200] [D loss: 0.000721] [G loss: 14.634753]\n",
      "[Epoch 104/200] [D loss: 0.000407] [G loss: 12.387094]\n",
      "[Epoch 105/200] [D loss: 0.000725] [G loss: 14.187465]\n",
      "[Epoch 106/200] [D loss: 0.001005] [G loss: 13.573315]\n",
      "[Epoch 107/200] [D loss: 0.000756] [G loss: 14.569175]\n",
      "[Epoch 108/200] [D loss: 0.000405] [G loss: 15.475184]\n",
      "[Epoch 109/200] [D loss: 0.000771] [G loss: 14.327866]\n",
      "[Epoch 110/200] [D loss: 0.000665] [G loss: 15.398967]\n",
      "[Epoch 111/200] [D loss: 0.000789] [G loss: 14.509840]\n",
      "[Epoch 112/200] [D loss: 0.000709] [G loss: 14.036806]\n",
      "[Epoch 113/200] [D loss: 0.001406] [G loss: 14.435261]\n",
      "[Epoch 114/200] [D loss: 0.000649] [G loss: 15.047720]\n",
      "[Epoch 115/200] [D loss: 0.000983] [G loss: 14.902684]\n",
      "[Epoch 116/200] [D loss: 0.000603] [G loss: 13.254745]\n",
      "[Epoch 117/200] [D loss: 0.000587] [G loss: 12.918088]\n",
      "[Epoch 118/200] [D loss: 0.000967] [G loss: 13.401926]\n",
      "[Epoch 119/200] [D loss: 0.000820] [G loss: 15.980196]\n",
      "[Epoch 120/200] [D loss: 0.001230] [G loss: 15.326706]\n",
      "[Epoch 121/200] [D loss: 0.000623] [G loss: 15.248790]\n",
      "[Epoch 122/200] [D loss: 0.000679] [G loss: 13.101797]\n",
      "[Epoch 123/200] [D loss: 0.000865] [G loss: 13.882204]\n",
      "[Epoch 124/200] [D loss: 0.000907] [G loss: 13.985266]\n",
      "[Epoch 125/200] [D loss: 0.001673] [G loss: 13.893730]\n",
      "[Epoch 126/200] [D loss: 0.000729] [G loss: 14.348194]\n",
      "[Epoch 127/200] [D loss: 0.000662] [G loss: 14.636325]\n",
      "[Epoch 128/200] [D loss: 0.000694] [G loss: 14.623710]\n",
      "[Epoch 129/200] [D loss: 0.000304] [G loss: 14.246642]\n",
      "[Epoch 130/200] [D loss: 0.000428] [G loss: 14.707264]\n",
      "[Epoch 131/200] [D loss: 0.000532] [G loss: 13.515870]\n",
      "[Epoch 132/200] [D loss: 0.000930] [G loss: 14.433742]\n",
      "[Epoch 133/200] [D loss: 0.001081] [G loss: 12.633394]\n",
      "[Epoch 134/200] [D loss: 0.000654] [G loss: 13.432565]\n",
      "[Epoch 135/200] [D loss: 0.000621] [G loss: 12.373332]\n",
      "[Epoch 136/200] [D loss: 0.000370] [G loss: 14.009272]\n",
      "[Epoch 137/200] [D loss: 0.000792] [G loss: 13.389254]\n",
      "[Epoch 138/200] [D loss: 0.000775] [G loss: 14.650696]\n",
      "[Epoch 139/200] [D loss: 0.000968] [G loss: 11.435125]\n",
      "[Epoch 140/200] [D loss: 0.000556] [G loss: 14.455100]\n",
      "[Epoch 141/200] [D loss: 0.000280] [G loss: 14.189186]\n",
      "[Epoch 142/200] [D loss: 0.000619] [G loss: 14.386757]\n",
      "[Epoch 143/200] [D loss: 0.000516] [G loss: 13.538346]\n",
      "[Epoch 144/200] [D loss: 0.000585] [G loss: 12.383701]\n",
      "[Epoch 145/200] [D loss: 0.000469] [G loss: 13.557287]\n",
      "[Epoch 146/200] [D loss: 0.000454] [G loss: 13.507080]\n",
      "[Epoch 147/200] [D loss: 0.000453] [G loss: 13.658925]\n",
      "[Epoch 148/200] [D loss: 0.000481] [G loss: 14.650876]\n",
      "[Epoch 149/200] [D loss: 0.000473] [G loss: 14.704038]\n",
      "[Epoch 150/200] [D loss: 0.000409] [G loss: 15.237303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 151/200] [D loss: 0.000375] [G loss: 17.084087]\n",
      "[Epoch 152/200] [D loss: 0.000473] [G loss: 15.293009]\n",
      "[Epoch 153/200] [D loss: 0.000368] [G loss: 15.931844]\n",
      "[Epoch 154/200] [D loss: 0.000374] [G loss: 14.440784]\n",
      "[Epoch 155/200] [D loss: 0.000382] [G loss: 13.773494]\n",
      "[Epoch 156/200] [D loss: 0.000444] [G loss: 13.729418]\n",
      "[Epoch 157/200] [D loss: 0.000383] [G loss: 15.169604]\n",
      "[Epoch 158/200] [D loss: 0.000601] [G loss: 12.548455]\n",
      "[Epoch 159/200] [D loss: 0.000310] [G loss: 14.998318]\n",
      "[Epoch 160/200] [D loss: 0.000473] [G loss: 14.356856]\n",
      "[Epoch 161/200] [D loss: 0.000368] [G loss: 13.958835]\n",
      "[Epoch 162/200] [D loss: 0.000407] [G loss: 15.414515]\n",
      "[Epoch 163/200] [D loss: 0.000416] [G loss: 15.048975]\n",
      "[Epoch 164/200] [D loss: 0.000426] [G loss: 15.135411]\n",
      "[Epoch 165/200] [D loss: 0.000490] [G loss: 16.413946]\n",
      "[Epoch 166/200] [D loss: 0.000309] [G loss: 14.780694]\n",
      "[Epoch 167/200] [D loss: 0.000531] [G loss: 14.324646]\n",
      "[Epoch 168/200] [D loss: 0.000440] [G loss: 13.728860]\n",
      "[Epoch 169/200] [D loss: 0.000311] [G loss: 14.844792]\n",
      "[Epoch 170/200] [D loss: 0.000319] [G loss: 16.825392]\n",
      "[Epoch 171/200] [D loss: 0.000417] [G loss: 13.096153]\n",
      "[Epoch 172/200] [D loss: 0.000417] [G loss: 12.573416]\n",
      "[Epoch 173/200] [D loss: 0.000565] [G loss: 13.987321]\n",
      "[Epoch 174/200] [D loss: 0.000502] [G loss: 14.161094]\n",
      "[Epoch 175/200] [D loss: 0.000258] [G loss: 15.058629]\n",
      "[Epoch 176/200] [D loss: 0.000221] [G loss: 15.566919]\n",
      "[Epoch 177/200] [D loss: 0.000198] [G loss: 14.076574]\n",
      "[Epoch 178/200] [D loss: 0.000348] [G loss: 13.200710]\n",
      "[Epoch 179/200] [D loss: 0.000314] [G loss: 13.979374]\n",
      "[Epoch 180/200] [D loss: 0.000527] [G loss: 12.418368]\n",
      "[Epoch 181/200] [D loss: 0.000202] [G loss: 16.024946]\n",
      "[Epoch 182/200] [D loss: 0.000199] [G loss: 13.777713]\n",
      "[Epoch 183/200] [D loss: 0.000432] [G loss: 13.210059]\n",
      "[Epoch 184/200] [D loss: 0.000380] [G loss: 14.217358]\n",
      "[Epoch 185/200] [D loss: 0.000277] [G loss: 14.928163]\n",
      "[Epoch 186/200] [D loss: 0.000383] [G loss: 14.266533]\n",
      "[Epoch 187/200] [D loss: 0.000357] [G loss: 14.283139]\n",
      "[Epoch 188/200] [D loss: 0.000253] [G loss: 14.382875]\n",
      "[Epoch 189/200] [D loss: 0.000331] [G loss: 16.353537]\n",
      "[Epoch 190/200] [D loss: 0.000268] [G loss: 13.274766]\n",
      "[Epoch 191/200] [D loss: 0.000386] [G loss: 16.053801]\n",
      "[Epoch 192/200] [D loss: 0.000549] [G loss: 14.112035]\n",
      "[Epoch 193/200] [D loss: 0.000609] [G loss: 14.813685]\n",
      "[Epoch 194/200] [D loss: 0.000433] [G loss: 14.570024]\n",
      "[Epoch 195/200] [D loss: 0.000251] [G loss: 14.485817]\n",
      "[Epoch 196/200] [D loss: 0.000168] [G loss: 14.569755]\n",
      "[Epoch 197/200] [D loss: 0.000245] [G loss: 14.425820]\n",
      "[Epoch 198/200] [D loss: 0.000265] [G loss: 15.269695]\n",
      "[Epoch 199/200] [D loss: 0.000257] [G loss: 14.872488]\n",
      "training finished! 3011 minutes\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "total_step=len(train_loader)\n",
    "for epochs in range(n_epochs):\n",
    "    for i ,image in enumerate(train_loader):\n",
    "        image_num=int(len(image))\n",
    "#         print(\"image_num : \",image_num)\n",
    "        #image 분리\n",
    "        y_image=image[:,:,:,0:image_width] # x_data\n",
    "        x_image=image[:,:,:,image_width:image_width*2]# y_data\n",
    "\n",
    "        #reshaped x,y data\n",
    "        reshaped_x_image=torch.FloatTensor(image_num,3,1,1)\n",
    "    #     reshaped_x_image=Variable(reshaped_x_image)\n",
    "        reshaped_x_image.data.resize_(x_image.size()).copy_(x_image)\n",
    "        reshaped_x_image.data.resize_((image_num,3,(image_width-44),(image_width-44)))\n",
    "#         print(\"reshaped x shape : \",reshaped_x_image.shape)\n",
    "        reshaped_y_image=torch.FloatTensor(image_num,3,1,1)\n",
    "    #     reshaped_y_image=Variable(reshaped_y_image)\n",
    "        reshaped_y_image.data.resize_(y_image.size()).copy_(y_image)\n",
    "        reshaped_y_image.data.resize_((image_num,3,(image_width-44),(image_width-44)))\n",
    "#         print(\"reshaped_y shape : \",reshaped_y_image.shape)\n",
    "\n",
    "        true_label=torch.ones(image_num,1,12,12).cuda() \n",
    "        false_label=torch.zeros(image_num,1,12,12).cuda()\n",
    "\n",
    "\n",
    "        x_image=Variable(x_image).cuda()\n",
    "        y_image=Variable(y_image).cuda()\n",
    "        reshaped_x_image=Variable(reshaped_x_image).cuda()\n",
    "        reshaped_y_image=Variable(reshaped_y_image).cuda()\n",
    "        #------------------\n",
    "        #Generator training\n",
    "        #------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        gen_out=generator_model.forward(x_image)\n",
    "#         print(\"gen_out.shape : \",gen_out.shape,\"reshaped_x_image.shape:\",reshaped_x_image.shape)\n",
    "        gen_dis_out=discriminator_model(gen_out,reshaped_x_image)\n",
    "\n",
    "#         print(\"gen_dis_out.shape : \",gen_dis_out.shape)\n",
    "        g_loss=gen_loss(gen_dis_out,true_label)\n",
    "        g_l1=l1_loss(gen_out,reshaped_y_image)\n",
    "\n",
    "        loss_G=g_loss+g_l1*100\n",
    "\n",
    "        loss_G.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "        #----------------------\n",
    "        #Discriminator training\n",
    "        #----------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        #d fake loss\n",
    "        dis_fake_out=discriminator_model.forward(gen_out,reshaped_y_image)\n",
    "        d_fake_loss=gen_loss(dis_fake_out,false_label)\n",
    "\n",
    "        #d real loss\n",
    "        dis_real_out=discriminator_model.forward(reshaped_x_image,reshaped_y_image)\n",
    "        d_real_loss=gen_loss(dis_real_out,true_label)\n",
    "\n",
    "        loss_D=(d_fake_loss+d_real_loss)*0.5\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    save_image(gen_out,os.path.join(\n",
    "        sample_dir,'fake_images-{}.png'.format(epochs+1)))\n",
    "    print (\"[Epoch %d/%d] [D loss: %f] [G loss: %f]\" % (epochs, n_epochs,\n",
    "                                                        loss_D.item(), loss_G.item()))\n",
    "    if(epochs%50==0):\n",
    "        # Save the model checkpoints\n",
    "        torch.save(optimizer_G.state_dict(), saved_dir +\n",
    "                   '/G_pix2pix_{}.ckpt'.format(epochs+1))\n",
    "        torch.save(optimizer_D.state_dict(), saved_dir +\n",
    "                   '/D_pix2pix_{}.ckpt'.format(epochs+1))\n",
    "finished = time.time()\n",
    "hours = finished-start\n",
    "print(\"training finished! %d minutes\" % hours)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
