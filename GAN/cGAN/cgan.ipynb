{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folders not created!\n",
      "folders not created!\n"
     ]
    }
   ],
   "source": [
    "n_epochs=200\n",
    "batch_size=100\n",
    "lr=0.0002\n",
    "latent_size=128\n",
    "hidden_size=256\n",
    "n_classes=10\n",
    "img_size=28\n",
    "channels=1\n",
    "sample_dir = './samples/cgan/'\n",
    "saved_dir='./saved_data/cgan/'\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    print(\"folders created!\")\n",
    "else:\n",
    "    print(\"folders not created!\")\n",
    "if not os.path.exists(saved_dir):\n",
    "    os.makedirs(saved_dir)\n",
    "    print(\"folders created!\")\n",
    "else:\n",
    "    print(\"folders not created!\")\n",
    "#Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "# MNIST dataset (images and labels)\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transform,\n",
    "                                           download=True)\n",
    "\n",
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "def denorm(x):\n",
    "    out=(x+1)/2\n",
    "    return out.clamp(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(latent_size+10, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, img_size*img_size),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x,labels):\n",
    "#         print(\"x.shape : \",x.shape,\", labels.shape : \",labels.shape)\n",
    "        gen_input=torch.cat((x,labels),-1)\n",
    "#         print(\"gen_input.shape : \",gen_input.shape)\n",
    "        out = self.layer1(gen_input)\n",
    "        out=out.view(batch_size,-1,28,28)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(img_size*img_size+10, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        x=x.view(batch_size,-1)\n",
    "#         print(\"x.shape:\",x.shape,\"labels.shape : \",labels.shape)\n",
    "        dis_input=torch.cat((x,labels),-1)\n",
    "        out = self.layer1(dis_input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=Generator().cuda()\n",
    "discriminator=Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun=nn.BCELoss()\n",
    "d_optimizer=torch.optim.Adam(discriminator.parameters(),lr=lr)\n",
    "g_optimizer=torch.optim.Adam(generator.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.185662] [G loss: 2.077805]\n",
      "[Epoch 1/200] [D loss: 0.122951] [G loss: 1.906410]\n",
      "[Epoch 2/200] [D loss: 0.264744] [G loss: 2.089813]\n",
      "[Epoch 3/200] [D loss: 0.414117] [G loss: 1.553129]\n",
      "[Epoch 4/200] [D loss: 0.194032] [G loss: 3.497908]\n",
      "[Epoch 5/200] [D loss: 0.148088] [G loss: 2.855737]\n",
      "[Epoch 6/200] [D loss: 0.219789] [G loss: 2.454251]\n",
      "[Epoch 7/200] [D loss: 0.454168] [G loss: 1.734352]\n",
      "[Epoch 8/200] [D loss: 0.175178] [G loss: 3.392596]\n",
      "[Epoch 9/200] [D loss: 0.070911] [G loss: 3.957847]\n",
      "[Epoch 10/200] [D loss: 0.077189] [G loss: 3.348700]\n",
      "[Epoch 11/200] [D loss: 0.169894] [G loss: 4.327690]\n",
      "[Epoch 12/200] [D loss: 0.109357] [G loss: 3.486545]\n",
      "[Epoch 13/200] [D loss: 0.117750] [G loss: 5.352796]\n",
      "[Epoch 14/200] [D loss: 0.135896] [G loss: 3.581517]\n",
      "[Epoch 15/200] [D loss: 0.038170] [G loss: 4.653923]\n",
      "[Epoch 16/200] [D loss: 0.100294] [G loss: 3.034500]\n",
      "[Epoch 17/200] [D loss: 0.091170] [G loss: 3.887155]\n",
      "[Epoch 18/200] [D loss: 0.177643] [G loss: 4.012461]\n",
      "[Epoch 19/200] [D loss: 0.239359] [G loss: 4.142139]\n",
      "[Epoch 20/200] [D loss: 0.109763] [G loss: 3.444381]\n",
      "[Epoch 21/200] [D loss: 0.173313] [G loss: 2.405488]\n",
      "[Epoch 22/200] [D loss: 0.074540] [G loss: 4.934662]\n",
      "[Epoch 23/200] [D loss: 0.113593] [G loss: 4.080246]\n",
      "[Epoch 24/200] [D loss: 0.113538] [G loss: 3.741763]\n",
      "[Epoch 25/200] [D loss: 0.215080] [G loss: 2.476607]\n",
      "[Epoch 26/200] [D loss: 0.134155] [G loss: 2.789655]\n",
      "[Epoch 27/200] [D loss: 0.170284] [G loss: 2.207576]\n",
      "[Epoch 28/200] [D loss: 0.168979] [G loss: 3.334196]\n",
      "[Epoch 29/200] [D loss: 0.219088] [G loss: 3.128777]\n",
      "[Epoch 30/200] [D loss: 0.217552] [G loss: 3.049234]\n",
      "[Epoch 31/200] [D loss: 0.163766] [G loss: 3.193816]\n",
      "[Epoch 32/200] [D loss: 0.304858] [G loss: 2.484440]\n",
      "[Epoch 33/200] [D loss: 0.171086] [G loss: 4.145532]\n",
      "[Epoch 34/200] [D loss: 0.246479] [G loss: 2.688961]\n",
      "[Epoch 35/200] [D loss: 0.226097] [G loss: 2.858815]\n",
      "[Epoch 36/200] [D loss: 0.274573] [G loss: 3.635514]\n",
      "[Epoch 37/200] [D loss: 0.269868] [G loss: 3.187178]\n",
      "[Epoch 38/200] [D loss: 0.183440] [G loss: 2.692569]\n",
      "[Epoch 39/200] [D loss: 0.212149] [G loss: 3.020279]\n",
      "[Epoch 40/200] [D loss: 0.304325] [G loss: 1.987725]\n",
      "[Epoch 41/200] [D loss: 0.243317] [G loss: 2.369978]\n",
      "[Epoch 42/200] [D loss: 0.261670] [G loss: 2.843122]\n",
      "[Epoch 43/200] [D loss: 0.248883] [G loss: 2.211792]\n",
      "[Epoch 44/200] [D loss: 0.261125] [G loss: 2.584710]\n",
      "[Epoch 45/200] [D loss: 0.344334] [G loss: 1.941419]\n",
      "[Epoch 46/200] [D loss: 0.175799] [G loss: 3.324349]\n",
      "[Epoch 47/200] [D loss: 0.257825] [G loss: 2.861380]\n",
      "[Epoch 48/200] [D loss: 0.389982] [G loss: 2.354152]\n",
      "[Epoch 49/200] [D loss: 0.311560] [G loss: 2.689255]\n",
      "[Epoch 50/200] [D loss: 0.317766] [G loss: 2.059917]\n",
      "[Epoch 51/200] [D loss: 0.319687] [G loss: 2.436800]\n",
      "[Epoch 52/200] [D loss: 0.293512] [G loss: 1.892576]\n",
      "[Epoch 53/200] [D loss: 0.312652] [G loss: 2.372090]\n",
      "[Epoch 54/200] [D loss: 0.371453] [G loss: 1.952522]\n",
      "[Epoch 55/200] [D loss: 0.252776] [G loss: 2.580537]\n",
      "[Epoch 56/200] [D loss: 0.379126] [G loss: 1.904766]\n",
      "[Epoch 57/200] [D loss: 0.483768] [G loss: 2.315504]\n",
      "[Epoch 58/200] [D loss: 0.496368] [G loss: 1.661036]\n",
      "[Epoch 59/200] [D loss: 0.310283] [G loss: 1.936525]\n",
      "[Epoch 60/200] [D loss: 0.289604] [G loss: 2.202678]\n",
      "[Epoch 61/200] [D loss: 0.462173] [G loss: 1.483814]\n",
      "[Epoch 62/200] [D loss: 0.360381] [G loss: 2.181438]\n",
      "[Epoch 63/200] [D loss: 0.337173] [G loss: 1.966732]\n",
      "[Epoch 64/200] [D loss: 0.529321] [G loss: 1.973738]\n",
      "[Epoch 65/200] [D loss: 0.369045] [G loss: 1.778197]\n",
      "[Epoch 66/200] [D loss: 0.330764] [G loss: 1.850326]\n",
      "[Epoch 67/200] [D loss: 0.466449] [G loss: 1.731904]\n",
      "[Epoch 68/200] [D loss: 0.492205] [G loss: 1.628199]\n",
      "[Epoch 69/200] [D loss: 0.349487] [G loss: 1.971484]\n",
      "[Epoch 70/200] [D loss: 0.516196] [G loss: 1.865458]\n",
      "[Epoch 71/200] [D loss: 0.356224] [G loss: 1.697432]\n",
      "[Epoch 72/200] [D loss: 0.475481] [G loss: 1.562954]\n",
      "[Epoch 73/200] [D loss: 0.466819] [G loss: 1.509010]\n",
      "[Epoch 74/200] [D loss: 0.350266] [G loss: 1.695913]\n",
      "[Epoch 75/200] [D loss: 0.465075] [G loss: 1.749724]\n",
      "[Epoch 76/200] [D loss: 0.558629] [G loss: 1.099544]\n",
      "[Epoch 77/200] [D loss: 0.550814] [G loss: 1.521672]\n",
      "[Epoch 78/200] [D loss: 0.567650] [G loss: 1.158287]\n",
      "[Epoch 79/200] [D loss: 0.425240] [G loss: 1.582797]\n",
      "[Epoch 80/200] [D loss: 0.412127] [G loss: 1.733978]\n",
      "[Epoch 81/200] [D loss: 0.460287] [G loss: 1.638127]\n",
      "[Epoch 82/200] [D loss: 0.525336] [G loss: 1.853506]\n",
      "[Epoch 83/200] [D loss: 0.376739] [G loss: 1.579863]\n",
      "[Epoch 84/200] [D loss: 0.665388] [G loss: 1.535329]\n",
      "[Epoch 85/200] [D loss: 0.551981] [G loss: 1.405995]\n",
      "[Epoch 86/200] [D loss: 0.414767] [G loss: 1.681116]\n",
      "[Epoch 87/200] [D loss: 0.470487] [G loss: 1.333943]\n",
      "[Epoch 88/200] [D loss: 0.449893] [G loss: 1.372697]\n",
      "[Epoch 89/200] [D loss: 0.570309] [G loss: 1.286172]\n",
      "[Epoch 90/200] [D loss: 0.420203] [G loss: 1.479161]\n",
      "[Epoch 91/200] [D loss: 0.589392] [G loss: 1.211972]\n",
      "[Epoch 92/200] [D loss: 0.475400] [G loss: 1.664203]\n",
      "[Epoch 93/200] [D loss: 0.546943] [G loss: 1.317790]\n",
      "[Epoch 94/200] [D loss: 0.410883] [G loss: 1.477026]\n",
      "[Epoch 95/200] [D loss: 0.567875] [G loss: 1.134946]\n",
      "[Epoch 96/200] [D loss: 0.531144] [G loss: 1.080259]\n",
      "[Epoch 97/200] [D loss: 0.520125] [G loss: 1.571661]\n",
      "[Epoch 98/200] [D loss: 0.428659] [G loss: 1.418331]\n",
      "[Epoch 99/200] [D loss: 0.476192] [G loss: 1.363006]\n",
      "[Epoch 100/200] [D loss: 0.527072] [G loss: 1.445319]\n",
      "[Epoch 101/200] [D loss: 0.528438] [G loss: 1.565085]\n",
      "[Epoch 102/200] [D loss: 0.523493] [G loss: 1.423329]\n",
      "[Epoch 103/200] [D loss: 0.461201] [G loss: 1.529713]\n",
      "[Epoch 104/200] [D loss: 0.549847] [G loss: 1.030980]\n",
      "[Epoch 105/200] [D loss: 0.546817] [G loss: 1.136996]\n",
      "[Epoch 106/200] [D loss: 0.534430] [G loss: 1.466555]\n",
      "[Epoch 107/200] [D loss: 0.516551] [G loss: 1.191637]\n",
      "[Epoch 108/200] [D loss: 0.452061] [G loss: 1.766030]\n",
      "[Epoch 109/200] [D loss: 0.478865] [G loss: 1.390488]\n",
      "[Epoch 110/200] [D loss: 0.471900] [G loss: 1.360534]\n",
      "[Epoch 111/200] [D loss: 0.502182] [G loss: 1.254691]\n",
      "[Epoch 112/200] [D loss: 0.519884] [G loss: 1.145389]\n",
      "[Epoch 113/200] [D loss: 0.609948] [G loss: 1.186840]\n",
      "[Epoch 114/200] [D loss: 0.606344] [G loss: 1.278326]\n",
      "[Epoch 115/200] [D loss: 0.494412] [G loss: 1.173954]\n",
      "[Epoch 116/200] [D loss: 0.465617] [G loss: 1.628241]\n",
      "[Epoch 117/200] [D loss: 0.530901] [G loss: 1.084850]\n",
      "[Epoch 118/200] [D loss: 0.539975] [G loss: 1.244461]\n",
      "[Epoch 119/200] [D loss: 0.522089] [G loss: 1.174072]\n",
      "[Epoch 120/200] [D loss: 0.496705] [G loss: 1.111848]\n",
      "[Epoch 121/200] [D loss: 0.598580] [G loss: 1.064798]\n",
      "[Epoch 122/200] [D loss: 0.706074] [G loss: 0.793962]\n",
      "[Epoch 123/200] [D loss: 0.430259] [G loss: 1.509137]\n",
      "[Epoch 124/200] [D loss: 0.555959] [G loss: 0.980879]\n",
      "[Epoch 125/200] [D loss: 0.627067] [G loss: 1.065087]\n",
      "[Epoch 126/200] [D loss: 0.516771] [G loss: 1.183282]\n",
      "[Epoch 127/200] [D loss: 0.530450] [G loss: 1.160984]\n",
      "[Epoch 128/200] [D loss: 0.580448] [G loss: 0.964097]\n",
      "[Epoch 129/200] [D loss: 0.600727] [G loss: 1.048454]\n",
      "[Epoch 130/200] [D loss: 0.509614] [G loss: 1.344291]\n",
      "[Epoch 131/200] [D loss: 0.479355] [G loss: 1.266590]\n",
      "[Epoch 132/200] [D loss: 0.657208] [G loss: 1.038660]\n",
      "[Epoch 133/200] [D loss: 0.482875] [G loss: 1.273791]\n",
      "[Epoch 134/200] [D loss: 0.497591] [G loss: 1.205819]\n",
      "[Epoch 135/200] [D loss: 0.525354] [G loss: 1.184490]\n",
      "[Epoch 136/200] [D loss: 0.539710] [G loss: 1.342407]\n",
      "[Epoch 137/200] [D loss: 0.465464] [G loss: 1.211150]\n",
      "[Epoch 138/200] [D loss: 0.436915] [G loss: 1.393339]\n",
      "[Epoch 139/200] [D loss: 0.704455] [G loss: 0.829144]\n",
      "[Epoch 140/200] [D loss: 0.590575] [G loss: 0.974274]\n",
      "[Epoch 141/200] [D loss: 0.453839] [G loss: 1.177168]\n",
      "[Epoch 142/200] [D loss: 0.561945] [G loss: 1.343135]\n",
      "[Epoch 143/200] [D loss: 0.465858] [G loss: 1.418497]\n",
      "[Epoch 144/200] [D loss: 0.491339] [G loss: 1.275841]\n",
      "[Epoch 145/200] [D loss: 0.518470] [G loss: 1.286392]\n",
      "[Epoch 146/200] [D loss: 0.555121] [G loss: 1.292580]\n",
      "[Epoch 147/200] [D loss: 0.562877] [G loss: 0.972198]\n",
      "[Epoch 148/200] [D loss: 0.538756] [G loss: 1.067834]\n",
      "[Epoch 149/200] [D loss: 0.526795] [G loss: 1.360859]\n",
      "[Epoch 150/200] [D loss: 0.671297] [G loss: 1.070800]\n",
      "[Epoch 151/200] [D loss: 0.537080] [G loss: 1.172539]\n",
      "[Epoch 152/200] [D loss: 0.493167] [G loss: 1.562252]\n",
      "[Epoch 153/200] [D loss: 0.505610] [G loss: 1.324994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 154/200] [D loss: 0.489371] [G loss: 1.241156]\n",
      "[Epoch 155/200] [D loss: 0.599540] [G loss: 0.902987]\n",
      "[Epoch 156/200] [D loss: 0.547441] [G loss: 1.068295]\n",
      "[Epoch 157/200] [D loss: 0.743011] [G loss: 0.911170]\n",
      "[Epoch 158/200] [D loss: 0.593401] [G loss: 1.153015]\n",
      "[Epoch 159/200] [D loss: 0.468596] [G loss: 1.253079]\n",
      "[Epoch 160/200] [D loss: 0.589373] [G loss: 1.159899]\n",
      "[Epoch 161/200] [D loss: 0.527665] [G loss: 1.091381]\n",
      "[Epoch 162/200] [D loss: 0.637500] [G loss: 1.146831]\n",
      "[Epoch 163/200] [D loss: 0.501745] [G loss: 1.135080]\n",
      "[Epoch 164/200] [D loss: 0.784317] [G loss: 1.034743]\n",
      "[Epoch 165/200] [D loss: 0.630397] [G loss: 0.995328]\n",
      "[Epoch 166/200] [D loss: 0.571397] [G loss: 0.910185]\n",
      "[Epoch 167/200] [D loss: 0.563520] [G loss: 1.047877]\n",
      "[Epoch 168/200] [D loss: 0.637534] [G loss: 0.992945]\n",
      "[Epoch 169/200] [D loss: 0.566276] [G loss: 1.124361]\n",
      "[Epoch 170/200] [D loss: 0.606888] [G loss: 0.931558]\n",
      "[Epoch 171/200] [D loss: 0.566181] [G loss: 1.094968]\n",
      "[Epoch 172/200] [D loss: 0.472251] [G loss: 1.184298]\n",
      "[Epoch 173/200] [D loss: 0.460824] [G loss: 1.295851]\n",
      "[Epoch 174/200] [D loss: 0.655240] [G loss: 1.010072]\n",
      "[Epoch 175/200] [D loss: 0.461466] [G loss: 1.166131]\n",
      "[Epoch 176/200] [D loss: 0.523013] [G loss: 1.134169]\n",
      "[Epoch 177/200] [D loss: 0.635549] [G loss: 1.009712]\n",
      "[Epoch 178/200] [D loss: 0.587042] [G loss: 1.258206]\n",
      "[Epoch 179/200] [D loss: 0.575342] [G loss: 0.977755]\n",
      "[Epoch 180/200] [D loss: 0.560870] [G loss: 1.041586]\n",
      "[Epoch 181/200] [D loss: 0.638606] [G loss: 0.906895]\n",
      "[Epoch 182/200] [D loss: 0.608844] [G loss: 1.238285]\n",
      "[Epoch 183/200] [D loss: 0.656024] [G loss: 0.998502]\n",
      "[Epoch 184/200] [D loss: 0.508657] [G loss: 1.218753]\n",
      "[Epoch 185/200] [D loss: 0.687331] [G loss: 1.074079]\n",
      "[Epoch 186/200] [D loss: 0.627058] [G loss: 1.102086]\n",
      "[Epoch 187/200] [D loss: 0.533467] [G loss: 1.025421]\n",
      "[Epoch 188/200] [D loss: 0.618244] [G loss: 0.991967]\n",
      "[Epoch 189/200] [D loss: 0.503775] [G loss: 1.113239]\n",
      "[Epoch 190/200] [D loss: 0.578780] [G loss: 1.193749]\n",
      "[Epoch 191/200] [D loss: 0.506315] [G loss: 1.106390]\n",
      "[Epoch 192/200] [D loss: 0.623473] [G loss: 1.026963]\n",
      "[Epoch 193/200] [D loss: 0.670895] [G loss: 0.922971]\n",
      "[Epoch 194/200] [D loss: 0.544635] [G loss: 1.047203]\n",
      "[Epoch 195/200] [D loss: 0.573415] [G loss: 1.106286]\n",
      "[Epoch 196/200] [D loss: 0.610418] [G loss: 1.046356]\n",
      "[Epoch 197/200] [D loss: 0.520613] [G loss: 1.204536]\n",
      "[Epoch 198/200] [D loss: 0.599396] [G loss: 0.836688]\n",
      "[Epoch 199/200] [D loss: 0.598763] [G loss: 0.973619]\n",
      "training finished! 2166 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# g_optimizer.load_state_dict(torch.load('./saved_data/cgan/G_cgan_151.ckpt'))\n",
    "# d_optimizer.load_state_dict(torch.load('./saved_data/cgan/D_cgan_151.ckpt'))\n",
    "total_step=len(train_loader)\n",
    "n_epochs=200\n",
    "for epochs in range(n_epochs):\n",
    "    for i,[images,labels] in enumerate(train_loader):\n",
    "        true_labels=torch.ones(batch_size,1).cuda()#true 마킹\n",
    "        false_labels=torch.zeros(batch_size,1).cuda()# false 마킹\n",
    "        #GT label 을 one hot label 로 변환\n",
    "        one_hot_labels = np.eye(n_classes)[labels]\n",
    "        one_hot_labels=np.int_(one_hot_labels)\n",
    "    #     print(\"one_hot_labels.shape : \",one_hot_labels.shape)\n",
    "\n",
    "        images=Variable(images).cuda()\n",
    "        one_hot_labels=torch.from_numpy(one_hot_labels)\n",
    "        one_hot_labels=one_hot_labels.type(torch.cuda.FloatTensor)\n",
    "        one_hot_labels=Variable(one_hot_labels).cuda()\n",
    "        #------------------------\n",
    "        #training generator phase\n",
    "        #------------------------\n",
    "        g_optimizer.zero_grad()\n",
    "        #noise 생성\n",
    "        z=Variable(torch.FloatTensor(torch.randn(batch_size,latent_size))).cuda()\n",
    "\n",
    "        #random gen label 생성\n",
    "        random_labels=np.random.randint(0, n_classes, batch_size)\n",
    "        gen_one_hot_labels = np.eye(n_classes)[random_labels]\n",
    "        gen_one_hot_labels=torch.from_numpy(gen_one_hot_labels)\n",
    "        gen_one_hot_labels=gen_one_hot_labels.type(torch.cuda.FloatTensor)\n",
    "        gen_one_hot_labels=Variable(gen_one_hot_labels).cuda()\n",
    "    #     print(\"z.type : \",torch.typename(z),\"gen_one_hot_labels.type : \",\n",
    "    #           torch.typename(gen_one_hot_labels))\n",
    "\n",
    "        generated_images=generator.forward(z,gen_one_hot_labels)\n",
    "#         print(\"generated_images.shape : \", generated_images.shape)\n",
    "        gen_valid=discriminator(generated_images,gen_one_hot_labels)\n",
    "\n",
    "        g_loss=loss_fun(gen_valid,true_labels)\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        g_optimizer.step()\n",
    "\n",
    "        #------------------------\n",
    "        #training discriminator phase\n",
    "        #------------------------    \n",
    "        d_optimizer.zero_grad()\n",
    "        real_valid=discriminator(images,one_hot_labels)\n",
    "        d_real_loss=loss_fun(real_valid,true_labels)\n",
    "\n",
    "        fake_valid=discriminator(generated_images,gen_one_hot_labels)\n",
    "        d_fake_loss=loss_fun(fake_valid,false_labels)\n",
    "\n",
    "        d_loss=(d_real_loss+d_fake_loss)/2\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "    print (\"[Epoch %d/%d] [D loss: %f] [G loss: %f]\" % (epochs, n_epochs,\n",
    "                                                            d_loss.item(), g_loss.item()))\n",
    "\n",
    "    save_image(generated_images, os.path.join(\n",
    "        sample_dir, 'fake_images-{}.png'.format(epochs+1)))\n",
    "    if(epochs%50==0):\n",
    "        # Save the model checkpoints\n",
    "        torch.save(g_optimizer.state_dict(), saved_dir +\n",
    "                   '/G_cgan_{}.ckpt'.format(epochs+1))\n",
    "        torch.save(d_optimizer.state_dict(), saved_dir +\n",
    "                   '/D_cgan_{}.ckpt'.format(epochs+1))\n",
    "finished = time.time()\n",
    "hours = finished-start\n",
    "print(\"training finished! %d minutes\" % hours)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #numpy one hot label\n",
    "# targets=np.random.randint(0, nb_classes, batch_size)\n",
    "\n",
    "# one_hot_targets = np.eye(n_classes)[targets]\n",
    "# int_one_hot=np.int_(one_hot_targets)\n",
    "# print(int_one_hot.shape)\n",
    "# tor_one_hot=Variable(torch.LongTensor(int_one_hot))\n",
    "# print(tor_one_hot.shape,tor_one_hot.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
